# Comparing `tmp/aesara-nightly-2.8.9.post118.tar.gz` & `tmp/aesara_nightly-2.9.0.post2.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "aesara-nightly-2.8.9.post118.tar", last modified: Wed Jan 18 20:56:56 2023, max compression
+gzip compressed data, last modified: Sun Feb  2 00:00:00 2020, max compression
```

## Comparing `aesara-nightly-2.8.9.post118.tar` & `aesara_nightly-2.9.0.post2.tar`

### file list

```diff
@@ -1,502 +1,608 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.757730 aesara-nightly-2.8.9.post118/
--rw-r--r--   0 runner    (1001) docker     (123)      809 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/DESCRIPTION.txt
--rw-r--r--   0 runner    (1001) docker     (123)     2515 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/LICENSE.txt
--rw-r--r--   0 runner    (1001) docker     (123)      260 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (123)     2206 2023-01-18 20:56:56.757730 aesara-nightly-2.8.9.post118/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     4112 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.701730 aesara-nightly-2.8.9.post118/aesara/
--rw-r--r--   0 runner    (1001) docker     (123)     5760 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      168 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara/_version.py
--rw-r--r--   0 runner    (1001) docker     (123)      252 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/assert_op.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.701730 aesara-nightly-2.8.9.post118/aesara/bin/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/bin/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4080 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/bin/aesara_cache.py
--rw-r--r--   0 runner    (1001) docker     (123)     6057 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/breakpoint.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.701730 aesara-nightly-2.8.9.post118/aesara/compile/
--rw-r--r--   0 runner    (1001) docker     (123)     1410 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    37547 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/builders.py
--rw-r--r--   0 runner    (1001) docker     (123)     9954 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/compiledir.py
--rw-r--r--   0 runner    (1001) docker     (123)     2041 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/compilelock.py
--rw-r--r--   0 runner    (1001) docker     (123)    85453 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/debugmode.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.701730 aesara-nightly-2.8.9.post118/aesara/compile/function/
--rw-r--r--   0 runner    (1001) docker     (123)    13377 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/function/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    22099 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/function/pfunc.py
--rw-r--r--   0 runner    (1001) docker     (123)    71335 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/function/types.py
--rw-r--r--   0 runner    (1001) docker     (123)     9102 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/io.py
--rw-r--r--   0 runner    (1001) docker     (123)    17823 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/mode.py
--rw-r--r--   0 runner    (1001) docker     (123)     3706 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/monitormode.py
--rw-r--r--   0 runner    (1001) docker     (123)     8326 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/nanguardmode.py
--rw-r--r--   0 runner    (1001) docker     (123)     9969 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/ops.py
--rw-r--r--   0 runner    (1001) docker     (123)    59779 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/profiling.py
--rw-r--r--   0 runner    (1001) docker     (123)     7202 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/compile/sharedvalue.py
--rw-r--r--   0 runner    (1001) docker     (123)    46230 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/configdefaults.py
--rw-r--r--   0 runner    (1001) docker     (123)    22530 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/configparser.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.701730 aesara-nightly-2.8.9.post118/aesara/d3viz/
--rw-r--r--   0 runner    (1001) docker     (123)       46 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.705730 aesara-nightly-2.8.9.post118/aesara/d3viz/css/
--rw-r--r--   0 runner    (1001) docker     (123)      448 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/css/d3-context-menu.css
--rw-r--r--   0 runner    (1001) docker     (123)     1302 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/css/d3viz.css
--rw-r--r--   0 runner    (1001) docker     (123)     3830 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/d3viz.py
--rw-r--r--   0 runner    (1001) docker     (123)    11843 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/formatting.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.705730 aesara-nightly-2.8.9.post118/aesara/d3viz/html/
--rw-r--r--   0 runner    (1001) docker     (123)     3085 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/html/template.html
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.705730 aesara-nightly-2.8.9.post118/aesara/d3viz/js/
--rw-r--r--   0 runner    (1001) docker     (123)     1203 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3-context-menu.js
--rw-r--r--   0 runner    (1001) docker     (123)   151143 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3.v3.min.js
--rw-r--r--   0 runner    (1001) docker     (123)    23208 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3viz.js
--rw-r--r--   0 runner    (1001) docker     (123)    47566 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/js/dagre-d3.min.js
--rw-r--r--   0 runner    (1001) docker     (123)   115617 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/d3viz/js/graphlib-dot.min.js
--rw-r--r--   0 runner    (1001) docker     (123)    87043 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/gradient.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.705730 aesara-nightly-2.8.9.post118/aesara/graph/
--rw-r--r--   0 runner    (1001) docker     (123)      505 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    59820 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    31374 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/destroyhandler.py
--rw-r--r--   0 runner    (1001) docker     (123)    26449 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/features.py
--rw-r--r--   0 runner    (1001) docker     (123)    35817 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/fg.py
--rw-r--r--   0 runner    (1001) docker     (123)      246 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/kanren.py
--rw-r--r--   0 runner    (1001) docker     (123)     1150 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/null_type.py
--rw-r--r--   0 runner    (1001) docker     (123)    25075 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/op.py
--rw-r--r--   0 runner    (1001) docker     (123)      793 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/opt.py
--rw-r--r--   0 runner    (1001) docker     (123)      799 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/opt_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)      786 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/optdb.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.705730 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   114248 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    19934 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/db.py
--rw-r--r--   0 runner    (1001) docker     (123)     3035 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/kanren.py
--rw-r--r--   0 runner    (1001) docker     (123)     7239 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/unify.py
--rw-r--r--   0 runner    (1001) docker     (123)     9148 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/rewriting/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     7865 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/sched.py
--rw-r--r--   0 runner    (1001) docker     (123)      223 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/toolbox.py
--rw-r--r--   0 runner    (1001) docker     (123)     8926 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/type.py
--rw-r--r--   0 runner    (1001) docker     (123)      243 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/unify.py
--rw-r--r--   0 runner    (1001) docker     (123)    12164 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/graph/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    29070 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/ifelse.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.709730 aesara-nightly-2.8.9.post118/aesara/link/
--rw-r--r--   0 runner    (1001) docker     (123)        3 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    23890 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/basic.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.709730 aesara-nightly-2.8.9.post118/aesara/link/c/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    72624 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/basic.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.709730 aesara-nightly-2.8.9.post118/aesara/link/c/c_code/
--rw-r--r--   0 runner    (1001) docker     (123)      706 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/c_code/aesara_mod_helper.h
--rw-r--r--   0 runner    (1001) docker     (123)    35583 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/c_code/lazylinker_c.c
--rw-r--r--   0 runner    (1001) docker     (123)   112626 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/cmodule.py
--rw-r--r--   0 runner    (1001) docker     (123)     4183 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/cutils.py
--rw-r--r--   0 runner    (1001) docker     (123)     1054 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/cvm.py
--rw-r--r--   0 runner    (1001) docker     (123)      402 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (123)    20016 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/interface.py
--rw-r--r--   0 runner    (1001) docker     (123)     6641 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/lazylinker_c.py
--rw-r--r--   0 runner    (1001) docker     (123)    24725 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/op.py
--rw-r--r--   0 runner    (1001) docker     (123)    31659 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/params_type.py
--rw-r--r--   0 runner    (1001) docker     (123)    26568 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/c/type.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.709730 aesara-nightly-2.8.9.post118/aesara/link/jax/
--rw-r--r--   0 runner    (1001) docker     (123)       48 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2370 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)     2945 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/elemwise.py
--rw-r--r--   0 runner    (1001) docker     (123)     3381 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/extra_ops.py
--rw-r--r--   0 runner    (1001) docker     (123)     3072 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/nlinalg.py
--rw-r--r--   0 runner    (1001) docker     (123)    10930 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/random.py
--rw-r--r--   0 runner    (1001) docker     (123)     5612 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/scalar.py
--rw-r--r--   0 runner    (1001) docker     (123)     5382 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/scan.py
--rw-r--r--   0 runner    (1001) docker     (123)     2746 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/shape.py
--rw-r--r--   0 runner    (1001) docker     (123)     1116 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/slinalg.py
--rw-r--r--   0 runner    (1001) docker     (123)     3192 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/subtensor.py
--rw-r--r--   0 runner    (1001) docker     (123)     3380 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/tensor_basic.py
--rw-r--r--   0 runner    (1001) docker     (123)      238 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/jax_dispatch.py
--rw-r--r--   0 runner    (1001) docker     (123)      232 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/jax_linker.py
--rw-r--r--   0 runner    (1001) docker     (123)     2991 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/jax/linker.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/link/numba/
--rw-r--r--   0 runner    (1001) docker     (123)       49 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/
--rw-r--r--   0 runner    (1001) docker     (123)      506 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    25914 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    22249 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/elemwise.py
--rw-r--r--   0 runner    (1001) docker     (123)     9266 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/extra_ops.py
--rw-r--r--   0 runner    (1001) docker     (123)     5085 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/nlinalg.py
--rw-r--r--   0 runner    (1001) docker     (123)    12537 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/random.py
--rw-r--r--   0 runner    (1001) docker     (123)     8896 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/scalar.py
--rw-r--r--   0 runner    (1001) docker     (123)    14205 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/scan.py
--rw-r--r--   0 runner    (1001) docker     (123)     6112 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/sparse.py
--rw-r--r--   0 runner    (1001) docker     (123)     6405 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/tensor_basic.py
--rw-r--r--   0 runner    (1001) docker     (123)     1705 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/numba/linker.py
--rw-r--r--   0 runner    (1001) docker     (123)    28718 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    50578 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/link/vm.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/misc/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9672 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/check_blas.py
--rwxr-xr-x   0 runner    (1001) docker     (123)      600 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/check_blas_many.sh
--rw-r--r--   0 runner    (1001) docker     (123)     2410 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/check_duplicate_key.py
--rw-r--r--   0 runner    (1001) docker     (123)     2166 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/elemwise_openmp_speedup.py
--rw-r--r--   0 runner    (1001) docker     (123)     1887 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/elemwise_time_test.py
--rw-r--r--   0 runner    (1001) docker     (123)     1347 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/frozendict.py
--rw-r--r--   0 runner    (1001) docker     (123)      607 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/latence_gpu_transfert.py
--rw-r--r--   0 runner    (1001) docker     (123)      921 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/may_share_memory.py
--rw-r--r--   0 runner    (1001) docker     (123)     7191 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/ordered_set.py
--rw-r--r--   0 runner    (1001) docker     (123)     9746 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/pkl_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     2292 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/misc/safe_asarray.py
--rw-r--r--   0 runner    (1001) docker     (123)    64090 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/printing.py
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/py.typed
--rw-r--r--   0 runner    (1001) docker     (123)     5838 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/raise_op.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/sandbox/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3873 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/fourier.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.713730 aesara-nightly-2.8.9.post118/aesara/sandbox/linalg/
--rw-r--r--   0 runner    (1001) docker     (123)       60 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/linalg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6062 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/linalg/ops.py
--rw-r--r--   0 runner    (1001) docker     (123)     1455 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/minimal.py
--rw-r--r--   0 runner    (1001) docker     (123)    14812 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/multinomial.py
--rw-r--r--   0 runner    (1001) docker     (123)    48272 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/rng_mrg.py
--rw-r--r--   0 runner    (1001) docker     (123)     8105 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/samples_MRG31k3p_12_7_5.txt
--rw-r--r--   0 runner    (1001) docker     (123)      217 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sandbox/solve.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.717730 aesara-nightly-2.8.9.post118/aesara/scalar/
--rw-r--r--   0 runner    (1001) docker     (123)       41 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   139093 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)      223 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/basic_scipy.py
--rw-r--r--   0 runner    (1001) docker     (123)     3275 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/basic_sympy.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.717730 aesara-nightly-2.8.9.post118/aesara/scalar/c_code/
--rw-r--r--   0 runner    (1001) docker     (123)   126227 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/c_code/Faddeeva.cc
--rw-r--r--   0 runner    (1001) docker     (123)     2645 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/c_code/Faddeeva.hh
--rw-r--r--   0 runner    (1001) docker     (123)    16816 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/c_code/gamma.c
--rw-r--r--   0 runner    (1001) docker     (123)    40497 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/math.py
--rw-r--r--   0 runner    (1001) docker     (123)     1851 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scalar/sharedvar.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.717730 aesara-nightly-2.8.9.post118/aesara/scan/
--rw-r--r--   0 runner    (1001) docker     (123)     1931 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    50325 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/basic.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.717730 aesara-nightly-2.8.9.post118/aesara/scan/c_code/
--rw-r--r--   0 runner    (1001) docker     (123)  1108062 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/c_code/scan_perform.c
--rw-r--r--   0 runner    (1001) docker     (123)     6743 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/checkpoints.py
--rw-r--r--   0 runner    (1001) docker     (123)   140552 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/op.py
--rw-r--r--   0 runner    (1001) docker     (123)      226 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    95135 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/rewriting.py
--rw-r--r--   0 runner    (1001) docker     (123)    23996 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/scan_perform.pyx
--rw-r--r--   0 runner    (1001) docker     (123)     3512 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/scan_perform_ext.py
--rw-r--r--   0 runner    (1001) docker     (123)    38175 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     4599 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/scan/views.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.721730 aesara-nightly-2.8.9.post118/aesara/sparse/
--rw-r--r--   0 runner    (1001) docker     (123)     1097 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   118012 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)      232 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    76908 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/rewriting.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.721730 aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    17297 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/sp.py
--rw-r--r--   0 runner    (1001) docker     (123)     7194 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/sp2.py
--rw-r--r--   0 runner    (1001) docker     (123)      827 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/sharedvar.py
--rw-r--r--   0 runner    (1001) docker     (123)     8073 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/type.py
--rw-r--r--   0 runner    (1001) docker     (123)      767 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/sparse/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.725730 aesara-nightly-2.8.9.post118/aesara/tensor/
--rw-r--r--   0 runner    (1001) docker     (123)     4289 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   135697 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)      461 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/basic_opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    98873 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/blas.py
--rw-r--r--   0 runner    (1001) docker     (123)    26486 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/blas_c.py
--rw-r--r--   0 runner    (1001) docker     (123)    68050 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/blas_headers.py
--rw-r--r--   0 runner    (1001) docker     (123)     2783 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/blas_scipy.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.725730 aesara-nightly-2.8.9.post118/aesara/tensor/c_code/
--rw-r--r--   0 runner    (1001) docker     (123)      897 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/c_code/alt_blas_common.h
--rw-r--r--   0 runner    (1001) docker     (123)    16236 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/c_code/alt_blas_template.c
--rw-r--r--   0 runner    (1001) docker     (123)     2038 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/c_code/dimshuffle.c
--rw-r--r--   0 runner    (1001) docker     (123)    66688 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/elemwise.py
--rw-r--r--   0 runner    (1001) docker     (123)    20866 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/elemwise_cgen.py
--rw-r--r--   0 runner    (1001) docker     (123)      362 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (123)    57998 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/extra_ops.py
--rw-r--r--   0 runner    (1001) docker     (123)     7591 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/fft.py
--rw-r--r--   0 runner    (1001) docker     (123)     6603 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/fourier.py
--rw-r--r--   0 runner    (1001) docker     (123)     7737 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/inplace.py
--rw-r--r--   0 runner    (1001) docker     (123)     7242 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/io.py
--rw-r--r--   0 runner    (1001) docker     (123)       72 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/linalg.py
--rw-r--r--   0 runner    (1001) docker     (123)    92466 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/math.py
--rw-r--r--   0 runner    (1001) docker     (123)      247 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/math_opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    22763 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nlinalg.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.725730 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/
--rw-r--r--   0 runner    (1001) docker     (123)     1431 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   138966 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/abstract_conv.py
--rw-r--r--   0 runner    (1001) docker     (123)    75762 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    35370 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/batchnorm.py
--rw-r--r--   0 runner    (1001) docker     (123)     8902 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/blocksparse.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/
--rw-r--r--   0 runner    (1001) docker     (123)    18972 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/corr3d_gemm.c
--rw-r--r--   0 runner    (1001) docker     (123)    26551 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/corr_gemm.c
--rw-r--r--   0 runner    (1001) docker     (123)     8195 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/ctc_wrapper.c
--rw-r--r--   0 runner    (1001) docker     (123)    94525 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/conv.py
--rw-r--r--   0 runner    (1001) docker     (123)     9910 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/conv3d2d.py
--rw-r--r--   0 runner    (1001) docker     (123)    40356 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/corr.py
--rw-r--r--   0 runner    (1001) docker     (123)    36145 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/corr3d.py
--rw-r--r--   0 runner    (1001) docker     (123)     8522 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/ctc.py
--rw-r--r--   0 runner    (1001) docker     (123)    35353 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/neighbours.py
--rw-r--r--   0 runner    (1001) docker     (123)      247 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    17298 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/rewriting.py
--rw-r--r--   0 runner    (1001) docker     (123)     5212 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/nnet/sigm.py
--rw-r--r--   0 runner    (1001) docker     (123)      277 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/opt_uncanonicalize.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/tensor/random/
--rw-r--r--   0 runner    (1001) docker     (123)      265 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    61298 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    14370 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/op.py
--rw-r--r--   0 runner    (1001) docker     (123)      253 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/opt.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/
--rw-r--r--   0 runner    (1001) docker     (123)      221 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    15291 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)     1887 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/jax.py
--rw-r--r--   0 runner    (1001) docker     (123)     6730 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/type.py
--rw-r--r--   0 runner    (1001) docker     (123)     9021 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     1321 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/random/var.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/
--rw-r--r--   0 runner    (1001) docker     (123)      384 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    42710 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)    39793 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/elemwise.py
--rw-r--r--   0 runner    (1001) docker     (123)     4846 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/extra_ops.py
--rw-r--r--   0 runner    (1001) docker     (123)     3954 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/jax.py
--rw-r--r--   0 runner    (1001) docker     (123)   122924 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/math.py
--rw-r--r--   0 runner    (1001) docker     (123)    44832 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/shape.py
--rw-r--r--   0 runner    (1001) docker     (123)     6102 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/special.py
--rw-r--r--   0 runner    (1001) docker     (123)    63205 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/subtensor.py
--rw-r--r--   0 runner    (1001) docker     (123)     9500 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/uncanonicalize.py
--rw-r--r--   0 runner    (1001) docker     (123)    33343 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/shape.py
--rw-r--r--   0 runner    (1001) docker     (123)     3858 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/sharedvar.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/tensor/signal/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/signal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3509 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/signal/conv.py
--rwxr-xr-x   0 runner    (1001) docker     (123)    97512 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/signal/pool.py
--rw-r--r--   0 runner    (1001) docker     (123)    25027 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/slinalg.py
--rw-r--r--   0 runner    (1001) docker     (123)    17849 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/sort.py
--rw-r--r--   0 runner    (1001) docker     (123)    27168 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/special.py
--rw-r--r--   0 runner    (1001) docker     (123)    91237 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/subtensor.py
--rw-r--r--   0 runner    (1001) docker     (123)      262 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/subtensor_opt.py
--rw-r--r--   0 runner    (1001) docker     (123)    41042 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/type.py
--rw-r--r--   0 runner    (1001) docker     (123)     4090 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/type_other.py
--rw-r--r--   0 runner    (1001) docker     (123)     3211 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    36091 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/var.py
--rw-r--r--   0 runner    (1001) docker     (123)     1831 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/tensor/xlogx.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.729730 aesara-nightly-2.8.9.post118/aesara/typed_list/
--rw-r--r--   0 runner    (1001) docker     (123)      127 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/typed_list/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    18222 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/typed_list/basic.py
--rw-r--r--   0 runner    (1001) docker     (123)      780 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/typed_list/rewriting.py
--rw-r--r--   0 runner    (1001) docker     (123)     3873 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/typed_list/type.py
--rw-r--r--   0 runner    (1001) docker     (123)     2925 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/updates.py
--rw-r--r--   0 runner    (1001) docker     (123)    13641 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)      939 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/aesara/version.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)     2206 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    12555 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)       62 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (123)      116 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)       11 2023-01-18 20:56:56.000000 aesara-nightly-2.8.9.post118/aesara_nightly.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/bin/
--rw-r--r--   0 runner    (1001) docker     (123)      239 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/bin/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (123)      285 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/bin/aesara-cache
--rw-r--r--   0 runner    (1001) docker     (123)      332 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/bin/aesara_cache.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/doc/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/doc/.build/
--rw-r--r--   0 runner    (1001) docker     (123)       59 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.build/PLACEHOLDER
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/doc/.static/
--rw-r--r--   0 runner    (1001) docker     (123)       59 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.static/PLACEHOLDER
--rw-r--r--   0 runner    (1001) docker     (123)      256 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.static/fix_rtd.css
--rw-r--r--   0 runner    (1001) docker     (123)     3799 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.static/version_switch.js
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.733730 aesara-nightly-2.8.9.post118/doc/.templates/
--rw-r--r--   0 runner    (1001) docker     (123)       59 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.templates/PLACEHOLDER
--rw-r--r--   0 runner    (1001) docker     (123)     1409 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/.templates/layout.html
--rw-r--r--   0 runner    (1001) docker     (123)     2515 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/LICENSE.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1159 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/acknowledgement.rst
--rw-r--r--   0 runner    (1001) docker     (123)    25804 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/bcast.png
--rw-r--r--   0 runner    (1001) docker     (123)    14117 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/bcast.svg
--rw-r--r--   0 runner    (1001) docker     (123)     8439 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/conf.py
--rw-r--r--   0 runner    (1001) docker     (123)     1282 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/core_development_guide.rst
--rw-r--r--   0 runner    (1001) docker     (123)      269 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/css.inc
--rw-r--r--   0 runner    (1001) docker     (123)     8604 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/dev_start_guide.rst
--rw-r--r--   0 runner    (1001) docker     (123)      239 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/environment.yml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.737730 aesara-nightly-2.8.9.post118/doc/extending/
--rw-r--r--   0 runner    (1001) docker     (123)    28371 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/apply.png
--rw-r--r--   0 runner    (1001) docker     (123)    20340 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/apply.svg
--rw-r--r--   0 runner    (1001) docker     (123)    32078 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/apply2.svg
--rw-r--r--   0 runner    (1001) docker     (123)    46604 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/creating_a_c_op.rst
--rw-r--r--   0 runner    (1001) docker     (123)     6334 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/creating_a_numba_jax_op.rst
--rw-r--r--   0 runner    (1001) docker     (123)    32993 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/creating_an_op.rst
--rw-r--r--   0 runner    (1001) docker     (123)    22664 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/ctype.rst
--rwxr-xr-x   0 runner    (1001) docker     (123)     5513 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/extending_aesara_solution_1.py
--rw-r--r--   0 runner    (1001) docker     (123)     1130 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/extending_faq.rst
--rw-r--r--   0 runner    (1001) docker     (123)    55625 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/graph_rewriting.rst
--rw-r--r--   0 runner    (1001) docker     (123)    13711 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/graphstructures.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1686 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)     9026 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/inplace.rst
--rw-r--r--   0 runner    (1001) docker     (123)    24970 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/op.rst
--rw-r--r--   0 runner    (1001) docker     (123)     9538 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/other_ops.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.737730 aesara-nightly-2.8.9.post118/doc/extending/pics/
--rw-r--r--   0 runner    (1001) docker     (123)    23471 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/pics/symbolic_graph_opt.png
--rw-r--r--   0 runner    (1001) docker     (123)    62062 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/pics/symbolic_graph_unopt.png
--rw-r--r--   0 runner    (1001) docker     (123)     4929 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/pipeline.rst
--rw-r--r--   0 runner    (1001) docker     (123)    17120 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/scan.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1622 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/tips.rst
--rw-r--r--   0 runner    (1001) docker     (123)    19679 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/type.rst
--rw-r--r--   0 runner    (1001) docker     (123)    10050 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/unittest.rst
--rw-r--r--   0 runner    (1001) docker     (123)     7699 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/extending/using_params.rst
--rw-r--r--   0 runner    (1001) docker     (123)     6714 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/faq.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1283 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/generate_dtype_tensor_table.py
--rw-r--r--   0 runner    (1001) docker     (123)     7094 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/glossary.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.737730 aesara-nightly-2.8.9.post118/doc/images/
--rw-r--r--   0 runner    (1001) docker     (123)    94102 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/Elman_srnn.png
--rw-r--r--   0 runner    (1001) docker     (123)   116646 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/aesara_logo_2400.png
--rw-r--r--   0 runner    (1001) docker     (123)   102018 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/blocksparse.png
--rw-r--r--   0 runner    (1001) docker     (123)    13780 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/lstm.png
--rw-r--r--   0 runner    (1001) docker     (123)    14362 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/lstm_memorycell.png
--rw-r--r--   0 runner    (1001) docker     (123)   273555 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/talk2010.gif
--rw-r--r--   0 runner    (1001) docker     (123)    12455 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/images/talk2010.png
--rw-r--r--   0 runner    (1001) docker     (123)     3122 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      733 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/install.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/internal/
--rw-r--r--   0 runner    (1001) docker     (123)     1074 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/internal/how_to_release.rst
--rw-r--r--   0 runner    (1001) docker     (123)      155 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/internal/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2534 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/internal/metadocumentation.rst
--rw-r--r--   0 runner    (1001) docker     (123)     7918 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/introduction.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/library/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/library/compile/
--rw-r--r--   0 runner    (1001) docker     (123)     8364 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/debugmode.rst
--rw-r--r--   0 runner    (1001) docker     (123)     8910 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/function.rst
--rw-r--r--   0 runner    (1001) docker     (123)      454 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)    11817 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/io.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2152 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/mode.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2033 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/nanguardmode.rst
--rw-r--r--   0 runner    (1001) docker     (123)      899 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/opfromgraph.rst
--rw-r--r--   0 runner    (1001) docker     (123)      203 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/ops.rst
--rw-r--r--   0 runner    (1001) docker     (123)      414 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/profilemode.rst
--rw-r--r--   0 runner    (1001) docker     (123)     3037 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/compile/shared.rst
--rw-r--r--   0 runner    (1001) docker     (123)    30660 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/config.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/library/d3viz/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.697730 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.741730 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/css/
--rw-r--r--   0 runner    (1001) docker     (123)      448 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/css/d3-context-menu.css
--rw-r--r--   0 runner    (1001) docker     (123)     1302 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/css/d3viz.css
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/
--rw-r--r--   0 runner    (1001) docker     (123)     1203 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3-context-menu.js
--rw-r--r--   0 runner    (1001) docker     (123)   151143 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3.v3.min.js
--rw-r--r--   0 runner    (1001) docker     (123)    23339 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3viz.js
--rw-r--r--   0 runner    (1001) docker     (123)    47566 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/dagre-d3.min.js
--rw-r--r--   0 runner    (1001) docker     (123)   115617 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/graphlib-dot.min.js
--rw-r--r--   0 runner    (1001) docker     (123)     6168 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp.html
--rw-r--r--   0 runner    (1001) docker     (123)    84140 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp.png
--rw-r--r--   0 runner    (1001) docker     (123)     6406 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.html
--rw-r--r--   0 runner    (1001) docker     (123)    13875 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.pdf
--rw-r--r--   0 runner    (1001) docker     (123)    46699 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.png
--rw-r--r--   0 runner    (1001) docker     (123)     8963 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/ofg.html
--rw-r--r--   0 runner    (1001) docker     (123)     8115 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/ofg2.html
--rw-r--r--   0 runner    (1001) docker     (123)   216157 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index.ipynb
--rw-r--r--   0 runner    (1001) docker     (123)     8530 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/
--rw-r--r--   0 runner    (1001) docker     (123)    93049 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_10_0.png
--rw-r--r--   0 runner    (1001) docker     (123)    93049 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_11_0.png
--rw-r--r--   0 runner    (1001) docker     (123)    46699 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_24_0.png
--rw-r--r--   0 runner    (1001) docker     (123)    46699 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_25_0.png
--rw-r--r--   0 runner    (1001) docker     (123)     1720 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/gradient.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/graph/
--rw-r--r--   0 runner    (1001) docker     (123)      793 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/features.rst
--rw-r--r--   0 runner    (1001) docker     (123)      898 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/fgraph.rst
--rw-r--r--   0 runner    (1001) docker     (123)      353 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/graph.rst
--rw-r--r--   0 runner    (1001) docker     (123)      371 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      365 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/op.rst
--rw-r--r--   0 runner    (1001) docker     (123)      453 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/params_type.rst
--rw-r--r--   0 runner    (1001) docker     (123)      356 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/type.rst
--rw-r--r--   0 runner    (1001) docker     (123)      445 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/graph/utils.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1273 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/index.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/misc/
--rw-r--r--   0 runner    (1001) docker     (123)      411 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/misc/pkl_utils.rst
--rw-r--r--   0 runner    (1001) docker     (123)     7161 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/printing.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/sandbox/
--rw-r--r--   0 runner    (1001) docker     (123)      358 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/sandbox/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      471 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/sandbox/linalg.rst
--rw-r--r--   0 runner    (1001) docker     (123)      397 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/sandbox/rng_mrg.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/scalar/
--rw-r--r--   0 runner    (1001) docker     (123)      202 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/scalar/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)    26706 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/scan.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.745730 aesara-nightly-2.8.9.post118/doc/library/sparse/
--rw-r--r--   0 runner    (1001) docker     (123)    11348 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/sparse/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      532 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/sparse/sandbox.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.749730 aesara-nightly-2.8.9.post118/doc/library/tensor/
--rw-r--r--   0 runner    (1001) docker     (123)    65290 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/basic.rst
--rw-r--r--   0 runner    (1001) docker     (123)      361 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/basic_opt.rst
--rw-r--r--   0 runner    (1001) docker     (123)    25804 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/bcast.png
--rw-r--r--   0 runner    (1001) docker     (123)    14117 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/bcast.svg
--rw-r--r--   0 runner    (1001) docker     (123)      400 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/elemwise.rst
--rw-r--r--   0 runner    (1001) docker     (123)      408 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/extra_ops.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/fft.rst
--rw-r--r--   0 runner    (1001) docker     (123)      658 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      754 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/io.rst
--rw-r--r--   0 runner    (1001) docker     (123)      436 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/math_opt.rst
--rw-r--r--   0 runner    (1001) docker     (123)      530 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/nlinalg.rst
--rw-r--r--   0 runner    (1001) docker     (123)    24638 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/plot_fft.png
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.749730 aesara-nightly-2.8.9.post118/doc/library/tensor/random/
--rw-r--r--   0 runner    (1001) docker     (123)     4687 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/random/basic.rst
--rw-r--r--   0 runner    (1001) docker     (123)      463 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/random/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2164 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/random/utils.rst
--rw-r--r--   0 runner    (1001) docker     (123)      732 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/slinalg.rst
--rw-r--r--   0 runner    (1001) docker     (123)      382 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/tensor/utils.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1387 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/library/typed_list.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1836 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/links.rst
--rw-r--r--   0 runner    (1001) docker     (123)     3022 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/mission.rst
--rw-r--r--   0 runner    (1001) docker     (123)    12085 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/optimizations.rst
--rw-r--r--   0 runner    (1001) docker     (123)     9038 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/pylintrc
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.749730 aesara-nightly-2.8.9.post118/doc/sandbox/
--rw-r--r--   0 runner    (1001) docker     (123)    12643 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/ccodegen.rst
--rw-r--r--   0 runner    (1001) docker     (123)      160 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/compilation.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2906 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/debugging_with_stepmode.rst
--rw-r--r--   0 runner    (1001) docker     (123)     5889 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/elemwise_compiler.rst
--rw-r--r--   0 runner    (1001) docker     (123)       83 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/function.rst
--rw-r--r--   0 runner    (1001) docker     (123)      164 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/functional.rst
--rw-r--r--   0 runner    (1001) docker     (123)    17336 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/how_to_make_ops.rst
--rw-r--r--   0 runner    (1001) docker     (123)      215 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      230 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/index2.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2360 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/interactive_debugger.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2618 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/logistic_regression_example.rst
--rw-r--r--   0 runner    (1001) docker     (123)      747 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/performance.rst
--rw-r--r--   0 runner    (1001) docker     (123)    10482 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/randomnumbers.rst
--rw-r--r--   0 runner    (1001) docker     (123)     4261 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/rethinkccodegen.rst
--rw-r--r--   0 runner    (1001) docker     (123)     5946 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/sandbox.rst
--rw-r--r--   0 runner    (1001) docker     (123)      985 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/software.rst
--rw-r--r--   0 runner    (1001) docker     (123)     6172 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/sparse.rst
--rw-r--r--   0 runner    (1001) docker     (123)      117 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/sandbox/tensoroptools.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.749730 aesara-nightly-2.8.9.post118/doc/scripts/
--rw-r--r--   0 runner    (1001) docker     (123)     3886 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/scripts/docgen.py
--rw-r--r--   0 runner    (1001) docker     (123)    11515 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/troubleshooting.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.753730 aesara-nightly-2.8.9.post118/doc/tutorial/
--rw-r--r--   0 runner    (1001) docker     (123)     6983 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/adding.rst
--rwxr-xr-x   0 runner    (1001) docker     (123)      371 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/adding_solution_1.py
--rw-r--r--   0 runner    (1001) docker     (123)    11485 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/aliasing.rst
--rw-r--r--   0 runner    (1001) docker     (123)    28371 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/apply.png
--rw-r--r--   0 runner    (1001) docker     (123)    20340 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/apply.svg
--rw-r--r--   0 runner    (1001) docker     (123)    25804 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/bcast.png
--rw-r--r--   0 runner    (1001) docker     (123)     2443 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/broadcasting.rst
--rw-r--r--   0 runner    (1001) docker     (123)     2882 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/conditions.rst
--rw-r--r--   0 runner    (1001) docker     (123)    23084 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/debug_faq.rst
--rw-r--r--   0 runner    (1001) docker     (123)     5838 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/dlogistic.png
--rw-r--r--   0 runner    (1001) docker     (123)    18865 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/examples.rst
--rw-r--r--   0 runner    (1001) docker     (123)     3223 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/faq_tutorial.rst
--rw-r--r--   0 runner    (1001) docker     (123)    10801 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/gradients.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1123 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)     5988 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/loading_and_saving.rst
--rw-r--r--   0 runner    (1001) docker     (123)      483 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/logistic.gp
--rw-r--r--   0 runner    (1001) docker     (123)     4887 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/logistic.png
--rw-r--r--   0 runner    (1001) docker     (123)    12715 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/loop.rst
--rwxr-xr-x   0 runner    (1001) docker     (123)     2517 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/loop_solution_1.py
--rw-r--r--   0 runner    (1001) docker     (123)    11672 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/modes.rst
--rwxr-xr-x   0 runner    (1001) docker     (123)     1881 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/modes_solution_1.py
--rw-r--r--   0 runner    (1001) docker     (123)     2697 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/multi_cores.rst
--rw-r--r--   0 runner    (1001) docker     (123)     4366 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/nan_tutorial.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-18 20:56:56.753730 aesara-nightly-2.8.9.post118/doc/tutorial/pics/
--rw-r--r--   0 runner    (1001) docker     (123)    55147 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/pics/d3viz.png
--rw-r--r--   0 runner    (1001) docker     (123)   106142 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_predict.png
--rw-r--r--   0 runner    (1001) docker     (123)   148860 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_prediction.png
--rw-r--r--   0 runner    (1001) docker     (123)   473403 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_train.png
--rw-r--r--   0 runner    (1001) docker     (123)     4965 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/printing_drawing.rst
--rw-r--r--   0 runner    (1001) docker     (123)     3716 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/profiling.rst
--rw-r--r--   0 runner    (1001) docker     (123)      312 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/profiling_example.py
--rw-r--r--   0 runner    (1001) docker     (123)     1552 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/profiling_example_out.prof
--rw-r--r--   0 runner    (1001) docker     (123)     3951 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/shape_info.rst
--rw-r--r--   0 runner    (1001) docker     (123)     8410 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/sparse.rst
--rw-r--r--   0 runner    (1001) docker     (123)       78 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/doc/tutorial/symbolic_graphs.rst
--rw-r--r--   0 runner    (1001) docker     (123)     9891 2023-01-18 20:56:46.000000 aesara-nightly-2.8.9.post118/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)      107 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/requirements-rtd.txt
--rw-r--r--   0 runner    (1001) docker     (123)      238 2023-01-18 20:56:45.000000 aesara-nightly-2.8.9.post118/requirements.txt
--rw-r--r--   0 runner    (1001) docker     (123)       38 2023-01-18 20:56:56.757730 aesara-nightly-2.8.9.post118/setup.cfg
+-rw-r--r--   0        0        0      125 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/.git_archival.txt
+-rw-r--r--   0        0        0       32 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/.gitattributes
+-rw-r--r--   0        0        0     5503 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/README.md
+-rw-r--r--   0        0        0      916 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/conftest.py
+-rw-r--r--   0        0        0      128 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/requirements-rtd.txt
+-rw-r--r--   0        0        0      240 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/requirements.txt
+-rw-r--r--   0        0        0     5760 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/__init__.py
+-rw-r--r--   0        0        0      166 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/_version.py
+-rw-r--r--   0        0        0      252 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/assert_op.py
+-rw-r--r--   0        0        0     6055 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/breakpoint.py
+-rw-r--r--   0        0        0    46225 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/configdefaults.py
+-rw-r--r--   0        0        0    22462 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/configparser.py
+-rw-r--r--   0        0        0    86751 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/gradient.py
+-rw-r--r--   0        0        0    29067 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/ifelse.py
+-rw-r--r--   0        0        0    67046 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/printing.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/py.typed
+-rw-r--r--   0        0        0     5837 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/raise_op.py
+-rw-r--r--   0        0        0     2924 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/updates.py
+-rw-r--r--   0        0        0    13640 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/utils.py
+-rw-r--r--   0        0        0      939 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/version.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/bin/__init__.py
+-rw-r--r--   0        0        0     4080 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/bin/aesara_cache.py
+-rw-r--r--   0        0        0     1410 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/__init__.py
+-rw-r--r--   0        0        0    41442 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/builders.py
+-rw-r--r--   0        0        0     9954 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/compiledir.py
+-rw-r--r--   0        0        0     2041 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/compilelock.py
+-rw-r--r--   0        0        0    85654 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/debugmode.py
+-rw-r--r--   0        0        0     9102 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/io.py
+-rw-r--r--   0        0        0    17793 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/mode.py
+-rw-r--r--   0        0        0     3706 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/monitormode.py
+-rw-r--r--   0        0        0     8326 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/nanguardmode.py
+-rw-r--r--   0        0        0    11245 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/ops.py
+-rw-r--r--   0        0        0    59770 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/profiling.py
+-rw-r--r--   0        0        0     7179 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/sharedvalue.py
+-rw-r--r--   0        0        0    13377 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/function/__init__.py
+-rw-r--r--   0        0        0    22096 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/function/pfunc.py
+-rw-r--r--   0        0        0    73889 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/compile/function/types.py
+-rw-r--r--   0        0        0       46 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/__init__.py
+-rw-r--r--   0        0        0     3830 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/d3viz.py
+-rw-r--r--   0        0        0    11843 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/formatting.py
+-rw-r--r--   0        0        0      448 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/css/d3-context-menu.css
+-rw-r--r--   0        0        0     1302 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/css/d3viz.css
+-rw-r--r--   0        0        0     3085 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/html/template.html
+-rw-r--r--   0        0        0     1203 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3-context-menu.js
+-rw-r--r--   0        0        0   151143 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3.v3.min.js
+-rw-r--r--   0        0        0    23208 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3viz.js
+-rw-r--r--   0        0        0    47566 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/js/dagre-d3.min.js
+-rw-r--r--   0        0        0   115617 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/d3viz/js/graphlib-dot.min.js
+-rw-r--r--   0        0        0      505 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/__init__.py
+-rw-r--r--   0        0        0    59773 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/basic.py
+-rw-r--r--   0        0        0    33216 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/destroyhandler.py
+-rw-r--r--   0        0        0    24835 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/features.py
+-rw-r--r--   0        0        0    36232 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/fg.py
+-rw-r--r--   0        0        0      246 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/kanren.py
+-rw-r--r--   0        0        0     1150 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/null_type.py
+-rw-r--r--   0        0        0    25036 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/op.py
+-rw-r--r--   0        0        0      793 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/opt.py
+-rw-r--r--   0        0        0      799 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/opt_utils.py
+-rw-r--r--   0        0        0      786 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/optdb.py
+-rw-r--r--   0        0        0     7865 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/sched.py
+-rw-r--r--   0        0        0      223 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/toolbox.py
+-rw-r--r--   0        0        0     9527 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/type.py
+-rw-r--r--   0        0        0      243 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/unify.py
+-rw-r--r--   0        0        0    12091 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/__init__.py
+-rw-r--r--   0        0        0   114199 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/basic.py
+-rw-r--r--   0        0        0    19934 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/db.py
+-rw-r--r--   0        0        0     3035 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/kanren.py
+-rw-r--r--   0        0        0     7239 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/unify.py
+-rw-r--r--   0        0        0     9148 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/graph/rewriting/utils.py
+-rw-r--r--   0        0        0        3 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/__init__.py
+-rw-r--r--   0        0        0    23890 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/basic.py
+-rw-r--r--   0        0        0    28716 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/utils.py
+-rw-r--r--   0        0        0    50565 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/vm.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/__init__.py
+-rw-r--r--   0        0        0    72572 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/basic.py
+-rw-r--r--   0        0        0   112844 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/cmodule.py
+-rw-r--r--   0        0        0     4182 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/cutils.py
+-rw-r--r--   0        0        0     1054 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/cvm.py
+-rw-r--r--   0        0        0      402 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/exceptions.py
+-rw-r--r--   0        0        0    19955 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/interface.py
+-rw-r--r--   0        0        0     6641 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/lazylinker_c.py
+-rw-r--r--   0        0        0    24724 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/op.py
+-rw-r--r--   0        0        0    31544 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/params_type.py
+-rw-r--r--   0        0        0    26540 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/type.py
+-rw-r--r--   0        0        0      706 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/c_code/aesara_mod_helper.h
+-rw-r--r--   0        0        0    35583 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/c/c_code/lazylinker_c.c
+-rw-r--r--   0        0        0       48 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/__init__.py
+-rw-r--r--   0        0        0      238 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/jax_dispatch.py
+-rw-r--r--   0        0        0      232 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/jax_linker.py
+-rw-r--r--   0        0        0     2991 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/linker.py
+-rw-r--r--   0        0        0      529 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/__init__.py
+-rw-r--r--   0        0        0     2370 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/basic.py
+-rw-r--r--   0        0        0     2944 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/elemwise.py
+-rw-r--r--   0        0        0     3380 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/extra_ops.py
+-rw-r--r--   0        0        0     3072 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/nlinalg.py
+-rw-r--r--   0        0        0    14480 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/random.py
+-rw-r--r--   0        0        0     5622 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/scalar.py
+-rw-r--r--   0        0        0     5382 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/scan.py
+-rw-r--r--   0        0        0     2745 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/shape.py
+-rw-r--r--   0        0        0     1115 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/slinalg.py
+-rw-r--r--   0        0        0     3188 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/subtensor.py
+-rw-r--r--   0        0        0     3380 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/tensor_basic.py
+-rw-r--r--   0        0        0       49 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/__init__.py
+-rw-r--r--   0        0        0     1044 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/linker.py
+-rw-r--r--   0        0        0      506 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/__init__.py
+-rw-r--r--   0        0        0    25903 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/basic.py
+-rw-r--r--   0        0        0    22260 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/elemwise.py
+-rw-r--r--   0        0        0     9262 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/extra_ops.py
+-rw-r--r--   0        0        0     5076 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/nlinalg.py
+-rw-r--r--   0        0        0    12812 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/random.py
+-rw-r--r--   0        0        0     8893 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/scalar.py
+-rw-r--r--   0        0        0    14203 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/scan.py
+-rw-r--r--   0        0        0     6109 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/sparse.py
+-rw-r--r--   0        0        0     6403 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/tensor_basic.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/__init__.py
+-rw-r--r--   0        0        0     9672 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/check_blas.py
+-rwxr-xr-x   0        0        0      600 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/check_blas_many.sh
+-rw-r--r--   0        0        0     2409 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/check_duplicate_key.py
+-rw-r--r--   0        0        0     2166 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/elemwise_openmp_speedup.py
+-rw-r--r--   0        0        0     1887 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/elemwise_time_test.py
+-rw-r--r--   0        0        0     1347 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/frozendict.py
+-rw-r--r--   0        0        0      607 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/latence_gpu_transfert.py
+-rw-r--r--   0        0        0      921 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/may_share_memory.py
+-rw-r--r--   0        0        0     7191 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/ordered_set.py
+-rw-r--r--   0        0        0     9746 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/pkl_utils.py
+-rw-r--r--   0        0        0     2293 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/misc/safe_asarray.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/__init__.py
+-rw-r--r--   0        0        0     3873 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/fourier.py
+-rw-r--r--   0        0        0     1455 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/minimal.py
+-rw-r--r--   0        0        0    14812 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/multinomial.py
+-rw-r--r--   0        0        0    48271 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/rng_mrg.py
+-rw-r--r--   0        0        0     8105 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/samples_MRG31k3p_12_7_5.txt
+-rw-r--r--   0        0        0      217 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/solve.py
+-rw-r--r--   0        0        0       60 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/linalg/__init__.py
+-rw-r--r--   0        0        0     6060 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sandbox/linalg/ops.py
+-rw-r--r--   0        0        0      709 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/__init__.py
+-rw-r--r--   0        0        0   143435 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/basic.py
+-rw-r--r--   0        0        0      223 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/basic_scipy.py
+-rw-r--r--   0        0        0     3275 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/basic_sympy.py
+-rw-r--r--   0        0        0    46142 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/math.py
+-rw-r--r--   0        0        0     1851 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/sharedvar.py
+-rw-r--r--   0        0        0   126227 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/c_code/Faddeeva.cc
+-rw-r--r--   0        0        0     2645 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/c_code/Faddeeva.hh
+-rw-r--r--   0        0        0    16816 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scalar/c_code/gamma.c
+-rw-r--r--   0        0        0     1931 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/__init__.py
+-rw-r--r--   0        0        0    50095 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/basic.py
+-rw-r--r--   0        0        0     6743 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/checkpoints.py
+-rw-r--r--   0        0        0   140522 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/op.py
+-rw-r--r--   0        0        0      226 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/opt.py
+-rw-r--r--   0        0        0    95587 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/rewriting.py
+-rw-r--r--   0        0        0    23996 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/scan_perform.pyx
+-rw-r--r--   0        0        0     3511 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/scan_perform_ext.py
+-rw-r--r--   0        0        0    38052 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/utils.py
+-rw-r--r--   0        0        0     4599 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/views.py
+-rw-r--r--   0        0        0  1114748 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/scan/c_code/scan_perform.c
+-rw-r--r--   0        0        0     1097 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/__init__.py
+-rw-r--r--   0        0        0   118008 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/basic.py
+-rw-r--r--   0        0        0      232 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/opt.py
+-rw-r--r--   0        0        0    76905 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/rewriting.py
+-rw-r--r--   0        0        0      827 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/sharedvar.py
+-rw-r--r--   0        0        0     8044 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/type.py
+-rw-r--r--   0        0        0      767 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/sandbox/__init__.py
+-rw-r--r--   0        0        0    17303 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/sandbox/sp.py
+-rw-r--r--   0        0        0     7194 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/sparse/sandbox/sp2.py
+-rw-r--r--   0        0        0     4883 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/__init__.py
+-rw-r--r--   0        0        0   135685 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/basic.py
+-rw-r--r--   0        0        0      461 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/basic_opt.py
+-rw-r--r--   0        0        0    98819 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/blas.py
+-rw-r--r--   0        0        0    26486 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/blas_c.py
+-rw-r--r--   0        0        0    68050 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/blas_headers.py
+-rw-r--r--   0        0        0     2783 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/blas_scipy.py
+-rw-r--r--   0        0        0    66675 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/elemwise.py
+-rw-r--r--   0        0        0    20860 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/elemwise_cgen.py
+-rw-r--r--   0        0        0      362 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/exceptions.py
+-rw-r--r--   0        0        0    57997 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/extra_ops.py
+-rw-r--r--   0        0        0     7589 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/fft.py
+-rw-r--r--   0        0        0     6565 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/fourier.py
+-rw-r--r--   0        0        0     7848 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/inplace.py
+-rw-r--r--   0        0        0     7239 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/io.py
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/linalg.py
+-rw-r--r--   0        0        0    96168 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/math.py
+-rw-r--r--   0        0        0      247 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/math_opt.py
+-rw-r--r--   0        0        0    22762 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nlinalg.py
+-rw-r--r--   0        0        0      277 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/opt_uncanonicalize.py
+-rw-r--r--   0        0        0    33298 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/shape.py
+-rw-r--r--   0        0        0     3858 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/sharedvar.py
+-rw-r--r--   0        0        0    24997 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/slinalg.py
+-rw-r--r--   0        0        0    17849 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/sort.py
+-rw-r--r--   0        0        0    27385 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/special.py
+-rw-r--r--   0        0        0    91231 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/subtensor.py
+-rw-r--r--   0        0        0      262 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/subtensor_opt.py
+-rw-r--r--   0        0        0    41188 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/type.py
+-rw-r--r--   0        0        0     4088 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/type_other.py
+-rw-r--r--   0        0        0     3211 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/utils.py
+-rw-r--r--   0        0        0    37592 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/var.py
+-rw-r--r--   0        0        0     1831 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/xlogx.py
+-rw-r--r--   0        0        0      897 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/c_code/alt_blas_common.h
+-rw-r--r--   0        0        0    16236 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/c_code/alt_blas_template.c
+-rw-r--r--   0        0        0     2038 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/c_code/dimshuffle.c
+-rw-r--r--   0        0        0     1431 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/__init__.py
+-rw-r--r--   0        0        0   138965 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/abstract_conv.py
+-rw-r--r--   0        0        0    75765 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/basic.py
+-rw-r--r--   0        0        0    35376 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/batchnorm.py
+-rw-r--r--   0        0        0     8902 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/blocksparse.py
+-rw-r--r--   0        0        0    94523 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/conv.py
+-rw-r--r--   0        0        0     9910 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/conv3d2d.py
+-rw-r--r--   0        0        0    40356 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/corr.py
+-rw-r--r--   0        0        0    36145 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/corr3d.py
+-rw-r--r--   0        0        0     8522 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/ctc.py
+-rw-r--r--   0        0        0    35353 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/neighbours.py
+-rw-r--r--   0        0        0      247 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/opt.py
+-rw-r--r--   0        0        0    17297 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/rewriting.py
+-rw-r--r--   0        0        0     5212 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/sigm.py
+-rw-r--r--   0        0        0    18972 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/corr3d_gemm.c
+-rw-r--r--   0        0        0    26551 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/corr_gemm.c
+-rw-r--r--   0        0        0     8195 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/ctc_wrapper.c
+-rw-r--r--   0        0        0      265 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/__init__.py
+-rw-r--r--   0        0        0    64232 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/basic.py
+-rw-r--r--   0        0        0    14324 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/op.py
+-rw-r--r--   0        0        0      253 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/opt.py
+-rw-r--r--   0        0        0     6730 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/type.py
+-rw-r--r--   0        0        0     9024 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/utils.py
+-rw-r--r--   0        0        0     1534 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/var.py
+-rw-r--r--   0        0        0      221 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/rewriting/__init__.py
+-rw-r--r--   0        0        0    15290 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/rewriting/basic.py
+-rw-r--r--   0        0        0     1887 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/random/rewriting/jax.py
+-rw-r--r--   0        0        0      384 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/__init__.py
+-rw-r--r--   0        0        0    42723 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/basic.py
+-rw-r--r--   0        0        0    39439 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/elemwise.py
+-rw-r--r--   0        0        0     4845 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/extra_ops.py
+-rw-r--r--   0        0        0     3954 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/jax.py
+-rw-r--r--   0        0        0   124250 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/math.py
+-rw-r--r--   0        0        0    43264 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/shape.py
+-rw-r--r--   0        0        0     6111 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/special.py
+-rw-r--r--   0        0        0    63199 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/subtensor.py
+-rw-r--r--   0        0        0     9500 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/uncanonicalize.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/signal/__init__.py
+-rw-r--r--   0        0        0     3509 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/signal/conv.py
+-rwxr-xr-x   0        0        0    97524 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/tensor/signal/pool.py
+-rw-r--r--   0        0        0      127 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/typed_list/__init__.py
+-rw-r--r--   0        0        0    18222 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/typed_list/basic.py
+-rw-r--r--   0        0        0      779 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/typed_list/rewriting.py
+-rw-r--r--   0        0        0     3933 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/aesara/typed_list/type.py
+-rw-r--r--   0        0        0      239 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/bin/__init__.py
+-rwxr-xr-x   0        0        0      285 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/bin/aesara-cache
+-rw-r--r--   0        0        0      332 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/bin/aesara_cache.py
+-rw-r--r--   0        0        0     1159 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/acknowledgement.rst
+-rw-r--r--   0        0        0     8338 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/conf.py
+-rw-r--r--   0        0        0    30688 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/config.rst
+-rw-r--r--   0        0        0     1209 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/core_development_guide.rst
+-rw-r--r--   0        0        0      269 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/css.inc
+-rw-r--r--   0        0        0     8925 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/dev_start_guide.rst
+-rw-r--r--   0        0        0     1283 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/generate_dtype_tensor_table.py
+-rw-r--r--   0        0        0     6807 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/glossary.rst
+-rw-r--r--   0        0        0      889 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/help.rst
+-rw-r--r--   0        0        0     6541 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/how_to_think_in_aesara.rst
+-rw-r--r--   0        0        0     4080 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/index.rst
+-rw-r--r--   0        0        0     1531 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/install.rst
+-rw-r--r--   0        0        0     7301 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/introduction.rst
+-rw-r--r--   0        0        0     3022 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/mission.rst
+-rw-r--r--   0        0        0     9038 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/pylintrc
+-rw-r--r--   0        0        0       59 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.build/PLACEHOLDER
+-rw-r--r--   0        0        0       59 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.static/PLACEHOLDER
+-rw-r--r--   0        0        0      256 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.static/fix_rtd.css
+-rw-r--r--   0        0        0     3799 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.static/version_switch.js
+-rw-r--r--   0        0        0       59 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.templates/PLACEHOLDER
+-rw-r--r--   0        0        0     1409 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/.templates/layout.html
+-rw-r--r--   0        0        0     8364 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/debugmode.rst
+-rw-r--r--   0        0        0    13302 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/function.rst
+-rw-r--r--   0        0        0      192 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/index.rst
+-rw-r--r--   0        0        0    11817 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/io.rst
+-rw-r--r--   0        0        0     2152 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/mode.rst
+-rw-r--r--   0        0        0    11661 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/modes.rst
+-rwxr-xr-x   0        0        0     1881 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/modes_solution_1.py
+-rw-r--r--   0        0        0     2033 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/nanguardmode.rst
+-rw-r--r--   0        0        0      899 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/opfromgraph.rst
+-rw-r--r--   0        0        0      203 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/ops.rst
+-rw-r--r--   0        0        0      414 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/profilemode.rst
+-rw-r--r--   0        0        0     8144 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/shared.rst
+-rw-r--r--   0        0        0      893 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/compile/rewrites/index.rst
+-rw-r--r--   0        0        0       54 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/rewrite.rst
+-rw-r--r--   0        0        0    46604 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/backend/creating_a_c_op.rst
+-rw-r--r--   0        0        0     6334 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/backend/creating_a_numba_jax_op.rst
+-rw-r--r--   0        0        0    22664 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/backend/ctype.rst
+-rw-r--r--   0        0        0      145 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/backend/index.rst
+-rw-r--r--   0        0        0    28371 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/apply.png
+-rw-r--r--   0        0        0    20340 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/apply.svg
+-rw-r--r--   0        0        0    32078 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/apply2.svg
+-rw-r--r--   0        0        0    32787 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/creating_an_op.rst
+-rw-r--r--   0        0        0    17336 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/how_to_make_ops.rst
+-rw-r--r--   0        0        0     1391 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/index.rst
+-rw-r--r--   0        0        0     9026 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/extend/op/inplace.rst
+-rw-r--r--   0        0        0       99 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/compilation/index.rst
+-rw-r--r--   0        0        0     4929 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/compilation/pipeline.rst
+-rw-r--r--   0        0        0    28371 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/apply.png
+-rw-r--r--   0        0        0    20340 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/apply.svg
+-rw-r--r--   0        0        0    32078 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/apply2.svg
+-rw-r--r--   0        0        0    13712 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graphstructures.rst
+-rw-r--r--   0        0        0      167 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/index.rst
+-rw-r--r--   0        0        0    24970 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/op.rst
+-rw-r--r--   0        0        0     9034 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/other_ops.rst
+-rw-r--r--   0        0        0    23471 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/symbolic_graph_opt.png
+-rw-r--r--   0        0        0    62062 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/symbolic_graph_unopt.png
+-rw-r--r--   0        0        0    19679 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/type.rst
+-rw-r--r--   0        0        0     7580 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/using_params.rst
+-rw-r--r--   0        0        0      793 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/features.rst
+-rw-r--r--   0        0        0      898 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/fgraph.rst
+-rw-r--r--   0        0        0      353 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/graph.rst
+-rw-r--r--   0        0        0      355 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/index.rst
+-rw-r--r--   0        0        0      365 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/op.rst
+-rw-r--r--   0        0        0      356 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/type.rst
+-rw-r--r--   0        0        0      445 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/utils.rst
+-rw-r--r--   0        0        0    55613 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/rewrites/graph_rewriting.rst
+-rw-r--r--   0        0        0      115 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/rewrites/index.rst
+-rw-r--r--   0        0        0    12027 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/fundamentals/rewrites/optimizations.rst
+-rw-r--r--   0        0        0    94102 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/Elman_srnn.png
+-rw-r--r--   0        0        0    15088 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/aesara_logo_200.png
+-rw-r--r--   0        0        0   116646 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/aesara_logo_2400.png
+-rw-r--r--   0        0        0   198151 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/aesara_overview_diagram.png
+-rw-r--r--   0        0        0   102018 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/blocksparse.png
+-rw-r--r--   0        0        0    13780 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/lstm.png
+-rw-r--r--   0        0        0    14362 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/lstm_memorycell.png
+-rw-r--r--   0        0        0   273555 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/talk2010.gif
+-rw-r--r--   0        0        0    12455 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/images/talk2010.png
+-rw-r--r--   0        0        0     2897 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/conditionals.rst
+-rw-r--r--   0        0        0      165 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/index.rst
+-rw-r--r--   0        0        0     5838 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/gradient/dlogistic.png
+-rw-r--r--   0        0        0     1473 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/gradient/gradient_api.rst
+-rw-r--r--   0        0        0    10641 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/gradient/gradient_tutorial.rst
+-rw-r--r--   0        0        0      568 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/gradient/index.rst
+-rw-r--r--   0        0        0      664 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/loops/index.rst
+-rwxr-xr-x   0        0        0     2517 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/loops/loop_solution_1.py
+-rw-r--r--   0        0        0    26346 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/loops/loops_api.rst
+-rw-r--r--   0        0        0    12565 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/loops/loops_tutorial.rst
+-rw-r--r--   0        0        0    17090 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/loops/scan_extend.rst
+-rw-r--r--   0        0        0    11127 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/random/index.rst
+-rw-r--r--   0        0        0    25804 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/bcast.png
+-rw-r--r--   0        0        0    14117 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/bcast.svg
+-rw-r--r--   0        0        0    13545 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/create.rst
+-rw-r--r--   0        0        0     1038 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/index.rst
+-rw-r--r--   0        0        0      670 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.binary_operations.rst
+-rw-r--r--   0        0        0      540 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.discrete_fourier.rst
+-rw-r--r--   0        0        0     1133 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.indexing.rst
+-rw-r--r--   0        0        0     8403 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.linalg.rst
+-rw-r--r--   0        0        0      681 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.logic.rst
+-rw-r--r--   0        0        0     2388 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.mathematical_functions.rst
+-rw-r--r--   0        0        0      197 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.padding.rst
+-rw-r--r--   0        0        0      977 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.rst
+-rw-r--r--   0        0        0      264 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.sorting.rst
+-rw-r--r--   0        0        0      175 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.statistics.rst
+-rw-r--r--   0        0        0     2041 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.tensor_creation.rst
+-rw-r--r--   0        0        0     5922 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.tensor_manipulation.rst
+-rw-r--r--   0        0        0      164 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/operations.window_functions.rst
+-rw-r--r--   0        0        0     6183 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/shapes.rst
+-rw-r--r--   0        0        0     6057 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/tensor.rst
+-rw-r--r--   0        0        0       90 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/utils.rst
+-rw-r--r--   0        0        0    11485 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/shared/aliasing.rst
+-rw-r--r--   0        0        0      113 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/shared/index.rst
+-rw-r--r--   0        0        0       51 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/shared/shared.rst
+-rw-r--r--   0        0        0     8470 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/index.rst
+-rw-r--r--   0        0        0      532 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/sandbox.rst
+-rw-r--r--   0        0        0    11274 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/sparse_api.rst
+-rw-r--r--   0        0        0    12643 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/ccodegen.rst
+-rw-r--r--   0        0        0      160 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/compilation.rst
+-rw-r--r--   0        0        0     2906 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/debugging_with_stepmode.rst
+-rw-r--r--   0        0        0     5889 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/elemwise_compiler.rst
+-rw-r--r--   0        0        0       83 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/function.rst
+-rw-r--r--   0        0        0      164 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/functional.rst
+-rw-r--r--   0        0        0      205 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/index.rst
+-rw-r--r--   0        0        0      230 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/index2.rst
+-rw-r--r--   0        0        0     2360 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/interactive_debugger.rst
+-rw-r--r--   0        0        0     2618 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/logistic_regression_example.rst
+-rw-r--r--   0        0        0      747 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/performance.rst
+-rw-r--r--   0        0        0    10482 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/randomnumbers.rst
+-rw-r--r--   0        0        0     4261 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/rethinkccodegen.rst
+-rw-r--r--   0        0        0     5946 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/sandbox.rst
+-rw-r--r--   0        0        0      985 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/software.rst
+-rw-r--r--   0        0        0     6172 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/sparse.rst
+-rw-r--r--   0        0        0      117 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/sandbox/tensoroptools.rst
+-rw-r--r--   0        0        0     3886 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/scripts/docgen.py
+-rw-r--r--   0        0        0      117 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/serializing/index.rst
+-rw-r--r--   0        0        0     5988 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/serializing/loading_and_saving.rst
+-rw-r--r--   0        0        0      411 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/serializing/pkl_utils.rst
+-rw-r--r--   0        0        0       48 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/breakpoints.rst
+-rw-r--r--   0        0        0    55147 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz.png
+-rw-r--r--   0        0        0    23084 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/debug_faq.rst
+-rw-r--r--   0        0        0      265 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/index.rst
+-rw-r--r--   0        0        0       72 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/interacting_with_graph.rst
+-rw-r--r--   0        0        0   106142 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_predict.png
+-rw-r--r--   0        0        0   148860 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_prediction.png
+-rw-r--r--   0        0        0   473403 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_train.png
+-rw-r--r--   0        0        0     4366 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/nan_tutorial.rst
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/optimisations.rst
+-rw-r--r--   0        0        0     7161 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/printing.rst
+-rw-r--r--   0        0        0     4918 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/printing_drawing.rst
+-rw-r--r--   0        0        0     3716 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/profiling.rst
+-rw-r--r--   0        0        0     1552 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/profiling_example_out.prof
+-rw-r--r--   0        0        0    11515 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/troubleshooting.rst
+-rw-r--r--   0        0        0   216157 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index.ipynb
+-rw-r--r--   0        0        0     8530 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index.rst
+-rw-r--r--   0        0        0     6168 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp.html
+-rw-r--r--   0        0        0    84140 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp.png
+-rw-r--r--   0        0        0     6406 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.html
+-rw-r--r--   0        0        0    13875 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.pdf
+-rw-r--r--   0        0        0    46699 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.png
+-rw-r--r--   0        0        0     8963 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/ofg.html
+-rw-r--r--   0        0        0     8115 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/ofg2.html
+-rw-r--r--   0        0        0      448 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/css/d3-context-menu.css
+-rw-r--r--   0        0        0     1302 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/css/d3viz.css
+-rw-r--r--   0        0        0     1203 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3-context-menu.js
+-rw-r--r--   0        0        0   151143 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3.v3.min.js
+-rw-r--r--   0        0        0    23339 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3viz.js
+-rw-r--r--   0        0        0    47566 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/dagre-d3.min.js
+-rw-r--r--   0        0        0   115617 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/graphlib-dot.min.js
+-rw-r--r--   0        0        0    93049 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_10_0.png
+-rw-r--r--   0        0        0    93049 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_11_0.png
+-rw-r--r--   0        0        0    46699 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_24_0.png
+-rw-r--r--   0        0        0    46699 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_25_0.png
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/__init__.py
+-rw-r--r--   0        0        0     2922 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_breakpoint.py
+-rw-r--r--   0        0        0    10470 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_config.py
+-rw-r--r--   0        0        0    34472 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_gradient.py
+-rw-r--r--   0        0        0    25050 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_ifelse.py
+-rw-r--r--   0        0        0    13025 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_printing.py
+-rw-r--r--   0        0        0     5383 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_raise_op.py
+-rw-r--r--   0        0        0    13207 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_rop.py
+-rw-r--r--   0        0        0     1679 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/test_updates.py
+-rw-r--r--   0        0        0    14042 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/unittest_tools.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/__init__.py
+-rw-r--r--   0        0        0    24285 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_builders.py
+-rw-r--r--   0        0        0     3917 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_compilelock.py
+-rw-r--r--   0        0        0    25864 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_debugmode.py
+-rw-r--r--   0        0        0     2161 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_misc.py
+-rw-r--r--   0        0        0     4687 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_mode.py
+-rw-r--r--   0        0        0     3259 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_monitormode.py
+-rw-r--r--   0        0        0     2479 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_nanguardmode.py
+-rw-r--r--   0        0        0     2026 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_ops.py
+-rw-r--r--   0        0        0     3557 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_profiling.py
+-rw-r--r--   0        0        0    10290 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/test_shared.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/function/__init__.py
+-rw-r--r--   0        0        0     7284 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/function/test_function.py
+-rw-r--r--   0        0        0    36404 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/function/test_pfunc.py
+-rw-r--r--   0        0        0    42215 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/compile/function/test_types.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/d3viz/__init__.py
+-rw-r--r--   0        0        0     1746 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/d3viz/models.py
+-rw-r--r--   0        0        0     1790 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/d3viz/test_d3viz.py
+-rw-r--r--   0        0        0     2102 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/d3viz/test_formatting.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/__init__.py
+-rw-r--r--   0        0        0    23703 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_basic.py
+-rw-r--r--   0        0        0    10663 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_compute_test_value.py
+-rw-r--r--   0        0        0    14846 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_destroyhandler.py
+-rw-r--r--   0        0        0     6933 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_features.py
+-rw-r--r--   0        0        0    22433 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_fg.py
+-rw-r--r--   0        0        0     6511 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_op.py
+-rw-r--r--   0        0        0     2089 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_sched.py
+-rw-r--r--   0        0        0     1326 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_types.py
+-rw-r--r--   0        0        0      389 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/test_utils.py
+-rw-r--r--   0        0        0     4119 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/__init__.py
+-rw-r--r--   0        0        0    28891 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/test_basic.py
+-rw-r--r--   0        0        0     2890 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/test_db.py
+-rw-r--r--   0        0        0     5385 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/test_kanren.py
+-rw-r--r--   0        0        0     8469 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/test_unify.py
+-rw-r--r--   0        0        0     5006 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/graph/rewriting/test_utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/__init__.py
+-rw-r--r--   0        0        0     7491 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/test_link.py
+-rw-r--r--   0        0        0     5653 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/test_utils.py
+-rw-r--r--   0        0        0    14430 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/test_vm.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/__init__.py
+-rw-r--r--   0        0        0    13074 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/test_basic.py
+-rw-r--r--   0        0        0     9069 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/test_cmodule.py
+-rw-r--r--   0        0        0     6848 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/test_op.py
+-rw-r--r--   0        0        0    12881 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/test_params_type.py
+-rw-r--r--   0        0        0     8730 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/test_type.py
+-rw-r--r--   0        0        0      144 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/c_code/test_cenum.h
+-rw-r--r--   0        0        0     2010 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/c/c_code/test_quadratic_function.c
+-rw-r--r--   0        0        0     5992 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_basic.py
+-rw-r--r--   0        0        0     4191 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_elemwise.py
+-rw-r--r--   0        0        0     4200 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_extra_ops.py
+-rw-r--r--   0        0        0     4681 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_nlinalg.py
+-rw-r--r--   0        0        0    18756 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_random.py
+-rw-r--r--   0        0        0     5652 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_scalar.py
+-rw-r--r--   0        0        0     4068 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_scan.py
+-rw-r--r--   0        0        0     2707 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_shape.py
+-rw-r--r--   0        0        0     3545 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_slinalg.py
+-rw-r--r--   0        0        0     8582 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_subtensor.py
+-rw-r--r--   0        0        0     2797 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/jax/test_tensor_basic.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/__init__.py
+-rw-r--r--   0        0        0    30411 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_basic.py
+-rw-r--r--   0        0        0    15952 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_elemwise.py
+-rw-r--r--   0        0        0    13197 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_extra_ops.py
+-rw-r--r--   0        0        0    12589 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_nlinalg.py
+-rw-r--r--   0        0        0     2038 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_performance.py
+-rw-r--r--   0        0        0    16845 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_random.py
+-rw-r--r--   0        0        0     4012 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_scalar.py
+-rw-r--r--   0        0        0    10723 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_scan.py
+-rw-r--r--   0        0        0     2353 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_sparse.py
+-rw-r--r--   0        0        0    10235 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/link/numba/test_tensor_basic.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/misc/__init__.py
+-rw-r--r--   0        0        0     3533 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/misc/test_may_share_memory.py
+-rw-r--r--   0        0        0     2212 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/misc/test_pkl_utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/__init__.py
+-rw-r--r--   0        0        0      836 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/test_minimal.py
+-rw-r--r--   0        0        0     3777 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/test_multinomial.py
+-rw-r--r--   0        0        0     7233 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/test_multinomial_wo_replacement.py
+-rw-r--r--   0        0        0    34649 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/test_rng_mrg.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/linalg/__init__.py
+-rw-r--r--   0        0        0     4367 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sandbox/linalg/test_linalg.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scalar/__init__.py
+-rw-r--r--   0        0        0    16995 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scalar/test_basic.py
+-rw-r--r--   0        0        0      991 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scalar/test_basic_sympy.py
+-rw-r--r--   0        0        0     2539 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scalar/test_math.py
+-rw-r--r--   0        0        0     1897 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scalar/test_type.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/__init__.py
+-rw-r--r--   0        0        0   133995 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_basic.py
+-rw-r--r--   0        0        0     1777 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_checkpoints.py
+-rw-r--r--   0        0        0    25319 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_printing.py
+-rw-r--r--   0        0        0    56551 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_rewriting.py
+-rw-r--r--   0        0        0    17205 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_utils.py
+-rw-r--r--   0        0        0     4534 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/scan/test_views.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/__init__.py
+-rw-r--r--   0        0        0   116949 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_basic.py
+-rw-r--r--   0        0        0     5942 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_rewriting.py
+-rw-r--r--   0        0        0      373 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_sharedvar.py
+-rw-r--r--   0        0        0     4094 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_sp2.py
+-rw-r--r--   0        0        0     2485 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_type.py
+-rw-r--r--   0        0        0     1608 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_utils.py
+-rw-r--r--   0        0        0     8061 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/test_var.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/sandbox/__init__.py
+-rw-r--r--   0        0        0     9198 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/sparse/sandbox/test_sp.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/__init__.py
+-rw-r--r--   0        0        0     1475 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/_test_mpi_roundtrip.py
+-rw-r--r--   0        0        0   148595 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_basic.py
+-rw-r--r--   0        0        0    99618 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_blas.py
+-rw-r--r--   0        0        0    14554 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_blas_c.py
+-rw-r--r--   0        0        0     2550 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_blas_scipy.py
+-rw-r--r--   0        0        0     4161 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_casting.py
+-rw-r--r--   0        0        0     4344 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_complex.py
+-rw-r--r--   0        0        0    34431 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_elemwise.py
+-rw-r--r--   0        0        0    47336 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_extra_ops.py
+-rw-r--r--   0        0        0     6580 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_fft.py
+-rw-r--r--   0        0        0     2218 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_fourier.py
+-rw-r--r--   0        0        0     4059 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_gc.py
+-rw-r--r--   0        0        0    11957 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_inplace.py
+-rw-r--r--   0        0        0     2080 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_io.py
+-rw-r--r--   0        0        0     6667 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_keepdims.py
+-rw-r--r--   0        0        0   123957 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_math.py
+-rw-r--r--   0        0        0    29972 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_math_scipy.py
+-rw-r--r--   0        0        0     2345 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_merge.py
+-rw-r--r--   0        0        0     2467 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_misc.py
+-rw-r--r--   0        0        0     2946 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_mpi.py
+-rw-r--r--   0        0        0    14603 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_nlinalg.py
+-rw-r--r--   0        0        0    22601 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_shape.py
+-rw-r--r--   0        0        0    27332 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_sharedvar.py
+-rw-r--r--   0        0        0    18787 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_slinalg.py
+-rw-r--r--   0        0        0    18538 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_sort.py
+-rw-r--r--   0        0        0     5148 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_special.py
+-rw-r--r--   0        0        0    91191 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_subtensor.py
+-rw-r--r--   0        0        0     9802 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_type.py
+-rw-r--r--   0        0        0     1766 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_type_other.py
+-rw-r--r--   0        0        0     2417 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_utils.py
+-rw-r--r--   0        0        0    12727 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_var.py
+-rw-r--r--   0        0        0      716 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/test_xlogx.py
+-rw-r--r--   0        0        0    38712 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/utils.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/__init__.py
+-rw-r--r--   0        0        0    15242 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/speed_test_conv.py
+-rw-r--r--   0        0        0   103862 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_abstract_conv.py
+-rw-r--r--   0        0        0    42020 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_basic.py
+-rw-r--r--   0        0        0    25674 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_batchnorm.py
+-rw-r--r--   0        0        0    10203 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_blocksparse.py
+-rw-r--r--   0        0        0    28956 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_conv.py
+-rw-r--r--   0        0        0     6947 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_conv3d2d.py
+-rw-r--r--   0        0        0    21906 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_corr.py
+-rw-r--r--   0        0        0    21818 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_corr3d.py
+-rw-r--r--   0        0        0     6197 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_ctc.py
+-rw-r--r--   0        0        0    25410 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_neighbours.py
+-rw-r--r--   0        0        0     1694 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_rewriting.py
+-rw-r--r--   0        0        0     4825 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/nnet/test_sigm.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/__init__.py
+-rw-r--r--   0        0        0    41556 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_basic.py
+-rw-r--r--   0        0        0     5974 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_op.py
+-rw-r--r--   0        0        0    17712 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_rewriting.py
+-rw-r--r--   0        0        0     6674 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_type.py
+-rw-r--r--   0        0        0    10653 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_utils.py
+-rw-r--r--   0        0        0     3642 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/random/test_var.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/__init__.py
+-rw-r--r--   0        0        0    63207 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_basic.py
+-rw-r--r--   0        0        0    41140 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_elemwise.py
+-rw-r--r--   0        0        0    10481 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_extra_ops.py
+-rw-r--r--   0        0        0   166414 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_math.py
+-rw-r--r--   0        0        0    18170 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_shape.py
+-rw-r--r--   0        0        0     4483 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_special.py
+-rw-r--r--   0        0        0    80378 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_subtensor.py
+-rw-r--r--   0        0        0     7105 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/rewriting/test_uncanonicalize.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/signal/__init__.py
+-rw-r--r--   0        0        0     4145 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/signal/test_conv.py
+-rw-r--r--   0        0        0    51694 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/tensor/signal/test_pool.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/typed_list/__init__.py
+-rw-r--r--   0        0        0    17535 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/typed_list/test_basic.py
+-rw-r--r--   0        0        0     4926 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/typed_list/test_rewriting.py
+-rw-r--r--   0        0        0     4903 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/tests/typed_list/test_type.py
+-rw-r--r--   0        0        0      669 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/.gitignore
+-rw-r--r--   0        0        0      809 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/DESCRIPTION.txt
+-rw-r--r--   0        0        0     2515 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/LICENSE.txt
+-rw-r--r--   0        0        0    10114 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/pyproject.toml
+-rw-r--r--   0        0        0     2572 2020-02-02 00:00:00.000000 aesara_nightly-2.9.0.post2/PKG-INFO
```

### Comparing `aesara-nightly-2.8.9.post118/DESCRIPTION.txt` & `aesara_nightly-2.9.0.post2/DESCRIPTION.txt`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/LICENSE.txt` & `aesara_nightly-2.9.0.post2/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/PKG-INFO` & `aesara_nightly-2.9.0.post2/PKG-INFO`

 * *Files 17% similar despite different names*

```diff
@@ -1,40 +1,48 @@
 Metadata-Version: 2.1
 Name: aesara-nightly
-Version: 2.8.9.post118
+Version: 2.9.0.post2
 Summary: A library for defining, optimizing, and efficiently evaluating mathematical expressions involving multi-dimensional arrays.
+Project-URL: Homepage, https://github.com/aesara-devs/aesara
 Author-email: aesara-devs <aesara.devs@gmail.com>
 License: BSD-3-Clause
-Project-URL: Homepage, https://github.com/aesara-devs/aesara
-Keywords: aesara,math,numerical,symbolic,blas,numpy,autodiff,differentiation
-Platform: Windows
-Platform: Linux
-Platform: Solaris
-Platform: Mac OS-X
-Platform: Unix
+License-File: LICENSE.txt
+Keywords: aesara,autodiff,blas,differentiation,math,numerical,numpy,symbolic
 Classifier: Development Status :: 6 - Mature
+Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Education
 Classifier: Intended Audience :: Science/Research
-Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: BSD License
-Classifier: Programming Language :: Python
-Classifier: Topic :: Software Development :: Code Generators
-Classifier: Topic :: Software Development :: Compilers
-Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Operating System :: MacOS
+Classifier: Operating System :: MacOS :: MacOS X
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX
+Classifier: Operating System :: POSIX :: Linux
+Classifier: Operating System :: POSIX :: SunOS/Solaris
 Classifier: Operating System :: Unix
-Classifier: Operating System :: MacOS
+Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
-Requires-Python: >=3.7
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Software Development :: Code Generators
+Classifier: Topic :: Software Development :: Compilers
+Requires-Python: >=3.8
+Requires-Dist: cons
+Requires-Dist: etuples
+Requires-Dist: filelock
+Requires-Dist: logical-unification
+Requires-Dist: minikanren
+Requires-Dist: numpy>=1.17.0
+Requires-Dist: scipy>=0.14
+Requires-Dist: setuptools>=48.0.0
+Requires-Dist: typing-extensions
 Description-Content-Type: text/x-rst
-License-File: LICENSE.txt
 
 Aesara is a Python library that allows you to define, optimize, and efficiently evaluate mathematical expressions involving multi-dimensional arrays. It is built on top of NumPy_. Aesara features:
 
  * **tight integration with NumPy:** a similar interface to NumPy's. numpy.ndarrays are also used internally in Aesara-compiled functions.
  * **efficient symbolic differentiation:** Aesara can compute derivatives for functions of one or many inputs.
  * **speed and stability optimizations:** avoid nasty bugs when computing expressions such as log(1 + exp(x)) for large values of x.
  * **dynamic C code generation:** evaluate expressions faster.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/bin/aesara_cache.py` & `aesara_nightly-2.9.0.post2/aesara/bin/aesara_cache.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/breakpoint.py` & `aesara_nightly-2.9.0.post2/aesara/breakpoint.py`

 * *Files 1% similar despite different names*

```diff
@@ -65,15 +65,14 @@
 
     __props__ = ("name",)
 
     def __init__(self, name):
         self.name = name
 
     def make_node(self, condition, *monitored_vars):
-
         # Ensure that condition is an Aesara tensor
         if not isinstance(condition, Variable):
             condition = as_tensor_variable(condition)
 
         # Validate that the condition is a scalar (else it is not obvious how
         # is should be evaluated)
         assert condition.ndim == 0
@@ -146,15 +145,14 @@
         return [DisconnectedType()()] + output_gradients
 
     def infer_shape(self, fgraph, inputs, input_shapes):
         # Return the shape of every input but the condition (first input)
         return input_shapes[1:]
 
     def connection_pattern(self, node):
-
         nb_inp = len(node.inputs)
         nb_out = nb_inp - 1
 
         # First input is connected to no output and every other input n is
         # connected to input n-1
         connections = [
             [out_idx == inp_idx - 1 for out_idx in range(nb_out)]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/compile/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/builders.py` & `aesara_nightly-2.9.0.post2/aesara/compile/builders.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 """Define new Ops from existing Ops"""
 from collections import OrderedDict
 from copy import copy
 from functools import partial
-from typing import Dict, List, Optional, Sequence, Tuple, cast
+from typing import List, Optional, Sequence, Tuple, cast
 
 import aesara.tensor as at
-from aesara import function
 from aesara.compile.function.pfunc import rebuild_collect_shared
+from aesara.compile.io import In, Out
 from aesara.compile.mode import optdb
+from aesara.compile.ops import update_placeholder
 from aesara.compile.sharedvalue import SharedVariable
 from aesara.configdefaults import config
 from aesara.gradient import DisconnectedType, Rop, grad
 from aesara.graph.basic import (
     Apply,
     Constant,
     NominalVariable,
@@ -42,15 +43,16 @@
     # let it initialize itself with an empty fgraph, otherwise we will
     # need to do it manually
     for inp, inp_shp in zip(inputs, input_shapes):
         if inp_shp is not None and len(inp_shp) != inp.type.ndim:
             assert len(inp_shp) == inp.type.ndim
 
     shape_feature = ShapeFeature()
-    shape_feature.on_attach(FunctionGraph([], []))
+    dummy_fgraph = FunctionGraph([], [])
+    shape_feature.on_attach(dummy_fgraph)
 
     # Initialize shape_of with the input shapes
     for inp, inp_shp in zip(inputs, input_shapes):
         shape_feature.set_shape(inp, inp_shp)
 
     def local_traverse(out):
         """
@@ -67,33 +69,45 @@
             # Recurse over inputs
             for inp in out.owner.inputs:
                 if inp not in shape_feature.shape_of:
                     local_traverse(inp)
 
             # shape_feature.on_import does not actually use an fgraph
             # It will call infer_shape and set_shape appropriately
-            dummy_fgraph = None
             shape_feature.on_import(dummy_fgraph, out.owner, reason="dummy")
 
     ret = []
     for o in outs:
         local_traverse(o)
         ret.append(shape_feature.shape_of[o])
     return ret
 
 
 def construct_nominal_fgraph(
     inputs: Sequence[Variable], outputs: Sequence[Variable]
-) -> Tuple[
-    FunctionGraph,
-    Sequence[Variable],
-    Dict[Variable, Variable],
-    Dict[Variable, Variable],
-]:
-    """Construct an inner-`FunctionGraph` with ordered nominal inputs."""
+) -> Tuple[FunctionGraph, Sequence[Variable],]:
+    r"""Construct an inner-`FunctionGraph` with ordered nominal inputs.
+
+    .. note::
+
+        Updates (e.g. from `SharedVariable.default_update`) are appended to the resulting
+        `FunctionGraph`'s outputs.
+
+    Parameters
+    ==========
+    inputs
+        A list of inputs.
+    outputs
+        A list of outputs.
+
+    Returns
+    =======
+    The `FunctionGraph` and a list of shared inputs.
+
+    """
     dummy_inputs = []
     for n, inp in enumerate(inputs):
         if (
             not isinstance(inp, Variable)
             or isinstance(inp, Constant)
             or isinstance(inp, SharedVariable)
         ):
@@ -101,47 +115,62 @@
                 f"Inputs and outputs must be non-Constant/shared Variable instances; got {inp}"
             )
 
         dummy_inputs.append(inp.type())
 
     dummy_shared_inputs = []
     shared_inputs = []
+    default_updates = {}
     for var in graph_inputs(outputs, inputs):
         if isinstance(var, SharedVariable):
             # To correctly support shared variables the inner-graph should
             # not see them; otherwise, there will be problems with
             # gradients.
             # That's why we collect the shared variables and replace them
             # with dummies.
             shared_inputs.append(var)
-            dummy_shared_inputs.append(var.type())
+            dummy_var = var.type()
+            dummy_shared_inputs.append(dummy_var)
+
+            if var.default_update:
+                default_updates[dummy_var] = var.default_update
         elif var not in inputs and not isinstance(var, Constant):
             raise MissingInputError(f"OpFromGraph is missing an input: {var}")
 
     replacements = dict(zip(inputs + shared_inputs, dummy_inputs + dummy_shared_inputs))
 
     new = rebuild_collect_shared(
-        cast(Sequence[Variable], outputs),
+        outputs=cast(Sequence[Variable], outputs + list(default_updates.values())),
         inputs=inputs + shared_inputs,
         replace=replacements,
         copy_inputs_over=False,
     )
     (
         local_inputs,
         local_outputs,
         (clone_d, update_d, update_expr, new_shared_inputs),
     ) = new
 
+    local_default_updates = local_outputs[len(outputs) :]
+    update_d.update(
+        {clone_d[k]: v for k, v in zip(default_updates.keys(), local_default_updates)}
+    )
+    update_expr.extend(local_default_updates)
+
     assert len(local_inputs) == len(inputs) + len(shared_inputs)
-    assert len(local_outputs) == len(outputs)
-    assert not update_d
-    assert not update_expr
+    assert len(local_outputs) == len(outputs) + len(default_updates)
     assert not new_shared_inputs
 
-    fgraph = FunctionGraph(local_inputs, local_outputs, clone=False)
+    update_mapping = {
+        local_outputs.index(v): local_inputs.index(k) for k, v in update_d.items()
+    }
+
+    fgraph = FunctionGraph(
+        local_inputs, local_outputs, clone=False, update_mapping=update_mapping
+    )
 
     # The inputs need to be `NominalVariable`s so that we can merge
     # inner-graphs
     nominal_local_inputs = tuple(
         NominalVariable(n, var.type) for n, var in enumerate(local_inputs)
     )
 
@@ -149,15 +178,15 @@
 
     for i, inp in enumerate(fgraph.inputs):
         nom_inp = nominal_local_inputs[i]
         fgraph.inputs[i] = nom_inp
         fgraph.clients.pop(inp, None)
         fgraph.add_input(nom_inp)
 
-    return fgraph, shared_inputs, update_d, update_expr
+    return fgraph, shared_inputs
 
 
 class OpFromGraph(Op, HasInnerGraph):
     r"""
     This creates an `Op` from inputs and outputs lists of variables.
     The signature is similar to :func:`aesara.function <aesara.function>`
     and the resulting `Op`'s perform will do the same operation as::
@@ -312,54 +341,61 @@
         lop_overrides: str = "default",
         grad_overrides: str = "default",
         rop_overrides: str = "default",
         connection_pattern: Optional[List[List[bool]]] = None,
         name: Optional[str] = None,
         **kwargs,
     ):
-        """
+        r"""Construct an `OpFromGraph` instance.
+
+        .. note::
+
+            `SharedVariable`\s in `outputs` will have their `SharedVariable.default_update` values
+            altered in order to support in-lining in the presence of updates.
+
         Parameters
         ----------
         inputs
             The inputs to the graph.
         outputs
             The outputs to the graph.
         inline
-            Defaults to ``False``
-
             ``True`` : Cause the :class:`Op`'s original graph being used during
             compilation, the :class:`Op` will not be visible in the compiled
             graph but rather its internal graph.
 
             ``False`` : will use a pre-compiled function inside.
+
+            Defaults to ``False``.
+
         grad_overrides
-            Defaults to ``'default'``.
             This argument is mutually exclusive with ``lop_overrides``.
 
-            ``'default'`` : Do not override, use default grad() result
+            ``'default'`` : Do not override, use default :meth:`Op.grad` result
 
             `OpFromGraph`: Override with another `OpFromGraph`, should
             accept inputs as the same order and types of ``inputs`` and ``output_grads``
-            arguments as one would specify in :meth:`Op.grad`() method.
+            arguments as one would specify in :meth:`Op.grad` method.
 
             `callable`: Should take two args: ``inputs`` and ``output_grads``.
             Each argument is expected to be a list of :class:`Variable `.
             Must return list of :class:`Variable `.
-        lop_overrides
+
             Defaults to ``'default'``.
 
+        lop_overrides
             This argument is mutually exclusive with ``grad_overrides``.
 
             These options are similar to the ``grad_overrides`` above, but for
             the :meth:`Op.L_op` method.
 
             ``'default'``: Do not override, use the default :meth:`Op.L_op` result
 
             `OpFromGraph`: Override with another `OpFromGraph`, should
-            accept inputs as the same order and types of ``inputs``,
+            accept inputs in the same order and types as `inputs`,
             ``outputs`` and ``output_grads`` arguments as one would specify in
             :meth:`Op.grad` method.
 
             `callable`: Should take three args: ``inputs``, ``outputs`` and ``output_grads``.
             Each argument is expected to be a list of :class:`Variable`.
             Must return list of :class:`Variable`.
 
@@ -367,19 +403,19 @@
             `DisconnectedType` instance: Treat as disconnected gradient,
             numerically gives zero
 
             ``list``: Each `OpFromGraph`/callable must return a single
             :class:`Variable`. Each list element corresponds to gradient of
             a specific input, length of list must be equal to number of inputs.
 
+            Defaults to ``'default'``.
+
         rop_overrides
             One of ``{'default', OpFromGraph, callable, Variable}``.
 
-            Defaults to ``'default'``.
-
             ``'default'``: Do not override, use the default :meth:`Op.R_op` result
 
             `OpFromGraph`: Override with another `OpFromGraph`, should
             accept inputs as the same order and types of ``inputs`` and ``eval_points``
             arguments as one would specify in :meth:`Op.R_op` method.
 
             `callable`: Should take two args: ``inputs`` and ``eval_points``.
@@ -393,19 +429,21 @@
             ``list``:
             Each :class:`OpFromGraph`/callable must return a single
             :class:`Variable <aesara.graph.basic.Variable>`. Each list element
             corresponds to a specific output of :meth:`Op.R_op`, length of list
             must be equal to number of outputs.  connection_pattern If not
             ``None``, this will be used as the connection_pattern for this
             :class:`Op`.
+
+            Defaults to ``'default'``.
+
         name
             A name for debugging purposes.
         kwargs
-            Check :func:`aesara.function` for more arguments, only works when not
-            inline.
+            See :func:`aesara.function`.
         """
 
         if not (isinstance(inputs, list) and isinstance(outputs, list)):
             raise TypeError("Inputs and outputs must be lists")
 
         for out in outputs:
             if not isinstance(out, Variable):
@@ -414,17 +452,32 @@
                 )
 
         if "updates" in kwargs or "givens" in kwargs:
             raise NotImplementedError("Updates and givens are not supported")
 
         self.is_inline = inline
 
-        self.fgraph, self.shared_inputs, _, _ = construct_nominal_fgraph(
-            inputs, outputs
-        )
+        # These `shared_inputs` are the original variables in `outputs`
+        # (i.e. not clones).
+        self.fgraph, shared_inputs = construct_nominal_fgraph(inputs, outputs)
+
+        # We need to hold on to the original variables so that gradients can be
+        # taken wrt. them.  Ideally, we wouldn't hold on to specific `Variable`
+        # references like this outside of graph, but we're maintaining support
+        # for old functionality right now.
+        self.shared_inputs = []
+        for v in shared_inputs:
+            # This is needed so that `aesara.function` will create an update
+            # output placeholder in the `FunctionGraph` it compiles.  We need
+            # placeholders like this in order to properly inline `OpFromGraph`s
+            # containing updates.
+            # FYI: When the corresponding updates aren't used, they should be
+            # removed at the `aesara.function` level.
+            v.default_update = update_placeholder(v)
+            self.shared_inputs.append(v)
 
         self.kwargs = kwargs
         self.input_types = [inp.type for inp in inputs]
         self.output_types = [out.type for out in outputs]
 
         self.lop_overrides = lop_overrides
         self.grad_overrides = grad_overrides
@@ -896,15 +949,14 @@
         # TODO in case DisconnectedType is implemented for R_op,
         # self._rop_op_stypes_l self._rop_op should considered for
         # connection_pattern
 
         return list(map(list, cpmat_self))
 
     def infer_shape(self, fgraph, node, shapes):
-
         # TODO: Use `fgraph.shape_feature` to do this instead.
         out_shapes = infer_shape(self.inner_outputs, self.inner_inputs, shapes)
 
         # Clone the output shape so that shape are computed from outer inputs.
         # Note:
         # Here we could do it more simply like:
         # `ret = [aesara.clone_replace(shp, replace=repl) for shp in out_shp]`
@@ -929,55 +981,113 @@
 
     @property
     def fn(self):
         """Lazily compile the inner function graph."""
         if getattr(self, "_fn", None) is not None:
             return self._fn
 
-        self._fn = function(self.inner_inputs, self.inner_outputs, **self.kwargs)
+        from aesara.compile.function.pfunc import pfunc
+
+        # We don't want calls/evaluations of this `Op` to change
+        # the inner-graph, so we need to clone it
+        fgraph, _ = self.fgraph.clone_get_equiv(copy_inputs=False, copy_orphans=False)
+
+        wrapped_inputs = [In(x, borrow=False) for x in fgraph.inputs]
+        wrapped_outputs = [Out(x, borrow=True) for x in fgraph.outputs]
+
+        n_inputs = len(fgraph.inputs)
+
+        for out_idx, in_idx in fgraph.update_mapping.items():
+            shared_input = self.shared_inputs[in_idx - n_inputs]
+            in_var = fgraph.inputs[in_idx]
+            updated_wrapped_input = In(
+                variable=in_var,
+                value=shared_input.container,
+                update=fgraph.outputs[out_idx],
+                implicit=True,
+                shared=True,
+            )
+            wrapped_inputs[in_idx] = updated_wrapped_input
+
+        self._fn = pfunc(
+            wrapped_inputs,
+            wrapped_outputs,
+            fgraph=fgraph,
+            no_default_updates=True,
+            **self.kwargs,
+        )
         self._fn.trust_input = True
 
         return self._fn
 
     @property
     def inner_inputs(self):
         return self.fgraph.inputs
 
     @property
     def inner_outputs(self):
+        """Return all the outputs except those used for updates."""
+        n_updates = len(self.fgraph.update_mapping)
+        if n_updates > 0:
+            return self.fgraph.outputs[:-n_updates]
+
         return self.fgraph.outputs
 
     def clone(self):
         res = copy(self)
         res.fgraph = res.fgraph.clone()
         return res
 
     def perform(self, node, inputs, outputs):
-        variables = self.fn(*inputs)
-        assert len(variables) == len(outputs)
-        for output, variable in zip(outputs, variables):
-            output[0] = variable
+        results = self.fn(*inputs)
+        for output, res in zip(outputs, results):
+            output[0] = res
 
 
 @node_rewriter([OpFromGraph])
 def inline_ofg_expansion(fgraph, node):
-    """
-    This optimization expands internal graph of OpFromGraph.
-    Only performed if node.op.is_inline == True
-    Doing so can improve optimization at the cost of compilation speed.
+    """Expand the internal graph of an `OpFromGraph`.
+
+    Only performed if ``node.op.is_inline == True``.
+
     """
     op = node.op
-    if not isinstance(op, OpFromGraph):
-        return False
+
     if not op.is_inline:
         return False
-    return clone_replace(
-        op.inner_outputs, {u: v for u, v in zip(op.inner_inputs, node.inputs)}
+
+    outputs = clone_replace(
+        op.fgraph.outputs, {u: v for u, v in zip(op.inner_inputs, node.inputs)}
     )
 
+    replacements = {
+        old_var: new_var
+        for old_var, new_var in zip(node.outputs, outputs[: len(op.inner_outputs)])
+    }
+
+    # Add the updates from `OpFromGraph` into the outer-graph
+    for out_idx, in_idx in op.fgraph.update_mapping.items():
+        shared_input = node.inputs[in_idx]
+        assert isinstance(shared_input, SharedVariable)
+
+        outer_in_idx = fgraph.inputs.index(shared_input)
+
+        # There should be a placeholder output in `fgraph.outputs` that we can
+        # use.  If there isn't, then someone forgot/removed the
+        # `SharedVariable.default_update`s on the inputs to the `OpFromGraph`
+        # (i.e. at the user-level/graph construction-time).
+        outer_out_idx = fgraph.inv_update_mapping[outer_in_idx]
+        update_var = fgraph.outputs[outer_out_idx]
+
+        assert update_var is not shared_input
+
+        replacements[update_var] = outputs[out_idx]
+
+    return replacements
+
 
 # We want to run this before the first merge optimizer
 # and before the first scan optimizer.
 optdb.register(
     "inline_ofg_expansion",
     in2out(inline_ofg_expansion),
     "fast_compile",
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/compiledir.py` & `aesara_nightly-2.9.0.post2/aesara/compile/compiledir.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/compilelock.py` & `aesara_nightly-2.9.0.post2/aesara/compile/compilelock.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/debugmode.py` & `aesara_nightly-2.9.0.post2/aesara/compile/debugmode.py`

 * *Files 4% similar despite different names*

```diff
@@ -27,15 +27,15 @@
     std_fgraph,
 )
 from aesara.compile.mode import Mode, register_mode
 from aesara.compile.ops import OutputGuard, _output_guard
 from aesara.configdefaults import config
 from aesara.graph.basic import Variable, io_toposort
 from aesara.graph.destroyhandler import DestroyHandler
-from aesara.graph.features import AlreadyThere, BadOptimization
+from aesara.graph.features import AlreadyThere, BadOptimization, Feature
 from aesara.graph.op import HasInnerGraph, Op
 from aesara.graph.utils import InconsistencyError, MethodNotDefined
 from aesara.link.basic import Container, LocalLinker
 from aesara.link.c.op import COp
 from aesara.link.utils import map_storage, raise_with_op
 from aesara.printing import _debugprint
 from aesara.tensor import TensorType
@@ -433,15 +433,15 @@
 
     """
     equivalence_tracker = _VariableEquivalenceTracker()
     fgraph, updates = std_fgraph(
         input_specs, output_specs, accept_inplace, force_clone=True
     )
     fgraph.attach_feature(equivalence_tracker)
-    return fgraph, updates, equivalence_tracker
+    return fgraph, updates
 
 
 class DataDestroyed:
     # this is a singleton class We put it in the storage_map when the
     # variable value was destroyed to prevent reusing bad value for
     # it.
     pass
@@ -563,15 +563,14 @@
       in view_map.
     - If not aliased to an input, check if two outputs are aliased together
       and used subsequently in the graph.
 
     """
 
     for oi, onode in enumerate(node.outputs):
-
         good_alias, bad_alias = {}, {}
         outstorage = storage_map[onode][0]
 
         # first find out which input it aliases
         view_map = node.op.view_map
         destroy_map = node.op.destroy_map
 
@@ -586,21 +585,19 @@
                 # view. So no need to check. Also, we don't have the
                 # original value, we we wouldn't be able to do this
                 # useless check.
                 continue
             if hasattr(inode.type, "may_share_memory") and inode.type.may_share_memory(
                 outstorage, in_storage
             ):
-
                 nodeid = id(inode)
                 bad_alias[nodeid] = ii
 
                 # check that the aliasing was declared in [view|destroy]_map
                 if [ii] == view_map.get(oi, None) or [ii] == destroy_map.get(oi, None):
-
                     good_alias[nodeid] = bad_alias.pop(nodeid)
 
         # TODO: make sure this is correct
         # According to OB, duplicate inputs are rejected on build graph time
         # if they cause problems. So if they are here it should be ok.
         for key, val in good_alias.items():
             bad_alias.pop(key, None)
@@ -1006,15 +1003,15 @@
         dmap = node.op.destroy_map
         vmap = node.op.view_map
         for i, r in enumerate(node.inputs):
             if any(i in v for v in chain(dmap.values(), vmap.values())):
                 aliased_inputs.add(r)
 
         _logger.debug("starting preallocated output checking")
-        for (name, out_map) in _get_preallocated_maps(
+        for name, out_map in _get_preallocated_maps(
             node,
             thunk,
             prealloc_modes,
             def_val,
             storage_map,
             r_vals,
             dr_vals,
@@ -1168,115 +1165,100 @@
                 rval = rval and getattr(self, attr) == getattr(other, attr)
         return rval
 
     def __ne__(self, other):
         return not (self == other)
 
 
-class _VariableEquivalenceTracker:
+class _VariableEquivalenceTracker(Feature):
     """
     A FunctionGraph Feature that keeps tabs on an FunctionGraph and
     tries to detect problems.
 
     """
 
-    fgraph = None
-    """WRITEME"""
-
-    equiv = None
-    """WRITEME"""
-
-    active_nodes = None
-    """WRITEME"""
-
-    inactive_nodes = None
-    """WRITEME"""
-
-    all_variables_ever = None
-    """WRITEME"""
-
-    reasons = None
-    """WRITEME"""
-
-    replaced_by = None
-    """WRITEME"""
-
-    event_list = None
-    """WRITEME"""
-
-    def __init__(self):
-        self.fgraph = None
-
     def on_attach(self, fgraph):
-        if self.fgraph is not None:
+        if hasattr(fgraph, "_eq_tracker_equiv"):
             raise AlreadyThere()
 
-        self.equiv = {}
-        self.active_nodes = set()
-        self.inactive_nodes = set()
-        self.fgraph = fgraph
-        self.all_variables_ever = []
-        self.reasons = {}
-        self.replaced_by = {}
-        self.event_list = []
+        fgraph._eq_tracker_equiv = {}
+        fgraph._eq_tracker_active_nodes = set()
+        fgraph._eq_tracker_inactive_nodes = set()
+        fgraph._eq_tracker_fgraph = fgraph
+        fgraph._eq_tracker_all_variables_ever = []
+        fgraph._eq_tracker_reasons = {}
+        fgraph._eq_tracker_replaced_by = {}
+        fgraph._eq_tracker_event_list = []
+
         for node in fgraph.toposort():
-            self.on_import(fgraph, node, "on_attach")
+            self.on_import(fgraph, node, "var_equiv_on_attach")
 
     def on_detach(self, fgraph):
-        assert fgraph is self.fgraph
         self.fgraph = None
+        del fgraph._eq_tracker_equiv
+        del fgraph._eq_tracker_active_nodes
+        del fgraph._eq_tracker_inactive_nodes
+        del fgraph._eq_tracker_fgraph
+        del fgraph._eq_tracker_all_variables_ever
+        del fgraph._eq_tracker_reasons
+        del fgraph._eq_tracker_replaced_by
+        del fgraph._eq_tracker_event_list
 
     def on_prune(self, fgraph, node, reason):
-        self.event_list.append(_FunctionGraphEvent("prune", node, reason=str(reason)))
-        assert node in self.active_nodes
-        assert node not in self.inactive_nodes
-        self.active_nodes.remove(node)
-        self.inactive_nodes.add(node)
+        fgraph._eq_tracker_event_list.append(
+            _FunctionGraphEvent("prune", node, reason=str(reason))
+        )
+        assert node in fgraph._eq_tracker_active_nodes
+        assert node not in fgraph._eq_tracker_inactive_nodes
+        fgraph._eq_tracker_active_nodes.remove(node)
+        fgraph._eq_tracker_inactive_nodes.add(node)
 
     def on_import(self, fgraph, node, reason):
-        self.event_list.append(_FunctionGraphEvent("import", node, reason=str(reason)))
+        fgraph._eq_tracker_event_list.append(
+            _FunctionGraphEvent("import", node, reason=str(reason))
+        )
 
-        assert node not in self.active_nodes
-        self.active_nodes.add(node)
+        assert node not in fgraph._eq_tracker_active_nodes
+        fgraph._eq_tracker_active_nodes.add(node)
 
-        if node in self.inactive_nodes:
-            self.inactive_nodes.remove(node)
+        if node in fgraph._eq_tracker_inactive_nodes:
+            fgraph._eq_tracker_inactive_nodes.remove(node)
             for r in node.outputs:
-                assert r in self.equiv
+                assert r in fgraph._eq_tracker_equiv
         else:
             for r in node.outputs:
-                assert r not in self.equiv
-                self.equiv[r] = {r}
-                self.all_variables_ever.append(r)
-                self.reasons.setdefault(r, [])
-                self.replaced_by.setdefault(r, [])
+                assert r not in fgraph._eq_tracker_equiv
+                fgraph._eq_tracker_equiv[r] = {r}
+                fgraph._eq_tracker_all_variables_ever.append(r)
+                fgraph._eq_tracker_reasons.setdefault(r, [])
+                fgraph._eq_tracker_replaced_by.setdefault(r, [])
             for r in node.inputs:
-                self.reasons.setdefault(r, [])
-                self.replaced_by.setdefault(r, [])
+                fgraph._eq_tracker_reasons.setdefault(r, [])
+                fgraph._eq_tracker_replaced_by.setdefault(r, [])
 
     def on_change_input(self, fgraph, node, i, r, new_r, reason=None):
         reason = str(reason)
-        self.event_list.append(
+        fgraph._eq_tracker_event_list.append(
             _FunctionGraphEvent("change", node, reason=reason, idx=i)
         )
 
-        self.reasons.setdefault(new_r, [])
-        self.replaced_by.setdefault(new_r, [])
+        fgraph._eq_tracker_reasons.setdefault(new_r, [])
+        fgraph._eq_tracker_replaced_by.setdefault(new_r, [])
 
         append_reason = True
-        for tup in self.reasons[new_r]:
+        for tup in fgraph._eq_tracker_reasons[new_r]:
             if tup[0] == reason and tup[1] is r:
                 append_reason = False
 
         if append_reason:
             # N.B. compute the debugprint now, because future
             # optimizations will change the graph
             done = dict()
             used_ids = dict()
-            self.reasons[new_r].append(
+            fgraph._eq_tracker_reasons[new_r].append(
                 (
                     reason,
                     r,
                     _debugprint(
                         r,
                         prefix="  ",
                         depth=6,
@@ -1292,46 +1274,40 @@
                         file=StringIO(),
                         done=done,
                         print_type=True,
                         used_ids=used_ids,
                     ).getvalue(),
                 )
             )
-            self.replaced_by[r].append((reason, new_r))
+            fgraph._eq_tracker_replaced_by[r].append((reason, new_r))
 
-        if r in self.equiv:
-            r_set = self.equiv[r]
+        if r in fgraph._eq_tracker_equiv:
+            r_set = fgraph._eq_tracker_equiv[r]
         else:
-            r_set = self.equiv.setdefault(r, {r})
-            self.all_variables_ever.append(r)
+            r_set = fgraph._eq_tracker_equiv.setdefault(r, {r})
+            fgraph._eq_tracker_all_variables_ever.append(r)
 
-        if new_r in self.equiv:
-            new_r_set = self.equiv[new_r]
+        if new_r in fgraph._eq_tracker_equiv:
+            new_r_set = fgraph._eq_tracker_equiv[new_r]
         else:
-            new_r_set = self.equiv.setdefault(new_r, {new_r})
-            self.all_variables_ever.append(new_r)
+            new_r_set = fgraph._eq_tracker_equiv.setdefault(new_r, {new_r})
+            fgraph._eq_tracker_all_variables_ever.append(new_r)
 
         assert new_r in new_r_set
         assert r in r_set
 
         # update one equivalence set to contain the other
         # transfer all the elements of the old one to the new one
         r_set.update(new_r_set)
         for like_new_r in new_r_set:
-            self.equiv[like_new_r] = r_set
+            fgraph._eq_tracker_equiv[like_new_r] = r_set
             assert like_new_r in r_set
 
-        assert self.equiv[r] is r_set
-        assert self.equiv[new_r] is r_set
-
-    def printstuff(self):
-        for key in self.equiv:
-            print(key)
-            for e in self.equiv[key]:
-                print("  ", e)
+        assert fgraph._eq_tracker_equiv[r] is r_set
+        assert fgraph._eq_tracker_equiv[new_r] is r_set
 
 
 # List of default version of make thunk.
 # This is needed to know if the user overrode it.
 default_make_thunk = [get_unbound_function(COp.make_thunk)]
 
 
@@ -1378,17 +1354,15 @@
         fgraph = self.fgraph
         input_storage_ = input_storage
         output_storage_ = output_storage
 
         # Compute a topological ordering that IGNORES the destroy_map
         # of destructive Ops.  This will be OK, because every thunk is
         # evaluated on a copy of its input.
-        fgraph_equiv = fgraph.equivalence_tracker
-        order_outputs = copy.copy(fgraph_equiv.all_variables_ever)
-        del fgraph_equiv
+        order_outputs = copy.copy(fgraph._eq_tracker_all_variables_ever)
         order_outputs.reverse()
         order = io_toposort(fgraph.inputs, order_outputs)
 
         # an ordering of just the active nodes
         active_order = self.schedule(fgraph)
         active_order_set = set(active_order)
 
@@ -1614,15 +1588,15 @@
                             thunk_py = None
                             thunks_py[i] = None
                         except Exception as e:
                             # I think that only 1 optimization can
                             # insert a given apply node. If that is not True,
                             # we would need to loop over all node outputs,
                             # But this make the output uglier.
-                            reason = fgraph.equivalence_tracker.reasons[node.outputs[0]]
+                            reason = fgraph._eq_tracker_reasons[node.outputs[0]]
                             if not reason:
                                 raise
                             opt = str(reason[0][0])
                             msg = (
                                 f"An optimization (probably {opt}) inserted an "
                                 "apply node that raise an error."
                                 + "\nThe information we have about this "
@@ -1693,15 +1667,14 @@
                                 inplace_outs=py_inplace_outs,
                                 init_outputs=init_outputs,
                             )
 
                         sys.stdout.flush()
 
                     if thunk_c:
-
                         clobber = True
                         if thunk_py:
                             dmap = node.op.destroy_map
                             vmap = node.op.view_map
                             for i, r in enumerate(node.inputs):
                                 # if thunk_py ran, and we still got
                                 # this far, it means that the
@@ -1727,15 +1700,15 @@
                         try:
                             thunk_c()
                         except Exception as e:
                             # I think that only 1 optimization can
                             # insert a given apply node. If that is not True,
                             # we would need to loop over all node outputs,
                             # But this make the output uglier.
-                            reason = fgraph.equivalence_tracker.reasons[node.outputs[0]]
+                            reason = fgraph._eq_tracker_reasons[node.outputs[0]]
                             if not reason:
                                 raise
                             opt = str(reason[0][0])
                             msg = (
                                 f"An optimization (probably {opt}) inserted "
                                 "an apply node that raise an error."
                                 + "\nThe information we have about this "
@@ -1854,17 +1827,15 @@
                             raise Exception(f"No code run for {node}")
 
                 if False:
                     # This could be useful to help finding refcount problem.
                     # But it is very slow and it is not sure it will help.
                     gc.collect()
 
-                _find_bad_optimizations(
-                    order, fgraph.equivalence_tracker.reasons, r_vals
-                )
+                _find_bad_optimizations(order, fgraph._eq_tracker_reasons, r_vals)
 
                 #####
                 #  Postcondition: the input and output variables are
                 #  in the storage map, nothing more
                 #####
 
                 # Nothing should be in storage map after evaluating
@@ -2038,31 +2009,30 @@
         # Check if some input variables are unused
         self.check_unused_inputs(inputs, outputs, on_unused_input)
 
         indices = [[input, None, [input]] for input in inputs]
 
         # make the fgraph
         for i in range(mode.stability_patience):
-            fgraph, additional_outputs, equivalence_tracker = _optcheck_fgraph(
+            fgraph, additional_outputs = _optcheck_fgraph(
                 inputs, outputs, accept_inplace
             )
-            fgraph.equivalence_tracker = equivalence_tracker
 
             with config.change_flags(compute_test_value=config.compute_test_value_opt):
                 optimizer(fgraph)
 
                 aesara.compile.function.types.insert_deepcopy(
                     fgraph, inputs, list(chain(outputs, additional_outputs))
                 )
 
             if i == 0:
                 fgraph0 = fgraph
             else:
-                li = fgraph.equivalence_tracker.event_list
-                l0 = fgraph0.equivalence_tracker.event_list
+                li = fgraph._eq_tracker_event_list
+                l0 = fgraph0._eq_tracker_event_list
                 if li != l0:
                     infolog = StringIO()
                     print("Optimization process is unstable...", file=infolog)
                     print(
                         "  (HINT: Ops that the nodes point to must compare " "equal)",
                         file=infolog,
                     )
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/function/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/compile/function/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/function/pfunc.py` & `aesara_nightly-2.9.0.post2/aesara/compile/function/pfunc.py`

 * *Files 0% similar despite different names*

```diff
@@ -172,15 +172,15 @@
                 "input. Consider substituting a non-shared"
                 " variable via the `givens` parameter"
             )
 
     # Fill update_d and update_expr with provided updates
     if updates is None:
         updates = []
-    for (store_into, update_val) in iter_over_pairs(updates):
+    for store_into, update_val in iter_over_pairs(updates):
         if not isinstance(store_into, SharedVariable):
             raise TypeError("update target must be a SharedVariable", store_into)
         if store_into in update_d:
             raise ValueError(
                 "this shared variable already has an update " "expression",
                 (store_into, update_d[store_into]),
             )
@@ -467,15 +467,14 @@
                 "`aesara.function([y], f(x), givens={x: g(y)})`. Another "
                 "solution consists in using `aesara.clone_replace`, e.g. like this: "
                 "`aesara.function([x], "
                 "aesara.clone_replace(f(x), replace={x: g(x)}))`."
             )
 
     if not fgraph:
-
         # Extend the outputs with the updates on input variables so they are
         # also cloned
         additional_outputs = [i.update for i in inputs if i.update]
         if outputs is None:
             out_list = []
         else:
             if isinstance(outputs, (list, tuple)):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/function/types.py` & `aesara_nightly-2.9.0.post2/aesara/compile/function/types.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,22 +2,23 @@
 
 import copy
 import copyreg
 import logging
 import time
 import warnings
 from itertools import chain
-from typing import TYPE_CHECKING, List, Optional, Tuple, Type
+from typing import TYPE_CHECKING, Iterable, List, Literal, Optional, Tuple, Type, Union
 
 import numpy as np
 
 import aesara
 import aesara.compile.profiling
-from aesara.compile.io import In, SymbolicInput, SymbolicOutput
-from aesara.compile.ops import deep_copy_op, view_op
+from aesara.compile.io import In, Out, SymbolicInput, SymbolicOutput
+from aesara.compile.ops import deep_copy_op, update_placeholder, view_op
+from aesara.compile.profiling import ProfileStats
 from aesara.configdefaults import config
 from aesara.graph.basic import (
     Constant,
     Variable,
     ancestors,
     clone_get_equiv,
     graph_inputs,
@@ -136,39 +137,38 @@
     """
     Listener for FunctionGraph events which makes sure that no
     operation overwrites the contents of protected Variables. The
     outputs of the FunctionGraph are protected by default.
 
     """
 
-    def __init__(self, protected):
-        self.fgraph = None
-        self.protected = list(protected)
-
-    def clone(self):
-        return type(self)(self.protected)
+    def __init__(self, protected: Iterable[Variable]):
+        self.initial_protected = set(protected)
 
     def on_attach(self, fgraph):
-        if hasattr(fgraph, "_supervisor"):
-            raise AlreadyThere(f"A Supervisor is already attached to {fgraph}.")
+        if hasattr(fgraph, "_supervisor_protected"):
+            # Add the protected variables from this `Supervisor` instance, in
+            # case something is trying to update them by adding another
+            # `Supervisor`
+            fgraph._supervisor_protected.update(self.initial_protected)
+            raise AlreadyThere("Supervisor feature is already present")
 
-        if self.fgraph is not None and self.fgraph != fgraph:
-            raise Exception("This Feature is already associated with a FunctionGraph")
+        fgraph._supervisor_protected = set(self.initial_protected)
 
-        fgraph._supervisor = self
-        self.fgraph = fgraph
+    def clone(self):
+        return type(self)(self.initial_protected)
 
     def validate(self, fgraph):
         if config.cycle_detection == "fast" and hasattr(fgraph, "has_destroyers"):
-            if fgraph.has_destroyers(self.protected):
+            if fgraph.has_destroyers(fgraph._supervisor_protected):
                 raise InconsistencyError("Trying to destroy protected variables.")
             return True
         if not hasattr(fgraph, "destroyers"):
             return True
-        for r in self.protected + list(fgraph.outputs):
+        for r in chain(fgraph._supervisor_protected, fgraph.outputs):
             if fgraph.destroyers(r):
                 raise InconsistencyError(f"Trying to destroy a protected variable: {r}")
 
 
 def std_fgraph(
     input_specs: List[SymbolicInput],
     output_specs: List[SymbolicOutput],
@@ -592,14 +592,15 @@
             as aesara.function profile parameter
 
         Returns
         -------
         aesara.Function
             Copied aesara.Function
         """
+
         # helper function
         def checkSV(sv_ori, sv_rpl):
             """
             Assert two SharedVariable follow some restirctions:
                 1. same type
                 2. same shape or dim?
             """
@@ -728,18 +729,18 @@
             profile = config.profile or config.print_global_stats
             # profile -> True or False
         if profile is True:
             if name:
                 message = name
             else:
                 message = str(profile.message) + " copy"
-            profile = aesara.compile.profiling.ProfileStats(message=message)
+            profile = ProfileStats(message=message)
             # profile -> object
         elif isinstance(profile, str):
-            profile = aesara.compile.profiling.ProfileStats(message=profile)
+            profile = ProfileStats(message=profile)
 
         f_cpy = maker.__class__(
             inputs=ins,
             outputs=outs,
             fgraph=fg_cpy,
             mode=maker.mode,
             profile=profile,
@@ -756,15 +757,14 @@
             accept_inplace=True,
             no_fgraph_prep=True,
         ).create(input_storage, storage_map=new_storage_map)
 
         for in_ori, in_cpy, ori, cpy in zip(
             maker.inputs, f_cpy.maker.inputs, self.input_storage, f_cpy.input_storage
         ):
-
             # Share immutable ShareVariable and constant input's storage
             swapped = swap is not None and in_ori.variable in swap
 
             # Using the original storage if SharedVariable will not be updated
             # and is not swapped
             if not in_ori.mutable and not swapped:
                 cpy.data = ori.data
@@ -906,15 +906,14 @@
             args_share_memory = []
             for i in range(len(self.input_storage)):
                 i_var = self.maker.inputs[i].variable
                 i_val = self.input_storage[i].storage[0]
                 if hasattr(i_var.type, "may_share_memory"):
                     is_aliased = False
                     for j in range(len(args_share_memory)):
-
                         group_j = zip(
                             [
                                 self.maker.inputs[k].variable
                                 for k in args_share_memory[j]
                             ],
                             [
                                 self.input_storage[k].storage[0]
@@ -924,15 +923,14 @@
                         if any(
                             (
                                 var.type is i_var.type
                                 and var.type.may_share_memory(val, i_val)
                             )
                             for (var, val) in group_j
                         ):
-
                             is_aliased = True
                             args_share_memory[j].append(i)
                             break
 
                     if not is_aliased:
                         args_share_memory.append([i])
 
@@ -1052,17 +1050,15 @@
                 profile.reset()
                 profile.ignore_first_call = False
         if self.return_none:
             return None
         elif self.unpack_single and len(outputs) == 1 and output_subset is None:
             return outputs[0]
         else:
-
             if self.output_keys is not None:
-
                 assert len(self.output_keys) == len(outputs)
 
                 if output_subset is None:
                     return dict(zip(self.output_keys, outputs))
                 else:
                     return {
                         self.output_keys[index]: outputs[index]
@@ -1388,21 +1384,43 @@
                         "Invalid value for keyword on_unused_input of aesara.function: "
                         f"'{on_unused_input}'.\n"
                         "Valid values are 'raise', 'warn', and 'ignore'."
                     )
 
     @staticmethod
     def prepare_fgraph(
-        inputs,
-        outputs,
-        additional_outputs,
+        inputs: List[In],
+        outputs: List[Out],
+        additional_outputs: List[Out],
         fgraph: FunctionGraph,
         mode: "Mode",
-        profile,
+        profile: Union[Optional[ProfileStats], Literal[False]],
     ):
+        r"""Perform rewrites on a graph, insert `DeepCopyOp`\s, and remove unused updates.
+
+        .. warning::
+
+            The `additional_outputs` list and `fgraph.outputs` are updated in-place by this method.
+
+        Parameters
+        ==========
+        inputs
+            The wrapped inputs.
+        outputs
+            The wrapped outputs (i.e. wrapped with `Out`).
+        additional_outputs
+            Output graphs that essentially serve as updates to mutable `inputs`.
+        fgraph
+            The `FunctionGraph` to be prepared.
+        mode
+            The `Mode` that determines--for example--which rewrites are applied.
+        profile
+            The profile object/setting to use.
+
+        """
 
         rewriter = mode.optimizer
 
         try:
             start_rewriter = time.perf_counter()
 
             rewriter_profile = None
@@ -1415,18 +1433,50 @@
             ):
                 rewriter_profile = rewriter(fgraph)
 
                 end_rewriter = time.perf_counter()
                 rewrite_time = end_rewriter - start_rewriter
                 _logger.debug(f"Rewriting took {rewrite_time:f} seconds")
 
+                fgraph_outputs = tuple(fgraph.outputs)
+                update_mappings = tuple(fgraph.update_mapping.items())
+                outputs_to_remove = []
+                additional_outputs_to_remove = []
+
+                # Remove unused updates
+                for i, (out_idx, in_idx) in enumerate(update_mappings):
+                    update = fgraph_outputs[out_idx]
+
+                    if update.owner and update.owner.op == update_placeholder:
+                        # TODO: Consider removing the corresponding
+                        # `FunctionGraph` input when it has no other
+                        # references?
+                        # updated_var = fgraph_inputs[in_idx]
+                        # if not fgraph.clients[updated_var]:
+                        #     fgraph.remove_input(updated_var)
+
+                        # Remove the update entry from the wrapped inputs
+                        inputs[in_idx].update = None
+
+                        # We assume that the orders of `fgraph.update_mapping` and
+                        # `additional_outputs` correspond (and they should)
+                        additional_outputs_to_remove.append(additional_outputs[i])
+
+                        outputs_to_remove.append(fgraph.outputs[out_idx])
+
+                for add_out, out in zip(
+                    additional_outputs_to_remove, outputs_to_remove
+                ):
+                    additional_outputs.remove(add_out)
+                    fgraph_out_idx = fgraph.outputs.index(out)
+                    fgraph.remove_output(fgraph_out_idx)
+
                 # Add deep copy to respect the memory interface
                 insert_deepcopy(fgraph, inputs, outputs + additional_outputs)
         finally:
-
             # If the rewriter got interrupted
             if rewrite_time is None:
                 end_rewriter = time.perf_counter()
                 rewrite_time = end_rewriter - start_rewriter
 
             aesara.compile.profiling.total_graph_rewrite_time += rewrite_time
 
@@ -1597,15 +1647,14 @@
 
         # The following loop is to fill in the input_storage_lists and
         # defaults lists.
         assert len(self.indices) == len(input_storage)
         for i, ((input, indices, subinputs), input_storage_i) in enumerate(
             zip(self.indices, input_storage)
         ):
-
             # Replace any default value given as a variable by its
             # container.  Note that this makes sense only in the
             # context of shared variables, but for now we avoid
             # dealing directly with them to avoid dependency on the
             # shared variables work-in-progress repository.
             if isinstance(input_storage_i, Variable):
                 input_storage_i = input_storage_i.container
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/io.py` & `aesara_nightly-2.9.0.post2/aesara/compile/io.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/mode.py` & `aesara_nightly-2.9.0.post2/aesara/compile/mode.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 """
 WRITEME
 
 """
 
 import logging
 import warnings
-from typing import Optional, Tuple, Union
-
-from typing_extensions import Literal
+from typing import Literal, Optional, Tuple, Union
 
 from aesara.compile.function.types import Supervisor
 from aesara.configdefaults import config
 from aesara.graph.destroyhandler import DestroyHandler
 from aesara.graph.rewriting.basic import (
     CheckStackTraceRewriter,
     GraphRewriter,
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/monitormode.py` & `aesara_nightly-2.9.0.post2/aesara/compile/monitormode.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/nanguardmode.py` & `aesara_nightly-2.9.0.post2/aesara/compile/nanguardmode.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/ops.py` & `aesara_nightly-2.9.0.post2/aesara/compile/ops.py`

 * *Files 4% similar despite different names*

```diff
@@ -325,7 +325,49 @@
     if infer_shape is not None and not callable(infer_shape):
         raise TypeError("infer_shape needs to be a callable")
 
     def make_op(fn):
         return FromFunctionOp(fn, itypes, otypes, infer_shape)
 
     return make_op
+
+
+class UpdatePlaceholder(Op):
+    """A placeholder for a `SharedVariable` update that hasn't been set.
+
+    These will appear in `FunctionGraph.outputs` and represent potential updates
+    (i.e. the `updates` argument to `aesara.function` and/or updates specified via
+    `SharedVariable.default_update`s) that could be specified by rewrites.
+
+    When present, these should be removed by non-rewrite steps in the
+    compilation pipeline (and before any thunks are created for them).
+
+    .. note::
+
+        One reason these can't be removed during the rewrite passes is that the
+        `FunctionGraph.outputs` list entries containing them need to be
+        entirely removed, and we don't want to add/remove
+        `FunctionGraph.outputs` during rewriting.
+
+    """
+
+    view_map = {0: [0]}
+
+    def make_node(self, x):
+        return Apply(self, [x], [x.type()])
+
+    def perform(self, node, inp, out):  # pragma: no cover
+        (x,) = inp
+        (z,) = out
+        z[0] = x
+
+    def __str__(self):  # pragma: no cover
+        return f"{self.__class__.__name__}"
+
+    def infer_shape(self, fgraph, node, input_shapes):
+        return input_shapes
+
+    def grad(self, args, g_outs):  # pragma: no cover
+        return g_outs
+
+
+update_placeholder = UpdatePlaceholder()
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/profiling.py` & `aesara_nightly-2.9.0.post2/aesara/compile/profiling.py`

 * *Files 1% similar despite different names*

```diff
@@ -61,15 +61,14 @@
             destination_file = "<stderr>"
         elif config.profiling__destination == "stdout":
             destination_file = "<stdout>"
         else:
             destination_file = config.profiling__destination
 
         with extended_open(destination_file, mode="w"):
-
             # Reverse sort in the order of compile+exec time
             for ps in sorted(
                 _atexit_print_list, key=lambda a: a.compile_time + a.fct_call_time
             )[::-1]:
                 if (
                     ps.fct_callcount >= 1
                     or ps.compile_time > 1
@@ -354,15 +353,15 @@
     def class_impl(self):
         """
         dict op -> total number of nodes
 
         """
         # timing is stored by node, we compute timing by class on demand
         rval = {}
-        for (fgraph, node) in self.apply_callcount:
+        for fgraph, node in self.apply_callcount:
             typ = type(node.op)
             if self.apply_cimpl[node]:
                 impl = "C "
             else:
                 impl = "Py"
             rval.setdefault(typ, impl)
             if rval[typ] != impl and len(rval[typ]) == 2:
@@ -397,15 +396,15 @@
 
     def compute_total_times(self):
         """
         dict op -> total time including the time for parents
 
         """
         rval = {}
-        for (fgraph, node) in self.apply_time:
+        for fgraph, node in self.apply_time:
             if node not in rval:
                 self.fill_node_total_time(fgraph, node, rval)
         return rval
 
     def op_callcount(self):
         """
         dict op -> total number of thunk calls
@@ -433,15 +432,15 @@
     def op_impl(self):
         """
         dict op -> 'C' or 'Py' depending how the op is implemented
 
         """
         # timing is stored by node, we compute timing by Op on demand
         rval = {}
-        for (fgraph, node) in self.apply_callcount:
+        for fgraph, node in self.apply_callcount:
             if self.apply_cimpl[node]:
                 rval[node.op] = "C "
             else:
                 rval[node.op] = "Py"
         return rval
 
     def summary_class(self, file=sys.stderr, N=None):
@@ -707,15 +706,15 @@
                     self.apply_callcount[(fgraph, a)],
                 )
             )
         del topos
 
         atimes.sort(reverse=True, key=lambda t: (t[1], t[3]))
         tot = 0
-        for (f, t, a, nd_id, nb_call) in atimes[:N]:
+        for f, t, a, nd_id, nb_call in atimes[:N]:
             tot += t
             ftot = tot * 100 / local_time
             if nb_call == 0:
                 continue
             if not self.variable_shape:
                 flops = ""
                 flops_s = ""
@@ -836,15 +835,15 @@
 
     def summary_memory(self, file, N=None):
         fct_memory = {}  # fgraph->dict(node->[outputs size])
         fct_shapes = {}  # fgraph->dict(node->[outputs shapes]))
         var_mem = {}  # variable->size in bytes; don't include input variables
         node_mem = {}  # (fgraph, node)->total outputs size (only dense outputs)
 
-        for (fgraph, node) in self.apply_callcount:
+        for fgraph, node in self.apply_callcount:
             fct_memory.setdefault(fgraph, {})
             fct_memory[fgraph].setdefault(node, [])
             fct_shapes.setdefault(fgraph, {})
             fct_shapes[fgraph].setdefault(node, [])
             sum_dense = 0
             for out in node.outputs:
                 if out in self.variable_shape:
@@ -1501,16 +1500,16 @@
             aes.AND,
             aes.Invert,
             aes.ScalarMaximum,
             aes.ScalarMinimum,
             aes.Add,
             aes.Mul,
             aes.Sub,
-            aes.TrueDiv,
-            aes.IntDiv,
+            aes.TrueDivide,
+            aes.FloorDivide,
             aes.Clip,
             aes.Second,
             aes.Identity,
             aes.Cast,
             aes.Sgn,
             aes.Neg,
             aes.Reciprocal,
@@ -1607,15 +1606,15 @@
                 "than in float64! Try Aesara flag floatX=float64, or "
                 "install amdlibm and set the aesara flags lib__amblibm=True",
                 file=file,
             )
             printed_tip = True
 
         # tip 4
-        for (fgraph, a) in self.apply_time:
+        for fgraph, a in self.apply_time:
             node = a
             if isinstance(node.op, Dot) and all(
                 len(i.type.broadcastable) == 2 for i in node.inputs
             ):
                 print(
                     (
                         "  - You have a dot operation that was not rewritten to"
@@ -1624,29 +1623,29 @@
                         f"Currently they are: {[i.type for i in node.inputs]}"
                     ),
                     file=file,
                 )
                 printed_tip = True
 
         # tip 5
-        for (fgraph, a) in self.apply_time:
+        for fgraph, a in self.apply_time:
             node = a
             if isinstance(node.op, RandomVariable):
                 printed_tip = True
                 print(
                     "  - Replace the default random number generator by "
                     "'from aesara.sandbox.rng_mrg import MRG_RandomStream "
                     "as RandomStream', as this is is faster. It is still "
                     "experimental, but seems to work correctly.",
                     file=file,
                 )
                 break
 
         # tip 6
-        for (fgraph, a) in self.apply_time:
+        for fgraph, a in self.apply_time:
             node = a
             if isinstance(node.op, Dot) and len({i.dtype for i in node.inputs}) != 1:
                 print(
                     (
                         "  - You have a dot operation that has different dtype "
                         f" for inputs ({[i.type for i in node.inputs]}). Make sure that the inputs have same "
                         " dtype."
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/compile/sharedvalue.py` & `aesara_nightly-2.9.0.post2/aesara/compile/sharedvalue.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,20 @@
 """Provide a simple user friendly API to Aesara-managed memory."""
 
 import copy
 from contextlib import contextmanager
 from functools import singledispatch
-from typing import TYPE_CHECKING, List, Optional
+from typing import List, Optional
 
-from aesara.graph.basic import Variable
+from aesara.graph.basic import Variable, _TypeType
 from aesara.graph.utils import add_tag_trace
 from aesara.link.basic import Container
 from aesara.link.c.type import generic
 
 
-if TYPE_CHECKING:
-    from aesara.graph.type import Type
-
-
 __SHARED_CONTEXT__: Optional[List[Variable]] = None
 
 
 @contextmanager
 def collect_new_shareds():
     r"""Return all the `SharedVariable`\s created within this context manager."""
     global __SHARED_CONTEXT__
@@ -27,20 +23,20 @@
     try:
         __SHARED_CONTEXT__ = context
         yield context
     finally:
         __SHARED_CONTEXT__ = old_context
 
 
-class SharedVariable(Variable):
+class SharedVariable(Variable[_TypeType, None]):
     """Variable that is shared between compiled functions."""
 
     def __init__(
         self,
-        type: "Type",
+        type: _TypeType,
         value,
         strict: bool,
         allow_downcast=None,
         container: Optional[Container] = None,
         name: Optional[str] = None,
     ):
         r"""
@@ -156,15 +152,15 @@
         (see `aesara.function`) for this `Variable` when no updates are
         provided through `aesara.function` and `no_default_updates` isn't
         enabled.
         """
         return self._default_update
 
     @default_update.setter
-    def default_update(self, value):
+    def default_update(self, value: Optional[Variable]):
         if value is not None:
             self._default_update = self.type.filter_variable(value, allow_convert=True)
         else:
             self._default_update = value
 
 
 def shared(value, name=None, strict=False, allow_downcast=None, **kwargs):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/configdefaults.py` & `aesara_nightly-2.9.0.post2/aesara/configdefaults.py`

 * *Files 0% similar despite different names*

```diff
@@ -274,15 +274,14 @@
     sr = "-".join(sp)
     p = p.replace(r, sr)
 
     return p
 
 
 def add_basic_configvars():
-
     config.add(
         "floatX",
         "Default floating-point precision for python casts.\n"
         "\n"
         "Note: float16 support is experimental, use at your own risk.",
         EnumStr("float64", ["float32", "float16"]),
         # TODO: see gh-4466 for how to remove it.
@@ -384,15 +383,14 @@
 
 
 def _is_greater_or_equal_0(x):
     return x >= 0
 
 
 def add_compile_configvars():
-
     config.add(
         "mode",
         "Default compilation mode",
         ConfigParam("Mode", apply=_filter_mode),
         in_c_key=False,
     )
 
@@ -627,15 +625,14 @@
 
 
 def _is_valid_cmp_sloppy(v):
     return v in (0, 1, 2)
 
 
 def add_tensor_configvars():
-
     # This flag is used when we import Aesara to initialize global variables.
     # So changing it after import will not modify these global variables.
     # This could be done differently... but for now we simply prevent it from being
     # changed at runtime.
     config.add(
         "tensor__cmp_sloppy",
         "Relax aesara.tensor.math._allclose (0) not at all, (1) a bit, (2) more",
@@ -713,15 +710,14 @@
         " an assert to highlight shape errors.",
         BoolParam(True),
         in_c_key=False,
     )
 
 
 def add_error_and_warning_configvars():
-
     ###
     # To disable some warning about old bug that are fixed now.
     ###
     config.add(
         "warn__ignore_bug_before",
         (
             "If 'None', we warn about all Aesara bugs found by default. "
@@ -1192,15 +1188,14 @@
         "the Stack VM; otherwise, use the Loop VM.",
         ConfigParam("None", apply=_filter_vm_lazy),
         in_c_key=False,
     )
 
 
 def add_deprecated_configvars():
-
     # TODO: remove this?
     config.add(
         "unittests__rseed",
         "Seed to use for randomized unit tests. "
         "Special value 'random' means using a seed of None.",
         StrParam(666, validate=_good_seem_param),
         in_c_key=False,
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/configparser.py` & `aesara_nightly-2.9.0.post2/aesara/configparser.py`

 * *Files 1% similar despite different names*

```diff
@@ -121,18 +121,15 @@
         """
         all_opts = sorted(
             [c for c in self._config_var_dict.values() if c.in_c_key],
             key=lambda cv: cv.name,
         )
         return hash_from_code(
             "\n".join(
-                [
-                    "{} = {}".format(cv.name, cv.__get__(self, self.__class__))
-                    for cv in all_opts
-                ]
+                [f"{cv.name} = {cv.__get__(self, self.__class__)}" for cv in all_opts]
             )
         )
 
     def add(self, name, doc, configparam, in_c_key=True):
         """Add a new variable to AesaraConfigParser.
 
         This method performs some of the work of initializing `ConfigParam` instances.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/css/d3viz.css` & `aesara_nightly-2.9.0.post2/aesara/d3viz/css/d3viz.css`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/d3viz.py` & `aesara_nightly-2.9.0.post2/aesara/d3viz/d3viz.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/formatting.py` & `aesara_nightly-2.9.0.post2/aesara/d3viz/formatting.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/html/template.html` & `aesara_nightly-2.9.0.post2/aesara/d3viz/html/template.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3-context-menu.js` & `aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3-context-menu.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3.v3.min.js` & `aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3.v3.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/js/d3viz.js` & `aesara_nightly-2.9.0.post2/aesara/d3viz/js/d3viz.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/js/dagre-d3.min.js` & `aesara_nightly-2.9.0.post2/aesara/d3viz/js/dagre-d3.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/d3viz/js/graphlib-dot.min.js` & `aesara_nightly-2.9.0.post2/aesara/d3viz/js/graphlib-dot.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/gradient.py` & `aesara_nightly-2.9.0.post2/aesara/gradient.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,25 +4,25 @@
 import warnings
 from functools import partial, reduce
 from typing import (
     TYPE_CHECKING,
     Callable,
     Dict,
     List,
+    Literal,
     Mapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     TypeVar,
     Union,
 )
 
 import numpy as np
-from typing_extensions import Literal
 
 import aesara
 from aesara.compile.ops import ViewOp
 from aesara.configdefaults import config
 from aesara.graph import utils
 from aesara.graph.basic import Apply, NominalVariable, Variable
 from aesara.graph.null_type import NullType, null_type
@@ -87,18 +87,16 @@
 
     Optionally adds a comment to the exception explaining why this
     gradient is not implemented.
     """
 
     return (
         NullType(
-            (
-                "This variable is Null because the grad method for "
-                f"input {x_pos} ({x}) of the {op} op is not implemented. {comment}"
-            )
+            "This variable is Null because the grad method for "
+            f"input {x_pos} ({x}) of the {op} op is not implemented. {comment}"
         )
     )()
 
 
 def grad_undefined(op, x_pos, x, comment=""):
     """Return an un-computable symbolic variable of type `x.type`.
 
@@ -110,18 +108,16 @@
 
     Optionally adds a comment to the exception explaining why this
     gradient is not defined.
     """
 
     return (
         NullType(
-            (
-                "This variable is Null because the grad method for "
-                f"input {x_pos} ({x}) of the {op} op is not implemented. {comment}"
-            )
+            "This variable is Null because the grad method for "
+            f"input {x_pos} ({x}) of the {op} op is not implemented. {comment}"
         )
     )()
 
 
 class DisconnectedType(Type):
     """A type indicating that a variable is the result of taking the gradient of
     ``c`` with respect to ``x`` when ``c`` is not a function of ``x``.
@@ -225,15 +221,14 @@
 
     if len(_wrt) != len(_eval_points):
         raise ValueError("`wrt` must be the same length as `eval_points`.")
 
     # Check that each element of wrt corresponds to an element
     # of eval_points with the same dimensionality.
     for i, (wrt_elem, eval_point) in enumerate(zip(_wrt, _eval_points)):
-
         try:
             if wrt_elem.type.ndim != eval_point.type.ndim:
                 raise ValueError(
                     f"Elements {i} of `wrt` and `eval_point` have mismatched dimensionalities: "
                     f"{wrt_elem.type.ndim} and {eval_point.type.ndim}"
                 )
         except AttributeError:
@@ -262,15 +257,14 @@
                 try:
                     local_eval_points.append(inp.zeros_like())
                 except Exception:
                     # None should be used for non-differentiable
                     # arguments, like for example random states
                     local_eval_points.append(None)
             elif inp.owner in seen_nodes:
-
                 local_eval_points.append(
                     seen_nodes[inp.owner][inp.owner.outputs.index(inp)]
                 )
 
             else:
                 # We actually need to compute the R_op for this node
 
@@ -683,17 +677,17 @@
     .. code-block:: python
 
         x, t = aesara.tensor.fvector('x'), aesara.tensor.fvector('t')
         w1 = aesara.shared(np.random.standard_normal((3,4)))
         w2 = aesara.shared(np.random.standard_normal((4,2)))
         a1 = aesara.tensor.tanh(aesara.tensor.dot(x,w1))
         a2 = aesara.tensor.tanh(aesara.tensor.dot(a1,w2))
-        cost2 = aesara.tensor.sqr(a2 - t).sum()
-        cost2 += aesara.tensor.sqr(w2.sum())
-        cost1 = aesara.tensor.sqr(w1.sum())
+        cost2 = aesara.tensor.square(a2 - t).sum()
+        cost2 += aesara.tensor.square(w2.sum())
+        cost1 = aesara.tensor.square(w1.sum())
 
         params = [[w2],[w1]]
         costs = [cost2,cost1]
         grad_ends = [[a1], [x]]
 
         next_grad = None
         param_grads = []
@@ -937,15 +931,14 @@
             app = var.owner
 
             connection_pattern = _node_to_pattern(app)
 
             var_idx = app.outputs.index(var)
 
             for i, ipt in enumerate(app.inputs):
-
                 # don't process ipt if it is not a true
                 # parent of var
                 if not connection_pattern[i][var_idx]:
                     continue
 
                 if ipt not in var_to_app_to_idx:
                     # This object here *must* be ordered, because
@@ -1048,15 +1041,14 @@
     # its inputs' gradients
     term_dict = {}
 
     def access_term_cache(node):
         """Populates term_dict[node] and returns it"""
 
         if node not in term_dict:
-
             inputs = node.inputs
 
             output_grads = [access_grad_cache(var) for var in node.outputs]
 
             # list of bools indicating if each output is connected to the cost
             outputs_connected = [
                 not isinstance(g.type, DisconnectedType) for g in output_grads
@@ -1263,30 +1255,27 @@
                         )
                     ]
                 )
                 for in_to_outs in connection_pattern
             ]
 
             for i, term in enumerate(input_grads):
-
                 # Disallow Nones
                 if term is None:
                     # We don't know what None means. in the past it has been
                     # used to mean undefined, zero, or disconnected.
                     # We therefore don't allow it because its usage has become
                     # so muddied.
                     raise TypeError(
-                        (
-                            f"{node.op}.grad returned None for a gradient term, "
-                            "this is prohibited. Instead of None,"
-                            "return zeros_like(input), disconnected_type(),"
-                            " or a NullType variable such as those made with "
-                            "the grad_undefined or grad_unimplemented helper "
-                            "functions."
-                        )
+                        f"{node.op}.grad returned None for a gradient term, "
+                        "this is prohibited. Instead of None,"
+                        "return zeros_like(input), disconnected_type(),"
+                        " or a NullType variable such as those made with "
+                        "the grad_undefined or grad_unimplemented helper "
+                        "functions."
                     )
 
                 # Check that the gradient term for this input
                 # has the right shape
                 if hasattr(term, "shape"):
                     orig_ipt = inputs[i]
                     if not isinstance(orig_ipt, NominalVariable):
@@ -1379,15 +1368,14 @@
             # If var is not in grad_dict already, we must compute it
             if var in var_to_app_to_idx:
                 null_terms = []
                 terms = []
                 node_to_idx = var_to_app_to_idx[var]
                 for node in node_to_idx:
                     for idx in node_to_idx[node]:
-
                         term = access_term_cache(node)[idx]
 
                         if not isinstance(term, Variable):
                             raise TypeError(
                                 f"{node.op}.grad returned {type(term)}, expected"
                                 " Variable instance."
                             )
@@ -1398,18 +1386,16 @@
 
                         # Don't try to sum up DisconnectedType placeholders
                         if isinstance(term.type, DisconnectedType):
                             continue
 
                         if hasattr(var, "ndim") and term.ndim != var.ndim:
                             raise ValueError(
-                                (
-                                    f"{node.op}.grad returned a term with"
-                                    f" {int(term.ndim)} dimensions, but {int(var.ndim)} are required."
-                                )
+                                f"{node.op}.grad returned a term with"
+                                f" {int(term.ndim)} dimensions, but {int(var.ndim)} are required."
                             )
 
                         terms.append(term)
 
                 # Add up the terms to get the total gradient on this variable
                 if len(null_terms) > 0:
                     # At least one term is a NullType : the total gradient
@@ -1763,18 +1749,16 @@
         raise TypeError("`pt` should be a list or tuple")
 
     pt = [np.array(p) for p in pt]
 
     for i, p in enumerate(pt):
         if p.dtype not in ("float16", "float32", "float64"):
             raise TypeError(
-                (
-                    "verify_grad can work only with floating point "
-                    f'inputs, but input {i} has dtype "{p.dtype}".'
-                )
+                "verify_grad can work only with floating point "
+                f'inputs, but input {i} has dtype "{p.dtype}".'
             )
 
     _type_tol = dict(  # relative error tolerances for different types
         float16=5e-2, float32=1e-2, float64=1e-4
     )
 
     if abs_tol is None:
@@ -1864,15 +1848,14 @@
         assert isinstance(analytic_grad, list)
 
         max_arg, max_err_pos, max_abs_err, max_rel_err = num_grad.max_err(
             analytic_grad, abs_tol, rel_tol
         )
 
         if max_abs_err > abs_tol and max_rel_err > rel_tol:
-
             raise GradientError(
                 max_arg,
                 max_err_pos,
                 analytic_grad[max_arg].shape,
                 analytic_grad[max_arg].flatten()[max_err_pos],
                 num_grad.gf[max_arg].flatten()[max_err_pos],
                 max_abs_err,
@@ -2048,15 +2031,14 @@
     if isinstance(wrt, (list, tuple)):
         wrt = list(wrt)
     else:
         wrt = [wrt]
 
     hessians = []
     for input in wrt:
-
         if not isinstance(input, Variable):
             raise TypeError("hessian expects a (list of) Variable as `wrt`")
 
         if input.ndim != 1:
             raise ValueError(
                 "hessian expects a (list of) 1 dimensional variable as `wrt`"
             )
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/basic.py` & `aesara_nightly-2.9.0.post2/aesara/graph/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -819,15 +819,14 @@
 
     while nodes:
         node: T = nodes_pop()
 
         node_hash: int = hash_fn(node)
 
         if node_hash not in rval_set:
-
             rval_set.add(node_hash)
 
             new_nodes: Optional[Iterable[T]] = expand(node)
 
             if return_children:
                 yield node, new_nodes
             else:
@@ -1180,19 +1179,17 @@
         items = list(replace.items())
     elif isinstance(replace, (list, tuple)):
         items = replace
     elif replace is None:
         items = []
     else:
         raise ValueError(
-            (
-                "replace is neither a dictionary, list, "
-                f"tuple or None ! The value provided is {replace},"
-                f"of type {type(replace)}"
-            )
+            "replace is neither a dictionary, list, "
+            f"tuple or None ! The value provided is {replace},"
+            f"of type {type(replace)}"
         )
     tmp_replace = [(x, x.type()) for x, y in items]
     new_replace = [(x, y) for ((_, x), (_, y)) in zip(tmp_replace, items)]
     _, _outs, _ = rebuild_collect_shared(output, [], tmp_replace, [], **rebuild_kwds)
 
     # TODO Explain why we call it twice ?!
     _, outs, _ = rebuild_collect_shared(_outs, [], new_replace, [], **rebuild_kwds)
@@ -1237,15 +1234,14 @@
     returned by the `deps` function.
 
     The second option removes a Python function call, and allows for more
     specialized code, so it can be faster.
 
     """
     if compute_deps_cache is None:
-
         if deps_cache is None:
             deps_cache = {}
 
         def _compute_deps_cache(io):
             if io not in deps_cache:
                 d = deps(io)
 
@@ -1374,15 +1370,14 @@
                 else:
                     deps_cache[obj] = rval
             else:
                 deps_cache[obj] = rval
             return rval
 
     else:
-
         # the inputs are used only here in the function that decides what
         # 'predecessors' to explore
         def compute_deps(obj):
             rval = []
             if obj not in iset:
                 if isinstance(obj, Variable):
                     if obj.owner:
@@ -1425,15 +1420,14 @@
         inp_connection_pattern = [i == j for j in range(nb_inputs)]
         connect_pattern_by_var[input] = inp_connection_pattern
 
     # Iterate through the nodes used to produce the outputs from the
     # inputs and, for every node, infer their connection pattern to
     # every input from the connection patterns of their parents.
     for n in inner_nodes:
-
         # Get the connection pattern of the inner node's op. If the op
         # does not define a connection_pattern method, assume that
         # every node output is connected to every node input
         try:
             op_connection_pattern = n.op.connection_pattern(n)
         except AttributeError:
             op_connection_pattern = [[True] * len(n.outputs)] * len(n.inputs)
@@ -1760,34 +1754,31 @@
 
             if all_in_common:
                 return True
 
             # Compare the individual inputs for equality
             for dx, dy in zip(nd_x.inputs, nd_y.inputs):
                 if (dx, dy) not in common:
-
                     # Equality between the variables is unknown, compare
                     # their respective owners, if they have some
                     if (
                         dx.owner
                         and dy.owner
                         and dx.owner.outputs.index(dx) == dy.owner.outputs.index(dy)
                     ):
-
                         nodes_equal = compare_nodes(
                             dx.owner, dy.owner, common, different
                         )
                         if not nodes_equal:
                             different.add((dx, dy))
                             return False
 
                     # If both variables don't have an owner, then they are
                     # inputs and can be directly compared
                     elif dx.owner is None and dy.owner is None:
-
                         if dx != dy:
                             if isinstance(dx, Constant) and isinstance(dy, Constant):
                                 if not dx.equals(dy):
                                     return False
                             else:
                                 return False
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/destroyhandler.py` & `aesara_nightly-2.9.0.post2/aesara/graph/destroyhandler.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,33 +1,43 @@
 """
 Classes and functions for validating graphs that contain view
 and inplace operations.
 
 """
 import itertools
 from collections import OrderedDict, deque
+from types import MethodType
+from typing import TYPE_CHECKING, Deque, Dict, Iterable, List, Optional, Set, Tuple
+from typing import Type as TypingType
+from typing import Union, cast
 
-import aesara
 from aesara.configdefaults import config
 from aesara.graph.basic import Constant
 from aesara.graph.features import AlreadyThere, Bookkeeper
 from aesara.graph.utils import InconsistencyError
 from aesara.misc.ordered_set import OrderedSet
 
 
+if TYPE_CHECKING:
+    from aesara.graph.basic import Apply, Variable
+    from aesara.graph.fg import FunctionGraph
+
+
 class ProtocolError(Exception):
     """
     Raised when FunctionGraph calls DestroyHandler callbacks in
     an invalid way, for example, pruning or changing a node that has
     never been imported.
 
     """
 
 
-def _contains_cycle(fgraph, orderings):
+def _contains_cycle(
+    fgraph: "FunctionGraph", orderings: Dict["Apply", Set["Apply"]]
+) -> bool:
     """
     Function to check if the given graph contains a cycle
 
     Parameters
     ----------
     fgraph
         The FunctionGraph to check for cycles.
@@ -72,48 +82,53 @@
     # so that the dict would do reference counting on its keys.
     # This caused a slowdown.
     # Separate benchmark tests showed that calling id is about
     # half as expensive as a dictionary access, and that the
     # dictionary also runs slower when storing ids than when
     # storing objects.
 
+    # TODO FIXME: This use of mixed `Apply` and `Variable` types is confusing
+    # and unnecessary.  We might need to start using nullary `Apply` nodes for
+    # atomic variables in order to fix this, though.
+
     # dict mapping an Apply or Variable instance to the number
     # of its parents (including parents imposed by orderings)
     # that haven't been visited yet
-    parent_counts = {}
+    parent_counts: Dict[Union["Apply", "Variable"], int] = {}
     # dict mapping an Apply or Variable instance to its children
-    node_to_children = {}
+    node_to_children: Dict[
+        Union["Apply", "Variable"], List[Union["Apply", "Variable"]]
+    ] = {}
 
     # visitable: A container holding all Variable and Apply instances
     # that can currently be visited according to the graph topology
     # (ie, whose parents have already been visited)
     # TODO: visitable is a fifo_queue. could this run faster if we
     # implement it as a stack rather than a deque?
     # TODO: visitable need not be a fifo_queue, any kind of container
     # that we can throw things into and take things out of quickly will
     # work. is there another kind of container that could run faster?
     # we don't care about the traversal order here as much as we do
     # in io_toposort because we aren't trying to generate an ordering
     # on the nodes
-    visitable = deque()
+    visitable: Deque[Union["Apply", "Variable"]] = deque()
 
     # IG: visitable could in principle be initialized to fgraph.inputs
     #     + fgraph.orphans... if there were an fgraph.orphans structure.
     #     I tried making one and maintaining it caused a huge slowdown.
     #     This may be because I made it a list, so it would have a
     #     deterministic iteration order, in hopes of using it to speed
     #     up toposort as well.
     #     I think since we need to scan through all variables and nodes
     #     to make parent_counts anyway, it's cheap enough to always
     #     detect orphans at cycle detection / toposort time
 
     # Pass through all the nodes to build visitable, parent_count, and
     # node_to_children
     for var in fgraph.variables:
-
         # this is faster than calling get_parents
         owner = var.owner
         # variables don't appear in orderings, so we don't need to worry
         # about that here
         if owner:
             # insert node in node_to_children[r]
             # (if r is not already in node_to_children,
@@ -121,15 +136,15 @@
             node_to_children.setdefault(owner, []).append(var)
             parent_counts[var] = 1
         else:
             visitable.append(var)
             parent_counts[var] = 0
 
     for a_n in fgraph.apply_nodes:
-        parents = list(a_n.inputs)
+        parents: List[Union["Apply", "Variable"]] = list(a_n.inputs)
         # This is faster than conditionally extending
         # IG: I tried using a shared empty_list = [] constructed
         # outside of the for loop to avoid constructing multiple
         # lists, but this was not any faster.
         parents.extend(orderings.get(a_n, []))
 
         if parents:
@@ -171,90 +186,108 @@
             # it may now be visited too
             if not parent_counts[client]:
                 visitable.append(client)
 
     return visited != len(parent_counts)
 
 
-def _build_droot_impact(destroy_handler):
-    droot = {}  # destroyed view + nonview variables -> foundation
-    impact = {}  # destroyed nonview variable -> it + all views of it
-    root_destroyer = {}  # root -> destroyer apply
+def _build_droot_impact(
+    fgraph: "FunctionGraph",
+) -> Tuple[
+    Dict["Variable", "Variable"],
+    Dict["Variable", Set["Variable"]],
+    Dict["Variable", "Apply"],
+]:
+    # destroyed view + nonview variables -> foundation
+    droot: Dict["Variable", "Variable"] = OrderedDict()
+    # destroyed nonview variable -> it + all views of it
+    impact: Dict["Variable", Set["Variable"]] = OrderedDict()
+    # root -> destroyer apply
+    root_destroyer: Dict["Variable", "Apply"] = OrderedDict()
+
+    # TODO FIXME: How do we get a type interface working for these
+    # `FunctionGraph` additions?
+    assert hasattr(fgraph, "_destroyhandler_destroyers")
+    assert hasattr(fgraph, "view_i")
+    assert hasattr(fgraph, "view_o")
 
-    for app in destroy_handler.destroyers:
+    for app in fgraph._destroyhandler_destroyers:
         for output_idx, input_idx_list in app.op.destroy_map.items():
             if len(input_idx_list) != 1:
                 raise NotImplementedError()
-            input_idx = input_idx_list[0]
-            input = app.inputs[input_idx]
+
+            input_idx: int = input_idx_list[0]
+            input: "Variable" = app.inputs[input_idx]
 
             # Find non-view variable which is ultimately viewed by input.
-            view_i = destroy_handler.view_i
-            _r = input
+            view_i: Dict["Variable", "Variable"] = fgraph.view_i
+            _r: Optional["Variable"] = input
             while _r is not None:
                 r = _r
                 _r = view_i.get(r)
             input_root = r
 
             if input_root in droot:
                 raise InconsistencyError(f"Multiple destroyers of {input_root}")
+
             droot[input_root] = input_root
             root_destroyer[input_root] = app
 
             # The code here add all the variables that are views of r into
             # an OrderedSet input_impact
             input_impact = OrderedSet()
 
-            q = deque()
+            q: Deque["Variable"] = deque()
             q.append(input_root)
             while len(q) > 0:
                 v = q.popleft()
-                for n in destroy_handler.view_o.get(v, []):
+                for n in fgraph.view_o.get(v, []):
                     input_impact.add(n)
                     q.append(n)
 
             for v in input_impact:
                 assert v not in droot
                 droot[v] = input_root
 
-            impact[input_root] = input_impact
+            impact[input_root] = cast(Set["Variable"], input_impact)
             impact[input_root].add(input_root)
 
     return droot, impact, root_destroyer
 
 
-def fast_inplace_check(fgraph, inputs):
+def fast_inplace_check(
+    fgraph: "FunctionGraph", inputs: List["Variable"]
+) -> List["Variable"]:
     """
     Return the variables in inputs that are possible candidate for as inputs of
     inplace operation.
 
     Parameters
     ----------
     inputs : list
         Inputs Variable that you want to use as inplace destination.
 
     """
-    Supervisor = aesara.compile.function.types.Supervisor
-    protected_inputs = [
-        f.protected for f in fgraph._features if isinstance(f, Supervisor)
-    ]
-    protected_inputs = sum(protected_inputs, [])  # flatten the list
-    protected_inputs.extend(fgraph.outputs)
+    assert hasattr(fgraph, "has_destroyers")
+
+    protected_inputs: Iterable["Variable"] = getattr(
+        fgraph, "_supervisor_protected", ()
+    )
 
     inputs = [
         i
         for i in inputs
         if not isinstance(i, Constant)
         and not fgraph.has_destroyers([i])
         and i not in protected_inputs
     ]
     return inputs
 
 
-class DestroyHandler(Bookkeeper):  # noqa
+class DestroyHandler(Bookkeeper):
     """
     The DestroyHandler class detects when a graph is impossible to evaluate
     because of aliasing and destructive operations.
 
     Several data structures are used to do this.
 
     An Op can use its view_map property to declare that an output may be
@@ -289,50 +322,20 @@
         <none>
 
     The following data structures remain to be converted:
         <unknown>
 
     """
 
-    pickle_rm_attr = ["destroyers", "has_destroyers"]
-
     def __init__(self, do_imports_on_attach=True, algo=None):
-        self.fgraph = None
         self.do_imports_on_attach = do_imports_on_attach
 
-        """
-        Maps every variable in the graph to its "foundation" (deepest
-        ancestor in view chain).
-        TODO: change name to var_to_vroot.
-
-        """
-        self.droot = OrderedDict()
-
-        """
-        Maps a variable to all variables that are indirect or direct views of it
-        (including itself) essentially the inverse of droot.
-        TODO: do all variables appear in this dict, or only those that are
-              foundations?
-        TODO: do only destroyed variables go in here? one old docstring said so.
-        TODO: rename to x_to_views after reverse engineering what x is
-
-        """
-        self.impact = OrderedDict()
-
-        """
-        If a var is destroyed, then this dict will map
-        droot[var] to the apply node that destroyed var
-        TODO: rename to vroot_to_destroyer
-
-        """
-        self.root_destroyer = OrderedDict()
         if algo is None:
             algo = config.cycle_detection
         self.algo = algo
-        self.fail_validate = OrderedDict()
 
     def clone(self):
         return type(self)(self.do_imports_on_attach, self.algo)
 
     def on_attach(self, fgraph):
         """
         When attaching to a new fgraph, check that
@@ -346,111 +349,138 @@
             1) A new method "destroyers(var)"
                TODO: what does this do exactly?
             2) A new attribute, "destroy_handler"
         TODO: WRITEME: what does this do besides the checks?
 
         """
 
-        if any(hasattr(fgraph, attr) for attr in ("destroyers", "destroy_handler")):
+        if hasattr(fgraph, "destroy_handler"):
             raise AlreadyThere("DestroyHandler feature is already present")
 
-        if self.fgraph is not None and self.fgraph != fgraph:
-            raise Exception(
-                "A DestroyHandler instance can only serve one FunctionGraph"
-            )
-
-        # Annotate the FunctionGraph #
-        self.unpickle(fgraph)
         fgraph.destroy_handler = self
 
-        self.fgraph = fgraph
-        self.destroyers = (
-            OrderedSet()
-        )  # set of Apply instances with non-null destroy_map
-        self.view_i = {}  # variable -> variable used in calculation
-        self.view_o = (
-            {}
-        )  # variable -> set of variables that use this one as a direct input
+        fgraph.fail_validate: Dict["Variable", "Variable"] = OrderedDict()
+        """
+        Maps every variable in the graph to its "foundation" (deepest
+        ancestor in view chain).
+        TODO: change name to var_to_vroot.
+
+        """
+        fgraph.droot: Dict["Variable", "Variable"] = OrderedDict()
+
+        """
+        Maps a variable to all variables that are indirect or direct views of it
+        (including itself) essentially the inverse of droot.
+        TODO: do all variables appear in this dict, or only those that are
+              foundations?
+        TODO: do only destroyed variables go in here? one old docstring said so.
+        TODO: rename to x_to_views after reverse engineering what x is
+
+        """
+        fgraph.impact: Dict["Variable", "Apply"] = OrderedDict()
+
+        """
+        If a var is destroyed, then this dict will map
+        droot[var] to the apply node that destroyed var
+        TODO: rename to vroot_to_destroyer
+
+        """
+        fgraph.root_destroyer: Dict["Variable", "Apply"] = OrderedDict()
+
+        # set of Apply instances with non-null destroy_map
+        fgraph._destroyhandler_destroyers: Set["Apply"] = OrderedSet()
+        # variable -> variable used in calculation
+        fgraph.view_i: Dict["Variable", "Variable"] = OrderedDict()
+        # variable -> set of variables that use this one as a direct input
+        fgraph.view_o: Dict["Variable", Set["Variable"]] = OrderedDict()
         # clients: how many times does an apply use a given variable
-        self.clients = OrderedDict()  # variable -> apply -> ninputs
-        self.stale_droot = True
+        fgraph._destroy_handler_clients: Dict[
+            "Variable", Dict["Apply", int]
+        ] = OrderedDict()
+        fgraph.stale_droot: bool = True
+
+        fgraph.debug_all_apps: Set["Apply"] = set()
 
-        self.debug_all_apps = set()
         if self.do_imports_on_attach:
-            Bookkeeper.on_attach(self, fgraph)
+            super().on_attach(fgraph)
 
-    def unpickle(self, fgraph):
-        def get_destroyers_of(r):
-            droot, _, root_destroyer = self.refresh_droot_impact()
+        def get_destroyers_of(
+            fgraph: "FunctionGraph", r: "Variable"
+        ) -> List["Variable"]:
+            droot, _, root_destroyer = self.refresh_droot_impact(fgraph)
             try:
                 return [root_destroyer[droot[r]]]
             except Exception:
                 return []
 
-        fgraph.destroyers = get_destroyers_of
+        fgraph.destroyers = MethodType(get_destroyers_of, fgraph)
 
-        def has_destroyers(protected_list):
+        def has_destroyers(
+            fgraph: "FunctionGraph", protected_vars: Iterable["Variable"]
+        ) -> bool:
             if self.algo != "fast":
-                droot, _, root_destroyer = self.refresh_droot_impact()
-                for protected_var in protected_list:
+                droot, _, root_destroyer = self.refresh_droot_impact(fgraph)
+                for protected_var in protected_vars:
                     try:
                         root_destroyer[droot[protected_var]]
                         return True
                     except KeyError:
                         pass
                 return False
 
-            def recursive_destroys_finder(protected_var):
+            def recursive_destroys_finder(protected_var: "Variable") -> bool:
                 # protected_var is the idx'th input of app.
-                for (app, idx) in fgraph.clients[protected_var]:
+                for app, idx in fgraph.clients[protected_var]:
                     if app == "output":
                         continue
-                    destroy_maps = app.op.destroy_map.values()
-                    # If True means that the apply node, destroys the protected_var.
-                    if idx in [dmap for sublist in destroy_maps for dmap in sublist]:
-                        return True
-                    for var_idx in app.op.view_map.keys():
-                        if idx in app.op.view_map[var_idx]:
-                            # We need to recursively check the destroy_map of all the
-                            # outputs that we have a view_map on.
-                            if recursive_destroys_finder(app.outputs[var_idx]):
-                                return True
+                    else:
+                        assert isinstance(app, Apply)
+                        destroy_maps = app.op.destroy_map.values()
+                        # If True means that the apply node, destroys the protected_var.
+                        if idx in [
+                            dmap for sublist in destroy_maps for dmap in sublist
+                        ]:
+                            return True
+                        for var_idx in app.op.view_map.keys():
+                            if idx in app.op.view_map[var_idx]:
+                                # We need to recursively check the destroy_map of all the
+                                # outputs that we have a view_map on.
+                                if recursive_destroys_finder(app.outputs[var_idx]):
+                                    return True
                 return False
 
-            for protected_var in protected_list:
+            for protected_var in protected_vars:
                 if recursive_destroys_finder(protected_var):
                     return True
             return False
 
-        fgraph.has_destroyers = has_destroyers
+        fgraph.has_destroyers = MethodType(has_destroyers, fgraph)
 
-    def refresh_droot_impact(self):
+    def refresh_droot_impact(self, fgraph):
         """
-        Makes sure self.droot, self.impact, and self.root_destroyer are up to
+        Makes sure ``droot``, ``impact``, and ``root_destroyer`` are up to
         date, and returns them (see docstrings for these properties above).
 
         """
-        if self.stale_droot:
-            self.droot, self.impact, self.root_destroyer = _build_droot_impact(self)
-            self.stale_droot = False
-        return self.droot, self.impact, self.root_destroyer
+        if fgraph.stale_droot:
+            fgraph.droot, fgraph.impact, fgraph.root_destroyer = _build_droot_impact(
+                fgraph
+            )
+            fgraph.stale_droot = False
+        return fgraph.droot, fgraph.impact, fgraph.root_destroyer
 
     def on_detach(self, fgraph):
-        if fgraph is not self.fgraph:
-            raise Exception("detaching wrong fgraph", fgraph)
-        del self.destroyers
-        del self.view_i
-        del self.view_o
-        del self.clients
-        del self.stale_droot
-        assert self.fgraph.destroyer_handler is self
-        delattr(self.fgraph, "destroyers")
-        delattr(self.fgraph, "has_destroyers")
-        delattr(self.fgraph, "destroy_handler")
-        self.fgraph = None
+        del fgraph._destroyhandler_destroyers
+        del fgraph.view_i
+        del fgraph.view_o
+        del fgraph._destroy_handler_clients
+        del fgraph.stale_droot
+        delattr(fgraph, "destroyers")
+        delattr(fgraph, "has_destroyers")
+        delattr(fgraph, "destroy_handler")
 
     def fast_destroy(self, fgraph, app, reason):
         """
         Do the check for only 1 level.
 
         For now:
         - Destroyed variables can have only 1 clients.
@@ -463,193 +493,200 @@
             return
         inputs = set(
             itertools.chain.from_iterable(dm.values())
         )  # list of app's destroyed inputs
         for inp_idx in inputs:
             inp = app.inputs[inp_idx]
             if getattr(inp.tag, "indestructible", False) or isinstance(inp, Constant):
-                self.fail_validate[app] = InconsistencyError(
+                fgraph.fail_validate[app] = InconsistencyError(
                     f"Attempting to destroy indestructible variables: {inp}"
                 )
             elif len(fgraph.clients[inp]) > 1:
-                self.fail_validate[app] = InconsistencyError(
-                    "Destroyed variable has more than one client. " + str(reason)
+                fgraph.fail_validate[app] = InconsistencyError(
+                    f"Destroyed variable has more than one client. {reason}"
                 )
             elif inp.owner:
                 app2 = inp.owner
                 inp_idx2 = app2.outputs.index(inp)
                 v = app2.op.view_map
                 d = app2.op.destroy_map
                 if v:
                     v = v.get(inp_idx2, [])
                     if len(v) > 0:
-                        self.fail_validate[app] = InconsistencyError(
-                            "Destroyed variable has view_map. " + str(reason)
+                        fgraph.fail_validate[app] = InconsistencyError(
+                            f"Destroyed variable has view_map. {reason}"
                         )
                 elif d:
                     d = d.get(inp_idx2, [])
                     if len(d) > 0:
-                        self.fail_validate[app] = InconsistencyError(
-                            "Destroyed variable has destroy_map. " + str(reason)
+                        fgraph.fail_validate[app] = InconsistencyError(
+                            f"Destroyed variable has destroy_map. {reason}"
                         )
 
                 # These 2 assertions are commented since this function is called so many times
                 # but they should be true.
                 # assert len(v) <= 1
                 # assert len(d) <= 1
 
     def on_import(self, fgraph, app, reason):
-        """
-        Add Apply instance to set which must be computed.
-
-        """
-        if app in self.debug_all_apps:
+        """Add an `Apply` instance to the set which must be computed."""
+        if app in fgraph.debug_all_apps:
             raise ProtocolError("double import")
-        self.debug_all_apps.add(app)
-        # print 'DH IMPORT', app, id(app), id(self), len(self.debug_all_apps)
+        fgraph.debug_all_apps.add(app)
+        # print 'DH IMPORT', app, id(app), id(self), len(fgraph.debug_all_apps)
 
         # If it's a destructive op, add it to our watch list
         dmap = app.op.destroy_map
         vmap = app.op.view_map
         if dmap:
-            self.destroyers.add(app)
+            fgraph._destroyhandler_destroyers.add(app)
             if self.algo == "fast":
                 self.fast_destroy(fgraph, app, reason)
 
         # add this symbol to the forward and backward maps
         for o_idx, i_idx_list in vmap.items():
             if len(i_idx_list) > 1:
                 raise NotImplementedError(
                     "destroying this output invalidates multiple inputs", (app.op)
                 )
             o = app.outputs[o_idx]
             i = app.inputs[i_idx_list[0]]
-            self.view_i[o] = i
-            self.view_o.setdefault(i, OrderedSet()).add(o)
+            fgraph.view_i[o] = i
+            fgraph.view_o.setdefault(i, OrderedSet()).add(o)
 
-        # update self.clients
+        # update fgraph._destroy_handler_clients
         for i, input in enumerate(app.inputs):
-            self.clients.setdefault(input, OrderedDict()).setdefault(app, 0)
-            self.clients[input][app] += 1
+            fgraph._destroy_handler_clients.setdefault(input, OrderedDict()).setdefault(
+                app, 0
+            )
+            fgraph._destroy_handler_clients[input][app] += 1
 
         for i, output in enumerate(app.outputs):
-            self.clients.setdefault(output, OrderedDict())
+            fgraph._destroy_handler_clients.setdefault(output, OrderedDict())
 
-        self.stale_droot = True
+        fgraph.stale_droot = True
 
     def on_prune(self, fgraph, app, reason):
         """
         Remove Apply instance from set which must be computed.
 
         """
-        if app not in self.debug_all_apps:
+        if app not in fgraph.debug_all_apps:
             raise ProtocolError("prune without import")
-        self.debug_all_apps.remove(app)
+        fgraph.debug_all_apps.remove(app)
 
-        # UPDATE self.clients
+        # UPDATE fgraph._destroy_handler_clients
         for input in set(app.inputs):
-            del self.clients[input][app]
+            del fgraph._destroy_handler_clients[input][app]
 
         if app.op.destroy_map:
-            self.destroyers.remove(app)
+            fgraph._destroyhandler_destroyers.remove(app)
 
         # Note: leaving empty client dictionaries in the struct.
         # Why? It's a pain to remove them. I think they aren't doing any harm, they will be
         # deleted on_detach().
 
-        # UPDATE self.view_i, self.view_o
+        # UPDATE fgraph.view_i, fgraph.view_o
         for o_idx, i_idx_list in app.op.view_map.items():
             if len(i_idx_list) > 1:
                 # destroying this output invalidates multiple inputs
                 raise NotImplementedError()
             o = app.outputs[o_idx]
             i = app.inputs[i_idx_list[0]]
 
-            del self.view_i[o]
-
-            self.view_o[i].remove(o)
-            if not self.view_o[i]:
-                del self.view_o[i]
-
-        self.stale_droot = True
-        if app in self.fail_validate:
-            del self.fail_validate[app]
+            del fgraph.view_i[o]
 
-    def on_change_input(self, fgraph, app, i, old_r, new_r, reason):
+            fgraph.view_o[i].remove(o)
+            if not fgraph.view_o[i]:
+                del fgraph.view_o[i]
+
+        fgraph.stale_droot = True
+        if app in fgraph.fail_validate:
+            del fgraph.fail_validate[app]
+
+    def on_change_input(
+        self,
+        fgraph,
+        app,
+        i,
+        old_r,
+        new_r,
+        reason,
+    ):
         """
         app.inputs[i] changed from old_r to new_r.
 
         """
         if app == "output":
             # app == 'output' is special key that means FunctionGraph is redefining which nodes are being
             # considered 'outputs' of the graph.
             pass
         else:
-            if app not in self.debug_all_apps:
+            if app not in fgraph.debug_all_apps:
                 raise ProtocolError("change without import")
 
-            # UPDATE self.clients
-            self.clients[old_r][app] -= 1
-            if self.clients[old_r][app] == 0:
-                del self.clients[old_r][app]
+            # UPDATE fgraph._destroy_handler_clients
+            fgraph._destroy_handler_clients[old_r][app] -= 1
+            if fgraph._destroy_handler_clients[old_r][app] == 0:
+                del fgraph._destroy_handler_clients[old_r][app]
 
-            self.clients.setdefault(new_r, OrderedDict()).setdefault(app, 0)
-            self.clients[new_r][app] += 1
+            fgraph._destroy_handler_clients.setdefault(new_r, OrderedDict()).setdefault(
+                app, 0
+            )
+            fgraph._destroy_handler_clients[new_r][app] += 1
 
-            # UPDATE self.view_i, self.view_o
+            # UPDATE fgraph.view_i, fgraph.view_o
             for o_idx, i_idx_list in app.op.view_map.items():
                 if len(i_idx_list) > 1:
                     # destroying this output invalidates multiple inputs
                     raise NotImplementedError()
                 i_idx = i_idx_list[0]
                 output = app.outputs[o_idx]
                 if i_idx == i:
                     if app.inputs[i_idx] is not new_r:
                         raise ProtocolError("wrong new_r on change")
 
-                    self.view_i[output] = new_r
+                    fgraph.view_i[output] = new_r
 
-                    self.view_o[old_r].remove(output)
-                    if not self.view_o[old_r]:
-                        del self.view_o[old_r]
+                    fgraph.view_o[old_r].remove(output)
+                    if not fgraph.view_o[old_r]:
+                        del fgraph.view_o[old_r]
 
-                    self.view_o.setdefault(new_r, OrderedSet()).add(output)
+                    fgraph.view_o.setdefault(new_r, OrderedSet()).add(output)
 
             if self.algo == "fast":
-                if app in self.fail_validate:
-                    del self.fail_validate[app]
+                if app in fgraph.fail_validate:
+                    del fgraph.fail_validate[app]
                 self.fast_destroy(fgraph, app, reason)
-        self.stale_droot = True
+        fgraph.stale_droot = True
 
-    def validate(self, fgraph):
+    def validate(self, fgraph) -> bool:
         """
-        Return None.
-
         Raise InconsistencyError when
-        a) orderings() raises an error
-        b) orderings cannot be topologically sorted.
+        a) `FunctionGraph.orderings` raises an error
+        b) `FunctionGraph.orderings` cannot be topologically sorted.
 
         """
-        if self.destroyers:
+        if fgraph._destroyhandler_destroyers:
             if self.algo == "fast":
-                if self.fail_validate:
-                    app_err_pairs = self.fail_validate
-                    self.fail_validate = OrderedDict()
-                    # self.fail_validate can only be a hint that maybe/probably
+                if fgraph.fail_validate:
+                    app_err_pairs = fgraph.fail_validate
+                    fgraph.fail_validate = OrderedDict()
+                    # fgraph.fail_validate can only be a hint that maybe/probably
                     # there is a cycle.This is because inside replace() we could
                     # record many reasons to not accept a change, but we don't
                     # know which one will fail first inside validate(). Thus,the
                     # graph might have already changed when we raise the
-                    # self.fail_validate error. So before raising the error, we
+                    # fgraph.fail_validate error. So before raising the error, we
                     # double check here.
                     for app in app_err_pairs:
                         if app in fgraph.apply_nodes:
                             self.fast_destroy(fgraph, app, "validate")
-                    if self.fail_validate:
-                        self.fail_validate = app_err_pairs
+                    if fgraph.fail_validate:
+                        fgraph.fail_validate = app_err_pairs
                         raise app_err_pairs[app]
             else:
                 ords = self.orderings(fgraph, ordered=False)
                 if _contains_cycle(fgraph, ords):
                     raise InconsistencyError("Dependency graph contains cycles")
         else:
             # James's Conjecture:
@@ -661,124 +698,128 @@
             # caught later. The error will be far from the source. But
             # doing this conjecture should speed up compilation most of
             # the time. The user should create such dependency except
             # if he mess too much with the internal.
             pass
         return True
 
-    def orderings(self, fgraph, ordered=True):
-        """
-        Return orderings induced by destructive operations.
+    def orderings(self, fgraph, ordered: bool = True) -> Dict["Apply", Set["Apply"]]:
+        """Return orderings induced by destructive operations.
 
-        Raise InconsistencyError when
-        a) attempting to destroy indestructable variable, or
-        b) attempting to destroy a value multiple times, or
-        c) an Apply destroys (illegally) one of its own inputs by aliasing
+        Raise an `InconsistencyError` when
+            a) attempting to destroy indestructible variable, or
+            b) attempting to destroy a value multiple times, or
+            c) an `Apply` destroys (illegally) one of its own inputs by aliasing
 
         """
         if ordered:
-            set_type = OrderedSet
-            rval = OrderedDict()
+            set_type = cast(TypingType[Set["Apply"]], OrderedSet)
         else:
             set_type = set
-            rval = dict()
 
-        if self.destroyers:
-            # BUILD DATA STRUCTURES
-            # CHECK for multiple destructions during construction of variables
-
-            droot, impact, __ignore = self.refresh_droot_impact()
-
-            # check for destruction of constants
-            illegal_destroy = [
-                r
-                for r in droot
-                if getattr(r.tag, "indestructible", False) or isinstance(r, Constant)
-            ]
-            if illegal_destroy:
-                raise InconsistencyError(
-                    f"Attempting to destroy indestructible variables: {illegal_destroy}"
+        rval: Dict["Apply", Set["Apply"]] = OrderedDict()
+
+        if not fgraph._destroyhandler_destroyers:
+            return rval
+
+        # BUILD DATA STRUCTURES
+        # CHECK for multiple destructions during construction of variables
+        droot, impact, __ignore = self.refresh_droot_impact(fgraph)
+
+        # check for destruction of constants
+        illegal_destructions = [
+            r
+            for r in droot
+            if getattr(r.tag, "indestructible", False) or isinstance(r, Constant)
+        ]
+        if illegal_destructions:
+            raise InconsistencyError(
+                f"Attempting to destroy indestructible variables: {illegal_destructions}"
+            )
+
+        # add destroyed variable clients as computational dependencies
+        for app in fgraph._destroyhandler_destroyers:
+            # keep track of clients that should run before the current Apply
+            root_clients: Set["Apply"] = set_type()
+            # for each destroyed input...
+            for output_idx, input_idx_list in app.op.destroy_map.items():
+                destroyed_idx = input_idx_list[0]
+                destroyed_variable = app.inputs[destroyed_idx]
+                root = droot[destroyed_variable]
+                root_impact = impact[root]
+                # we generally want to put all clients of things which depend on root
+                # as pre-requisites of app.
+                # But, app is itself one such client!
+                # App will always be a client of the node we're destroying
+                # (destroyed_variable, but the tricky thing is when it is also a client of
+                # *another variable* viewing on the root.  Generally this is illegal, (e.g.,
+                # add_inplace(x, x.T).  In some special cases though, the in-place op will
+                # actually be able to work properly with multiple destroyed inputs (e.g,
+                # add_inplace(x, x).  An Op that can still work in this case should declare
+                # so via the 'destroyhandler_tolerate_same' attribute or
+                # 'destroyhandler_tolerate_aliased' attribute.
+                #
+                # destroyhandler_tolerate_same should be a list of pairs of the form
+                # [(idx0, idx1), (idx0, idx2), ...]
+                # The first element of each pair is the input index of a destroyed
+                # variable.
+                # The second element of each pair is the index of a different input where
+                # we will permit exactly the same variable to appear.
+                # For example, add_inplace.tolerate_same might be [(0,1)] if the destroyed
+                # input is also allowed to appear as the second argument.
+                #
+                # destroyhandler_tolerate_aliased is the same sort of list of
+                # pairs.
+                # op.destroyhandler_tolerate_aliased = [(idx0, idx1)] tells the
+                # destroyhandler to IGNORE an aliasing between a destroyed
+                # input idx0 and another input idx1.
+                # This is generally a bad idea, but it is safe in some
+                # cases, such as
+                # - the op reads from the aliased idx1 before modifying idx0
+                # - the idx0 and idx1 are guaranteed not to overlap (e.g.
+                #   they are pointed at different rows of a matrix).
+                #
+
+                # CHECK FOR INPUT ALIASING
+                # OPT: pre-compute this on import
+                tolerate_same = getattr(app.op, "destroyhandler_tolerate_same", [])
+                assert isinstance(tolerate_same, list)
+                tolerated = {
+                    idx1 for idx0, idx1 in tolerate_same if idx0 == destroyed_idx
+                }
+                tolerated.add(destroyed_idx)
+                tolerate_aliased = getattr(
+                    app.op, "destroyhandler_tolerate_aliased", []
                 )
+                assert isinstance(tolerate_aliased, list)
+                ignored = {
+                    idx1 for idx0, idx1 in tolerate_aliased if idx0 == destroyed_idx
+                }
+                for i, input in enumerate(app.inputs):
+                    if i in ignored:
+                        continue
+                    if input in root_impact and (
+                        i not in tolerated or input is not destroyed_variable
+                    ):
+                        raise InconsistencyError(
+                            f"Input aliasing: {app} ({destroyed_idx}, {i})"
+                        )
 
-            # add destroyed variable clients as computational dependencies
-            for app in self.destroyers:
-                # keep track of clients that should run before the current Apply
-                root_clients = set_type()
-                # for each destroyed input...
-                for output_idx, input_idx_list in app.op.destroy_map.items():
-                    destroyed_idx = input_idx_list[0]
-                    destroyed_variable = app.inputs[destroyed_idx]
-                    root = droot[destroyed_variable]
-                    root_impact = impact[root]
-                    # we generally want to put all clients of things which depend on root
-                    # as pre-requisites of app.
-                    # But, app is itself one such client!
-                    # App will always be a client of the node we're destroying
-                    # (destroyed_variable, but the tricky thing is when it is also a client of
-                    # *another variable* viewing on the root.  Generally this is illegal, (e.g.,
-                    # add_inplace(x, x.T).  In some special cases though, the in-place op will
-                    # actually be able to work properly with multiple destroyed inputs (e.g,
-                    # add_inplace(x, x).  An Op that can still work in this case should declare
-                    # so via the 'destroyhandler_tolerate_same' attribute or
-                    # 'destroyhandler_tolerate_aliased' attribute.
-                    #
-                    # destroyhandler_tolerate_same should be a list of pairs of the form
-                    # [(idx0, idx1), (idx0, idx2), ...]
-                    # The first element of each pair is the input index of a destroyed
-                    # variable.
-                    # The second element of each pair is the index of a different input where
-                    # we will permit exactly the same variable to appear.
-                    # For example, add_inplace.tolerate_same might be [(0,1)] if the destroyed
-                    # input is also allowed to appear as the second argument.
-                    #
-                    # destroyhandler_tolerate_aliased is the same sort of list of
-                    # pairs.
-                    # op.destroyhandler_tolerate_aliased = [(idx0, idx1)] tells the
-                    # destroyhandler to IGNORE an aliasing between a destroyed
-                    # input idx0 and another input idx1.
-                    # This is generally a bad idea, but it is safe in some
-                    # cases, such as
-                    # - the op reads from the aliased idx1 before modifying idx0
-                    # - the idx0 and idx1 are guaranteed not to overlap (e.g.
-                    #   they are pointed at different rows of a matrix).
-                    #
-
-                    # CHECK FOR INPUT ALIASING
-                    # OPT: pre-compute this on import
-                    tolerate_same = getattr(app.op, "destroyhandler_tolerate_same", [])
-                    assert isinstance(tolerate_same, list)
-                    tolerated = {
-                        idx1 for idx0, idx1 in tolerate_same if idx0 == destroyed_idx
-                    }
-                    tolerated.add(destroyed_idx)
-                    tolerate_aliased = getattr(
-                        app.op, "destroyhandler_tolerate_aliased", []
+                # add the rule: app must be preceded by all other Apply instances that
+                # depend on destroyed_input
+                for r in root_impact:
+                    assert not [
+                        a
+                        for a, c in fgraph._destroy_handler_clients[r].items()
+                        if not c
+                    ]
+                    root_clients.update(
+                        [a for a, c in fgraph._destroy_handler_clients[r].items() if c]
                     )
-                    assert isinstance(tolerate_aliased, list)
-                    ignored = {
-                        idx1 for idx0, idx1 in tolerate_aliased if idx0 == destroyed_idx
-                    }
-                    for i, input in enumerate(app.inputs):
-                        if i in ignored:
-                            continue
-                        if input in root_impact and (
-                            i not in tolerated or input is not destroyed_variable
-                        ):
-                            raise InconsistencyError(
-                                f"Input aliasing: {app} ({destroyed_idx}, {i})"
-                            )
-
-                    # add the rule: app must be preceded by all other Apply instances that
-                    # depend on destroyed_input
-                    for r in root_impact:
-                        assert not [a for a, c in self.clients[r].items() if not c]
-                        root_clients.update(
-                            [a for a, c in self.clients[r].items() if c]
-                        )
 
-                # app itself is a client of the destroyed inputs,
-                # but should not run before itself
-                root_clients.remove(app)
-                if root_clients:
-                    rval[app] = root_clients
+            # app itself is a client of the destroyed inputs,
+            # but should not run before itself
+            root_clients.remove(app)
+            if root_clients:
+                rval[app] = root_clients
 
         return rval
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/features.py` & `aesara_nightly-2.9.0.post2/aesara/graph/features.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,28 @@
 import inspect
 import sys
 import time
+import types
 import warnings
 from collections import OrderedDict
-from functools import partial
 from io import StringIO
+from typing import TYPE_CHECKING, Dict, Optional, Set
 
 import numpy as np
 
 import aesara
 from aesara.configdefaults import config
 from aesara.graph.basic import Variable, io_toposort
 from aesara.graph.utils import InconsistencyError
 
 
+if TYPE_CHECKING:
+    from aesara.graph.basic import Apply
+
+
 class AlreadyThere(Exception):
     """
     Raised by a Feature's on_attach callback method if the FunctionGraph
     attempting to attach the feature already has a functionally identical
     feature.
 
     """
@@ -282,43 +287,51 @@
     def on_detach(self, fgraph):
         """
         Called by `FunctionGraph.remove_feature`.  Should remove any
         dynamically-added functionality that it installed into the fgraph.
 
         """
 
-    def on_import(self, fgraph, node, reason):
+    def on_import(self, fgraph, node: "Apply", reason: Optional[str]):
         """
         Called whenever a node is imported into `fgraph`, which is just before
         the node is actually connected to the graph.
 
         Note: this is not called when the graph is created. If you want to
         detect the first nodes to be implemented to the graph, you should do
         this by implementing `on_attach`.
 
         """
 
-    def on_change_input(self, fgraph, node, i, var, new_var, reason=None):
+    def on_change_input(
+        self,
+        fgraph,
+        node: "Apply",
+        i: int,
+        var: "Variable",
+        new_var: "Variable",
+        reason: Optional[str] = None,
+    ):
         """
         Called whenever ``node.inputs[i]`` is changed from `var` to `new_var`.
         At the moment the callback is done, the change has already taken place.
 
         If you raise an exception in this function, the state of the graph
         might be broken for all intents and purposes.
 
         """
 
-    def on_prune(self, fgraph, node, reason):
+    def on_prune(self, fgraph, node: "Apply", reason: Optional[str]) -> None:
         """
         Called whenever a node is pruned (removed) from the `fgraph`, after it
         is disconnected from the graph.
 
         """
 
-    def orderings(self, fgraph):
+    def orderings(self, fgraph, ordered: bool = True) -> Dict["Apply", Set["Apply"]]:
         """
         Called by `FunctionGraph.toposort`. It should return a dictionary of
         ``{node: predecessors}`` where ``predecessors`` is a list of
         nodes that should be computed before the key node.
 
         If you raise an exception in this function, the state of the graph
         might be broken for all intents and purposes.
@@ -337,33 +350,21 @@
         """
         return self
 
 
 class Bookkeeper(Feature):
     def on_attach(self, fgraph):
         for node in io_toposort(fgraph.inputs, fgraph.outputs):
-            self.on_import(fgraph, node, "on_attach")
+            self.on_import(fgraph, node, "Bookkeeper.on_attach")
 
     def on_detach(self, fgraph):
         for node in io_toposort(fgraph.inputs, fgraph.outputs):
             self.on_prune(fgraph, node, "Bookkeeper.detach")
 
 
-class GetCheckpoint:
-    def __init__(self, history, fgraph):
-        self.h = history
-        self.fgraph = fgraph
-        self.nb = 0
-
-    def __call__(self):
-        self.h.history[self.fgraph] = []
-        self.nb += 1
-        return self.nb
-
-
 class LambdaExtract:
     def __init__(self, fgraph, node, i, r, reason=None):
         self.fgraph = fgraph
         self.node = node
         self.i = i
         self.r = r
         self.reason = reason
@@ -371,107 +372,92 @@
     def __call__(self):
         return self.fgraph.change_node_input(
             self.node, self.i, self.r, reason=("Revert", self.reason), check=False
         )
 
 
 class History(Feature):
-    """Keep an history of changes to an FunctionGraph.
+    """Keep a history of changes to a `FunctionGraph`.
 
-    This history can be reverted up to the last checkpoint.. We can
-    revert to only 1 point in the past. This limit was added to lower
-    the memory usage.
+    A `FunctionGraph` can be reverted up to the last checkpoint using this
+    `Feature`.  It can revert to only one point in the past.  This limit was
+    added to lower memory usage.
 
     """
 
-    pickle_rm_attr = ["checkpoint", "revert"]
-
-    def __init__(self):
-        self.history = {}
-
     def on_attach(self, fgraph):
         if hasattr(fgraph, "checkpoint") or hasattr(fgraph, "revert"):
             raise AlreadyThere(
                 "History feature is already present or in"
                 " conflict with another plugin."
             )
-        self.history[fgraph] = []
-        # Don't call unpickle here, as ReplaceValidate.on_attach()
-        # call to History.on_attach() will call the
-        # ReplaceValidate.unpickle and not History.unpickle
-        fgraph.checkpoint = GetCheckpoint(self, fgraph)
-        fgraph.revert = partial(self.revert, fgraph)
+        fgraph._history_is_reverting = False
+        fgraph._history_nb = 0
+        fgraph._history_history = []
+        fgraph.checkpoint = types.MethodType(self.checkpoint, fgraph)
+        fgraph.revert = types.MethodType(self.revert, fgraph)
 
     def clone(self):
         return type(self)()
 
-    def unpickle(self, fgraph):
-        fgraph.checkpoint = GetCheckpoint(self, fgraph)
-        fgraph.revert = partial(self.revert, fgraph)
-
     def on_detach(self, fgraph):
-        """
-        Should remove any dynamically added functionality
-        that it installed into the function_graph
-        """
         del fgraph.checkpoint
         del fgraph.revert
-        del self.history[fgraph]
+        del fgraph._history_history
+        del fgraph._history_is_reverting
 
     def on_change_input(self, fgraph, node, i, r, new_r, reason=None):
-        if self.history[fgraph] is None:
+        if fgraph._history_is_reverting:
             return
-        h = self.history[fgraph]
-        h.append(LambdaExtract(fgraph, node, i, r, reason))
+        fgraph._history_history.append(LambdaExtract(fgraph, node, i, r, str(reason)))
 
-    def revert(self, fgraph, checkpoint):
+    @staticmethod
+    def checkpoint(fgraph):
+        fgraph._history_history = []
+        fgraph._history_nb += 1
+        return fgraph._history_nb
+
+    @staticmethod
+    def revert(fgraph, checkpoint):
         """
         Reverts the graph to whatever it was at the provided
         checkpoint (undoes all replacements). A checkpoint at any
-        given time can be obtained using self.checkpoint().
+        given time can be obtained using :meth:`self.checkpoint`.
 
         """
-        h = self.history[fgraph]
-        self.history[fgraph] = None
-        assert fgraph.checkpoint.nb == checkpoint
+        h = fgraph._history_history
+        fgraph._history_is_reverting = True
+        assert fgraph._history_nb == checkpoint
         while h:
             f = h.pop()
             f()
-        self.history[fgraph] = h
+        fgraph._history_is_reverting = False
 
 
 class Validator(Feature):
-    pickle_rm_attr = ["validate", "consistent"]
-
     def on_attach(self, fgraph):
         for attr in ("validate", "validate_time"):
             if hasattr(fgraph, attr):
                 raise AlreadyThere(
                     "Validator feature is already present or in"
                     " conflict with another plugin."
                 )
-        # Don't call unpickle here, as ReplaceValidate.on_attach()
-        # call to History.on_attach() will call the
-        # ReplaceValidate.unpickle and not History.unpickle
-        fgraph.validate = partial(self.validate_, fgraph)
-        fgraph.consistent = partial(self.consistent_, fgraph)
-
-    def unpickle(self, fgraph):
-        fgraph.validate = partial(self.validate_, fgraph)
-        fgraph.consistent = partial(self.consistent_, fgraph)
+        fgraph.validate = types.MethodType(self.validate_, fgraph)
+        fgraph.consistent = types.MethodType(self.consistent_, fgraph)
 
     def on_detach(self, fgraph):
         """
         Should remove any dynamically added functionality
         that it installed into the function_graph
         """
         del fgraph.validate
         del fgraph.consistent
 
-    def validate_(self, fgraph):
+    @staticmethod
+    def validate_(fgraph):
         """
         If the caller is replace_all_validate, just raise the
         exception. replace_all_validate will print out the
         verbose output. Or it has to be done here before raise.
         """
         t0 = time.perf_counter()
         try:
@@ -495,76 +481,69 @@
                     print(f"validate failed on node {r}.\n Reason: {reason}, {e}")
                 raise
         t1 = time.perf_counter()
         if fgraph.profile:
             fgraph.profile.validate_time += t1 - t0
         return ret
 
-    def consistent_(self, fgraph):
+    @staticmethod
+    def consistent_(fgraph):
         try:
             fgraph.validate()
             return True
         except Exception:
             return False
 
 
 class ReplaceValidate(History, Validator):
-    pickle_rm_attr = (
-        ["replace_validate", "replace_all_validate", "replace_all_validate_remove"]
-        + History.pickle_rm_attr
-        + Validator.pickle_rm_attr
-    )
-
     def on_attach(self, fgraph):
         for attr in (
             "replace_validate",
             "replace_all_validate",
             "replace_all_validate_remove",
         ):
             if hasattr(fgraph, attr):
                 raise AlreadyThere(
                     "ReplaceValidate feature is already present"
                     " or in conflict with another plugin."
                 )
-        self._nodes_removed = set()
-        self.fail_validate = False
+        fgraph._replace_nodes_removed = set()
+        fgraph._replace_validate_failed = False
+
         History.on_attach(self, fgraph)
         Validator.on_attach(self, fgraph)
-        self.unpickle(fgraph)
-
-    def clone(self):
-        return type(self)()
 
-    def unpickle(self, fgraph):
-        History.unpickle(self, fgraph)
-        Validator.unpickle(self, fgraph)
-        fgraph.replace_validate = partial(self.replace_validate, fgraph)
-        fgraph.replace_all_validate = partial(self.replace_all_validate, fgraph)
-        fgraph.replace_all_validate_remove = partial(
+        fgraph.replace_validate = types.MethodType(self.replace_validate, fgraph)
+        fgraph.replace_all_validate = types.MethodType(
+            self.replace_all_validate, fgraph
+        )
+        fgraph.replace_all_validate_remove = types.MethodType(
             self.replace_all_validate_remove, fgraph
         )
 
+    def clone(self):
+        return type(self)()
+
     def on_detach(self, fgraph):
-        """
-        Should remove any dynamically added functionality
-        that it installed into the function_graph
-        """
         History.on_detach(self, fgraph)
         Validator.on_detach(self, fgraph)
-        del self._nodes_removed
+        del fgraph._replace_nodes_removed
+        del fgraph._replace_validate_failed
         del fgraph.replace_validate
         del fgraph.replace_all_validate
         del fgraph.replace_all_validate_remove
 
-    def replace_validate(self, fgraph, r, new_r, reason=None, **kwargs):
-        self.replace_all_validate(fgraph, [(r, new_r)], reason=reason, **kwargs)
+    @staticmethod
+    def replace_validate(fgraph, r, new_r, reason=None, **kwargs):
+        ReplaceValidate.replace_all_validate(
+            fgraph, [(r, new_r)], reason=reason, **kwargs
+        )
 
-    def replace_all_validate(
-        self, fgraph, replacements, reason=None, verbose=None, **kwargs
-    ):
+    @staticmethod
+    def replace_all_validate(fgraph, replacements, reason=None, verbose=None, **kwargs):
         chk = fgraph.checkpoint()
 
         if verbose is None:
             verbose = config.optimizer_verbose
 
         for r, new_r in replacements:
             try:
@@ -611,24 +590,25 @@
             print(
                 f"rewriting: rewrite {reason} replaces {r} of {r.owner} with {new_r} of {new_r.owner}"
             )
 
         # The return is needed by replace_all_validate_remove
         return chk
 
+    @staticmethod
     def replace_all_validate_remove(
-        self, fgraph, replacements, remove, reason=None, warn=True, **kwargs
+        fgraph, replacements, remove, reason=None, warn=True, **kwargs
     ):
         """
         As replace_all_validate, revert the replacement if the ops
         in the list remove are still in the graph. Also print a warning.
 
         """
         chk = fgraph.replace_all_validate(replacements, reason=reason, **kwargs)
-        self._nodes_removed.update(remove)
+        fgraph._replace_nodes_removed.update(remove)
         for rm in remove:
             if rm in fgraph.apply_nodes or rm in fgraph.variables:
                 fgraph.revert(chk)
                 if warn:
                     warnings.warn(
                         "An optimization wanted to replace a Variable"
                         " in the graph, but the replacement for it doesn't"
@@ -640,86 +620,61 @@
     def __getstate__(self):
         d = self.__dict__.copy()
         if "history" in d:
             del d["history"]
         return d
 
     def on_import(self, fgraph, node, reason):
-        if node in self._nodes_removed:
-            self.fail_validate = True
+        if node in fgraph._replace_nodes_removed:
+            fgraph._replace_validate_failed = True
 
     def validate(self, fgraph):
-        if self.fail_validate:
-            self.fail_validate = False
+        if fgraph._replace_validate_failed:
+            fgraph._replace_validate_failed = False
             raise InconsistencyError("Trying to reintroduce a removed node")
 
 
 class NodeFinder(Bookkeeper):
-    def __init__(self):
-        self.fgraph = None
-        self.d = {}
-
     def on_attach(self, fgraph):
         if hasattr(fgraph, "get_nodes"):
             raise AlreadyThere("NodeFinder is already present")
 
-        if self.fgraph is not None and self.fgraph != fgraph:
-            raise Exception("A NodeFinder instance can only serve one FunctionGraph.")
+        fgraph._finder_ops_to_nodes = {}
 
-        self.fgraph = fgraph
-        fgraph.get_nodes = partial(self.query, fgraph)
-        Bookkeeper.on_attach(self, fgraph)
+        def query(self, op):
+            return self._finder_ops_to_nodes.get(op, [])
+
+        fgraph.get_nodes = types.MethodType(query, fgraph)
+        super().on_attach(fgraph)
 
     def clone(self):
         return type(self)()
 
     def on_detach(self, fgraph):
-        """
-        Should remove any dynamically added functionality
-        that it installed into the function_graph
-        """
-        if self.fgraph is not fgraph:
-            raise Exception(
-                "This NodeFinder instance was not attached to the" " provided fgraph."
-            )
-        self.fgraph = None
         del fgraph.get_nodes
-        Bookkeeper.on_detach(self, fgraph)
+        del fgraph._finder_ops_to_nodes
 
     def on_import(self, fgraph, node, reason):
         try:
-            self.d.setdefault(node.op, []).append(node)
-        except TypeError:  # node.op is unhashable
+            fgraph._finder_ops_to_nodes.setdefault(node.op, []).append(node)
+        except TypeError:
+            # In case the `Op` is unhashable
             return
-        except Exception as e:
-            print("OFFENDING node", type(node), type(node.op), file=sys.stderr)
-            try:
-                print("OFFENDING node hash", hash(node.op), file=sys.stderr)
-            except Exception:
-                print("OFFENDING node not hashable", file=sys.stderr)
-            raise e
 
     def on_prune(self, fgraph, node, reason):
         try:
-            nodes = self.d[node.op]
-        except TypeError:  # node.op is unhashable
+            nodes = fgraph._finder_ops_to_nodes[node.op]
+        except TypeError:
+            # In case the `Op` is unhashable
             return
+
         nodes.remove(node)
-        if not nodes:
-            del self.d[node.op]
 
-    def query(self, fgraph, op):
-        try:
-            all = self.d.get(op, [])
-        except TypeError:
-            raise TypeError(
-                f"{op} in unhashable and cannot be queried by the optimizer"
-            )
-        all = list(all)
-        return all
+        if not nodes:
+            del fgraph._finder_ops_to_nodes[node.op]
 
 
 class PrintListener(Feature):
     def __init__(self, active=True):
         self.active = active
 
     def on_attach(self, fgraph):
@@ -778,15 +733,14 @@
         return type(self)(self.protected_out_ids)
 
     def validate(self, fgraph):
         if not hasattr(fgraph, "destroyers"):
             return True
 
         for out in tuple(fgraph.outputs[i] for i in self.protected_out_ids):
-
             node = out.owner
 
             if node is None:
                 continue
 
             # Validate that the node that produces the output does not produce
             # it by modifying something else in-place.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/fg.py` & `aesara_nightly-2.9.0.post2/aesara/graph/fg.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """A container for specifying and manipulating a graph with distinct inputs and outputs."""
 import time
 from collections import OrderedDict
+from types import MethodType
 from typing import (
     TYPE_CHECKING,
     Any,
     Dict,
     Iterable,
     List,
+    Literal,
     Optional,
     Sequence,
     Set,
     Tuple,
     Union,
     cast,
 )
 
-from typing_extensions import Literal
-
 import aesara
 from aesara.configdefaults import config
 from aesara.graph.basic import Apply, AtomicVariable, Variable, applys_between
 from aesara.graph.basic import as_string as graph_as_string
 from aesara.graph.basic import clone_get_equiv, graph_inputs, io_toposort, vars_between
 from aesara.graph.features import AlreadyThere, Feature, ReplaceValidate
 from aesara.graph.utils import MetaObject, MissingInputError, TestValueError
@@ -68,15 +68,15 @@
 
     def __init__(
         self,
         inputs: Optional[Sequence[Variable]] = None,
         outputs: Optional[Sequence[Variable]] = None,
         features: Optional[Sequence[Feature]] = None,
         clone: bool = True,
-        update_mapping: Optional[Dict[Variable, Variable]] = None,
+        update_mapping: Optional[Dict[int, int]] = None,
         **clone_kwds,
     ):
         """
         Create a `FunctionGraph` which operates on the subgraph between the
         `inputs` and `outputs`.
 
         Parameters
@@ -86,16 +86,16 @@
         outputs
             Output variables of the graph.
         features
             A list of features to be added to the `FunctionGraph`.
         clone
             If ``True``, the graph will be cloned.
         update_mapping
-            Mapping between the `inputs` with updates and the `outputs`
-            corresponding to their updates.
+            Mapping between the `outputs` indices of update graphs and the `inputs`
+            indices that are updated with the former's values.
         clone_kwds
             Keywords passed to `clone_get_equiv` when `clone` is ``True``.
         """
         if outputs is None:
             raise ValueError("No outputs specified")
 
         if inputs is None:
@@ -149,15 +149,26 @@
 
             self.add_input(in_var, check=False)
 
         for output in outputs:
             self.add_output(output, reason="init")
 
         self.profile = None
-        self.update_mapping = update_mapping
+
+        self.set_update_mapping(update_mapping)
+
+    def set_update_mapping(self, update_mapping):
+        self.update_mapping = {}
+        self.inv_update_mapping = {}
+
+        if update_mapping:
+            for k, v in update_mapping.items():
+                self.update_mapping[k] = v
+                # `update_mapping` should be bijective, making this reasonable
+                self.inv_update_mapping[v] = k
 
     def add_output(
         self, var: Variable, reason: Optional[str] = None, import_missing: bool = False
     ):
         """Add a new variable as an output to this `FunctionGraph`."""
         self.outputs.append(var)
         self.import_var(var, reason=reason, import_missing=import_missing)
@@ -536,21 +547,31 @@
         seems fine, because the `FunctionGraph.clients` ``dict`` and list in
         which they're contained are already being updated in-place.
         """
         old_idx_mappings = tuple((out, i) for i, out in enumerate(self.outputs))
         self.outputs.pop(idx)
 
         new_idx = 0
-        for (out, old_idx) in old_idx_mappings:
+        for out, old_idx in old_idx_mappings:
+            # We need to update `update_mappings`, as well
+            map_in_idx = self.update_mapping.pop(old_idx, None)
+            self.inv_update_mapping.pop(map_in_idx, None)
+
             if old_idx == idx:
                 continue
+
+            if map_in_idx is not None:
+                self.update_mapping[new_idx] = map_in_idx
+                self.inv_update_mapping[map_in_idx] = new_idx
+
             out_clients = self.clients[out]
             arrow: ClientType = ("output", old_idx)
             arrow_idx = out_clients.index(arrow)
             out_clients[arrow_idx] = ("output", new_idx)
+
             new_idx += 1
 
     def remove_node(self, node: Apply, reason: Optional[str] = None):
         """Remove an `Apply` node from the `FunctionGraph`.
 
         This will remove everything that depends on the outputs of `node`, as
         well as any "orphaned" variables and nodes created by `node`'s removal.
@@ -571,15 +592,14 @@
             self.variables.remove(out)
 
             out_clients = self.clients.get(out, ())
             while out_clients:
                 out_client, out_idx = out_clients.pop()
 
                 if out_client == "output":
-
                     self._remove_output(out_idx)
 
                     # TODO: We could short-circuit all of the graph walking and
                     # clear everything at once when all the outputs are gone.
                     # if not self.outputs:
                     #     self.clients = {inp: [] for inp in self.inputs}
                     #     self.variables = set()
@@ -597,15 +617,14 @@
 
             if out in self.clients:
                 del self.clients[out]
 
         # Remove all the arrows pointing to this `node`, and any orphaned
         # variables created by removing those arrows
         for inp_idx, inp in enumerate(node.inputs):
-
             inp_clients: List[ClientType] = self.clients.get(inp, [])
 
             arrow = (node, inp_idx)
 
             if arrow not in inp_clients:
                 continue
 
@@ -633,16 +652,27 @@
 
         # The callbacks be triggered after everything has been removed so that
         # the `FunctionGraph` state subscribers see is valid.
         self.execute_callbacks("on_prune", node, reason)
 
     def remove_input(self, input_idx: int, reason: Optional[str] = None):
         """Remove the input at index `input_idx`."""
+
         var = self.inputs.pop(input_idx)
 
+        for in_idx, out_idx in tuple(self.inv_update_mapping.items()):
+            if in_idx == input_idx:
+                del self.update_mapping[out_idx]
+                del self.inv_update_mapping[in_idx]
+            elif in_idx > input_idx:
+                new_in_idx = in_idx - 1
+                self.update_mapping[out_idx] = new_in_idx
+                del self.inv_update_mapping[in_idx]
+                self.inv_update_mapping[new_in_idx] = out_idx
+
         for client, idx in list(self.clients[var]):
             if client == "output":
                 out_var = self.outputs[idx]
                 out_node = out_var.owner
                 if out_node is None:
                     assert out_var in self.inputs
                     self.outputs.pop(idx)
@@ -663,51 +693,43 @@
             var, ("output", output_idx), reason=reason, remove_if_empty=True
         )
 
     def attach_feature(self, feature: Feature) -> None:
         """Add a ``graph.features.Feature`` to this function graph and trigger its ``on_attach`` callback."""
         # Filter out literally identical `Feature`s
         if feature in self._features:
-            return  # the feature is already present
+            return
 
         # Filter out functionally identical `Feature`s.
-        # `Feature`s may use their `on_attach` method to raise
-        # `AlreadyThere` if they detect that some
-        # installed `Feature` does the same thing already
-        attach = getattr(feature, "on_attach", None)
-        if attach is not None:
-            try:
-                attach(self)
-            except AlreadyThere:
-                return
+        # `Feature`s may use their `on_attach` method to raise `AlreadyThere`
+        # if they detect that some installed `Feature` does the same thing
+        # already
+        try:
+            feature.on_attach(self)
+        except AlreadyThere:
+            return
+
         self.execute_callbacks_times.setdefault(feature, 0.0)
-        # It would be nice if we could require a specific class instead of
-        # a "workalike" so we could do actual error checking
-        # if not isinstance(feature, Feature):
-        #    raise TypeError("Expected Feature instance, got "+\
-        #            str(type(feature)))
 
-        # Add the feature
         self._features.append(feature)
 
     def remove_feature(self, feature: Feature) -> None:
         """Remove a feature from the graph.
 
         Calls ``feature.on_detach(function_graph)`` if an ``on_detach`` method
         is defined.
 
         """
         try:
             # Why do we catch the exception anyway?
             self._features.remove(feature)
         except ValueError:
             return
-        detach = getattr(feature, "on_detach", None)
-        if detach is not None:
-            detach(self)
+
+        feature.on_detach(self)
 
     def execute_callbacks(self, name: str, *args, **kwargs) -> None:
         """Execute callbacks.
 
         Calls ``getattr(feature, name)(*args)`` for each feature which has
         a method called after name.
 
@@ -899,30 +921,25 @@
 
         if attach_feature:
             for feature in self._features:
                 e.attach_feature(feature.clone())
         return e, equiv
 
     def __getstate__(self):
-        # This is needed as some features introduce instance methods
-        # This is not picklable
-        d = self.__dict__.copy()
-        for feature in self._features:
-            for attr in getattr(feature, "pickle_rm_attr", []):
-                del d[attr]
-
-        # XXX: The `Feature` `DispatchingFeature` takes functions as parameter
-        # and they can be lambda functions, making them unpicklable.
+        # Remove methods that were attached by features
+        self_dict = {
+            k: v for k, v in self.__dict__.items() if not isinstance(v, MethodType)
+        }
+
+        # `execute_callbacks_times` holds references to optimizers, so they
+        # can't be pickled
+        if "execute_callbacks_times" in self_dict:
+            del self_dict["execute_callbacks_times"]
 
-        # execute_callbacks_times have reference to optimizer, and they can't
-        # be pickled as the decorators with parameters aren't pickable.
-        if "execute_callbacks_times" in d:
-            del d["execute_callbacks_times"]
-
-        return d
+        return self_dict
 
     def __setstate__(self, dct):
         self.__dict__.update(dct)
         for feature in self._features:
             if hasattr(feature, "unpickle"):
                 feature.unpickle(self)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/null_type.py` & `aesara_nightly-2.9.0.post2/aesara/graph/null_type.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/op.py` & `aesara_nightly-2.9.0.post2/aesara/graph/op.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,24 +5,22 @@
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Dict,
     List,
     Optional,
+    Protocol,
     Sequence,
-    Text,
     Tuple,
     TypeVar,
     Union,
     cast,
 )
 
-from typing_extensions import Protocol
-
 import aesara
 from aesara.configdefaults import config
 from aesara.graph.basic import Apply, NoParams, Variable
 from aesara.graph.utils import (
     MetaObject,
     MethodNotDefined,
     TestValueError,
@@ -492,15 +490,15 @@
         raise MethodNotDefined("get_params")
 
     def prepare_node(
         self,
         node: Apply,
         storage_map: Optional[StorageMapType],
         compute_map: Optional[ComputeMapType],
-        impl: Optional[Text],
+        impl: Optional[str],
     ) -> None:
         """Make any special modifications that the `Op` needs before doing :meth:`Op.make_thunk`.
 
         This can modify the node inplace and should return nothing.
 
         It can be called multiple time with different `impl` values.
 
@@ -569,15 +567,15 @@
 
     def make_thunk(
         self,
         node: Apply,
         storage_map: StorageMapType,
         compute_map: ComputeMapType,
         no_recycling: List[Variable],
-        impl: Optional[Text] = None,
+        impl: Optional[str] = None,
     ) -> ThunkType:
         r"""Create a thunk.
 
         This function must return a thunk, that is a zero-arguments
         function that encapsulates the computation to be performed
         by this op on the arguments of the node.
 
@@ -672,15 +670,15 @@
     """
     if not isinstance(v, Variable):
         v = aesara.tensor.as_tensor_variable(v)
 
     return v.get_test_value()
 
 
-def missing_test_message(msg: Text) -> None:
+def missing_test_message(msg: str) -> None:
     """Display a message saying that some test_value is missing.
 
     This uses the appropriate form based on ``config.compute_test_value``:
 
         off:
             The interactive debugger is off, so we do nothing.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/opt.py` & `aesara_nightly-2.9.0.post2/aesara/graph/opt.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/opt_utils.py` & `aesara_nightly-2.9.0.post2/aesara/graph/opt_utils.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/optdb.py` & `aesara_nightly-2.9.0.post2/aesara/graph/optdb.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/rewriting/basic.py` & `aesara_nightly-2.9.0.post2/aesara/graph/rewriting/basic.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,17 +11,15 @@
 import warnings
 from collections import UserList, defaultdict, deque
 from collections.abc import Iterable
 from functools import _compose_mro, partial, reduce  # type: ignore
 from itertools import chain
 from typing import TYPE_CHECKING, Callable, Dict
 from typing import Iterable as IterableType
-from typing import List, Optional, Sequence, Tuple, Union, cast
-
-from typing_extensions import Literal
+from typing import List, Literal, Optional, Sequence, Tuple, Union, cast
 
 import aesara
 from aesara.configdefaults import config
 from aesara.graph import destroyhandler as dh
 from aesara.graph.basic import (
     Apply,
     AtomicVariable,
@@ -311,15 +309,14 @@
                 except Exception as e:
                     if self.failure_callback:
                         self.failure_callback(e, self, rewriter)
                         continue
                     else:
                         raise
         finally:
-
             if fgraph.profile:
                 validate_time = fgraph.profile.validate_time - validate_before
                 callbacks_time = {}
                 for k, v in fgraph.execute_callbacks_times.items():
                     if k in callbacks_before:
                         t = v - callbacks_before[k]
                         if t > 0:
@@ -407,24 +404,24 @@
         if level == 0:
             print(
                 blanc,
                 "  time      - (name, class, index, nodes before, nodes after) - validate time",
                 file=stream,
             )
         ll = []
-        for (rewrite, nb_n) in zip(rewrites, nb_nodes):
+        for rewrite, nb_n in zip(rewrites, nb_nodes):
             if hasattr(rewrite, "__name__"):
                 name = rewrite.__name__
             else:
                 name = rewrite.name
             idx = rewrites.index(rewrite)
             ll.append((name, rewrite.__class__.__name__, idx) + nb_n)
         lll = sorted(zip(prof, ll), key=lambda a: a[0])
 
-        for (t, rewrite) in lll[::-1]:
+        for t, rewrite in lll[::-1]:
             i = rewrite[2]
             if sub_validate_time:
                 val_time = sub_validate_time[i + 1] - sub_validate_time[i]
                 print(
                     blanc,
                     f"  {t:.6f}s - {rewrite} - {val_time:.3f}s",
                     file=stream,
@@ -640,15 +637,14 @@
             # If two nodes have no input, but perform the same operation,
             # they are not always constant-folded, so we want to merge them.
             # In that case, the candidates are all the nodes without inputs.
             merge_candidates = self.noinput_nodes
 
         replacement_candidates = []
         for candidate in merge_candidates:
-
             if candidate is node:
                 continue
             if len(node.inputs) != len(candidate.inputs):
                 continue
 
             inputs_match = all(
                 node_in is cand_in
@@ -816,15 +812,14 @@
         )
 
     def __str__(self):
         return self.__class__.__name__
 
     @classmethod
     def print_profile(cls, stream, prof, level=0):
-
         (
             nb_fail,
             replace_time,
             validate_time,
             callback_time,
             callbacks_time,
             nb_merged,
@@ -911,15 +906,14 @@
     seen_var = set()
     # signature -> variable (for constants)
     const_sig_inv = {}
     if isinstance(variables, Variable):
         variables = [variables]
 
     def recursive_merge(var):
-
         if var in seen_var:
             return var
 
         if not hasattr(var, "owner"):
             return var
 
         # We don't want to merge constants that are *within* the
@@ -1189,15 +1183,15 @@
         matches = []
         for t in mro:
             match = self.tracked_types.get(t, None)
             if match:
                 matches.extend(match)
         return matches
 
-    @functools.lru_cache()
+    @functools.lru_cache
     def get_trackers(self, op: Op) -> List[NodeRewriter]:
         """Get all the rewrites applicable to `op`."""
         return (
             self._find_impl(type(op))
             + self.tracked_instances.get(op, [])
             + self.untracked_rewrites
         )
@@ -1264,15 +1258,14 @@
             self.process_count: Dict[Rewriter, int] = {}
             self.applied_true: Dict[Rewriter, int] = {}
             self.node_created: Dict[Rewriter, int] = {}
 
         self.tracker = OpToRewriterTracker()
 
         for o in self.rewrites:
-
             self.tracker.add_tracker(o)
 
             if self.profile:
                 self.time_rewrites.setdefault(o, 0.0)
                 self.process_count.setdefault(o, 0)
                 self.applied_true.setdefault(o, 0)
                 self.node_created.setdefault(o, 0)
@@ -1365,30 +1358,30 @@
         if count_rewrite:
             print(
                 blanc,
                 "  time taken - times applied - times tried - name - node_created:",
                 file=stream,
             )
             count_rewrite.sort()
-            for (t, a_t, count, o, n_c) in count_rewrite[::-1]:
+            for t, a_t, count, o, n_c in count_rewrite[::-1]:
                 print(
                     blanc,
                     f"  {t:.3f}s - {int(a_t)} - {int(count)} - {o} - {int(n_c)}",
                     file=stream,
                 )
             print(
                 blanc,
                 (
                     f"  {not_used_time:.3f}s - in {len(not_used)} rewrite(s) that were not used "
                     "(displaying only those with a runtime greater than 0)"
                 ),
                 file=stream,
             )
             not_used.sort(key=lambda nu: (nu[0], str(nu[1])))
-            for (t, o) in not_used[::-1]:
+            for t, o in not_used[::-1]:
                 if t > 0:
                     # Skip rewrites that have 0 times; they probably weren't even tried.
                     print(blanc + "  ", f"  {t:.3f}s - {o}", file=stream)
         else:
             print(blanc, " The rewriter wasn't successful ", file=stream)
 
         print(file=stream)
@@ -2635,27 +2628,27 @@
                 not_used_time += time_rewrites[o]
 
         if count_rewrite:
             print(
                 blanc, "  times - times applied - nb node created - name:", file=stream
             )
             count_rewrite.sort()
-            for (t, count, n_created, o) in count_rewrite[::-1]:
+            for t, count, n_created, o in count_rewrite[::-1]:
                 print(
                     blanc,
                     f"  {t:.3f}s - {int(count)} - {int(n_created)} - {o}",
                     file=stream,
                 )
             print(
                 blanc,
                 f"  {not_used_time:.3f}s - in {len(not_used)} rewrites that were not used (i.e. those with a run-time of zero)",
                 file=stream,
             )
             not_used.sort(key=lambda nu: (nu[0], str(nu[1])))
-            for (t, o) in not_used[::-1]:
+            for t, o in not_used[::-1]:
                 if t > 0:
                     # Skip rewrites that have no run-times; they probably weren't even tried.
                     print(blanc + "  ", f"  {t:.3f}s - {o}", file=stream)
             print(file=stream)
         gf_rewrites = [
             o
             for o in (
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/rewriting/db.py` & `aesara_nightly-2.9.0.post2/aesara/graph/rewriting/db.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/rewriting/kanren.py` & `aesara_nightly-2.9.0.post2/aesara/graph/rewriting/kanren.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/rewriting/unify.py` & `aesara_nightly-2.9.0.post2/aesara/graph/rewriting/unify.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/rewriting/utils.py` & `aesara_nightly-2.9.0.post2/aesara/graph/rewriting/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -110,15 +110,15 @@
     # When two variables perform the same computations, they will have the same
     # owner in the rewritten graph.
     # We need to be careful with the special case where the owner is None,
     # which happens when the graph is made of a single Variable.
     # We also need to make sure we replace a Variable if it is present in
     # `givens`.
     vars_replaced = [givens.get(v, v) for v in fgraph.outputs]
-    o1, o2 = [v.owner for v in vars_replaced]
+    o1, o2 = (v.owner for v in vars_replaced)
     if o1 is None and o2 is None:
         # Comparing two single-Variable graphs: they are equal if they are
         # the same Variable.
         return vars_replaced[0] == vars_replaced[1]
     else:
         return o1 is o2
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/sched.py` & `aesara_nightly-2.9.0.post2/aesara/graph/sched.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/type.py` & `aesara_nightly-2.9.0.post2/aesara/graph/type.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-from abc import abstractmethod
-from typing import Any, Generic, Optional, Text, Tuple, TypeVar, Union
+from abc import ABC, abstractmethod
+from typing import Any, Generic, Optional, Tuple, TypeVar, Union
 
 from typing_extensions import TypeAlias
 
 from aesara.graph import utils
 from aesara.graph.basic import Constant, Variable
 from aesara.graph.utils import MetaObject
 
@@ -184,26 +184,26 @@
         """Return ``True`` for any python object that would be a legal value for a `Variable` of this `Type`."""
         try:
             self.filter(data, strict=strict)
             return True
         except (TypeError, ValueError):
             return False
 
-    def make_variable(self, name: Optional[Text] = None) -> variable_type:
+    def make_variable(self, name: Optional[str] = None) -> variable_type:
         """Return a new `Variable` instance of this `Type`.
 
         Parameters
         ----------
         name: None or str
             A pretty string for printing and debugging.
 
         """
         return self.variable_type(self, None, name=name)
 
-    def make_constant(self, value: D, name: Optional[Text] = None) -> constant_type:
+    def make_constant(self, value: D, name: Optional[str] = None) -> constant_type:
         """Return a new `Constant` instance of this `Type`.
 
         Parameters
         ----------
         value: array-like
             The constant value.
         name: None or str
@@ -212,15 +212,15 @@
         """
         return self.constant_type(type=self, data=value, name=name)
 
     def clone(self, *args, **kwargs) -> "Type":
         """Clone a copy of this type with the given arguments/keyword values, if any."""
         return type(self)(*args, **kwargs)
 
-    def __call__(self, name: Optional[Text] = None) -> variable_type:
+    def __call__(self, name: Optional[str] = None) -> variable_type:
         """Return a new `Variable` instance of Type `self`.
 
         Parameters
         ----------
         name : None or str
             A pretty string for printing and debugging.
 
@@ -258,18 +258,37 @@
         -------
         bool
 
         """
         return cls.values_eq(a, b)
 
 
-class HasDataType:
+class HasDataType(ABC):
     """A mixin for a type that has a :attr:`dtype` attribute."""
 
     dtype: str
 
+    @classmethod
+    def __subclasshook__(cls, C):
+        if cls is HasDataType:
+            if any("dtype" in B.__dict__ for B in C.__mro__):
+                return True
+        return NotImplemented
+
 
-class HasShape:
+class HasShape(ABC):
     """A mixin for a type that has :attr:`shape` and :attr:`ndim` attributes."""
 
     ndim: int
     shape: Tuple[Optional[int], ...]
+
+    @classmethod
+    def __subclasshook__(cls, C):
+        if cls is HasShape:
+            has_shape, has_ndim = False, False
+            for B in C.__mro__:
+                has_shape = has_shape or ("shape" in B.__dict__)
+                has_ndim = has_ndim or ("ndim" in B.__dict__)
+
+                if has_shape and has_ndim:
+                    return True
+        return NotImplemented
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/graph/utils.py` & `aesara_nightly-2.9.0.post2/aesara/graph/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -241,17 +241,15 @@
                         return f"{self.__class__.__name__}"
 
                 else:
 
                     def __str__(self):
                         return "{}{{{}}}".format(
                             self.__class__.__name__,
-                            ", ".join(
-                                "{}={!r}".format(p, getattr(self, p)) for p in props
-                            ),
+                            ", ".join(f"{p}={getattr(self, p)!r}" for p in props),
                         )
 
                 dct["__str__"] = __str__
 
         return super().__new__(cls, name, bases, dct)
 
 
@@ -295,15 +293,14 @@
     def __init__(self, attr, attr_filter):
         super().__init__()
 
         object.__setattr__(self, "attr", attr)
         object.__setattr__(self, "attr_filter", attr_filter)
 
     def __setattr__(self, attr, obj):
-
         if getattr(self, "attr", None) == attr:
             obj = self.attr_filter(obj)
 
         return object.__setattr__(self, attr, obj)
 
 
 class D:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/ifelse.py` & `aesara_nightly-2.9.0.post2/aesara/ifelse.py`

 * *Files 1% similar despite different names*

```diff
@@ -165,15 +165,14 @@
         inputs_true_branch = true_false_branches[: self.n_outs]
         inputs_false_branch = true_false_branches[self.n_outs :]
 
         output_vars = []
         new_inputs_true_branch = []
         new_inputs_false_branch = []
         for input_t, input_f in zip(inputs_true_branch, inputs_false_branch):
-
             if not isinstance(input_t, Variable):
                 input_t = as_symbolic(input_t)
             if not isinstance(input_f, Variable):
                 input_f = as_symbolic(input_f)
 
             if type(input_f.type) != type(input_t.type):  # noqa: E721
                 raise TypeError(
@@ -191,15 +190,14 @@
                         "IfElse requires compatible dtypes for both branches: got "
                         f"true_branch={input_t.type.dtype}, false_branch={input_f.type.dtype}"
                     )
 
             if isinstance(input_t.type, HasShape) and isinstance(
                 input_f.type, HasShape
             ):
-
                 if input_t.type.ndim != input_f.type.ndim:
                     raise TypeError(
                         "IfElse requires compatible ndim values for both branches: got "
                         f"true_branch={input_t.type.ndim}, false_branch={input_f.type.ndim}"
                     )
 
                 # We can only use static shape information that corresponds
@@ -231,15 +229,14 @@
             output_vars,
         )
 
     def R_op(self, inputs, eval_points):
         return self(inputs[0], *eval_points[1:], return_list=True)
 
     def grad(self, ins, grads):
-
         condition = ins[0]
         inputs_true_branch = ins[1:][: self.n_outs]
         inputs_false_branch = ins[1:][self.n_outs :]
 
         if self.name is not None:
             nw_name_t = self.name + "_grad_t"
             nw_name_f = self.name + "_grad_f"
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/basic.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/basic.py`

 * *Files 1% similar despite different names*

```diff
@@ -695,15 +695,14 @@
         init_blocks = []
         blocks = []
 
         failure_var = "__failure"
         id = 1
 
         for variable in self.variables:
-
             if not isinstance(variable.type, CLinkerType):
                 raise NotImplementedError(f"Type of {variable} cannot produce C code")
 
             sub = dict(failure_var=failure_var)
 
             # it might be possible to inline constant variables as C literals
             # policy = [[what to declare in the struct,
@@ -793,15 +792,14 @@
 
             tasks.append((variable, "get", id + 1))
             blocks.append(block)
 
             id += 2
 
         for node_num, node in enumerate(self.node_order):
-
             op = node.op
 
             if not isinstance(op, CLinkerOp):
                 raise NotImplementedError(f"{op} cannot produce C code")
 
             sub = dict(failure_var=failure_var)
 
@@ -1296,15 +1294,14 @@
         no_recycling,
         compile_args=None,
         libraries=None,
         header_dirs=None,
         insert_config_hash=True,
         c_compiler=None,
     ):
-
         # Assemble a dummy fgraph using the provided inputs and outputs. It is
         # only used to compute the cmodule key so it only need to expose an
         # `inputs` and an `outputs` attribute as well as a toposort() method
         # which returns a deterministic result.
         class FakeFunctionGraph:
             def __init__(self, inputs, outputs):
                 self.inputs = inputs
@@ -1694,24 +1691,22 @@
             ") != 0) {",
             file=code,
         )
         print("    delete struct_ptr;", file=code)
         print("    return NULL;", file=code)
         print("  }", file=code)
         print(
-            """\
+            f"""\
     PyObject* thunk = PyCapsule_New((void*)(&{struct_name}_executor), NULL, {struct_name}_destructor);
     if (thunk != NULL && PyCapsule_SetContext(thunk, struct_ptr) != 0) {{
         PyErr_Clear();
         Py_DECREF(thunk);
         thunk = NULL;
     }}
-""".format(
-                **locals()
-            ),
+""",
             file=code,
         )
         print("  return thunk; }", file=code)
         return code.getvalue()
 
 
 class _CThunk:
@@ -1844,15 +1839,14 @@
         self.fgraph = fgraph
         self.no_recycling = no_recycling
         return self
 
     def make_all(
         self, profiler=None, input_storage=None, output_storage=None, storage_map=None
     ):
-
         fgraph = self.fgraph
         order = self.schedule(fgraph)
         no_recycling = self.no_recycling
 
         input_storage, output_storage, storage_map = map_storage(
             fgraph, order, input_storage, output_storage, storage_map
         )
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/c_code/aesara_mod_helper.h` & `aesara_nightly-2.9.0.post2/aesara/link/c/c_code/aesara_mod_helper.h`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/c_code/lazylinker_c.c` & `aesara_nightly-2.9.0.post2/aesara/link/c/c_code/lazylinker_c.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/cmodule.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/cmodule.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,24 +15,33 @@
 import sys
 import sysconfig
 import tempfile
 import textwrap
 import time
 import warnings
 from io import BytesIO, StringIO
-from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Set, Tuple, cast
+from typing import (
+    TYPE_CHECKING,
+    Callable,
+    Dict,
+    List,
+    Optional,
+    Protocol,
+    Set,
+    Tuple,
+    cast,
+)
 
 import numpy as np
 from setuptools._distutils.sysconfig import (
     get_config_h_filename,
     get_config_var,
     get_python_inc,
     get_python_lib,
 )
-from typing_extensions import Protocol
 
 # we will abuse the lockfile mechanism when reading and writing the registry
 from aesara.compile.compilelock import lock_ctx
 from aesara.configdefaults import config, gcc_version_str
 from aesara.configparser import BoolParam, StrParam
 from aesara.graph.op import Op
 from aesara.link.c.exceptions import CompileError, MissingGXX
@@ -2153,23 +2162,21 @@
                 )
             else:
                 default_lines = get_lines(f"{config.cxx} -E -v -")
                 _logger.info(f"g++ default lines: {default_lines}")
                 if len(default_lines) < 1:
                     reported_lines = get_lines(f"{config.cxx} -E -v -", parse=False)
                     warnings.warn(
-                        (
-                            "Aesara was not able to find the "
-                            "default g++ parameters. This is needed to tune "
-                            "the compilation to your specific "
-                            "CPU. This can slow down the execution of Aesara "
-                            "functions. Please submit the following lines to "
-                            "Aesara's mailing list so that we can fix this "
-                            f"problem:\n {reported_lines}"
-                        )
+                        "Aesara was not able to find the "
+                        "default g++ parameters. This is needed to tune "
+                        "the compilation to your specific "
+                        "CPU. This can slow down the execution of Aesara "
+                        "functions. Please submit the following lines to "
+                        "Aesara's mailing list so that we can fix this "
+                        f"problem:\n {reported_lines}"
                     )
                 else:
                     # Some options are actually given as "-option value",
                     # we want to treat them as only one token when comparing
                     # different command lines.
                     # Heuristic: tokens not starting with a dash should be
                     # joined with the previous one.
@@ -2244,15 +2251,15 @@
                                     # OK
                                     continue
                                 # Check the version of GCC
                                 version = gcc_version_str.split(".")
                                 if len(version) != 3:
                                     # Unexpected, but should not be a problem
                                     continue
-                                mj, mn, patch = [int(vp) for vp in version]
+                                mj, mn, patch = (int(vp) for vp in version)
                                 if (
                                     ((mj, mn) == (4, 6) and patch < 4)
                                     or ((mj, mn) == (4, 7) and patch <= 3)
                                     or ((mj, mn) == (4, 8) and patch < 1)
                                 ):
                                     new_flags[i] = p.rstrip("-avx")
 
@@ -2359,14 +2366,20 @@
             # link with libpython.
             cxxflags.append("-DMS_WIN64")
 
         if sys.platform == "darwin":
             # Use the already-loaded python symbols.
             cxxflags.extend(["-undefined", "dynamic_lookup"])
 
+            # Resolves C++11 narrowing error on Mac OS
+            # https://github.com/aesara-devs/aesara/issues/127
+            no_cpp_narrowing_flag = "-Wno-c++11-narrowing"
+            if no_cpp_narrowing_flag not in cxxflags:
+                cxxflags.append(no_cpp_narrowing_flag)
+
         if sys.platform == "win32":
             # Workaround for https://github.com/Theano/Theano/issues/4926.
             # https://github.com/python/cpython/pull/11283/ removed the "hypot"
             # redefinition for recent CPython versions (>=2.7.16 and >=3.7.3).
             # The following nullifies that redefinition, if it is found.
             python_version = sys.version_info[:3]
             if (3,) <= python_version < (3, 7, 3):
@@ -2530,15 +2543,14 @@
 
         include_dirs = include_dirs + std_include_dirs()
         libs = libs + std_libs()
         lib_dirs = lib_dirs + std_lib_dirs()
 
         cppfilename = os.path.join(location, "mod.cpp")
         with open(cppfilename, "w") as cppfile:
-
             _logger.debug(f"Writing module C++ code to {cppfilename}")
 
             cppfile.write(src_code)
             # Avoid gcc warning "no newline at end of file".
             if not src_code.endswith("\n"):
                 cppfile.write("\n")
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/cutils.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/cutils.py`

 * *Files 0% similar despite different names*

```diff
@@ -108,13 +108,12 @@
             # compile the cutils_ext module simultaneously.
             try:
                 # We must retry to import it as some other process could
                 # have been compiling it between the first failed import
                 # and when we receive the lock
                 from cutils_ext.cutils_ext import *  # noqa
             except ImportError:
-
                 compile_cutils()
                 from cutils_ext.cutils_ext import *  # noqa
 finally:
     if sys.path[0] == config.compiledir:
         del sys.path[0]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/cvm.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/cvm.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/interface.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/interface.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import warnings
 from abc import abstractmethod
-from typing import Callable, Dict, List, Text, Tuple, Union
+from typing import Callable, Dict, List, Tuple, Union
 
 from aesara.graph.basic import Apply, Constant
 from aesara.graph.utils import MethodNotDefined
 
 
 class CLinkerObject:
     """Standard methods for an `Op` or `Type` used with the `CLinker`."""
 
-    def c_headers(self, **kwargs) -> List[Text]:
+    def c_headers(self, **kwargs) -> List[str]:
         """Return a list of header files required by code returned by this class.
 
         These strings will be prefixed with ``#include`` and inserted at the
         beginning of the C source code.
 
         Strings in this list that start neither with ``<`` nor ``"`` will be
         enclosed in double-quotes.
@@ -26,15 +26,15 @@
             def c_headers(self, **kwargs):
                 return ['<iostream>', '<math.h>', '/full/path/to/header.h']
 
 
         """
         return []
 
-    def c_header_dirs(self, **kwargs) -> List[Text]:
+    def c_header_dirs(self, **kwargs) -> List[str]:
         """Return a list of header search paths required by code returned by this class.
 
         Provides search paths for headers, in addition to those in any relevant
         environment variables.
 
         .. note::
 
@@ -49,15 +49,15 @@
 
             def c_header_dirs(self, **kwargs):
                 return ['/usr/local/include', '/opt/weirdpath/src/include']
 
         """
         return []
 
-    def c_libraries(self, **kwargs) -> List[Text]:
+    def c_libraries(self, **kwargs) -> List[str]:
         """Return a list of libraries required by code returned by this class.
 
         The compiler will search the directories specified by the environment
         variable ``LD_LIBRARY_PATH`` in addition to any returned by
         :meth:`CLinkerOp.c_lib_dirs`.
 
         .. note::
@@ -73,15 +73,15 @@
 
             def c_libraries(self, **kwargs):
                 return ['gsl', 'gslcblas', 'm', 'fftw3', 'g2c'].
 
         """
         return []
 
-    def c_lib_dirs(self, **kwargs) -> List[Text]:
+    def c_lib_dirs(self, **kwargs) -> List[str]:
         """Return a list of library search paths required by code returned by this class.
 
         Provides search paths for libraries, in addition to those in any
         relevant environment variables (e.g. ``LD_LIBRARY_PATH``).
 
         .. note::
 
@@ -96,30 +96,30 @@
 
             def c_lib_dirs(self, **kwargs):
                 return ['/usr/local/lib', '/opt/weirdpath/build/libs'].
 
         """
         return []
 
-    def c_support_code(self, **kwargs) -> Text:
+    def c_support_code(self, **kwargs) -> str:
         """Return utility code for use by a `Variable` or `Op`.
 
         This is included at global scope prior to the rest of the code for this class.
 
         Question: How many times will this support code be emitted for a graph
         with many instances of the same type?
 
         Returns
         -------
         str
 
         """
         return ""
 
-    def c_compile_args(self, **kwargs) -> List[Text]:
+    def c_compile_args(self, **kwargs) -> List[str]:
         """Return a list of recommended compile arguments for code returned by other methods in this class.
 
         Compiler arguments related to headers, libraries and search paths
         should be provided via the functions `c_headers`, `c_libraries`,
         `c_header_dirs`, and `c_lib_dirs`.
 
         Examples
@@ -129,27 +129,27 @@
 
             def c_compile_args(self, **kwargs):
                 return ['-ffast-math']
 
         """
         return []
 
-    def c_no_compile_args(self, **kwargs) -> List[Text]:
+    def c_no_compile_args(self, **kwargs) -> List[str]:
         """Return a list of incompatible ``gcc`` compiler arguments.
 
         We will remove those arguments from the command line of ``gcc``. So if
         another `Op` adds a compile arg in the graph that is incompatible
         with this `Op`, the incompatible arg will not be used.
 
         This is used, for instance, to remove ``-ffast-math``.
 
         """
         return []
 
-    def c_init_code(self, **kwargs) -> List[Text]:
+    def c_init_code(self, **kwargs) -> List[str]:
         """Return a list of code snippets to be inserted in module initialization."""
         return []
 
     def c_code_cache_version(self) -> Union[Tuple[int, ...], Tuple]:
         """Return a tuple of integers indicating the version of this `Op`.
 
         An empty tuple indicates an "unversioned" `Op` that will not be cached
@@ -172,19 +172,19 @@
 class CLinkerOp(CLinkerObject):
     """Interface definition for `Op` subclasses compiled by `CLinker`."""
 
     @abstractmethod
     def c_code(
         self,
         node: Apply,
-        name: Text,
-        inputs: List[Text],
-        outputs: List[Text],
-        sub: Dict[Text, Text],
-    ) -> Text:
+        name: str,
+        inputs: List[str],
+        outputs: List[str],
+        sub: Dict[str, str],
+    ) -> str:
         """Return the C implementation of an ``Op``.
 
         Returns C code that does the computation associated to this ``Op``,
         given names for the inputs and outputs.
 
         Parameters
         ----------
@@ -236,19 +236,19 @@
 
         """
         return self.c_code_cache_version()
 
     def c_code_cleanup(
         self,
         node: Apply,
-        name: Text,
-        inputs: List[Text],
-        outputs: List[Text],
-        sub: Dict[Text, Text],
-    ) -> Text:
+        name: str,
+        inputs: List[str],
+        outputs: List[str],
+        sub: Dict[str, str],
+    ) -> str:
         """Return C code to run after :meth:`CLinkerOp.c_code`, whether it failed or not.
 
         This is a convenient place to clean up things allocated by :meth:`CLinkerOp.c_code`.
 
         Parameters
         ----------
         node : Apply
@@ -271,15 +271,15 @@
             the name in the list.
         sub : dict of str
             Extra symbols defined in `CLinker` sub symbols (such as ``'fail'``).
 
         """
         return ""
 
-    def c_support_code_apply(self, node: Apply, name: Text) -> Text:
+    def c_support_code_apply(self, node: Apply, name: str) -> str:
         """Return `Apply`-specialized utility code for use by an `Op` that will be inserted at global scope.
 
         Parameters
         ----------
         node : Apply
             The node in the graph being compiled.
         name : str
@@ -292,15 +292,15 @@
         -----
         This function is called in addition to :meth:`CLinkerObject.c_support_code`
         and will supplement whatever is returned from there.
 
         """
         return ""
 
-    def c_init_code_apply(self, node: Apply, name: Text) -> Text:
+    def c_init_code_apply(self, node: Apply, name: str) -> str:
         """Return a code string specific to the `Apply` to be inserted in the module initialization code.
 
         Parameters
         ----------
         node
             An `Apply` instance in the graph being compiled
         name : str
@@ -314,15 +314,15 @@
         This function is called in addition to
         :meth:`CLinkerObject.c_init_code` and will supplement whatever is
         returned from there.
 
         """
         return ""
 
-    def c_init_code_struct(self, node: Apply, name, sub) -> Text:
+    def c_init_code_struct(self, node: Apply, name, sub) -> str:
         """Return an `Apply`-specific code string to be inserted in the struct initialization code.
 
         Parameters
         ----------
         node : Apply
             The node in the graph being compiled.
         name : str
@@ -331,29 +331,29 @@
             A dictionary of values to substitute in the code.
             Most notably it contains a ``'fail'`` entry that you should place
             in your code after setting a Python exception to indicate an error.
 
         """
         return ""
 
-    def c_support_code_struct(self, node: Apply, name: Text) -> Text:
+    def c_support_code_struct(self, node: Apply, name: str) -> str:
         """Return `Apply`-specific utility code for use by an `Op` that will be inserted at struct scope.
 
         Parameters
         ----------
         node : Apply
             The node in the graph being compiled
         name : str
             A unique name to distinguish you variables from those of other
             nodes.
 
         """
         return ""
 
-    def c_cleanup_code_struct(self, node: Apply, name: Text) -> Text:
+    def c_cleanup_code_struct(self, node: Apply, name: str) -> str:
         """Return an `Apply`-specific code string to be inserted in the struct cleanup code.
 
         Parameters
         ----------
         node : Apply
             The node in the graph being compiled
         name : str
@@ -369,16 +369,16 @@
     A `CLinkerType` instance is mainly responsible  for providing the C code that
     interfaces python objects with a C `CLinkerOp` implementation.
 
     """
 
     @abstractmethod
     def c_declare(
-        self, name: Text, sub: Dict[Text, Text], check_input: bool = True
-    ) -> Text:
+        self, name: str, sub: Dict[str, str], check_input: bool = True
+    ) -> str:
         """Return C code to declare variables that will be instantiated by :meth:`CLinkerType.c_extract`.
 
         Parameters
         ----------
         name
             The name of the ``PyObject *`` pointer that will the value for this
             `Type`.
@@ -407,15 +407,15 @@
 
             def c_declare(self, name, sub, check_input=True):
                 return "PyObject ** addr_of_%(name)s;"
 
         """
 
     @abstractmethod
-    def c_init(self, name: Text, sub: Dict[Text, Text]) -> Text:
+    def c_init(self, name: str, sub: Dict[str, str]) -> str:
         """Return C code to initialize the variables that were declared by :meth:`CLinkerType.c_declare`.
 
         Notes
         -----
         The variable called `name` is not necessarily defined yet
         where this code is inserted. This code might be inserted in a
         class constructor for example, whereas the variable `name`
@@ -431,16 +431,16 @@
             def c_init(self, name, sub):
                 return "addr_of_%(name)s = NULL;"
 
         """
 
     @abstractmethod
     def c_extract(
-        self, name: Text, sub: Dict[Text, Text], check_input: bool = True, **kwargs
-    ) -> Text:
+        self, name: str, sub: Dict[str, str], check_input: bool = True, **kwargs
+    ) -> str:
         r"""Return C code to extract a ``PyObject *`` instance.
 
         The code returned from this function must be templated using
         ``%(name)s``, representing the name that the caller wants to
         call this `Variable`. The Python object ``self.data`` is in a
         variable called ``"py_%(name)s"`` and this code must set the
         variables declared by :meth:`CLinkerType.c_declare` to something
@@ -471,15 +471,15 @@
                     "else" + \\\
                     { PyErr_SetString(PyExc_ValueError, \\\
                             'was expecting None'); %(fail)s;}"
 
         """
 
     @abstractmethod
-    def c_sync(self, name: Text, sub: Dict[Text, Text]) -> Text:
+    def c_sync(self, name: str, sub: Dict[str, str]) -> str:
         """Return C code to pack C types back into a ``PyObject``.
 
         The code returned from this function must be templated using
         ``"%(name)s"``, representing the name that the caller wants to
         call this `Variable`. The returned code may set ``"py_%(name)s"``
         to a ``PyObject*`` and that ``PyObject*`` will be accessible from
         Python via ``variable.data``. Do not forget to adjust reference
@@ -490,15 +490,15 @@
         name
             WRITEME
         sub
             WRITEME
 
         """
 
-    def c_element_type(self) -> Text:
+    def c_element_type(self) -> str:
         """Return the name of the primitive C type of items into variables handled by this type.
 
         e.g:
 
          - For ``TensorType(dtype='int64', ...)``: should return ``"npy_int64"``.
         """
         return ""
@@ -509,28 +509,28 @@
         A hint to tell the compiler that this type is a builtin C type or a
         small struct and that its memory footprint is negligible. Simple
         objects may be passed on the stack.
 
         """
         return False
 
-    def c_literal(self, data: Constant) -> Text:
+    def c_literal(self, data: Constant) -> str:
         """Provide a C literal string value for the specified `data`.
 
         Parameters
         ----------
         data
             The data to be converted into a C literal string.
 
         """
         return ""
 
     def c_extract_out(
-        self, name: Text, sub: Dict[Text, Text], check_input: bool = True, **kwargs
-    ) -> Text:
+        self, name: str, sub: Dict[str, str], check_input: bool = True, **kwargs
+    ) -> str:
         """Return C code to extract a ``PyObject *`` instance.
 
         Unlike :math:`CLinkerType.c_extract`, :meth:`CLinkerType.c_extract_out` has to
         accept ``Py_None``, meaning that the variable should be left
         uninitialized.
 
         """
@@ -545,15 +545,15 @@
         }
         """ % dict(
             name=name,
             c_init_code=self.c_init(name, sub),
             c_extract_code=self.c_extract(name, sub, check_input),
         )
 
-    def c_cleanup(self, name: Text, sub: Dict[Text, Text]) -> Text:
+    def c_cleanup(self, name: str, sub: Dict[str, str]) -> str:
         """Return C code to clean up after :meth:`CLinkerType.c_extract`.
 
         This returns C code that should deallocate whatever
         :meth:`CLinkerType.c_extract` allocated or decrease the reference counts. Do
         not decrease ``py_%(name)s``'s reference count.
 
         Parameters
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/lazylinker_c.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/lazylinker_c.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/op.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/op.py`

 * *Files 0% similar despite different names*

```diff
@@ -385,15 +385,14 @@
                         self.code_sections["support_code_apply"] = split[n + 1]
                     elif split[n] == "SUPPORT":
                         self.code_sections["support_code"] = split[n + 1]
                     n += 2
                 continue
 
             elif self.section_re.search(code):
-
                 # Check for code outside of the supported sections
                 split = self.section_re.split(code)
                 if split[0].strip() != "":
                     raise ValueError(
                         "Stray code before first #section "
                         f"statement (in file {func_files[i]}): {split[0]}"
                     )
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/params_type.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/params_type.py`

 * *Files 1% similar despite different names*

```diff
@@ -260,18 +260,15 @@
                     f'Params: ParamsType attribute "{field}" not in Params args.'
                 )
         super().__init__(**kwargs)
         self.__dict__.update(__params_type__=params_type, __signatures__=None)
 
     def __repr__(self):
         return "Params(%s)" % ", ".join(
-            [
-                ("{}:{}:{}".format(k, type(self[k]).__name__, self[k]))
-                for k in sorted(self.keys())
-            ]
+            [(f"{k}:{type(self[k]).__name__}:{self[k]}") for k in sorted(self.keys())]
         )
 
     def __getattr__(self, key):
         if key not in self:
             raise AttributeError(f'Params: attribute "{key}" does not exist.')
         return self[key]
 
@@ -426,18 +423,15 @@
         # Now we can access value of each enum defined inside enum types wrapped into the current ParamsType.
         if key in self.__const_to_enum:
             return self.__const_to_enum[key][key]
         return super().__getattr__(self, key)
 
     def __repr__(self):
         return "ParamsType<%s>" % ", ".join(
-            [
-                ("{}:{}".format(self.fields[i], self.types[i]))
-                for i in range(self.length)
-            ]
+            [(f"{self.fields[i]}:{self.types[i]}") for i in range(self.length)]
         )
 
     def __eq__(self, other):
         return (
             type(self) == type(other)
             and self.fields == other.fields
             and self.types == other.types
@@ -709,15 +703,14 @@
         struct_name_defined = struct_name.upper()
         c_support_code_set = set()
         c_declare_list = []
         c_init_list = []
         c_cleanup_list = []
         c_extract_list = []
         for attribute_name, type_instance in zip(self.fields, self.types):
-
             try:
                 # c_support_code() may return a code string or a list of code strings.
                 support_code = type_instance.c_support_code()
                 if not isinstance(support_code, list):
                     support_code = [support_code]
                 c_support_code_set.update(support_code)
             except MethodNotDefined:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/c/type.py` & `aesara_nightly-2.9.0.post2/aesara/link/c/type.py`

 * *Files 1% similar despite different names*

```diff
@@ -485,16 +485,15 @@
         names_to_aliases = {constant_name: "" for constant_name in self}
         for alias in self.aliases:
             names_to_aliases[self.aliases[alias]] = f"({alias})"
         return "{}<{}>({})".format(
             type(self).__name__,
             self.ctype,
             ", ".join(
-                "{}{}:{}".format(k, names_to_aliases[k], self[k])
-                for k in sorted(self.keys())
+                f"{k}{names_to_aliases[k]}:{self[k]}" for k in sorted(self.keys())
             ),
         )
 
     def __getattr__(self, key):
         if key in self:
             return self[key]
         return CType.__getattr__(self, key)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/basic.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/elemwise.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/elemwise.py`

 * *Files 0% similar despite different names*

```diff
@@ -54,15 +54,14 @@
 
     return careduce
 
 
 @jax_funcify.register(DimShuffle)
 def jax_funcify_DimShuffle(op, **kwargs):
     def dimshuffle(x):
-
         res = jnp.transpose(x, op.transposition)
 
         shape = list(res.shape[: len(op.shuffle)])
 
         for augm in op.augment:
             shape.insert(augm, 1)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/extra_ops.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/extra_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -116,15 +116,14 @@
         return value.at[..., i, j].set(diagonal)
 
     return filldiagonal
 
 
 @jax_funcify.register(FillDiagonalOffset)
 def jax_funcify_FillDiagonalOffset(op, **kwargs):
-
     # def filldiagonaloffset(a, val, offset):
     #     height, width = a.shape
     #
     #     if offset >= 0:
     #         start = offset
     #         num_of_step = min(min(width, height), width - offset)
     #     else:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/nlinalg.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/nlinalg.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/random.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/random.py`

 * *Files 18% similar despite different names*

```diff
@@ -134,15 +134,14 @@
 
 
 @jax_sample_fn.register(aer.CauchyRV)
 @jax_sample_fn.register(aer.GumbelRV)
 @jax_sample_fn.register(aer.LaplaceRV)
 @jax_sample_fn.register(aer.LogisticRV)
 @jax_sample_fn.register(aer.NormalRV)
-@jax_sample_fn.register(aer.StandardNormalRV)
 def jax_sample_fn_loc_scale(op):
     """JAX implementation of random variables in the loc-scale families.
 
     JAX only implements the standard version of random variables in the
     loc-scale family. We thus need to translate and rescale the results
     manually.
 
@@ -342,7 +341,136 @@
         loc, scale = parameters
         sample = loc + jax.random.normal(sampling_key, size, dtype) * scale
         sample_exp = jax.numpy.exp(sample)
         rng["jax_state"] = rng_key
         return (rng, sample_exp)
 
     return sample_fn
+
+
+@jax_sample_fn.register(aer.WaldRV)
+def jax_sample_fn_wald(op):
+    r"""Provide a JAX implementation of `WaldRV`.
+
+    The uses the Multiple Roots transformation sampling from [1]_.
+
+    It is based on the following observation:
+
+    .. math::
+
+        \frac{\lambda(X - \mu^2)}{\mu^2X} \sim \chi_{(1)}^2
+
+    References
+    ----------
+    .. [1] Michael, John R.; Schucany, William R.; Haas, Roy W.
+        Generating Random Variates Using Transformations with Multiple Roots
+
+    """
+
+    def sample_fn(rng, size, dtype, *parameters):
+        rng_key = rng["jax_state"]
+        rng_key, sampling_key = jax.random.split(rng_key, 2)
+        mean, scale = parameters
+
+        key1, key2 = jax.random.split(sampling_key, 2)
+        y = jax.random.normal(key1, size, dtype)
+
+        w = mean * y * y
+        c = mean / (2 * scale)
+        x = mean + c * (w - jax.numpy.sqrt(4 * scale * w + w * w))
+
+        z = jax.random.uniform(key2, size, dtype)
+
+        cond = z <= mean / (mean + x)
+        samples = jax.numpy.where(cond, x, mean * mean / x)
+
+        rng["jax_state"] = rng_key
+        return (rng, samples)
+
+    return sample_fn
+
+
+@jax_sample_fn.register(aer.ChiSquareRV)
+def jax_sample_fn_chisquare(op):
+    """JAX implementation of `ChiSquareRV`"""
+
+    def sample_fn(rng, size, dtype, *parameters):
+        rng_key = rng["jax_state"]
+        rng_key, sampling_key = jax.random.split(rng_key, 2)
+        (df,) = parameters
+        sample = jax.random.gamma(sampling_key, df / 2, size, dtype) * 2
+        rng["jax_state"] = rng_key
+        return (rng, sample)
+
+    return sample_fn
+
+
+@jax_sample_fn.register(aer.GeometricRV)
+def jax_sample_fn_geometric(op):
+    """JAX implementation of `GeometricRV`."""
+
+    def sample_fn(rng, size, dtype, *parameters):
+        rng_key = rng["jax_state"]
+        rng_key, sampling_key = jax.random.split(rng_key, 2)
+        p = parameters[0]
+        sample_num = jax.numpy.log(jax.random.uniform(sampling_key, size))
+        sample = sample_num / jax.numpy.log1p(-p)
+        sample_ceil = jax.numpy.ceil(sample)
+        rng["jax_state"] = rng_key
+        return (rng, sample_ceil)
+
+    return sample_fn
+
+
+@jax_sample_fn.register(aer.GenGammaRV)
+def jax_sample_fn_gengamma(op):
+    r"""Provide a JAX implementation of `GenGammaRV`.
+
+    Samples are obtained from inverse sampling using the following:
+
+    .. math::
+
+        F^{-1}(q; a, d, p) = a \left( G^{-1}(q) \right)^{1/p}
+
+    where :math:`G` is the CDF of a gamma distribution with
+    :math:`\alpha = d/p` and :math:`\beta = 1`.
+
+    .. note::
+
+        Here we use the parametrization :math:`\alpha = d/p`.
+
+    """
+
+    def sample_fn(rng, size, dtype, *parameters):
+        rng_key = rng["jax_state"]
+        rng_key, sampling_key = jax.random.split(rng_key, 2)
+
+        alpha, lam, p = parameters
+        d = alpha / p
+        samples = jax.random.gamma(sampling_key, d, size, dtype)
+        samples = lam * samples ** (1.0 / p)
+
+        rng["jax_state"] = rng_key
+        return (rng, samples)
+
+    return sample_fn
+
+
+@jax_sample_fn.register(aer.InvGammaRV)
+def jax_sample_fn_invgamma(op):
+    """JAX implementation of `InvGammaRV`."""
+
+    def sample_fn(rng, size, dtype, *parameters):
+        rng_key = rng["jax_state"]
+        rng_key, sampling_key = jax.random.split(rng_key, 2)
+
+        (
+            shape,
+            scale,
+        ) = parameters
+        # InvGamma[shape, scale] <-> 1 / Gamma[shape, 1 / scale]
+        samples = 1 / (jax.random.gamma(sampling_key, shape, size, dtype) / scale)
+
+        rng["jax_state"] = rng_key
+        return (rng, samples)
+
+    return sample_fn
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/scalar.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/scalar.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 from aesara.link.jax.dispatch.basic import jax_funcify
 from aesara.scalar import Softplus
 from aesara.scalar.basic import (
     Add,
     Cast,
     Clip,
     Composite,
+    FloorDivide,
     Identity,
-    IntDiv,
     Mod,
     Mul,
     ScalarOp,
     Second,
     Sub,
 )
 from aesara.scalar.math import Erf, Erfc, Erfinv, Log1mexp, Psi
@@ -109,15 +109,15 @@
 def elemwise_scalar_sub(op):
     def elemwise(x, y):
         return x - y
 
     return elemwise
 
 
-@elemwise_scalar.register(IntDiv)
+@elemwise_scalar.register(FloorDivide)
 def elemwise_scalar_intdiv(op):
     def elemwise(x, y):
         return x // y
 
     return elemwise
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/scan.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/scan.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/shape.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/shape.py`

 * *Files 1% similar despite different names*

```diff
@@ -53,15 +53,14 @@
     shape_op = shape.owner.op
     if not isinstance(shape_op, (Shape, Shape_i, JAXShapeTuple)):
         raise NotImplementedError(SHAPE_NOT_COMPATIBLE)
 
 
 @jax_funcify.register(Reshape)
 def jax_funcify_Reshape(op, node, **kwargs):
-
     shape = node.inputs[1]
 
     if isinstance(shape, Constant):
         constant_shape = shape.data
 
         def reshape(x, shape):
             return jnp.reshape(x, constant_shape)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/slinalg.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/slinalg.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,14 @@
         return jax.scipy.linalg.cholesky(a, lower=lower).astype(a.dtype)
 
     return cholesky
 
 
 @jax_funcify.register(Solve)
 def jax_funcify_Solve(op, **kwargs):
-
     if op.assume_a != "gen" and op.lower:
         lower = True
     else:
         lower = False
 
     def solve(a, b, lower=lower):
         return jax.scipy.linalg.solve(a, b, lower=lower)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/subtensor.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/subtensor.py`

 * *Files 2% similar despite different names*

```diff
@@ -33,29 +33,27 @@
 
 def subtensor_assert_indices_jax_compatible(node, idx_list):
     from aesara.graph.basic import Constant
     from aesara.tensor.var import TensorVariable
 
     ilist = indices_from_subtensor(node.inputs[1:], idx_list)
     for idx in ilist:
-
         if isinstance(idx, TensorVariable):
             if idx.type.dtype == "bool":
                 raise NotImplementedError(BOOLEAN_MASK_ERROR)
         elif isinstance(idx, slice):
             for slice_arg in (idx.start, idx.stop, idx.step):
                 if slice_arg is not None and not isinstance(slice_arg, Constant):
                     raise NotImplementedError(DYNAMIC_SLICE_LENGTH_ERROR)
 
 
 @jax_funcify.register(Subtensor)
 @jax_funcify.register(AdvancedSubtensor)
 @jax_funcify.register(AdvancedSubtensor1)
 def jax_funcify_Subtensor(op, node, **kwargs):
-
     idx_list = getattr(op, "idx_list", None)
     subtensor_assert_indices_jax_compatible(node, idx_list)
 
     def subtensor_constant(x, *ilists):
         indices = indices_from_subtensor(ilists, idx_list)
         if len(indices) == 1:
             indices = indices[0]
@@ -64,15 +62,14 @@
 
     return subtensor_constant
 
 
 @jax_funcify.register(IncSubtensor)
 @jax_funcify.register(AdvancedIncSubtensor1)
 def jax_funcify_IncSubtensor(op, node, **kwargs):
-
     idx_list = getattr(op, "idx_list", None)
 
     if getattr(op, "set_instead_of_inc", False):
 
         def jax_fn(x, indices, y):
             return x.at[indices].set(y)
 
@@ -89,15 +86,14 @@
         return jax_fn(x, indices, y)
 
     return incsubtensor
 
 
 @jax_funcify.register(AdvancedIncSubtensor)
 def jax_funcify_AdvancedIncSubtensor(op, node, **kwargs):
-
     if getattr(op, "set_instead_of_inc", False):
 
         def jax_fn(x, indices, y):
             return x.at[indices].set(y)
 
     else:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/dispatch/tensor_basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/dispatch/tensor_basic.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/jax/linker.py` & `aesara_nightly-2.9.0.post2/aesara/link/jax/linker.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/basic.py`

 * *Files 1% similar despite different names*

```diff
@@ -50,15 +50,14 @@
 
 if TYPE_CHECKING:
     from aesara.graph.basic import Variable
     from aesara.graph.op import StorageMapType
 
 
 def numba_njit(*args, **kwargs):
-
     if len(args) > 0 and callable(args[0]):
         return numba.njit(*args[1:], cache=config.numba__cache, **kwargs)(args[0])
 
     return numba.njit(*args, cache=config.numba__cache, **kwargs)
 
 
 def numba_vectorize(*args, **kwargs):
@@ -233,15 +232,15 @@
 
         (
             default_start_pos,
             default_start_neg,
             default_stop_pos,
             default_stop_neg,
             default_step,
-        ) = [context.get_constant(types.intp, x) for x in get_defaults(context)]
+        ) = (context.get_constant(types.intp, x) for x in get_defaults(context))
 
         step = pyval.step
         if step is None:
             step_is_neg = False
             step = default_step
         else:
             step_is_neg = step < 0
@@ -436,15 +435,14 @@
         return ret
 
     return cast(Callable, perform)
 
 
 @_numba_funcify.register(OpFromGraph)
 def numba_funcify_OpFromGraph(op, node=None, **kwargs):
-
     _ = kwargs.pop("storage_map", None)
 
     fgraph_fn = numba_njit(numba_funcify(op.fgraph, **kwargs))
 
     if len(op.fgraph.outputs) == 1:
 
         @numba_njit
@@ -568,15 +566,14 @@
     return subtensor_def_src
 
 
 @_numba_funcify.register(Subtensor)
 @_numba_funcify.register(AdvancedSubtensor)
 @_numba_funcify.register(AdvancedSubtensor1)
 def numba_funcify_Subtensor(op, node, **kwargs):
-
     subtensor_def_src = create_index_func(
         node, objmode=isinstance(op, AdvancedSubtensor)
     )
 
     global_env = {"np": np, "objmode": numba.objmode}
 
     subtensor_fn = compile_function_src(
@@ -585,15 +582,14 @@
 
     return numba_njit(subtensor_fn)
 
 
 @_numba_funcify.register(IncSubtensor)
 @_numba_funcify.register(AdvancedIncSubtensor)
 def numba_funcify_IncSubtensor(op, node, **kwargs):
-
     incsubtensor_def_src = create_index_func(
         node, objmode=isinstance(op, AdvancedIncSubtensor)
     )
 
     global_env = {"np": np, "objmode": numba.objmode}
 
     incsubtensor_fn = compile_function_src(
@@ -634,15 +630,14 @@
             return advancedincsubtensor1_inplace(x, vals, idxs)
 
         return advancedincsubtensor1
 
 
 @_numba_funcify.register(DeepCopyOp)
 def numba_funcify_DeepCopyOp(op, node, **kwargs):
-
     # Scalars are apparently returned as actual Python scalar types and not
     # NumPy scalars, so we need two separate Numba functions for each case.
 
     # The type can also be RandomType with no ndims
     if not hasattr(node.outputs[0].type, "ndim") or node.outputs[0].type.ndim == 0:
         # TODO: Do we really need to compile a pass-through function like this?
         @numba_njit(inline="always")
@@ -685,15 +680,14 @@
         return np.shape(x)[i]
 
     return shape_i
 
 
 @numba.extending.intrinsic
 def direct_cast(typingctx, val, typ):
-
     if isinstance(typ, numba.types.TypeRef):
         casted = typ.instance_type
     elif isinstance(typ, numba.types.DTypeSpec):
         casted = typ.dtype
     else:
         casted = typ
 
@@ -755,15 +749,14 @@
     return numba_njit(specify_shape)
 
 
 def int_to_float_fn(inputs, out_dtype):
     """Create a Numba function that converts integer and boolean ``ndarray``s to floats."""
 
     if any(i.type.numpy_dtype.kind in "ib" for i in inputs):
-
         args_dtype = np.dtype(f"f{out_dtype.itemsize}")
 
         @numba_njit(inline="always")
         def inputs_cast(x):
             return x.astype(args_dtype)
 
     else:
@@ -790,15 +783,14 @@
         return np.asarray(np.dot(inputs_cast(x), inputs_cast(y))).astype(out_dtype)
 
     return dot
 
 
 @_numba_funcify.register(Softplus)
 def numba_funcify_Softplus(op, node, **kwargs):
-
     x_dtype = np.dtype(node.inputs[0].dtype)
 
     @numba_njit
     def softplus(x):
         if x < -37.0:
             return direct_cast(np.exp(x), x_dtype)
         elif x < 18.0:
@@ -814,15 +806,14 @@
 @_numba_funcify.register(Cholesky)
 def numba_funcify_Cholesky(op, node, **kwargs):
     lower = op.lower
 
     out_dtype = node.outputs[0].type.numpy_dtype
 
     if lower:
-
         inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
         @numba_njit(inline="always")
         def cholesky(a):
             return np.linalg.cholesky(inputs_cast(a)).astype(out_dtype)
 
     else:
@@ -845,20 +836,18 @@
             return ret
 
     return cholesky
 
 
 @_numba_funcify.register(Solve)
 def numba_funcify_Solve(op, node, **kwargs):
-
     assume_a = op.assume_a
     # check_finite = op.check_finite
 
     if assume_a != "gen":
-
         lower = op.lower
 
         warnings.warn(
             (
                 "Numba will use object mode to allow the "
                 "`compute_uv` argument to `numpy.linalg.svd`."
             ),
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/elemwise.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/elemwise.py`

 * *Files 1% similar despite different names*

```diff
@@ -24,21 +24,21 @@
     unique_name_generator,
 )
 from aesara.scalar.basic import (
     AND,
     OR,
     XOR,
     Add,
-    IntDiv,
+    FloorDivide,
     Mean,
     Mul,
     ScalarMaximum,
     ScalarMinimum,
     Sub,
-    TrueDiv,
+    TrueDivide,
 )
 from aesara.scalar.basic import add as add_as
 from aesara.scalar.basic import scalar_maximum
 from aesara.tensor.elemwise import CAReduce, DimShuffle, Elemwise
 from aesara.tensor.math import MaxAndArgmax, MulWithoutZeros
 from aesara.tensor.special import LogSoftmax, Softmax, SoftmaxGrad
 
@@ -97,20 +97,20 @@
 
 
 @scalar_in_place_fn.register(XOR)
 def scalar_in_place_fn_XOR(op, idx, res, arr):
     return f"{res}[{idx}] ^= {arr}"
 
 
-@scalar_in_place_fn.register(TrueDiv)
+@scalar_in_place_fn.register(TrueDivide)
 def scalar_in_place_fn_TrueDiv(op, idx, res, arr):
     return f"{res}[{idx}] /= {arr}"
 
 
-@scalar_in_place_fn.register(IntDiv)
+@scalar_in_place_fn.register(FloorDivide)
 def scalar_in_place_fn_IntDiv(op, idx, res, arr):
     return f"{res}[{idx}] //= {arr}"
 
 
 @scalar_in_place_fn.register(ScalarMaximum)
 def scalar_in_place_fn_ScalarMaximum(op, idx, res, arr):
     return f"""
@@ -421,15 +421,14 @@
         return res
 
     return axis_apply_fn
 
 
 @_numba_funcify.register(Elemwise)
 def numba_funcify_Elemwise(op, node, **kwargs):
-
     scalar_op_fn = numba_funcify(op.scalar_op, node=node, inline="always", **kwargs)
     elemwise_fn = create_vectorize_func(scalar_op_fn, node, use_signature=False)
     elemwise_fn_name = elemwise_fn.__name__
 
     if op.inplace_pattern:
         input_idx = op.inplace_pattern[0]
         sign_obj = inspect.signature(elemwise_fn.py_scalar_func)
@@ -589,15 +588,14 @@
         return dimshuffle_inner(np.asarray(x), shuffle)
 
     return dimshuffle
 
 
 @_numba_funcify.register(Softmax)
 def numba_funcify_Softmax(op, node, **kwargs):
-
     x_at = node.inputs[0]
     x_dtype = x_at.type.numpy_dtype
     x_dtype = numba.np.numpy_support.from_dtype(x_dtype)
     axis = op.axis
 
     if axis is not None:
         reduce_max_py = create_axis_reducer(
@@ -626,15 +624,14 @@
     softmax = jit_compile_reducer(node, softmax_py_fn)
 
     return softmax
 
 
 @_numba_funcify.register(SoftmaxGrad)
 def numba_funcify_SoftmaxGrad(op, node, **kwargs):
-
     sm_at = node.inputs[1]
     sm_dtype = sm_at.type.numpy_dtype
     sm_dtype = numba.np.numpy_support.from_dtype(sm_dtype)
 
     axis = op.axis
     if axis is not None:
         reduce_sum_py = create_axis_reducer(
@@ -657,15 +654,14 @@
     softmax_grad = jit_compile_reducer(node, softmax_grad_py_fn)
 
     return softmax_grad
 
 
 @_numba_funcify.register(LogSoftmax)
 def numba_funcify_LogSoftmax(op, node, **kwargs):
-
     x_at = node.inputs[0]
     x_dtype = x_at.type.numpy_dtype
     x_dtype = numba.np.numpy_support.from_dtype(x_dtype)
     axis = op.axis
 
     if axis is not None:
         reduce_max_py = create_axis_reducer(
@@ -704,15 +700,14 @@
     if x_ndim == 0:
 
         @numba_basic.numba_njit(inline="always")
         def maxandargmax(x):
             return x, 0
 
     else:
-
         axes = tuple(int(ax) for ax in axis)
 
         # NumPy does not support multiple axes for argmax; this is a
         # work-around
         keep_axes = tuple(i for i in range(x_ndim) if i not in axes)
 
         reduce_max_py_fn = create_multiaxis_reducer(
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/extra_ops.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/extra_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -98,15 +98,14 @@
         return b.reshape(a.shape)
 
     return filldiagonaloffset
 
 
 @_numba_funcify.register(RavelMultiIndex)
 def numba_funcify_RavelMultiIndex(op, node, **kwargs):
-
     mode = op.mode
     order = op.order
 
     if order != "C":
         raise NotImplementedError(
             "Numba does not implement `order` in `numpy.ravel_multi_index`"
         )
@@ -171,15 +170,14 @@
 
     use_python = False
 
     if axis is not None:
         use_python = True
 
     if use_python:
-
         warnings.warn(
             (
                 "Numba will use object mode to allow the "
                 "`axis` argument to `numpy.repeat`."
             ),
             UserWarning,
         )
@@ -229,15 +227,14 @@
     if not use_python:
 
         @numba_basic.numba_njit(inline="always")
         def unique(x):
             return np.unique(x)
 
     else:
-
         warnings.warn(
             (
                 "Numba will use object mode to allow the "
                 "`axis` and/or `return_*` arguments to `numpy.unique`."
             ),
             UserWarning,
         )
@@ -325,15 +322,14 @@
             return np.searchsorted(a, v, side)
 
     return searchsorted
 
 
 @_numba_funcify.register(BroadcastTo)
 def numba_funcify_BroadcastTo(op, node, **kwargs):
-
     create_zeros_tuple = numba_basic.create_tuple_creator(
         lambda _: 0, len(node.inputs) - 1
     )
 
     @numba_basic.numba_njit
     def broadcast_to(x, *shape):
         scalars_shape = create_zeros_tuple()
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/nlinalg.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/nlinalg.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,15 +23,14 @@
 
 @_numba_funcify.register(SVD)
 def numba_funcify_SVD(op, node, **kwargs):
     full_matrices = op.full_matrices
     compute_uv = op.compute_uv
 
     if not compute_uv:
-
         warnings.warn(
             (
                 "Numba will use object mode to allow the "
                 "`compute_uv` argument to `numpy.linalg.svd`."
             ),
             UserWarning,
         )
@@ -41,41 +40,38 @@
         @numba_basic.numba_njit
         def svd(x):
             with numba.objmode(ret=ret_sig):
                 ret = np.linalg.svd(x, full_matrices, compute_uv)
             return ret
 
     else:
-
         out_dtype = node.outputs[0].type.numpy_dtype
         inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
         @numba_basic.numba_njit(inline="always")
         def svd(x):
             return np.linalg.svd(inputs_cast(x), full_matrices)
 
     return svd
 
 
 @_numba_funcify.register(Det)
 def numba_funcify_Det(op, node, **kwargs):
-
     out_dtype = node.outputs[0].type.numpy_dtype
     inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
     @numba_basic.numba_njit(inline="always")
     def det(x):
         return numba_basic.direct_cast(np.linalg.det(inputs_cast(x)), out_dtype)
 
     return det
 
 
 @_numba_funcify.register(Eig)
 def numba_funcify_Eig(op, node, **kwargs):
-
     out_dtype_1 = node.outputs[0].type.numpy_dtype
     out_dtype_2 = node.outputs[1].type.numpy_dtype
 
     inputs_cast = int_to_float_fn(node.inputs, out_dtype_1)
 
     @numba_basic.numba_njit
     def eig(x):
@@ -86,15 +82,14 @@
 
 
 @_numba_funcify.register(Eigh)
 def numba_funcify_Eigh(op, node, **kwargs):
     uplo = op.UPLO
 
     if uplo != "L":
-
         warnings.warn(
             (
                 "Numba will use object mode to allow the "
                 "`UPLO` argument to `numpy.linalg.eigh`."
             ),
             UserWarning,
         )
@@ -121,41 +116,38 @@
             return np.linalg.eigh(x)
 
     return eigh
 
 
 @_numba_funcify.register(Inv)
 def numba_funcify_Inv(op, node, **kwargs):
-
     out_dtype = node.outputs[0].type.numpy_dtype
     inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
     @numba_basic.numba_njit(inline="always")
     def inv(x):
         return np.linalg.inv(inputs_cast(x)).astype(out_dtype)
 
     return inv
 
 
 @_numba_funcify.register(MatrixInverse)
 def numba_funcify_MatrixInverse(op, node, **kwargs):
-
     out_dtype = node.outputs[0].type.numpy_dtype
     inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
     @numba_basic.numba_njit(inline="always")
     def matrix_inverse(x):
         return np.linalg.inv(inputs_cast(x)).astype(out_dtype)
 
     return matrix_inverse
 
 
 @_numba_funcify.register(MatrixPinv)
 def numba_funcify_MatrixPinv(op, node, **kwargs):
-
     out_dtype = node.outputs[0].type.numpy_dtype
     inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
     @numba_basic.numba_njit(inline="always")
     def matrixpinv(x):
         return np.linalg.pinv(inputs_cast(x)).astype(out_dtype)
 
@@ -185,15 +177,14 @@
         @numba_basic.numba_njit
         def qr_full(x):
             with numba.objmode(ret=ret_sig):
                 ret = np.linalg.qr(x, mode=mode)
             return ret
 
     else:
-
         out_dtype = node.outputs[0].type.numpy_dtype
         inputs_cast = int_to_float_fn(node.inputs, out_dtype)
 
         @numba_basic.numba_njit(inline="always")
         def qr_full(x):
             return np.linalg.qr(inputs_cast(x))
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/random.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/random.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,210 +1,145 @@
+from copy import copy
+from math import log
 from textwrap import dedent, indent
-from typing import Any, Callable, Dict, Optional
+from typing import Callable, Optional
 
+import numba
 import numba.np.unsafe.ndarray as numba_ndarray
 import numpy as np
-from numba import _helperlib, types
-from numba.core import cgutils
-from numba.extending import (
-    NativeValue,
-    box,
-    models,
-    overload,
-    register_model,
-    typeof_impl,
-    unbox,
-)
-from numpy.random import RandomState
+from numba import types
+from numba.extending import overload, overload_method, register_jitable
+from numba.np.random.distributions import random_beta, random_standard_gamma
+from numba.np.random.generator_core import next_double
+from numba.np.random.generator_methods import check_size, check_types, is_nonelike
 
 import aesara.tensor.random.basic as aer
 from aesara.graph.basic import Apply
-from aesara.graph.op import Op
 from aesara.link.numba.dispatch import basic as numba_basic
-from aesara.link.numba.dispatch.basic import _numba_funcify, numba_const_convert
-from aesara.link.utils import (
-    compile_function_src,
-    get_name_for_object,
-    unique_name_generator,
+from aesara.link.numba.dispatch.basic import (
+    _numba_funcify,
+    create_arg_string,
+    get_numba_type,
 )
+from aesara.link.utils import compile_function_src, unique_name_generator
 from aesara.tensor.basic import get_vector_length
-from aesara.tensor.random.type import RandomStateType
-
-
-class RandomStateNumbaType(types.Type):
-    def __init__(self):
-        super(RandomStateNumbaType, self).__init__(name="RandomState")
-
+from aesara.tensor.random.type import RandomGeneratorType
 
-random_state_numba_type = RandomStateNumbaType()
 
+@get_numba_type.register(RandomGeneratorType)
+def get_numba_type_RandomGeneratorType(aesara_type, var, **kwargs):
+    return numba.types.npy_rng
 
-@typeof_impl.register(RandomState)
-def typeof_index(val, c):
-    return random_state_numba_type
-
-
-@register_model(RandomStateNumbaType)
-class RandomStateNumbaModel(models.StructModel):
-    def __init__(self, dmm, fe_type):
-        members = [
-            # TODO: We can add support for boxing and unboxing
-            # the attributes that describe a RandomState so that
-            # they can be accessed inside njit functions, if required.
-            ("state_key", types.Array(types.uint32, 1, "C")),
-        ]
-        models.StructModel.__init__(self, dmm, fe_type, members)
 
+@overload(copy)
+def copy_NumPyRandomGeneratorType(rng):
+    if not isinstance(rng, types.NumPyRandomGeneratorType):
+        raise TypeError("`copy` only supports Generators right now")
 
-@unbox(RandomStateNumbaType)
-def unbox_random_state(typ, obj, c):
-    """Convert a `RandomState` object to a native `RandomStateNumbaModel` structure.
-
-    Note that this will create a 'fake' structure which will just get the
-    `RandomState` objects accepted in Numba functions but the actual information
-    of the Numba's random state is stored internally and can be accessed
-    anytime using ``numba._helperlib.rnd_get_np_state_ptr()``.
-    """
-    interval = cgutils.create_struct_proxy(typ)(c.context, c.builder)
-    is_error = cgutils.is_not_null(c.builder, c.pyapi.err_occurred())
-    return NativeValue(interval._getvalue(), is_error=is_error)
-
-
-@box(RandomStateNumbaType)
-def box_random_state(typ, val, c):
-    """Convert a native `RandomStateNumbaModel` structure to an `RandomState` object
-    using Numba's internal state array.
-
-    Note that `RandomStateNumbaModel` is just a placeholder structure with no
-    inherent information about Numba internal random state, all that information
-    is instead retrieved from Numba using ``_helperlib.rnd_get_state()`` and a new
-    `RandomState` is constructed using the Numba's current internal state.
-    """
-    pos, state_list = _helperlib.rnd_get_state(_helperlib.rnd_get_np_state_ptr())
-    rng = RandomState()
-    rng.set_state(("MT19937", state_list, pos))
-    class_obj = c.pyapi.unserialize(c.pyapi.serialize_object(rng))
-    return class_obj
-
+    def impl(rng):
+        # TODO: This seems rather inefficient, but also necessary at this
+        # point.  Let's keep an eye out for a better approach.
+        with numba.objmode(new_rng=types.npy_rng):
+            new_rng = copy(rng)
 
-@overload(np.random.uniform)
-def uniform_empty_size(a, b, size):
-    if isinstance(size, types.Tuple) and size.count == 0:
+        return new_rng
 
-        def uniform_no_size(a, b, size):
-            return np.random.uniform(a, b)
+    return impl
 
-        return uniform_no_size
 
-
-@numba_const_convert.register(RandomState)
-def numba_const_convert_RandomState(state, **kwargs):
-    # The `numba_const_convert` in this case is just a passthrough function
-    # that synchronizes Numba's internal random state with the current
-    # `RandomState` object.
-    ints, index = state.get_state()[1:3]
-    ptr = _helperlib.rnd_get_np_state_ptr()
-    _helperlib.rnd_set_state(ptr, (index, [int(x) for x in ints]))
-    return state
-
-
-def make_numba_random_fn(node, np_random_func):
-    """Create Numba implementations for existing Numba-supported ``np.random`` functions.
-
-    The functions generated here add parameter broadcasting and the ``size``
-    argument to the Numba-supported scalar ``np.random`` functions.
-    """
-    if not isinstance(node.inputs[0].type, RandomStateType):
-        raise TypeError("Numba does not support NumPy `Generator`s")
+def make_numba_random_fn(
+    node: Apply, sampler_name: str, sampler_fn: Optional[Callable] = None
+):
+    """Create Numba implementations for Numba-supported `np.random` functions."""
+    if not isinstance(node.inputs[0].type, RandomGeneratorType):
+        raise TypeError("Numba does not support NumPy `RandomState`s")
 
     tuple_size = int(get_vector_length(node.inputs[1]))
     size_dims = tuple_size - max(i.ndim for i in node.inputs[3:])
 
-    # Make a broadcast-capable version of the Numba supported scalar sampling
-    # function
-    bcast_fn_name = f"aesara_random_{get_name_for_object(np_random_func)}"
+    out_dtype = node.outputs[1].type.numpy_dtype
 
-    sized_fn_name = "sized_random_variable"
+    if not node.op.inplace:
+        copy_rng_stmts = "rng = copy(rng)\n"
+    else:
+        copy_rng_stmts = ""
 
     unique_names = unique_name_generator(
         [
-            bcast_fn_name,
-            sized_fn_name,
             "np",
             "np_random_func",
-            "numba_vectorize",
             "to_fixed_tuple",
+            "out_shape",
             "tuple_size",
             "size_dims",
             "rng",
             "size",
             "dtype",
+            "i",
+            "copy",
         ],
         suffix_sep="_",
     )
 
-    bcast_fn_input_names = ", ".join(
-        [unique_names(i, force_unique=True) for i in node.inputs[3:]]
+    dist_arg_names = [unique_names(i) for i in node.inputs[3:]]
+    bcasted_input_stmts = "\n".join(
+        [
+            f"{name}_bcast = np.broadcast_to({name}, out_shape)"
+            if v.type.ndim > 0
+            else f"{name}_bcast = {name}"
+            for name, v in zip(dist_arg_names, node.inputs[3:])
+        ]
     )
-    bcast_fn_global_env = {
-        "np_random_func": np_random_func,
-        "numba_vectorize": numba_basic.numba_vectorize,
-    }
-
-    bcast_fn_src = f"""
-@numba_vectorize
-def {bcast_fn_name}({bcast_fn_input_names}):
-    return np_random_func({bcast_fn_input_names})
-    """
-    bcast_fn = compile_function_src(
-        bcast_fn_src, bcast_fn_name, {**globals(), **bcast_fn_global_env}
+    indexed_inputs = create_arg_string(
+        [
+            f"{name}_bcast[i]" if v.type.ndim > 0 else f"to_scalar({name}_bcast)"
+            for name, v in zip(dist_arg_names, node.inputs[3:])
+        ]
     )
-
-    random_fn_input_names = ", ".join(
-        ["rng", "size", "dtype"] + [unique_names(i) for i in node.inputs[3:]]
+    random_fn_input_names = ", ".join(["rng", "size", "dtype"] + dist_arg_names)
+    input_shape_exprs = create_arg_string(
+        [f"np.shape({name})" for name in dist_arg_names]
     )
 
-    # Now, create a Numba JITable function that implements the `size` parameter
     out_dtype = node.outputs[1].type.numpy_dtype
     random_fn_global_env = {
-        bcast_fn_name: bcast_fn,
         "out_dtype": out_dtype,
+        "np": np,
+        "to_fixed_tuple": numba_ndarray.to_fixed_tuple,
+        "tuple_size": tuple_size,
+        "size_dims": size_dims,
+        "to_scalar": numba_basic.to_scalar,
+        "copy": copy,
     }
 
-    if tuple_size > 0:
-        random_fn_body = dedent(
-            f"""
-        size = to_fixed_tuple(size, tuple_size)
-
-        data = np.empty(size, dtype=out_dtype)
-        for i in np.ndindex(size[:size_dims]):
-            data[i] = {bcast_fn_name}({bcast_fn_input_names})
-
-        """
-        )
-        random_fn_global_env.update(
-            {
-                "np": np,
-                "to_fixed_tuple": numba_ndarray.to_fixed_tuple,
-                "tuple_size": tuple_size,
-                "size_dims": size_dims,
-            }
-        )
+    if sampler_fn is not None:
+        random_fn_global_env[sampler_name] = sampler_fn
+        sampler_fn_expr = f"{sampler_name}(rng, "
+        nb_sampler_fn_name = f"{sampler_name}_sampler"
     else:
-        random_fn_body = f"""data = {bcast_fn_name}({bcast_fn_input_names})"""
+        sampler_fn_expr = f"rng.{sampler_name}("
+        nb_sampler_fn_name = f"{sampler_name}_sampler"
 
-    sized_fn_src = dedent(
+    sampler_fn_src = dedent(
         f"""
-def {sized_fn_name}({random_fn_input_names}):
-{indent(random_fn_body, " " * 4)}
-    return (rng, data)
+    def {nb_sampler_fn_name}({random_fn_input_names}):
+        size_tpl = to_fixed_tuple(size, tuple_size)
+        out_shape = np.broadcast_shapes(size_tpl, {input_shape_exprs})
+{indent(bcasted_input_stmts, " " * 8)}
+{indent(copy_rng_stmts, " " * 8)}
+        samples = np.empty(out_shape, dtype=out_dtype)
+        for i in np.ndindex(out_shape):
+            samples[i] = {sampler_fn_expr}{indexed_inputs})
+
+        return (rng, samples)
     """
-    )
+    ).strip()
+
     random_fn = compile_function_src(
-        sized_fn_src, sized_fn_name, {**globals(), **random_fn_global_env}
+        sampler_fn_src, nb_sampler_fn_name, {**globals(), **random_fn_global_env}
     )
     random_fn = numba_basic.numba_njit(random_fn)
 
     return random_fn
 
 
 @_numba_funcify.register(aer.UniformRV)
@@ -218,154 +153,126 @@
 @_numba_funcify.register(aer.GumbelRV)
 @_numba_funcify.register(aer.ExponentialRV)
 @_numba_funcify.register(aer.WeibullRV)
 @_numba_funcify.register(aer.LogisticRV)
 @_numba_funcify.register(aer.VonMisesRV)
 @_numba_funcify.register(aer.PoissonRV)
 @_numba_funcify.register(aer.GeometricRV)
-@_numba_funcify.register(aer.HyperGeometricRV)
+# @_numba_funcify.register(aer.HyperGeometricRV)
 @_numba_funcify.register(aer.WaldRV)
 @_numba_funcify.register(aer.LaplaceRV)
-@_numba_funcify.register(aer.BinomialRV)
+# @_numba_funcify.register(aer.BinomialRV)
 @_numba_funcify.register(aer.MultinomialRV)
-@_numba_funcify.register(aer.RandIntRV)  # only the first two arguments are supported
 @_numba_funcify.register(aer.ChoiceRV)  # the `p` argument is not supported
 @_numba_funcify.register(aer.PermutationRV)
 def numba_funcify_RandomVariable(op, node, **kwargs):
-    name = op.name
-    np_random_func = getattr(np.random, name)
+    return make_numba_random_fn(node, op.name)
 
-    return make_numba_random_fn(node, np_random_func)
 
+@_numba_funcify.register(aer.NegBinomialRV)
+def numba_funcify_NegBinomialRV(op, node, **kwargs):
+    return make_numba_random_fn(node, "negative_binomial")
 
-def create_numba_random_fn(
-    op: Op,
-    node: Apply,
-    scalar_fn: Callable[[str], str],
-    global_env: Optional[Dict[str, Any]] = None,
-) -> Callable:
-    """Create a vectorized function from a callable that generates the ``str`` function body.
 
-    TODO: This could/should be generalized for other simple function
-    construction cases that need unique-ified symbol names.
-    """
-    np_random_fn_name = f"aesara_random_{get_name_for_object(op.name)}"
+def gamma_scalar_fn(rng, shape, scale):
+    return rng.gamma(shape, scale)
 
-    if global_env:
-        np_global_env = global_env.copy()
-    else:
-        np_global_env = {}
 
-    np_global_env["np"] = np
-    np_global_env["numba_vectorize"] = numba_basic.numba_vectorize
+@_numba_funcify.register(aer.GammaRV)
+def numba_funcify_GammaRV(op, node, **kwargs):
+    scalar_fn = numba_basic.numba_njit(gamma_scalar_fn)
+    return make_numba_random_fn(node, "gamma", scalar_fn)
 
-    unique_names = unique_name_generator(
-        [
-            np_random_fn_name,
-        ]
-        + list(np_global_env.keys())
-        + [
-            "rng",
-            "size",
-            "dtype",
-        ],
-        suffix_sep="_",
-    )
 
-    np_names = [unique_names(i, force_unique=True) for i in node.inputs[3:]]
-    np_input_names = ", ".join(np_names)
-    np_random_fn_src = f"""
-@numba_vectorize
-def {np_random_fn_name}({np_input_names}):
-{scalar_fn(*np_names)}
-    """
-    np_random_fn = compile_function_src(
-        np_random_fn_src, np_random_fn_name, {**globals(), **np_global_env}
-    )
+def cauchy_scalar_fn(rng, loc, scale):
+    return loc + rng.standard_cauchy() * scale
 
-    return make_numba_random_fn(node, np_random_fn)
 
+@_numba_funcify.register(aer.CauchyRV)
+def numba_funcify_CauchyRV(op, node, **kwargs):
+    scalar_fn = numba_basic.numba_njit(cauchy_scalar_fn)
+    return make_numba_random_fn(node, "cauchy", scalar_fn)
 
-@_numba_funcify.register(aer.NegBinomialRV)
-def numba_funcify_NegBinomialRV(op, node, **kwargs):
-    return make_numba_random_fn(node, np.random.negative_binomial)
 
+def pareto_scalar_fn(rng, b, scale):
+    return rng.pareto(b) / scale
 
-@_numba_funcify.register(aer.CauchyRV)
-def numba_funcify_CauchyRV(op, node, **kwargs):
-    def body_fn(loc, scale):
-        return f"    return ({loc} + np.random.standard_cauchy()) / {scale}"
 
-    return create_numba_random_fn(op, node, body_fn)
+@_numba_funcify.register(aer.ParetoRV)
+def numba_funcify_ParetoRV(op, node, **kwargs):
+    scalar_fn = numba_basic.numba_njit(pareto_scalar_fn)
+    return make_numba_random_fn(node, "pareto", scalar_fn)
+
+
+def halfnormal_scalar_fn(rng, loc, scale):
+    return loc + abs(rng.standard_normal()) * scale
 
 
 @_numba_funcify.register(aer.HalfNormalRV)
 def numba_funcify_HalfNormalRV(op, node, **kwargs):
-    def body_fn(a, b):
-        return f"    return {a} + {b} * abs(np.random.normal(0, 1))"
-
-    return create_numba_random_fn(op, node, body_fn)
+    scalar_fn = numba_basic.numba_njit(halfnormal_scalar_fn)
+    return make_numba_random_fn(node, "halfnormal", scalar_fn)
 
 
 @_numba_funcify.register(aer.BernoulliRV)
 def numba_funcify_BernoulliRV(op, node, **kwargs):
     out_dtype = node.outputs[1].type.numpy_dtype
 
-    def body_fn(a):
-        return f"""
-    if {a} < np.random.uniform(0, 1):
-        return direct_cast(0, out_dtype)
-    else:
-        return direct_cast(1, out_dtype)
-        """
+    @numba_basic.numba_njit
+    def scalar_fn(rng, a):
+        if a < rng.uniform(0, 1):
+            return numba_basic.direct_cast(0, out_dtype)
+        else:
+            return numba_basic.direct_cast(1, out_dtype)
 
-    return create_numba_random_fn(
-        op,
-        node,
-        body_fn,
-        {"out_dtype": out_dtype, "direct_cast": numba_basic.direct_cast},
-    )
+    return make_numba_random_fn(node, "bernoulli", scalar_fn)
 
 
 @_numba_funcify.register(aer.CategoricalRV)
 def numba_funcify_CategoricalRV(op, node, **kwargs):
     out_dtype = node.outputs[1].type.numpy_dtype
     size_len = int(get_vector_length(node.inputs[1]))
+    inplace = op.inplace
 
     @numba_basic.numba_njit
     def categorical_rv(rng, size, dtype, p):
+        if not inplace:
+            rng = copy(rng)
+
         if not size_len:
             size_tpl = p.shape[:-1]
         else:
             size_tpl = numba_ndarray.to_fixed_tuple(size, size_len)
             p = np.broadcast_to(p, size_tpl + p.shape[-1:])
 
-        unif_samples = np.asarray(np.random.uniform(0, 1, size_tpl))
+        unif_samples = np.asarray(rng.uniform(0, 1, size_tpl))
 
         res = np.empty(size_tpl, dtype=out_dtype)
         for idx in np.ndindex(*size_tpl):
             res[idx] = np.searchsorted(np.cumsum(p[idx]), unif_samples[idx])
 
         return (rng, res)
 
     return categorical_rv
 
 
 @_numba_funcify.register(aer.DirichletRV)
 def numba_funcify_DirichletRV(op, node, **kwargs):
-
     out_dtype = node.outputs[1].type.numpy_dtype
     alphas_ndim = node.inputs[3].type.ndim
     neg_ind_shape_len = -alphas_ndim + 1
     size_len = int(get_vector_length(node.inputs[1]))
+    inplace = op.inplace
 
     if alphas_ndim > 1:
 
         @numba_basic.numba_njit
         def dirichlet_rv(rng, size, dtype, alphas):
+            if not inplace:
+                rng = copy(rng)
 
             if size_len > 0:
                 size_tpl = numba_ndarray.to_fixed_tuple(size, size_len)
                 if (
                     0 < alphas.ndim - 1 <= len(size_tpl)
                     and size_tpl[neg_ind_shape_len:] != alphas.shape[:-1]
                 ):
@@ -374,19 +281,133 @@
             else:
                 samples_shape = alphas.shape
 
             res = np.empty(samples_shape, dtype=out_dtype)
             alphas_bcast = np.broadcast_to(alphas, samples_shape)
 
             for index in np.ndindex(*samples_shape[:-1]):
-                res[index] = np.random.dirichlet(alphas_bcast[index])
+                res[index] = rng.dirichlet(alphas_bcast[index])
 
             return (rng, res)
 
     else:
 
         @numba_basic.numba_njit
         def dirichlet_rv(rng, size, dtype, alphas):
+            if not inplace:
+                rng = copy(rng)
+
             size = numba_ndarray.to_fixed_tuple(size, size_len)
-            return (rng, np.random.dirichlet(alphas, size))
+            return (rng, rng.dirichlet(alphas, size))
 
     return dirichlet_rv
+
+
+@register_jitable
+def random_dirichlet(bitgen, alpha, size):
+    """
+    This implementation is straight from ``numpy/random/_generator.pyx``.
+    """
+
+    k = len(alpha)
+    alpha_arr = np.asarray(alpha, dtype=np.float64)
+
+    if np.any(np.less_equal(alpha_arr, 0)):
+        raise ValueError("alpha <= 0")
+
+    shape = size + (k,)
+
+    diric = np.zeros(shape, np.float64)
+
+    i = 0
+    totsize = diric.size
+
+    if (k > 0) and (alpha_arr.max() < 0.1):
+        alpha_csum_arr = np.empty_like(alpha_arr)
+        csum = 0.0
+        for j in range(k - 1, -1, -1):
+            csum += alpha_arr[j]
+            alpha_csum_arr[j] = csum
+
+        while i < totsize:
+            acc = 1.0
+            for j in range(k - 1):
+                v = random_beta(bitgen, alpha_arr[j], alpha_csum_arr[j + 1])
+                diric[i + j] = acc * v
+                acc *= 1.0 - v
+            diric[i + k - 1] = acc
+            i = i + k
+
+    else:
+        while i < totsize:
+            acc = 0.0
+            for j in range(k):
+                diric[i + j] = random_standard_gamma(bitgen, alpha_arr[j])
+                acc = acc + diric[i + j]
+            invacc = 1.0 / acc
+            for j in range(k):
+                diric[i + j] = diric[i + j] * invacc
+            i = i + k
+
+    return diric
+
+
+@overload_method(types.NumPyRandomGeneratorType, "dirichlet")
+def NumPyRandomGeneratorType_dirichlet(inst, alphas, size=None):
+    check_types(alphas, [types.Array, types.List], "alphas")
+
+    if isinstance(size, types.Omitted):
+        size = size.value
+
+    if is_nonelike(size):
+
+        def impl(inst, alphas, size=None):
+            return random_dirichlet(inst.bit_generator, alphas, ())
+
+    elif isinstance(size, (int, types.Integer)):
+
+        def impl(inst, alphas, size=None):
+            return random_dirichlet(inst.bit_generator, alphas, (size,))
+
+    else:
+        check_size(size)
+
+        def impl(inst, alphas, size=None):
+            return random_dirichlet(inst.bit_generator, alphas, size)
+
+    return impl
+
+
+@register_jitable
+def random_gumbel(bitgen, loc, scale):
+    """
+    This implementation is adapted from ``numpy/random/src/distributions/distributions.c``.
+    """
+    while True:
+        u = 1.0 - next_double(bitgen)
+        if u < 1.0:
+            return loc - scale * log(-log(u))
+
+
+@overload_method(types.NumPyRandomGeneratorType, "gumbel")
+def NumPyRandomGeneratorType_gumbel(inst, loc=0.0, scale=1.0, size=None):
+    check_types(loc, [types.Float, types.Integer, int, float], "loc")
+    check_types(scale, [types.Float, types.Integer, int, float], "scale")
+
+    if isinstance(size, types.Omitted):
+        size = size.value
+
+    if is_nonelike(size):
+
+        def impl(inst, loc=0.0, scale=1.0, size=None):
+            return random_gumbel(inst.bit_generator, loc, scale)
+
+    else:
+        check_size(size)
+
+        def impl(inst, loc=0.0, scale=1.0, size=None):
+            out = np.empty(size)
+            for i in np.ndindex(size):
+                out[i] = random_gumbel(inst.bit_generator, loc, scale)
+            return out
+
+    return impl
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/scalar.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/scalar.py`

 * *Files 1% similar despite different names*

```diff
@@ -156,39 +156,36 @@
     nary_fn = compile_function_src(nary_src, binary_op_name, globals())
 
     return nary_fn
 
 
 @_numba_funcify.register(Add)
 def numba_funcify_Add(op, node, **kwargs):
-
     signature = create_numba_signature(node, force_scalar=True)
 
     nary_add_fn = binary_to_nary_func(node.inputs, "add", "+")
 
     return numba_basic.numba_njit(
         signature, inline="always", fastmath=config.numba__fastmath
     )(nary_add_fn)
 
 
 @_numba_funcify.register(Mul)
 def numba_funcify_Mul(op, node, **kwargs):
-
     signature = create_numba_signature(node, force_scalar=True)
 
     nary_mul_fn = binary_to_nary_func(node.inputs, "mul", "*")
 
     return numba_basic.numba_njit(
         signature, inline="always", fastmath=config.numba__fastmath
     )(nary_mul_fn)
 
 
 @_numba_funcify.register(Cast)
 def numba_funcify_Cast(op, node, **kwargs):
-
     dtype = np.dtype(op.o_type.dtype)
 
     @numba_basic.numba_njit(inline="always")
     def cast(x):
         return numba_basic.direct_cast(x, dtype)
 
     return cast
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/scan.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/scan.py`

 * *Files 0% similar despite different names*

```diff
@@ -149,15 +149,14 @@
     # which the output storage is large enough to contain both the initial taps
     # values and the output storage.  In this truncated case, we use the
     # storage array like a circular buffer, and that's why we need to track the
     # storage size along with the taps length/indexing offset.
     def add_output_storage_post_proc_stmt(
         outer_in_name: str, tap_sizes: Tuple[int], storage_size: str
     ):
-
         tap_size = max(tap_sizes)
 
         if op.info.as_while:
             # While loops need to truncate the output storage to a length given
             # by the number of iterations performed.
             output_storage_post_proc_stmts.append(
                 dedent(
@@ -201,15 +200,14 @@
     # `inner_out_post_processing_stmts`.
     storage_alloc_stmts: List[str] = []
 
     for outer_in_name in outer_in_outtap_names:
         outer_in_var = outer_in_names_to_vars[outer_in_name]
 
         if outer_in_name not in outer_in_nit_sot_names:
-
             storage_name = outer_in_to_storage_name[outer_in_name]
 
             is_tensor_type = isinstance(outer_in_var.type, TensorType)
             if is_tensor_type:
                 storage_size_name = f"{outer_in_name}_len"
                 storage_size_stmt = f"{storage_size_name} = {outer_in_name}.shape[0]"
                 input_taps = inner_in_names_to_input_taps[outer_in_name]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/sparse.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/sparse.py`

 * *Files 0% similar despite different names*

```diff
@@ -101,15 +101,14 @@
         ]
         super().__init__(dmm, fe_type, members)
 
 
 @unbox(CSCMatrixType)
 @unbox(CSRMatrixType)
 def unbox_matrix(typ, obj, c):
-
     struct_ptr = cgutils.create_struct_proxy(typ)(c.context, c.builder)
 
     data = c.pyapi.object_getattr_string(obj, "data")
     indices = c.pyapi.object_getattr_string(obj, "indices")
     indptr = c.pyapi.object_getattr_string(obj, "indptr")
     shape = c.pyapi.object_getattr_string(obj, "shape")
 
@@ -163,15 +162,14 @@
 def overload_sparse_shape(x):
     if isinstance(x, CSMatrixType):
         return lambda x: x.shape
 
 
 @overload_attribute(CSMatrixType, "ndim")
 def overload_sparse_ndim(inst):
-
     if not isinstance(inst, CSMatrixType):
         return
 
     def ndim(inst):
         return 2
 
     return ndim
@@ -197,15 +195,14 @@
     sig = inst(inst, inst.data, inst.indices, inst.indptr, inst.shape)
 
     return sig, _construct
 
 
 @overload_method(CSMatrixType, "copy")
 def overload_sparse_copy(inst):
-
     if not isinstance(inst, CSMatrixType):
         return
 
     def copy(inst):
         return _sparse_copy(
             inst, inst.data.copy(), inst.indices.copy(), inst.indptr.copy(), inst.shape
         )
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/dispatch/tensor_basic.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/dispatch/tensor_basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,15 +19,14 @@
     TensorFromScalar,
 )
 from aesara.tensor.shape import Unbroadcast
 
 
 @_numba_funcify.register(AllocEmpty)
 def numba_funcify_AllocEmpty(op, node, **kwargs):
-
     global_env = {
         "np": np,
         "to_scalar": numba_basic.to_scalar,
         "dtype": np.dtype(op.dtype),
     }
 
     unique_names = unique_name_generator(
@@ -57,15 +56,14 @@
     )
 
     return numba_basic.numba_njit(alloc_fn)
 
 
 @_numba_funcify.register(Alloc)
 def numba_funcify_Alloc(op, node, **kwargs):
-
     global_env = {"np": np, "to_scalar": numba_basic.to_scalar}
 
     unique_names = unique_name_generator(
         ["np", "to_scalar", "alloc", "val_np", "val", "scalar_shape", "res"],
         suffix_sep="_",
     )
     shape_var_names = [unique_names(v, force_unique=True) for v in node.inputs[1:]]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/numba/linker.py` & `aesara_nightly-2.9.0.post2/aesara/link/numba/linker.py`

 * *Files 20% similar despite different names*

```diff
@@ -29,26 +29,12 @@
     def jit_compile(self, fn):
         from aesara.link.numba.dispatch import numba_njit
 
         jitted_fn = numba_njit(fn)
         return jitted_fn
 
     def create_thunk_inputs(self, storage_map):
-        from numpy.random import RandomState
-
-        from aesara.link.numba.dispatch import numba_const_convert
-
         thunk_inputs = []
         for n in self.fgraph.inputs:
-            sinput = storage_map[n]
-            if isinstance(sinput[0], RandomState):
-                new_value = numba_const_convert(
-                    sinput[0], dtype=getattr(sinput[0], "dtype", None)
-                )
-                # We need to remove the reference-based connection to the
-                # original `RandomState`/shared variable's storage, because
-                # subsequent attempts to use the same shared variable within
-                # other non-Numba-fied graphs will have problems.
-                sinput = [new_value]
-            thunk_inputs.append(sinput)
+            thunk_inputs.append(storage_map[n])
 
         return thunk_inputs
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/utils.py` & `aesara_nightly-2.9.0.post2/aesara/link/utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -389,15 +389,14 @@
             " provide a back-trace showing when this node was created. This can"
             " be done by setting the Aesara flag"
             " 'optimizer=fast_compile'. If that does not work,"
             " Aesara optimizations can be disabled with 'optimizer=None'."
         )
 
     if verbosity == "high":
-
         import aesara.printing
 
         f = io.StringIO()
         aesara.printing.debugprint(node, file=f, stop_on_name=True, print_type=True)
         detailed_err_msg += "\nDebug print of the apply node: \n"
         detailed_err_msg += f.getvalue()
 
@@ -587,15 +586,14 @@
 
 def compile_function_src(
     src: str,
     function_name: str,
     global_env: Optional[Dict[Any, Any]] = None,
     local_env: Optional[Dict[Any, Any]] = None,
 ) -> Callable:
-
     with NamedTemporaryFile(delete=False) as f:
         filename = f.name
         f.write(src.encode())
 
     if global_env is None:
         global_env = {}
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/link/vm.py` & `aesara_nightly-2.9.0.post2/aesara/link/vm.py`

 * *Files 0% similar despite different names*

```diff
@@ -623,15 +623,15 @@
                         if config.profile or config.print_global_stats:
                             current_idx = self.node_idx[current_apply]
                             self.call_counts[current_idx] += 1
                             self.call_times[current_idx] += dt
                             # Computing the memory footprint of the the op
                             # ?? What about inplace .. if the op is inplace
                             # you don't actually ask for more memory!
-                            for (idx, o) in enumerate(
+                            for idx, o in enumerate(
                                 thunks[self.node_idx[current_apply]].outputs
                             ):
                                 var = self.nodes[current_idx].outputs[idx]
                                 if hasattr(var.type, "get_shape_info"):
                                     sh = var.type.get_shape_info(o[0])
                                 else:
                                     sh = "no shape"
@@ -717,15 +717,15 @@
                         # back and see to get the inputs we are
                         # missing
                         apply_stack.append(current_apply)
                         if current_apply.inputs[r].owner:
                             apply_stack.append(current_apply.inputs[r].owner)
                 else:
                     if config.profile or config.print_global_stats:
-                        for (idx, o) in enumerate(
+                        for idx, o in enumerate(
                             thunks[self.node_idx[current_apply]].outputs
                         ):
                             var = self.nodes[self.node_idx[current_apply]].outputs[idx]
 
                             if hasattr(var.type, "get_shape_info"):
                                 sh = var.type.get_shape_info(o[0])
                             else:
@@ -1010,29 +1010,27 @@
         output_storage,
         storage_map,
         post_thunk_clear,
         computed,
         compute_map,
         updated_vars,
     ):
-
         pre_call_clear = [storage_map[v] for v in self.no_recycling]
 
         try:
             from aesara.link.c.cvm import CVM
         except (MissingGXX, ImportError):
             CVM = None
 
         if (
             self.callback is not None
             or self.callback_input is not None
             or ((config.profile or config.print_global_stats) and config.profile_memory)
             or (self.allow_partial_eval and not self.use_cloop)
         ):
-
             if self.use_cloop and (
                 self.callback is not None or self.callback_input is not None
             ):
                 warnings.warn("CVM does not support callback, using Stack VM.")
             if self.use_cloop and config.profile_memory:
                 warnings.warn("CVM does not support memory profiling, using Stack VM.")
             if not self.use_cloop and self.allow_partial_eval:
@@ -1053,30 +1051,29 @@
                 compute_map,
                 self.allow_gc,
                 dependencies=deps,
                 callback=self.callback,
                 callback_input=self.callback_input,
             )
         elif self.use_cloop and CVM is not None:
-
             # create a map from nodes to ints and vars to ints
             nodes_idx = {}
             vars_idx = {}
             for i, node in enumerate(nodes):
                 nodes_idx[node] = i
                 for v in node.inputs + node.outputs:
                     vars_idx.setdefault(v, len(vars_idx))
             for v in self.fgraph.inputs + self.fgraph.outputs:
                 vars_idx.setdefault(v, len(vars_idx))
 
             nodes_idx_inv = {}
             vars_idx_inv = {}
-            for (node, i) in nodes_idx.items():
+            for node, i in nodes_idx.items():
                 nodes_idx_inv[i] = node
-            for (var, i) in vars_idx.items():
+            for var, i in vars_idx.items():
                 vars_idx_inv[i] = var
 
             # put storage_map and compute_map into a int-based scheme
             storage_map_list = [
                 storage_map[vars_idx_inv[i]] for i in range(len(vars_idx_inv))
             ]
             compute_map_list = [
@@ -1107,15 +1104,15 @@
                 node_input_offset.append(len(base_input_output_list))
                 base_input_output_list.extend(inputs_idx)
                 node_output_offset.append(len(base_input_output_list))
                 base_input_output_list.extend(outputs_idx)
 
             # build the var owner array
             var_owner = [None] * len(vars_idx)
-            for (var, i) in vars_idx.items():
+            for var, i in vars_idx.items():
                 if var.owner:
                     var_owner[i] = nodes_idx[var.owner]
 
             is_lazy_list = [int(th.lazy) for th in thunks]
             output_vars = [vars_idx[v] for v in self.fgraph.outputs]
 
             # builds the list of prereqs induced by e.g. destroy_handler
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/check_blas.py` & `aesara_nightly-2.9.0.post2/aesara/misc/check_blas.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/check_blas_many.sh` & `aesara_nightly-2.9.0.post2/aesara/misc/check_blas_many.sh`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/check_duplicate_key.py` & `aesara_nightly-2.9.0.post2/aesara/misc/check_duplicate_key.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,15 +15,14 @@
         dirs.extend([os.path.join(compiledir, d) for d in os.listdir(compiledir)])
 else:
     dirs = os.listdir(config.compiledir)
     dirs = [os.path.join(config.compiledir, d) for d in dirs]
 keys: Dict = {}  # key -> nb seen
 mods: Dict = {}
 for dir in dirs:
-
     key = None
     try:
         with open(os.path.join(dir, "key.pkl")) as f:
             key = f.read()
         keys.setdefault(key, 0)
         keys[key] += 1
         del f
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/elemwise_openmp_speedup.py` & `aesara_nightly-2.9.0.post2/aesara/misc/elemwise_openmp_speedup.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/elemwise_time_test.py` & `aesara_nightly-2.9.0.post2/aesara/misc/elemwise_time_test.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/frozendict.py` & `aesara_nightly-2.9.0.post2/aesara/misc/frozendict.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/latence_gpu_transfert.py` & `aesara_nightly-2.9.0.post2/aesara/misc/latence_gpu_transfert.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/may_share_memory.py` & `aesara_nightly-2.9.0.post2/aesara/misc/may_share_memory.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/ordered_set.py` & `aesara_nightly-2.9.0.post2/aesara/misc/ordered_set.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/pkl_utils.py` & `aesara_nightly-2.9.0.post2/aesara/misc/pkl_utils.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/misc/safe_asarray.py` & `aesara_nightly-2.9.0.post2/aesara/misc/safe_asarray.py`

 * *Files 10% similar despite different names*

```diff
@@ -28,15 +28,15 @@
     This function's name starts with a '_' to indicate that it is meant to be
     used internally. It is imported so as to be available directly through
         _asarray
     """
     if str(dtype) == "floatX":
         dtype = config.floatX
     dtype = np.dtype(dtype)  # Convert into dtype object.
-    rval = np.asarray(a, dtype=dtype, order=order)
+    rval = np.asarray(a, order=order).astype(dtype)
     # Note that dtype comparison must be done by comparing their `num`
     # attribute. One cannot assume that two identical data types are pointers
     # towards the same object (e.g. under Windows this appears not to be the
     # case).
     if rval.dtype.num != dtype.num:
         # Type mismatch between the data type we asked for, and the one
         # returned by numpy.asarray.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/printing.py` & `aesara_nightly-2.9.0.post2/aesara/printing.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,18 +6,28 @@
 import sys
 import warnings
 from abc import ABC, abstractmethod
 from contextlib import contextmanager
 from copy import copy
 from functools import reduce, singledispatch
 from io import StringIO
-from typing import Any, Callable, Dict, List, Optional, Sequence, TextIO, Tuple, Union
+from typing import (
+    Any,
+    Callable,
+    Dict,
+    List,
+    Literal,
+    Optional,
+    Sequence,
+    TextIO,
+    Tuple,
+    Union,
+)
 
 import numpy as np
-from typing_extensions import Literal
 
 from aesara.compile import Function, SharedVariable
 from aesara.compile.io import In, Out
 from aesara.compile.profiling import ProfileStats
 from aesara.configdefaults import config
 from aesara.graph.basic import Apply, Constant, Variable, graph_inputs, io_toposort
 from aesara.graph.fg import FunctionGraph
@@ -116,14 +126,15 @@
     done: Optional[Dict[Union[Literal["output"], Variable, Apply], str]] = None,
     print_storage: bool = False,
     used_ids: Optional[Dict[Union[Literal["output"], Variable, Apply], str]] = None,
     print_op_info: bool = False,
     print_destroy_map: bool = False,
     print_view_map: bool = False,
     print_fgraph_inputs: bool = False,
+    print_default_updates: bool = False,
     ids: Optional[IDTypesType] = None,
 ) -> Union[str, TextIO]:
     r"""Print a graph as text.
 
     Each line printed represents a `Variable` in a graph.
     The indentation of lines corresponds to its depth in the symbolic graph.
     The first part of the text identifies whether it is an input or the output
@@ -173,14 +184,16 @@
         print the tap information for `Scan` inputs and outputs.
     print_destroy_map
         Whether to print the `destroy_map`\s of printed objects
     print_view_map
         Whether to print the `view_map`\s of printed objects
     print_fgraph_inputs
         Print the inputs of `FunctionGraph`\s.
+    print_default_updates
+        Print the `SharedVariable.default_update` values.
 
     Returns
     -------
     A string representing the printed graph, if `file` is a string, else `file`.
 
     """
     if not isinstance(depth, int):
@@ -259,14 +272,15 @@
             profile_list.append(None)
             storage_maps.append(None)
             topo_orders.append(None)
         else:
             raise TypeError(f"debugprint cannot print an object type {type(obj)}")
 
     inner_graph_vars: List[Variable] = []
+    default_updates: List[Variable] = []
 
     if any(p for p in profile_list if p is not None and p.fct_callcount > 0):
         print(
             """
 Timing Info
 -----------
 --> <time> <% time> - <total time> <% total time>'
@@ -293,62 +307,64 @@
             var,
             prefix="-",
             depth=depth,
             done=done,
             print_type=print_type,
             file=_file,
             id_type=id_type,
-            inner_graph_ops=inner_graph_vars,
+            inner_graph_vars=inner_graph_vars,
             stop_on_name=stop_on_name,
             used_ids=used_ids,
             op_information=op_information,
             parent_node=var.owner,
             print_op_info=print_op_info,
             print_destroy_map=print_destroy_map,
             print_view_map=print_view_map,
+            print_default_updates=print_default_updates,
+            default_updates=default_updates,
         )
 
     for var, profile, storage_map, topo_order in zip(
         outputs_to_print, profile_list, storage_maps, topo_orders
     ):
-
         if hasattr(var.owner, "op"):
             if isinstance(var.owner.op, HasInnerGraph) and var not in inner_graph_vars:
                 inner_graph_vars.append(var)
             if print_op_info:
                 op_information.update(op_debug_information(var.owner.op, var.owner))
 
         _debugprint(
             var,
             depth=depth,
             done=done,
             print_type=print_type,
             file=_file,
             topo_order=topo_order,
             id_type=id_type,
-            inner_graph_ops=inner_graph_vars,
+            inner_graph_vars=inner_graph_vars,
             stop_on_name=stop_on_name,
             profile=profile,
             storage_map=storage_map,
             used_ids=used_ids,
             op_information=op_information,
             parent_node=var.owner,
             print_op_info=print_op_info,
             print_destroy_map=print_destroy_map,
             print_view_map=print_view_map,
+            print_default_updates=print_default_updates,
+            default_updates=default_updates,
         )
 
     if len(inner_graph_vars) > 0:
         print("", file=_file)
         new_prefix = " >"
         new_prefix_child = " >"
         print("Inner graphs:", file=_file)
 
         for ig_var in inner_graph_vars:
-
             # This is a work-around to maintain backward compatibility
             # (e.g. to only print inner graphs that have been compiled through
             # a call to `Op.prepare_node`)
             inner_fn = getattr(ig_var.owner.op, "_fn", None)
 
             if inner_fn:
                 # If the op was compiled, print the optimized version.
@@ -380,50 +396,53 @@
             _debugprint(
                 ig_var,
                 depth=depth,
                 done=done,
                 print_type=print_type,
                 file=_file,
                 id_type=id_type,
-                inner_graph_ops=inner_graph_vars,
+                inner_graph_vars=inner_graph_vars,
                 stop_on_name=stop_on_name,
                 inner_to_outer_inputs=inner_to_outer_inputs,
                 used_ids=used_ids,
                 op_information=op_information,
                 parent_node=ig_var.owner,
                 print_op_info=print_op_info,
                 print_destroy_map=print_destroy_map,
                 print_view_map=print_view_map,
+                print_default_updates=print_default_updates,
+                default_updates=default_updates,
             )
 
             if print_fgraph_inputs:
                 for inp in inner_inputs:
                     _debugprint(
                         inp,
                         prefix="-",
                         depth=depth,
                         done=done,
                         print_type=print_type,
                         file=_file,
                         id_type=id_type,
                         stop_on_name=stop_on_name,
-                        inner_graph_ops=inner_graph_vars,
+                        inner_graph_vars=inner_graph_vars,
                         inner_to_outer_inputs=inner_to_outer_inputs,
                         used_ids=used_ids,
                         op_information=op_information,
                         parent_node=ig_var.owner,
                         print_op_info=print_op_info,
                         print_destroy_map=print_destroy_map,
                         print_view_map=print_view_map,
                         inner_graph_node=ig_var.owner,
+                        print_default_updates=print_default_updates,
+                        default_updates=default_updates,
                     )
                 inner_to_outer_inputs = None
 
             for out in inner_outputs:
-
                 if (
                     isinstance(getattr(out.owner, "op", None), HasInnerGraph)
                     and out not in inner_graph_vars
                 ):
                     inner_graph_vars.append(out)
 
                 _debugprint(
@@ -432,25 +451,59 @@
                     depth=depth,
                     done=done,
                     print_type=print_type,
                     file=_file,
                     id_type=id_type,
                     stop_on_name=stop_on_name,
                     prefix_child=new_prefix_child,
-                    inner_graph_ops=inner_graph_vars,
+                    inner_graph_vars=inner_graph_vars,
                     inner_to_outer_inputs=inner_to_outer_inputs,
                     used_ids=used_ids,
                     op_information=op_information,
                     parent_node=ig_var.owner,
                     print_op_info=print_op_info,
                     print_destroy_map=print_destroy_map,
                     print_view_map=print_view_map,
                     inner_graph_node=ig_var.owner,
+                    print_default_updates=print_default_updates,
+                    default_updates=default_updates,
                 )
 
+    if len(default_updates) > 0:
+        print("", file=_file)
+        print("Default updates:", file=_file)
+
+        inner_to_outer_inputs = {}
+
+        for var in default_updates:
+            print("", file=_file)
+
+            update_var = var.default_update
+            inner_to_outer_inputs[update_var] = var
+
+            _debugprint(
+                update_var,
+                depth=depth,
+                done=done,
+                print_type=print_type,
+                file=_file,
+                id_type=id_type,
+                inner_graph_vars=inner_graph_vars,
+                stop_on_name=stop_on_name,
+                inner_to_outer_inputs=inner_to_outer_inputs,
+                used_ids=used_ids,
+                op_information=op_information,
+                parent_node=None,
+                print_op_info=print_op_info,
+                print_destroy_map=print_destroy_map,
+                print_view_map=print_view_map,
+                print_default_updates=print_default_updates,
+                default_updates=default_updates,
+            )
+
     if file is _file:
         return file
     elif file == "str":
         assert isinstance(_file, StringIO)
         return _file.getvalue()
     else:
         _file.flush()
@@ -466,23 +519,25 @@
     file: TextIO = sys.stdout,
     print_destroy_map: bool = False,
     print_view_map: bool = False,
     topo_order: Optional[Sequence[Apply]] = None,
     id_type: IDTypesType = "CHAR",
     stop_on_name: bool = False,
     prefix_child: Optional[str] = None,
-    inner_graph_ops: Optional[List[Variable]] = None,
+    inner_graph_vars: Optional[List[Variable]] = None,
     profile: Optional[ProfileStats] = None,
     inner_to_outer_inputs: Optional[Dict[Variable, Variable]] = None,
     storage_map: Optional[StorageMapType] = None,
     used_ids: Optional[Dict[Union[Literal["output"], Variable, Apply], str]] = None,
     op_information: Optional[Dict[Apply, Dict[Variable, str]]] = None,
     parent_node: Optional[Apply] = None,
     print_op_info: bool = False,
     inner_graph_node: Optional[Apply] = None,
+    print_default_updates: bool = False,
+    default_updates: Optional[List[Variable]] = None,
 ) -> TextIO:
     r"""Print the graph represented by `var`.
 
     Parameters
     ----------
     var
         A `Variable` instance.
@@ -502,44 +557,51 @@
         Whether to print `Op` ``destroy_map``\s.
     topo_order
         If not empty will print the index in the toposort.
     id_type
         See `debugprint`.
     stop_on_name
         Whether to print `Op` ``view_map``\s.
-    inner_graph_ops
-        A list of `Op`\s with inner graphs.
+    inner_graph_vars
+        A list of `Variables`\s with inner graphs.
     inner_to_outer_inputs
         A dictionary mapping an `Op`'s inner-inputs to its outer-inputs.
     storage_map
         ``None`` or the storage map (e.g. when printing an Aesara function).
     used_ids
         See `debugprint`.
     op_information
         Extra `Op`-level information to be added to variable print-outs.
     parent_node
         The parent node of `var`.
     print_op_info
         See `debugprint`.
     inner_graph_node
         The inner-graph node in which `var` is contained.
+    print_default_updates
+        Print the `SharedVariable.default_update` values.
+    default_updates
+        A list of `Variables`\s with default updates.
     """
     if depth == 0:
         return file
 
     if topo_order is None:
         topo_order = []
 
     if done is None:
         _done = dict()
     else:
         _done = done
 
-    if inner_graph_ops is None:
-        inner_graph_ops = []
+    if inner_graph_vars is None:
+        inner_graph_vars = []
+
+    if default_updates is None:
+        default_updates = []
 
     if print_type:
         type_str = f" <{var.type}>"
     else:
         type_str = ""
 
     if prefix_child is None:
@@ -660,60 +722,79 @@
             for in_idx, in_var in enumerate(node.inputs):
                 if in_idx == len(node.inputs) - 1:
                     new_prefix_child = prefix_child + "  "
 
                 if hasattr(in_var, "owner") and hasattr(in_var.owner, "op"):
                     if (
                         isinstance(in_var.owner.op, HasInnerGraph)
-                        and in_var not in inner_graph_ops
+                        and in_var not in inner_graph_vars
                     ):
-                        inner_graph_ops.append(in_var)
+                        inner_graph_vars.append(in_var)
 
                 _debugprint(
                     in_var,
                     new_prefix,
                     depth=depth - 1,
                     done=_done,
                     print_type=print_type,
                     file=file,
                     topo_order=topo_order,
                     id_type=id_type,
                     stop_on_name=stop_on_name,
                     prefix_child=new_prefix_child,
-                    inner_graph_ops=inner_graph_ops,
+                    inner_graph_vars=inner_graph_vars,
                     profile=profile,
                     inner_to_outer_inputs=inner_to_outer_inputs,
                     storage_map=storage_map,
                     used_ids=_used_ids,
                     op_information=op_information,
                     parent_node=node,
                     print_op_info=print_op_info,
                     print_destroy_map=print_destroy_map,
                     print_view_map=print_view_map,
                     inner_graph_node=inner_graph_node,
+                    print_default_updates=print_default_updates,
+                    default_updates=default_updates,
                 )
     else:
-
         id_str = get_id_str(var)
 
         if id_str:
             id_str = f" {id_str}"
 
         if storage_map and var in storage_map:
             data = f" {storage_map[var]}"
         else:
             data = ""
 
         var_output = f"{prefix}{var}{id_str}{type_str}{data}"
 
+        # `SharedVariable`s with default updates are considered "inner-graph" variables
+        if (
+            print_default_updates
+            and isinstance(var, SharedVariable)
+            and var.default_update is not None
+        ):
+            update_obj = (
+                var.default_update
+                if var.default_update.owner is None
+                else var.default_update.owner
+            )
+            update_obj_id = get_id_str(update_obj)
+            var_output = f"{var_output} <- {update_obj_id}"
+
+            # We still want to print the graph later
+            if var not in default_updates:
+                default_updates.append(var)
+                del _done[update_obj]
+
         if print_op_info and var.owner and var.owner not in op_information:
             op_information.update(op_debug_information(var.owner.op, var.owner))
 
         if inner_to_outer_inputs is not None and var in inner_to_outer_inputs:
-
             outer_var = inner_to_outer_inputs[var]
 
             if outer_var.owner:
                 outer_id_str = get_id_str(outer_var.owner)
             else:
                 outer_id_str = get_id_str(outer_var)
 
@@ -1144,15 +1225,14 @@
         alpha="\\alpha",
         beta="\\beta",
         gamma="\\gamma",
         delta="\\delta",
         epsilon="\\epsilon",
     )
 else:
-
     special = dict(middle_dot="\u00B7", big_sigma="\u03A3")
 
     greek = dict(
         alpha="\u03B1",
         beta="\u03B2",
         gamma="\u03B3",
         delta="\u03B4",
@@ -1428,15 +1508,14 @@
     # Update the inputs that have an update function
     input_update = {}
     reverse_input_update = {}
     # Here outputs can be the original list, as we should not change
     # it, we must copy it.
     outputs = list(outputs)
     if isinstance(fct, Function):
-
         # TODO: Get rid of all this `expanded_inputs` nonsense and use
         # `fgraph.update_mapping`
         function_inputs = zip(fct.maker.expanded_inputs, fgraph.inputs)
         for i, fg_ii in reversed(list(function_inputs)):
             if i.update is not None:
                 k = outputs.pop()
                 # Use the fgaph.inputs as it isn't the same as maker.inputs
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/raise_op.py` & `aesara_nightly-2.9.0.post2/aesara/raise_op.py`

 * *Files 2% similar despite different names*

```diff
@@ -37,15 +37,14 @@
     __props__ = ("msg", "exc_type")
     view_map = {0: [0]}
 
     check_input = False
     params_type = ParamsType(exc_type=exception_type)
 
     def __init__(self, exc_type, msg=""):
-
         if not issubclass(exc_type, Exception):
             raise ValueError("`exc_type` must be an Exception subclass")
 
         self.exc_type = exc_type
         self.msg = msg
 
     def __str__(self):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/fourier.py` & `aesara_nightly-2.9.0.post2/aesara/sandbox/fourier.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/linalg/ops.py` & `aesara_nightly-2.9.0.post2/aesara/sandbox/linalg/ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -116,15 +116,15 @@
     """
     If we have det(X) and there is already an L=cholesky(X)
     floating around, then we can use prod(diag(L)) to get the determinant.
 
     """
     if isinstance(node.op, Det):
         (x,) = node.inputs
-        for (cl, xpos) in fgraph.clients[x]:
+        for cl, xpos in fgraph.clients[x]:
             if isinstance(cl.op, Cholesky):
                 L = cl.outputs[0]
                 return [prod(at.extract_diag(L) ** 2)]
 
 
 @register_canonicalize
 @register_stabilize
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/minimal.py` & `aesara_nightly-2.9.0.post2/aesara/sandbox/minimal.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/multinomial.py` & `aesara_nightly-2.9.0.post2/aesara/sandbox/multinomial.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/rng_mrg.py` & `aesara_nightly-2.9.0.post2/aesara/sandbox/rng_mrg.py`

 * *Files 0% similar despite different names*

```diff
@@ -1352,15 +1352,14 @@
             )
 
     return at.as_tensor_variable(size, ndim=1)
 
 
 @node_rewriter((mrg_uniform_base,))
 def mrg_random_make_inplace(fgraph, node):
-
     op = node.op
     if isinstance(op, mrg_uniform_base) and not op.inplace:
         # op might be gpu version
         new_op = op.__class__(op.output_type, inplace=True)
         return new_op.make_node(*node.inputs).outputs
     return False
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sandbox/samples_MRG31k3p_12_7_5.txt` & `aesara_nightly-2.9.0.post2/aesara/sandbox/samples_MRG31k3p_12_7_5.txt`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/basic.py` & `aesara_nightly-2.9.0.post2/aesara/scalar/basic.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 import builtins
 import math
 from collections.abc import Callable
 from copy import copy
 from itertools import chain
 from textwrap import dedent
-from typing import Any, Dict, Mapping, Optional, Tuple, Type, Union
+from typing import Any, Dict, List, Mapping, Optional, Tuple, Type, Union
 
 import numpy as np
 from typing_extensions import TypeAlias
 
 import aesara
 from aesara import printing
 from aesara.configdefaults import config
@@ -494,15 +494,14 @@
             sub, name=name, dtype=specs[1], cls=specs[2]
         )
 
     def c_cleanup(self, name, sub):
         return ""
 
     def c_support_code(self, **kwargs):
-
         if self.dtype.startswith("complex"):
             cplx_types = ["aesara_complex64", "aesara_complex128"]
             real_types = [
                 "npy_int8",
                 "npy_int16",
                 "npy_int32",
                 "npy_int64",
@@ -790,18 +789,18 @@
     def __sub__(self, other):
         return sub(self, other)
 
     def __mul__(self, other):
         return mul(self, other)
 
     def __truediv__(self, other):
-        return true_div(self, other)
+        return true_divide(self, other)
 
     def __floordiv__(self, other):
-        return int_div(self, other)
+        return floor_divide(self, other)
 
     def __mod__(self, other):
         return mod_check(self, other)
 
     def __pow__(self, other):
         return pow(self, other)
 
@@ -1077,15 +1076,14 @@
         return (float32,)
     if type == complex128:
         return (float64,)
     return (type,)
 
 
 class ScalarOp(COp):
-
     nin = -1
     nout = 1
 
     def __init__(self, output_types_preference=None, name=None):
         self.name = name
         if output_types_preference is not None:
             if not isinstance(output_types_preference, Callable):
@@ -1170,15 +1168,15 @@
                 for k, v in self.__dict__.items()
                 if k
                 not in ("name", "_op_use_c_code", "bool", "output_types_preference")
             ]
             if param:
                 return "{}{{{}}}".format(
                     self.__class__.__name__,
-                    ", ".join("{}={}".format(k, v) for k, v in param),
+                    ", ".join(f"{k}={v}" for k, v in param),
                 )
             else:
                 return self.__class__.__name__
 
     def c_code_cache_version(self):
         return (4,)
 
@@ -1975,15 +1973,15 @@
 
         return first_part, second_part
 
 
 sub = Sub(upcast_out_nobool, name="sub")
 
 
-class TrueDiv(BinaryScalarOp):
+class TrueDivide(BinaryScalarOp):
     nfunc_spec = ("true_divide", 2, 1)
 
     def output_types(self, types):
         if all(t in discrete_types for t in types):
             return [get_scalar_type(config.floatX)]
         else:
             return super().output_types(types)
@@ -2006,15 +2004,14 @@
             node.inputs[0].type in discrete_types
             and node.inputs[1].type in discrete_types
         ):
             return f"{z} = ((double){x}) / {y};"
         return f"{z} = {x} / {y};"
 
     def grad(self, inputs, gout):
-
         (x, y) = inputs
         (gz,) = gout
         if x.type in complex_types:
             raise NotImplementedError()
 
         # If the output of this op is discrete, then it
         # it is locally flat everywhere, so the gradient
@@ -2031,18 +2028,19 @@
             raise NotImplementedError()
 
         second_part = -(gz * x) / (y * y)
 
         return first_part, second_part
 
 
-true_div = TrueDiv(upcast_out, name="true_div")
+true_divide = TrueDivide(upcast_out, name="true_divide")
+divide = true_divide
 
 
-class IntDiv(BinaryScalarOp):
+class FloorDivide(BinaryScalarOp):
     nfunc_spec = ("floor_divide", 2, 1)
     complex_error = ComplexError(
         "Aesara does not support integer division (//) on "
         "complex numbers, since numpy deprecated it."
     )
 
     def impl(self, x, y):
@@ -2128,18 +2126,15 @@
     def c_code_cache_version(self):
         return (6,)
 
     def grad(self, inputs, g_output):
         return [inp.zeros_like(dtype=config.floatX) for inp in inputs]
 
 
-int_div = IntDiv(upcast_out, name="int_div")
-
-
-floor_div = int_div
+floor_divide = FloorDivide(upcast_out, name="floor_divide")
 
 
 def mod_check(x, y):
     if as_scalar(x).type in complex_types or as_scalar(y).type in complex_types:
         # Currently forbidden.
         raise Mod.complex_error
     else:
@@ -2389,22 +2384,20 @@
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x, y) = inputs
         (z,) = outputs
         return f"{z} = {y};"
 
     def connection_pattern(self, node):
-
         # x is never connected because its elements are never used
         # y is connected because its elements are copied over
 
         return [[False], [True]]
 
     def grad(self, inputs, gout):
-
         (x, y) = inputs
         (gz,) = gout
         if y.type in continuous_types:
             # x is disconnected because the elements of x are not used
             return DisconnectedType()(), gz
         else:
             # when y is discrete, we assume the function can be extended
@@ -2865,16 +2858,16 @@
 
 neg = Neg(same_out_nobool, name="neg")
 
 pprint.assign(add, printing.OperatorPrinter("+", -2, "either"))
 pprint.assign(mul, printing.OperatorPrinter("*", -1, "either"))
 pprint.assign(sub, printing.OperatorPrinter("-", -2, "left"))
 pprint.assign(neg, printing.OperatorPrinter("-", 0, "either"))
-pprint.assign(true_div, printing.OperatorPrinter("/", -1, "left"))
-pprint.assign(int_div, printing.OperatorPrinter("//", -1, "left"))
+pprint.assign(true_divide, printing.OperatorPrinter("/", -1, "left"))
+pprint.assign(floor_divide, printing.OperatorPrinter("//", -1, "left"))
 pprint.assign(pow, printing.OperatorPrinter("**", 1, "right"))
 pprint.assign(mod, printing.OperatorPrinter("%", -1, "left"))
 
 
 class Reciprocal(UnaryScalarOp):
     """Multiplicative inverse."""
 
@@ -3214,15 +3207,15 @@
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         return f"{z} = {x} * {x};"
 
 
-sqr = Sqr(same_out, name="sqr")
+square = Sqr(same_out, name="square")
 
 
 class Sqrt(UnaryScalarOp):
     nfunc_spec = ("sqrt", 1, 1)
 
     def impl(self, x):
         # If x is an int8 or uint8, numpy.sqrt will compute the result in
@@ -3383,15 +3376,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (-gz / sqrt(np.cast[x.type](1) - sqr(x)),)
+        return (-gz / sqrt(np.cast[x.type](1) - square(x)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3457,15 +3450,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / sqrt(np.cast[x.type](1) - sqr(x)),)
+        return (gz / sqrt(np.cast[x.type](1) - square(x)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3493,15 +3486,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / sqr(cos(x)),)
+        return (gz / square(cos(x)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3529,15 +3522,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / (np.cast[x.type](1) + sqr(x)),)
+        return (gz / (np.cast[x.type](1) + square(x)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3575,15 +3568,18 @@
                     gy = y.zeros_like(dtype=config.floatX)
                 else:
                     gy = y.zeros_like()
                 return [gx, gy]
 
             # If the output is float, the gradient should flow,
             # even if the inputs are ints
-            return [gz * x / (sqr(x) + sqr(y)), gz * neg(y) / (sqr(x) + sqr(y))]
+            return [
+                gz * x / (square(x) + square(y)),
+                gz * neg(y) / (square(x) + square(y)),
+            ]
 
     def c_code(self, node, name, inputs, outputs, sub):
         (y, x) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types or node.inputs[1].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3652,15 +3648,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / sqrt(sqr(x) - np.cast[x.type](1)),)
+        return (gz / sqrt(square(x) - np.cast[x.type](1)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3729,15 +3725,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / sqrt(sqr(x) + np.cast[x.type](1)),)
+        return (gz / sqrt(square(x) + np.cast[x.type](1)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3771,15 +3767,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz * (1 - sqr(tanh(x))),)
+        return (gz * (1 - square(tanh(x))),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -3807,15 +3803,15 @@
             raise NotImplementedError()
         if outputs[0].type in discrete_types:
             if x.type in discrete_types:
                 return [x.zeros_like(dtype=config.floatX)]
             else:
                 return [x.zeros_like()]
 
-        return (gz / (np.cast[x.type](1) - sqr(x)),)
+        return (gz / (np.cast[x.type](1) - square(x)),)
 
     def c_code(self, node, name, inputs, outputs, sub):
         (x,) = inputs
         (z,) = outputs
         if node.inputs[0].type in complex_types:
             raise NotImplementedError("type not supported", type)
         cast = node.outputs[0].type.dtype_specs()[1]
@@ -4308,15 +4304,14 @@
         _c_code += "}\n"
 
         self._c_code = _c_code
 
         return self._c_code
 
     def c_code(self, node, nodename, inames, onames, sub):
-
         d = dict(
             chain(
                 zip((f"i{int(i)}" for i in range(len(inames))), inames),
                 zip((f"o{int(i)}" for i in range(len(onames))), onames),
             ),
             **sub,
         )
@@ -4447,18 +4442,30 @@
     for o, no in zip(node.outputs, new_outs):
         mapping[o] = no
 
 
 Compositef32.special[Composite] = handle_composite
 
 
-DEPRECATED_NAMES = [
+DEPRECATED_NAMES: List[Tuple[str, str, object]] = [
     ("Inv", "`Inv` is deprecated; use `Reciprocal` instead.", Reciprocal),
     ("inv", "`inv` is deprecated; use `reciprocal` instead.", reciprocal),
     ("Scalar", "`Scalar` is deprecated; use `ScalarType` instead.", ScalarType),
+    (
+        "true_div",
+        "`true_div` is deprecated; use `true_divide` or `divide` instead.",
+        true_divide,
+    ),
+    ("int_div", "`int_div` is deprecated; use `floor_divide` instead.", floor_divide),
+    (
+        "floor_div",
+        "`floor_div` is deprecated; use `floor_divide` instead.",
+        floor_divide,
+    ),
+    ("sqr", "`sqr` is deprecated; use `square` instead.", square),
 ]
 
 
 def __getattr__(name):
     """Intercept module-level attribute access of deprecated symbols.
 
     Adapted from https://stackoverflow.com/a/55139609/3006474.
@@ -4468,7 +4475,237 @@
 
     for old_name, msg, old_object in DEPRECATED_NAMES:
         if name == old_name:
             warn(msg, DeprecationWarning, stacklevel=2)
             return old_object
 
     raise AttributeError(f"module {__name__} has no attribute {name}")
+
+
+__all__ = [
+    "constant",
+    "as_scalar",
+    "ComplexError",
+    "IntegerDivisionError",
+    "upcast",
+    "as_common_dtype",
+    "NumpyAutocaster",
+    "autocast_float_as",
+    "convert",
+    "ScalarType",
+    "get_scalar_type",
+    "ScalarVariable",
+    "ScalarConstant",
+    "upcast_out",
+    "upcast_out_nobool",
+    "upcast_out_min8",
+    "upcast_out_no_complex",
+    "same_out_float_only",
+    "transfer_type",
+    "specific_out",
+    "int_out",
+    "float_out",
+    "upgrade_to_float_no_complex",
+    "same_out_nocomplex",
+    "int_out_nocomplex",
+    "float_out_nocomplex",
+    "unary_out_lookup",
+    "real_out",
+    "ScalarOp",
+    "UnaryScalarOp",
+    "BinaryScalarOp",
+    "LogicalComparison",
+    "FixedLogicalComparison",
+    "LT",
+    "GT",
+    "LE",
+    "GE",
+    "EQ",
+    "NEQ",
+    "IsNan",
+    "IsInf",
+    "InRange",
+    "Switch",
+    "UnaryBitOp",
+    "BinaryBitOp",
+    "OR",
+    "XOR",
+    "AND",
+    "Invert",
+    "ScalarMaximum",
+    "ScalarMinimum",
+    "Add",
+    "Mean",
+    "Mul",
+    "Sub",
+    "TrueDivide",
+    "FloorDivide",
+    "mod_check",
+    "Mod",
+    "Pow",
+    "Clip",
+    "Second",
+    "Identity",
+    "Cast",
+    "cast",
+    "Abs",
+    "Sgn",
+    "Ceil",
+    "Floor",
+    "Trunc",
+    "RoundHalfToEven",
+    "round_half_away_from_zero_",
+    "round_half_away_from_zero_vec",
+    "RoundHalfAwayFromZero",
+    "Neg",
+    "Reciprocal",
+    "Log",
+    "Log2",
+    "Log10",
+    "Log1p",
+    "Exp",
+    "Exp2",
+    "Expm1",
+    "Sqr",
+    "Sqrt",
+    "Deg2Rad",
+    "Rad2Deg",
+    "Cos",
+    "ArcCos",
+    "Sin",
+    "ArcSin",
+    "Tan",
+    "ArcTan",
+    "ArcTan2",
+    "Cosh",
+    "ArcCosh",
+    "Sinh",
+    "ArcSinh",
+    "Tanh",
+    "ArcTanh",
+    "Real",
+    "Imag",
+    "Angle",
+    "Complex",
+    "Conj",
+    "ComplexFromPolar",
+    "Composite",
+    "Compositef32",
+    "handle_cast",
+    "handle_composite",
+    "autocast_int",
+    "autocast_float",
+    "bool",
+    "int8",
+    "int16",
+    "int32",
+    "int64",
+    "uint8",
+    "uint16",
+    "uint32",
+    "uint64",
+    "float16",
+    "float32",
+    "float64",
+    "complex64",
+    "complex128",
+    "int_types",
+    "uint_types",
+    "float_types",
+    "complex_types",
+    "integer_types",
+    "discrete_types",
+    "continuous_types",
+    "all_types",
+    "discrete_dtypes",
+    "ints",
+    "floats",
+    "complexs",
+    "complexs64",
+    "complexs128",
+    "lt",
+    "gt",
+    "le",
+    "ge",
+    "eq",
+    "neq",
+    "isnan",
+    "isinf",
+    "inopenrange",
+    "inclosedrange",
+    "switch",
+    "or_",
+    "xor",
+    "and_",
+    "invert",
+    "scalar_maximum",
+    "scalar_minimum",
+    "add",
+    "mean",
+    "mul",
+    "sub",
+    "true_divide",
+    "divide",
+    "floor_divide",
+    "mod",
+    "pow",
+    "clip",
+    "second",
+    "identity",
+    "_cast_mapping",
+    "convert_to_bool",
+    "convert_to_int8",
+    "convert_to_int16",
+    "convert_to_int32",
+    "convert_to_int64",
+    "convert_to_uint8",
+    "convert_to_uint16",
+    "convert_to_uint32",
+    "convert_to_uint64",
+    "convert_to_float16",
+    "convert_to_float32",
+    "convert_to_float64",
+    "convert_to_complex64",
+    "convert_to_complex128",
+    "abs",
+    "sgn",
+    "ceil",
+    "floor",
+    "trunc",
+    "round_half_to_even",
+    "round_half_away_from_zero_vec64",
+    "round_half_away_from_zero_vec32",
+    "round_half_away_from_zero",
+    "neg",
+    "reciprocal",
+    "log",
+    "log2",
+    "log10",
+    "log1p",
+    "exp",
+    "exp2",
+    "expm1",
+    "square",
+    "sqrt",
+    "deg2rad",
+    "rad2deg",
+    "cos",
+    "arccos",
+    "sin",
+    "arcsin",
+    "tan",
+    "arctan",
+    "arctan2",
+    "cosh",
+    "arccosh",
+    "sinh",
+    "arcsinh",
+    "tanh",
+    "arctanh",
+    "real",
+    "imag",
+    "angle",
+    "complex",
+    "conj",
+    "complex_from_polar",
+    "composite_f32",
+]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/basic_sympy.py` & `aesara_nightly-2.9.0.post2/aesara/scalar/basic_sympy.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/c_code/Faddeeva.cc` & `aesara_nightly-2.9.0.post2/aesara/scalar/c_code/Faddeeva.cc`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/c_code/Faddeeva.hh` & `aesara_nightly-2.9.0.post2/aesara/scalar/c_code/Faddeeva.hh`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/c_code/gamma.c` & `aesara_nightly-2.9.0.post2/aesara/scalar/c_code/gamma.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/math.py` & `aesara_nightly-2.9.0.post2/aesara/scalar/math.py`

 * *Files 12% similar despite different names*

```diff
@@ -24,15 +24,15 @@
     expm1,
     float64,
     float_types,
     isinf,
     log,
     log1p,
     switch,
-    true_div,
+    true_divide,
     upcast,
     upgrade_to_float,
     upgrade_to_float64,
     upgrade_to_float_no_complex,
 )
 
 
@@ -681,15 +681,14 @@
     argument (k, a.k.a. alpha). Adapted from STAN `grad_reg_lower_inc_gamma.hpp`
 
     Reference: Gautschi, W. (1979). A computational procedure for incomplete gamma functions.
     ACM Transactions on Mathematical Software (TOMS), 5(4), 466-481.
     """
 
     def impl(self, k, x):
-
         if x == 0:
             return 0
 
         sqrt_exp = -756 - x**2 + 60 * x
         if (
             (k < 0.8 and x > 15)
             or (k < 12 and x > 30)
@@ -1086,15 +1085,15 @@
 
 
 i0 = I0(upgrade_to_float, name="i0")
 
 
 class Sigmoid(UnaryScalarOp):
     """
-    Logistic sigmoid function (1 / (1 + exp(x)), also known as expit or inverse logit
+    Logistic sigmoid function (1 / (1 + exp(-x)), also known as expit or inverse logit
     """
 
     nfunc_spec = ("scipy.special.expit", 1, 1)
 
     def impl(self, x):
         return scipy.special.expit(x)
 
@@ -1237,15 +1236,15 @@
 
     def impl(self, x):
         return Log1mexp.static_impl(x)
 
     def grad(self, inp, grads):
         (x,) = inp
         (gz,) = grads
-        res = true_div(-1.0, expm1(-x))
+        res = true_divide(-1.0, expm1(-x))
         # Correct gradient at 0.0 to be -inf
         res = switch(isinf(res), -np.inf, res)
         return [gz * res]
 
     def c_code(self, node, name, inp, out, sub):
         (x,) = inp
         (z,) = out
@@ -1477,7 +1476,184 @@
         return np.nan
 
     def c_code(self, *args, **kwargs):
         raise NotImplementedError()
 
 
 betainc_der = BetaIncDer(upgrade_to_float_no_complex, name="betainc_der")
+
+
+class Hyp2F1(ScalarOp):
+    """
+    Gaussian hypergeometric function ``2F1(a, b; c; z)``.
+    """
+
+    nin = 4
+    nfunc_spec = ("scipy.special.hyp2f1", 4, 1)
+
+    @staticmethod
+    def st_impl(a, b, c, z):
+        return scipy.special.hyp2f1(a, b, c, z)
+
+    def impl(self, a, b, c, z):
+        return Hyp2F1.st_impl(a, b, c, z)
+
+    def grad(self, inputs, grads):
+        a, b, c, z = inputs
+        (gz,) = grads
+        return [
+            gz * hyp2f1_der(a, b, c, z, wrt=0),
+            gz * hyp2f1_der(a, b, c, z, wrt=1),
+            gz * hyp2f1_der(a, b, c, z, wrt=2),
+            gz * ((a * b) / c) * hyp2f1(a + 1, b + 1, c + 1, z),
+        ]
+
+    def c_code(self, *args, **kwargs):
+        raise NotImplementedError()
+
+
+hyp2f1 = Hyp2F1(upgrade_to_float, name="hyp2f1")
+
+
+class Hyp2F1Der(ScalarOp):
+    """Derivatives of the Gaussian hypergeometric function :math:`2_F_1(a, b; c; z)`.
+
+    This is only implemented for one of the first three inputs.
+
+    Adapted from https://github.com/stan-dev/math/blob/develop/stan/math/prim/fun/grad_2F1.hpp
+
+    """
+
+    nin = 5
+
+    def impl(self, a, b, c, z, wrt):
+        def check_2f1_converges(a, b, c, z) -> bool:
+            num_terms = 0
+            is_polynomial = False
+
+            def is_nonpositive_integer(x):
+                return x <= 0 and x.is_integer()
+
+            if is_nonpositive_integer(a) and abs(a) >= num_terms:
+                is_polynomial = True
+                num_terms = int(np.floor(abs(a)))
+            if is_nonpositive_integer(b) and abs(b) >= num_terms:
+                is_polynomial = True
+                num_terms = int(np.floor(abs(b)))
+
+            is_undefined = is_nonpositive_integer(c) and abs(c) <= num_terms
+
+            return not is_undefined and (
+                is_polynomial or np.abs(z) < 1 or (np.abs(z) == 1 and c > (a + b))
+            )
+
+        def compute_grad_2f1(a, b, c, z, wrt):
+            r"""
+
+            Notes
+            -----
+            The algorithm can be derived by looking at the ratio of two successive terms in the series:
+
+            .. math::
+
+                \beta_{k+1} / \beta_{k} = A(k) / B(k) \\
+                \beta_{k+1} = A(k) / B(k) \beta_{k} \\
+                d[\beta_{k+1}] = d[A(k) / B(k)] \beta_{k} + A(k) / B(k) d[\beta_{k}]
+
+            via the product rule.
+
+            In the :math:`2_F_1`, :math:`A(k) / B(k)` corresponds to
+            :math:`(((a + k) (b + k) / ((c + k) (1 + k))) z` The partial
+            :math:`d[A(k)/B(k)]` with respect to the first three inputs can be
+            obtained from the ratio :math:`A(k)/B(k)`, by dropping the
+            respective term
+
+            .. math::
+
+                d/da[A(k) / B(k)] = A(k) / B(k) / (a + k) \\
+                d/db[A(k) / B(k)] = A(k) / B(k) / (b + k) \\
+                d/dc[A(k) / B(k)] = A(k) / B(k) (c + k)
+
+            The algorithm is implemented in the log scale, which adds the
+            complexity of working with absolute terms and tracking their signs.
+            """
+
+            wrt_a = wrt_b = False
+            if wrt == 0:
+                wrt_a = True
+            elif wrt == 1:
+                wrt_b = True
+            elif wrt != 2:
+                raise ValueError(f"wrt must be 0, 1, or 2; got {wrt}")
+
+            min_steps = 10  # https://github.com/stan-dev/math/issues/2857
+            max_steps = int(1e6)
+            precision = 1e-14
+
+            res = 0
+
+            if z == 0:
+                return res
+
+            log_g_old = -np.inf
+            log_t_old = 0.0
+            log_t_new = 0.0
+            sign_z = np.sign(z)
+            log_z = np.log(np.abs(z))
+
+            log_g_old_sign = 1
+            log_t_old_sign = 1
+            log_t_new_sign = 1
+            sign_zk = sign_z
+
+            for k in range(max_steps):
+                p = (a + k) * (b + k) / ((c + k) * (k + 1))
+                if p == 0:
+                    return res
+                log_t_new += np.log(np.abs(p)) + log_z
+                log_t_new_sign = np.sign(p) * log_t_new_sign
+
+                term = log_g_old_sign * log_t_old_sign * np.exp(log_g_old - log_t_old)
+                if wrt_a:
+                    term += np.reciprocal(a + k)
+                elif wrt_b:
+                    term += np.reciprocal(b + k)
+                else:
+                    term -= np.reciprocal(c + k)
+
+                log_g_old = log_t_new + np.log(np.abs(term))
+                log_g_old_sign = np.sign(term) * log_t_new_sign
+                g_current = log_g_old_sign * np.exp(log_g_old) * sign_zk
+                res += g_current
+
+                log_t_old = log_t_new
+                log_t_old_sign = log_t_new_sign
+                sign_zk *= sign_z
+
+                if k >= min_steps and np.abs(g_current) <= precision:
+                    return res
+
+            warnings.warn(
+                f"hyp2f1_der did not converge after {k} iterations",
+                RuntimeWarning,
+            )
+            return np.nan
+
+        # TODO: We could implement the Euler transform to expand supported domain, as Stan does
+        if not check_2f1_converges(a, b, c, z):
+            warnings.warn(
+                f"Hyp2F1 does not meet convergence conditions with given arguments a={a}, b={b}, c={c}, z={z}",
+                RuntimeWarning,
+            )
+            return np.nan
+
+        return compute_grad_2f1(a, b, c, z, wrt=wrt)
+
+    def __call__(self, a, b, c, z, wrt):
+        # This allows wrt to be a keyword argument
+        return super().__call__(a, b, c, z, wrt)
+
+    def c_code(self, *args, **kwargs):
+        raise NotImplementedError()
+
+
+hyp2f1_der = Hyp2F1Der(upgrade_to_float, name="hyp2f1_der")
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scalar/sharedvar.py` & `aesara_nightly-2.9.0.post2/aesara/scalar/sharedvar.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/scan/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/basic.py` & `aesara_nightly-2.9.0.post2/aesara/scan/basic.py`

 * *Files 1% similar despite different names*

```diff
@@ -605,19 +605,17 @@
                     try:
                         nw_slice.tag.test_value = get_test_value(_seq_val_slice)
                     except TestValueError:
                         if config.compute_test_value != "ignore":
                             # No need to print a warning or raise an error now,
                             # it will be done when fn will be called.
                             warnings.warn(
-                                (
-                                    "Cannot compute test value for "
-                                    "the inner function of scan, input value "
-                                    f"missing {_seq_val_slice}"
-                                )
+                                "Cannot compute test value for "
+                                "the inner function of scan, input value "
+                                f"missing {_seq_val_slice}"
                             )
 
                 # Add names to slices for debugging and pretty printing ..
                 # that is if the input already has a name
                 if getattr(seq["input"], "name", None) is not None:
                     if k > 0:
                         nw_name = seq["input"].name + f"[t+{int(k)}]"
@@ -716,15 +714,14 @@
         # Note that our convention dictates that if an output uses
         # just the previous time step, as a initial state we will only
         # provide a tensor of the same dimension as one time step; This
         # makes code much cleaner for those who do not use taps. Otherwise
         # they would always had to shape_padleft the initial state ..
         # which is ugly
         if init_out.get("taps", None) == [-1]:
-
             actual_arg = init_out["initial"]
             if not isinstance(actual_arg, Variable):
                 actual_arg = at.as_tensor_variable(actual_arg)
             arg = safe_new(actual_arg)
             if isinstance(arg, Constant):
                 # safe new returns a clone of the constants, but that is not
                 # what we need for initial states
@@ -733,18 +730,16 @@
             # Try to transfer test_value to the new variable
             if config.compute_test_value != "off":
                 try:
                     arg.tag.test_value = get_test_value(actual_arg)
                 except TestValueError:
                     if config.compute_test_value != "ignore":
                         warnings.warn(
-                            (
-                                "Cannot compute test value for the "
-                                f"inner function of scan, test value missing: {actual_arg}"
-                            )
+                            "Cannot compute test value for the "
+                            f"inner function of scan, test value missing: {actual_arg}"
                         )
 
             if getattr(init_out["initial"], "name", None) is not None:
                 arg.name = init_out["initial"].name + "[t-1]"
 
             # We need now to allocate space for storing the output and copy
             # the initial state over. We do this using the expand function
@@ -760,15 +755,14 @@
             if i in return_steps:
                 sit_sot_return_steps[n_sit_sot] = return_steps[i]
             sit_sot_inner_inputs.append(arg)
             sit_sot_rightOrder.append(i)
             n_sit_sot += 1
 
         elif init_out.get("taps", None):
-
             if np.any(np.array(init_out.get("taps", [])) > 0):
                 # Make sure we do not have requests for future values of a
                 # sequence we can not provide such values
                 raise ValueError("Can not use future taps of outputs", init_out)
             # go through the taps
             mintap = abs(np.min(init_out["taps"]))
             mit_sot_tap_array.append(init_out["taps"])
@@ -791,19 +785,17 @@
                 # Try to transfer test_value to the new variable
                 if config.compute_test_value != "off":
                     try:
                         nw_slice.tag.test_value = get_test_value(_init_out_var_slice)
                     except TestValueError:
                         if config.compute_test_value != "ignore":
                             warnings.warn(
-                                (
-                                    "Cannot compute test value for "
-                                    "the inner function of scan, test value "
-                                    f"missing: {_init_out_var_slice}"
-                                )
+                                "Cannot compute test value for "
+                                "the inner function of scan, test value "
+                                f"missing: {_init_out_var_slice}"
                             )
 
                 # give it a name or debugging and pretty printing
                 if getattr(init_out["initial"], "name", None) is not None:
                     if k > 0:
                         nw_slice.name = init_out["initial"].name + f"[t+{int(k)}]"
                     elif k == 0:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/c_code/scan_perform.c` & `aesara_nightly-2.9.0.post2/aesara/scan/c_code/scan_perform.c`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-/* Generated by Cython 0.29.28 */
+/* Generated by Cython 0.29.33 */
 
 #ifndef PY_SSIZE_T_CLEAN
 #define PY_SSIZE_T_CLEAN
 #endif /* PY_SSIZE_T_CLEAN */
 #include "Python.h"
 #ifndef Py_PYTHON_H
     #error Python headers needed to compile C extensions, please install development version of Python.
 #elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
     #error Cython requires Python 2.6+ or Python 3.3+.
 #else
-#define CYTHON_ABI "0_29_28"
-#define CYTHON_HEX_VERSION 0x001D1CF0
+#define CYTHON_ABI "0_29_33"
+#define CYTHON_HEX_VERSION 0x001D21F0
 #define CYTHON_FUTURE_DIVISION 1
 #include <stddef.h>
 #ifndef offsetof
   #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
 #endif
 #if !defined(WIN32) && !defined(MS_WINDOWS)
   #ifndef __stdcall
@@ -45,14 +45,15 @@
 #ifndef Py_HUGE_VAL
   #define Py_HUGE_VAL HUGE_VAL
 #endif
 #ifdef PYPY_VERSION
   #define CYTHON_COMPILING_IN_PYPY 1
   #define CYTHON_COMPILING_IN_PYSTON 0
   #define CYTHON_COMPILING_IN_CPYTHON 0
+  #define CYTHON_COMPILING_IN_NOGIL 0
   #undef CYTHON_USE_TYPE_SLOTS
   #define CYTHON_USE_TYPE_SLOTS 0
   #undef CYTHON_USE_PYTYPE_LOOKUP
   #define CYTHON_USE_PYTYPE_LOOKUP 0
   #if PY_VERSION_HEX < 0x03050000
     #undef CYTHON_USE_ASYNC_SLOTS
     #define CYTHON_USE_ASYNC_SLOTS 0
@@ -81,18 +82,22 @@
   #define CYTHON_PEP489_MULTI_PHASE_INIT 0
   #undef CYTHON_USE_TP_FINALIZE
   #define CYTHON_USE_TP_FINALIZE 0
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
+  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
+    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
+  #endif
 #elif defined(PYSTON_VERSION)
   #define CYTHON_COMPILING_IN_PYPY 0
   #define CYTHON_COMPILING_IN_PYSTON 1
   #define CYTHON_COMPILING_IN_CPYTHON 0
+  #define CYTHON_COMPILING_IN_NOGIL 0
   #ifndef CYTHON_USE_TYPE_SLOTS
     #define CYTHON_USE_TYPE_SLOTS 1
   #endif
   #undef CYTHON_USE_PYTYPE_LOOKUP
   #define CYTHON_USE_PYTYPE_LOOKUP 0
   #undef CYTHON_USE_ASYNC_SLOTS
   #define CYTHON_USE_ASYNC_SLOTS 0
@@ -122,18 +127,67 @@
   #define CYTHON_PEP489_MULTI_PHASE_INIT 0
   #undef CYTHON_USE_TP_FINALIZE
   #define CYTHON_USE_TP_FINALIZE 0
   #undef CYTHON_USE_DICT_VERSIONS
   #define CYTHON_USE_DICT_VERSIONS 0
   #undef CYTHON_USE_EXC_INFO_STACK
   #define CYTHON_USE_EXC_INFO_STACK 0
+  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
+    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
+  #endif
+#elif defined(PY_NOGIL)
+  #define CYTHON_COMPILING_IN_PYPY 0
+  #define CYTHON_COMPILING_IN_PYSTON 0
+  #define CYTHON_COMPILING_IN_CPYTHON 0
+  #define CYTHON_COMPILING_IN_NOGIL 1
+  #ifndef CYTHON_USE_TYPE_SLOTS
+    #define CYTHON_USE_TYPE_SLOTS 1
+  #endif
+  #undef CYTHON_USE_PYTYPE_LOOKUP
+  #define CYTHON_USE_PYTYPE_LOOKUP 0
+  #ifndef CYTHON_USE_ASYNC_SLOTS
+    #define CYTHON_USE_ASYNC_SLOTS 1
+  #endif
+  #undef CYTHON_USE_PYLIST_INTERNALS
+  #define CYTHON_USE_PYLIST_INTERNALS 0
+  #ifndef CYTHON_USE_UNICODE_INTERNALS
+    #define CYTHON_USE_UNICODE_INTERNALS 1
+  #endif
+  #undef CYTHON_USE_UNICODE_WRITER
+  #define CYTHON_USE_UNICODE_WRITER 0
+  #undef CYTHON_USE_PYLONG_INTERNALS
+  #define CYTHON_USE_PYLONG_INTERNALS 0
+  #ifndef CYTHON_AVOID_BORROWED_REFS
+    #define CYTHON_AVOID_BORROWED_REFS 0
+  #endif
+  #ifndef CYTHON_ASSUME_SAFE_MACROS
+    #define CYTHON_ASSUME_SAFE_MACROS 1
+  #endif
+  #ifndef CYTHON_UNPACK_METHODS
+    #define CYTHON_UNPACK_METHODS 1
+  #endif
+  #undef CYTHON_FAST_THREAD_STATE
+  #define CYTHON_FAST_THREAD_STATE 0
+  #undef CYTHON_FAST_PYCALL
+  #define CYTHON_FAST_PYCALL 0
+  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
+    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
+  #endif
+  #ifndef CYTHON_USE_TP_FINALIZE
+    #define CYTHON_USE_TP_FINALIZE 1
+  #endif
+  #undef CYTHON_USE_DICT_VERSIONS
+  #define CYTHON_USE_DICT_VERSIONS 0
+  #undef CYTHON_USE_EXC_INFO_STACK
+  #define CYTHON_USE_EXC_INFO_STACK 0
 #else
   #define CYTHON_COMPILING_IN_PYPY 0
   #define CYTHON_COMPILING_IN_PYSTON 0
   #define CYTHON_COMPILING_IN_CPYTHON 1
+  #define CYTHON_COMPILING_IN_NOGIL 0
   #ifndef CYTHON_USE_TYPE_SLOTS
     #define CYTHON_USE_TYPE_SLOTS 1
   #endif
   #if PY_VERSION_HEX < 0x02070000
     #undef CYTHON_USE_PYTYPE_LOOKUP
     #define CYTHON_USE_PYTYPE_LOOKUP 0
   #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
@@ -175,15 +229,15 @@
   #if PY_VERSION_HEX >= 0x030B00A4
     #undef CYTHON_FAST_THREAD_STATE
     #define CYTHON_FAST_THREAD_STATE 0
   #elif !defined(CYTHON_FAST_THREAD_STATE)
     #define CYTHON_FAST_THREAD_STATE 1
   #endif
   #ifndef CYTHON_FAST_PYCALL
-    #define CYTHON_FAST_PYCALL (PY_VERSION_HEX < 0x030B00A1)
+    #define CYTHON_FAST_PYCALL (PY_VERSION_HEX < 0x030A0000)
   #endif
   #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
     #define CYTHON_PEP489_MULTI_PHASE_INIT (PY_VERSION_HEX >= 0x03050000)
   #endif
   #ifndef CYTHON_USE_TP_FINALIZE
     #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
   #endif
@@ -192,14 +246,17 @@
   #endif
   #if PY_VERSION_HEX >= 0x030B00A4
     #undef CYTHON_USE_EXC_INFO_STACK
     #define CYTHON_USE_EXC_INFO_STACK 0
   #elif !defined(CYTHON_USE_EXC_INFO_STACK)
     #define CYTHON_USE_EXC_INFO_STACK (PY_VERSION_HEX >= 0x030700A3)
   #endif
+  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
+    #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
+  #endif
 #endif
 #if !defined(CYTHON_FAST_PYCCALL)
 #define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
 #endif
 #if CYTHON_USE_PYLONG_INTERNALS
   #if PY_MAJOR_VERSION < 3
     #include "longintrepr.h"
@@ -491,35 +548,35 @@
 #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030500A1 && CYTHON_USE_UNICODE_INTERNALS
 #define __Pyx_PyDict_GetItemStr(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
 #else
 #define __Pyx_PyDict_GetItemStr(dict, name)  PyDict_GetItem(dict, name)
 #endif
 #if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
   #define CYTHON_PEP393_ENABLED 1
-  #if defined(PyUnicode_IS_READY)
-  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
-                                              0 : _PyUnicode_Ready((PyObject *)(op)))
+  #if PY_VERSION_HEX >= 0x030C0000
+    #define __Pyx_PyUnicode_READY(op)       (0)
   #else
-  #define __Pyx_PyUnicode_READY(op)       (0)
+    #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
+                                                0 : _PyUnicode_Ready((PyObject *)(op)))
   #endif
   #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
   #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
   #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
   #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
   #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
   #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
   #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
-  #if defined(PyUnicode_IS_READY) && defined(PyUnicode_GET_SIZE)
-  #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
-  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
+  #if PY_VERSION_HEX >= 0x030C0000
+    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
   #else
-  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
-  #endif
-  #else
-  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
+    #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
+    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
+    #else
+    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
+    #endif
   #endif
 #else
   #define CYTHON_PEP393_ENABLED 0
   #define PyUnicode_1BYTE_KIND  1
   #define PyUnicode_2BYTE_KIND  2
   #define PyUnicode_4BYTE_KIND  4
   #define __Pyx_PyUnicode_READY(op)       (0)
@@ -643,16 +700,18 @@
     typedef struct {
         unaryfunc am_await;
         unaryfunc am_aiter;
         unaryfunc am_anext;
     } __Pyx_PyAsyncMethodsStruct;
 #endif
 
-#if defined(WIN32) || defined(MS_WINDOWS)
-  #define _USE_MATH_DEFINES
+#if defined(_WIN32) || defined(WIN32) || defined(MS_WINDOWS)
+  #if !defined(_USE_MATH_DEFINES)
+    #define _USE_MATH_DEFINES
+  #endif
 #endif
 #include <math.h>
 #ifdef NAN
 #define __PYX_NAN() ((float) NAN)
 #else
 static CYTHON_INLINE float __PYX_NAN() {
   float value;
@@ -945,51 +1004,47 @@
 #define __Pyx_MemoryView_Len(m)  (m.shape[0])
 
 /* Atomics.proto */
 #include <pythread.h>
 #ifndef CYTHON_ATOMICS
     #define CYTHON_ATOMICS 1
 #endif
+#define __PYX_CYTHON_ATOMICS_ENABLED() CYTHON_ATOMICS
 #define __pyx_atomic_int_type int
-#if CYTHON_ATOMICS && __GNUC__ >= 4 && (__GNUC_MINOR__ > 1 ||\
-                    (__GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL >= 2)) &&\
-                    !defined(__i386__)
-    #define __pyx_atomic_incr_aligned(value, lock) __sync_fetch_and_add(value, 1)
-    #define __pyx_atomic_decr_aligned(value, lock) __sync_fetch_and_sub(value, 1)
+#if CYTHON_ATOMICS && (__GNUC__ >= 5 || (__GNUC__ == 4 &&\
+                    (__GNUC_MINOR__ > 1 ||\
+                    (__GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 2))))
+    #define __pyx_atomic_incr_aligned(value) __sync_fetch_and_add(value, 1)
+    #define __pyx_atomic_decr_aligned(value) __sync_fetch_and_sub(value, 1)
     #ifdef __PYX_DEBUG_ATOMICS
         #warning "Using GNU atomics"
     #endif
-#elif CYTHON_ATOMICS && defined(_MSC_VER) && 0
-    #include <Windows.h>
+#elif CYTHON_ATOMICS && defined(_MSC_VER) && CYTHON_COMPILING_IN_NOGIL
+    #include <intrin.h>
     #undef __pyx_atomic_int_type
-    #define __pyx_atomic_int_type LONG
-    #define __pyx_atomic_incr_aligned(value, lock) InterlockedIncrement(value)
-    #define __pyx_atomic_decr_aligned(value, lock) InterlockedDecrement(value)
+    #define __pyx_atomic_int_type long
+    #pragma intrinsic (_InterlockedExchangeAdd)
+    #define __pyx_atomic_incr_aligned(value) _InterlockedExchangeAdd(value, 1)
+    #define __pyx_atomic_decr_aligned(value) _InterlockedExchangeAdd(value, -1)
     #ifdef __PYX_DEBUG_ATOMICS
         #pragma message ("Using MSVC atomics")
     #endif
-#elif CYTHON_ATOMICS && (defined(__ICC) || defined(__INTEL_COMPILER)) && 0
-    #define __pyx_atomic_incr_aligned(value, lock) _InterlockedIncrement(value)
-    #define __pyx_atomic_decr_aligned(value, lock) _InterlockedDecrement(value)
-    #ifdef __PYX_DEBUG_ATOMICS
-        #warning "Using Intel atomics"
-    #endif
 #else
     #undef CYTHON_ATOMICS
     #define CYTHON_ATOMICS 0
     #ifdef __PYX_DEBUG_ATOMICS
         #warning "Not using atomics"
     #endif
 #endif
 typedef volatile __pyx_atomic_int_type __pyx_atomic_int;
 #if CYTHON_ATOMICS
     #define __pyx_add_acquisition_count(memview)\
-             __pyx_atomic_incr_aligned(__pyx_get_slice_count_pointer(memview), memview->lock)
+             __pyx_atomic_incr_aligned(__pyx_get_slice_count_pointer(memview))
     #define __pyx_sub_acquisition_count(memview)\
-            __pyx_atomic_decr_aligned(__pyx_get_slice_count_pointer(memview), memview->lock)
+            __pyx_atomic_decr_aligned(__pyx_get_slice_count_pointer(memview))
 #else
     #define __pyx_add_acquisition_count(memview)\
             __pyx_add_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
     #define __pyx_sub_acquisition_count(memview)\
             __pyx_sub_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
 #endif
 
@@ -1038,195 +1093,195 @@
   char enc_type;
   char new_packmode;
   char enc_packmode;
   char is_valid_array;
 } __Pyx_BufFmt_Context;
 
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":690
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":689
  * # in Cython to enable them only on the right systems.
  * 
  * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t
  */
 typedef npy_int8 __pyx_t_5numpy_int8_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":691
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":690
  * 
  * ctypedef npy_int8       int8_t
  * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int32      int32_t
  * ctypedef npy_int64      int64_t
  */
 typedef npy_int16 __pyx_t_5numpy_int16_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":692
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":691
  * ctypedef npy_int8       int8_t
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_int64      int64_t
  * #ctypedef npy_int96      int96_t
  */
 typedef npy_int32 __pyx_t_5numpy_int32_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":693
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":692
  * ctypedef npy_int16      int16_t
  * ctypedef npy_int32      int32_t
  * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_int96      int96_t
  * #ctypedef npy_int128     int128_t
  */
 typedef npy_int64 __pyx_t_5numpy_int64_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":697
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":696
  * #ctypedef npy_int128     int128_t
  * 
  * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t
  */
 typedef npy_uint8 __pyx_t_5numpy_uint8_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":698
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":697
  * 
  * ctypedef npy_uint8      uint8_t
  * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint32     uint32_t
  * ctypedef npy_uint64     uint64_t
  */
 typedef npy_uint16 __pyx_t_5numpy_uint16_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":699
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":698
  * ctypedef npy_uint8      uint8_t
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uint64     uint64_t
  * #ctypedef npy_uint96     uint96_t
  */
 typedef npy_uint32 __pyx_t_5numpy_uint32_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":700
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":699
  * ctypedef npy_uint16     uint16_t
  * ctypedef npy_uint32     uint32_t
  * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_uint96     uint96_t
  * #ctypedef npy_uint128    uint128_t
  */
 typedef npy_uint64 __pyx_t_5numpy_uint64_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":704
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":703
  * #ctypedef npy_uint128    uint128_t
  * 
  * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
  * ctypedef npy_float64    float64_t
  * #ctypedef npy_float80    float80_t
  */
 typedef npy_float32 __pyx_t_5numpy_float32_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":705
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":704
  * 
  * ctypedef npy_float32    float32_t
  * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
  * #ctypedef npy_float80    float80_t
  * #ctypedef npy_float128   float128_t
  */
 typedef npy_float64 __pyx_t_5numpy_float64_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":714
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":713
  * # The int types are mapped a bit surprising --
  * # numpy.int corresponds to 'l' and numpy.long to 'q'
  * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
  * ctypedef npy_longlong   long_t
  * ctypedef npy_longlong   longlong_t
  */
 typedef npy_long __pyx_t_5numpy_int_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":715
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":714
  * # numpy.int corresponds to 'l' and numpy.long to 'q'
  * ctypedef npy_long       int_t
  * ctypedef npy_longlong   long_t             # <<<<<<<<<<<<<<
  * ctypedef npy_longlong   longlong_t
  * 
  */
 typedef npy_longlong __pyx_t_5numpy_long_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":716
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":715
  * ctypedef npy_long       int_t
  * ctypedef npy_longlong   long_t
  * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_ulong      uint_t
  */
 typedef npy_longlong __pyx_t_5numpy_longlong_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":718
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":717
  * ctypedef npy_longlong   longlong_t
  * 
  * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
  * ctypedef npy_ulonglong  ulong_t
  * ctypedef npy_ulonglong  ulonglong_t
  */
 typedef npy_ulong __pyx_t_5numpy_uint_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":719
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":718
  * 
  * ctypedef npy_ulong      uint_t
  * ctypedef npy_ulonglong  ulong_t             # <<<<<<<<<<<<<<
  * ctypedef npy_ulonglong  ulonglong_t
  * 
  */
 typedef npy_ulonglong __pyx_t_5numpy_ulong_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":720
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":719
  * ctypedef npy_ulong      uint_t
  * ctypedef npy_ulonglong  ulong_t
  * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_intp       intp_t
  */
 typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":722
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":721
  * ctypedef npy_ulonglong  ulonglong_t
  * 
  * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
  * ctypedef npy_uintp      uintp_t
  * 
  */
 typedef npy_intp __pyx_t_5numpy_intp_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":723
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":722
  * 
  * ctypedef npy_intp       intp_t
  * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_double     float_t
  */
 typedef npy_uintp __pyx_t_5numpy_uintp_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":725
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":724
  * ctypedef npy_uintp      uintp_t
  * 
  * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
  * ctypedef npy_double     double_t
  * ctypedef npy_longdouble longdouble_t
  */
 typedef npy_double __pyx_t_5numpy_float_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":726
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":725
  * 
  * ctypedef npy_double     float_t
  * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
  * ctypedef npy_longdouble longdouble_t
  * 
  */
 typedef npy_double __pyx_t_5numpy_double_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":727
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":726
  * ctypedef npy_double     float_t
  * ctypedef npy_double     double_t
  * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_cfloat      cfloat_t
  */
 typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
@@ -1257,51 +1312,51 @@
 
 /*--- Type declarations ---*/
 struct __pyx_array_obj;
 struct __pyx_MemviewEnum_obj;
 struct __pyx_memoryview_obj;
 struct __pyx_memoryviewslice_obj;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":729
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":728
  * ctypedef npy_longdouble longdouble_t
  * 
  * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
  * ctypedef npy_cdouble     cdouble_t
  * ctypedef npy_clongdouble clongdouble_t
  */
 typedef npy_cfloat __pyx_t_5numpy_cfloat_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":730
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":729
  * 
  * ctypedef npy_cfloat      cfloat_t
  * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
  * ctypedef npy_clongdouble clongdouble_t
  * 
  */
 typedef npy_cdouble __pyx_t_5numpy_cdouble_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":731
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":730
  * ctypedef npy_cfloat      cfloat_t
  * ctypedef npy_cdouble     cdouble_t
  * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
  * 
  * ctypedef npy_cdouble     complex_t
  */
 typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":733
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":732
  * ctypedef npy_clongdouble clongdouble_t
  * 
  * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew1(a):
  */
 typedef npy_cdouble __pyx_t_5numpy_complex_t;
 
-/* "View.MemoryView":105
+/* "View.MemoryView":106
  * 
  * @cname("__pyx_array")
  * cdef class array:             # <<<<<<<<<<<<<<
  * 
  *     cdef:
  */
 struct __pyx_array_obj {
@@ -1318,28 +1373,28 @@
   PyObject *_format;
   void (*callback_free_data)(void *);
   int free_data;
   int dtype_is_object;
 };
 
 
-/* "View.MemoryView":279
+/* "View.MemoryView":280
  * 
  * @cname('__pyx_MemviewEnum')
  * cdef class Enum(object):             # <<<<<<<<<<<<<<
  *     cdef object name
  *     def __init__(self, name):
  */
 struct __pyx_MemviewEnum_obj {
   PyObject_HEAD
   PyObject *name;
 };
 
 
-/* "View.MemoryView":330
+/* "View.MemoryView":331
  * 
  * @cname('__pyx_memoryview')
  * cdef class memoryview(object):             # <<<<<<<<<<<<<<
  * 
  *     cdef object obj
  */
 struct __pyx_memoryview_obj {
@@ -1354,15 +1409,15 @@
   Py_buffer view;
   int flags;
   int dtype_is_object;
   __Pyx_TypeInfo *typeinfo;
 };
 
 
-/* "View.MemoryView":965
+/* "View.MemoryView":967
  * 
  * @cname('__pyx_memoryviewslice')
  * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
  *     "Internal class for passing memoryview slices to Python"
  * 
  */
 struct __pyx_memoryviewslice_obj {
@@ -1371,29 +1426,29 @@
   PyObject *from_object;
   PyObject *(*to_object_func)(char *);
   int (*to_dtype_func)(char *, PyObject *);
 };
 
 
 
-/* "View.MemoryView":105
+/* "View.MemoryView":106
  * 
  * @cname("__pyx_array")
  * cdef class array:             # <<<<<<<<<<<<<<
  * 
  *     cdef:
  */
 
 struct __pyx_vtabstruct_array {
   PyObject *(*get_memview)(struct __pyx_array_obj *);
 };
 static struct __pyx_vtabstruct_array *__pyx_vtabptr_array;
 
 
-/* "View.MemoryView":330
+/* "View.MemoryView":331
  * 
  * @cname('__pyx_memoryview')
  * cdef class memoryview(object):             # <<<<<<<<<<<<<<
  * 
  *     cdef object obj
  */
 
@@ -1405,15 +1460,15 @@
   PyObject *(*setitem_indexed)(struct __pyx_memoryview_obj *, PyObject *, PyObject *);
   PyObject *(*convert_item_to_object)(struct __pyx_memoryview_obj *, char *);
   PyObject *(*assign_item_from_object)(struct __pyx_memoryview_obj *, char *, PyObject *);
 };
 static struct __pyx_vtabstruct_memoryview *__pyx_vtabptr_memoryview;
 
 
-/* "View.MemoryView":965
+/* "View.MemoryView":967
  * 
  * @cname('__pyx_memoryviewslice')
  * cdef class _memoryviewslice(memoryview):             # <<<<<<<<<<<<<<
  *     "Internal class for passing memoryview slices to Python"
  * 
  */
 
@@ -1527,14 +1582,20 @@
     (sizeof(char [1 - 2*!(cond)]) - 1)
 #ifndef Py_MEMBER_SIZE
 #define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
 #endif
 #if CYTHON_FAST_PYCALL
   static size_t __pyx_pyframe_localsplus_offset = 0;
   #include "frameobject.h"
+#if PY_VERSION_HEX >= 0x030b00a6
+  #ifndef Py_BUILD_CORE
+    #define Py_BUILD_CORE 1
+  #endif
+  #include "internal/pycore_frame.h"
+#endif
   #define __Pxy_PyFrame_Initialize_Offsets()\
     ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
      (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
   #define __Pyx_PyFrame_GetLocalsplus(frame)\
     (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
 #endif // CYTHON_FAST_PYCALL
 #endif
@@ -1700,26 +1761,26 @@
 #define __PYX_GET_DICT_VERSION(dict)  (0)
 #define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
 #define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
 #endif
 
 /* GetModuleGlobalName.proto */
 #if CYTHON_USE_DICT_VERSIONS
-#define __Pyx_GetModuleGlobalName(var, name)  {\
+#define __Pyx_GetModuleGlobalName(var, name)  do {\
     static PY_UINT64_T __pyx_dict_version = 0;\
     static PyObject *__pyx_dict_cached_value = NULL;\
     (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_d))) ?\
         (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
         __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
-}
-#define __Pyx_GetModuleGlobalNameUncached(var, name)  {\
+} while(0)
+#define __Pyx_GetModuleGlobalNameUncached(var, name)  do {\
     PY_UINT64_T __pyx_dict_version;\
     PyObject *__pyx_dict_cached_value;\
     (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
-}
+} while(0)
 static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
 #else
 #define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
 #define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
 static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
 #endif
 
@@ -1945,14 +2006,20 @@
 
 /* None.proto */
 static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);
 
 /* DivInt[long].proto */
 static CYTHON_INLINE long __Pyx_div_long(long, long);
 
+/* PySequenceContains.proto */
+static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
+    int result = PySequence_Contains(seq, item);
+    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
+}
+
 /* ImportFrom.proto */
 static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);
 
 /* HasAttr.proto */
 static CYTHON_INLINE int __Pyx_HasAttr(PyObject *, PyObject *);
 
 /* PyObject_GenericGetAttrNoDict.proto */
@@ -2519,15 +2586,15 @@
 static const char __pyx_k_This_code_implements_the_operat[] = "\n This code implements the operations that scan has to carry on when called\n as a stand alone function.\n\n IF anything this is the entire code that needs to be transported to C.\n\n Short description of how this code works:\n     Scan divides its inputs ( Op's inputs) into different classes of inputs\n     as follows:\n         i) sequences : inputs over which scan loops to get data. Nothing is\n         written into them ( they are readonly, loop over)\n\n         ii) mit_mot : multiple input taps multiple output taps arguments.\n         These are inputs over which scan loops and gets data but into which\n         scan also writes data. The shorthand mit_mot describes how scan\n         deal with them at each step : at each step take several slices as\n         input and produce several slices as outputs\n\n         iii) mit_sot : multiple input taps single output tap arguments.\n         As before scan reads from these but also writes. At each step scan\n         uses several slices as input but produces only one as output\n\n         iv) sit_sot : single input tap single output tap arguments.\n         At each step use only the previous slice as input, produce only one\n         slice as output\n\n         v) nit_sot: no input tap single output tap arguments.\n         At each step don't use any previous values, only produce new onese\n\n         vi) shared_outs: arguments corresponding to shared variables with\n         updates.\n         At each step use its value as input, and afterwards replace it with\n         a new value.\n         vii) other_args: arguments that are passed to every call of the\n         inner function as they are ( no slicing is performed)\n\n    All these outputs are one after the other in the inputs list (named in\n    this code as outer_inputs) in a given order ( namely the one described above\n    with little discrepancies depending if we are talking about the outputs\n    of the Scan op or the inputs of the Scan op Node, and if w""e are talking\n    about the inputs of the inner function of scan or of the scan op).\n\n    Because of this, all we need to be able to separate and tell arguments\n    apart is how many of which we have as well as how many taps and which\n    ones (where applicable). All this information is described (more or less)\n    by describing the arguments of this function)\n";
 static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
 static const char __pyx_k_Buffer_view_does_not_expose_stri[] = "Buffer view does not expose strides";
 static const char __pyx_k_Can_only_create_a_buffer_that_is[] = "Can only create a buffer that is contiguous in memory.";
 static const char __pyx_k_Cannot_assign_to_read_only_memor[] = "Cannot assign to read-only memoryview";
 static const char __pyx_k_Cannot_create_writable_memory_vi[] = "Cannot create writable memory view from read-only memoryview";
 static const char __pyx_k_Empty_shape_tuple_for_cython_arr[] = "Empty shape tuple for cython.array";
-static const char __pyx_k_Incompatible_checksums_s_vs_0xb0[] = "Incompatible checksums (%s vs 0xb068931 = (name))";
+static const char __pyx_k_Incompatible_checksums_0x_x_vs_0[] = "Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))";
 static const char __pyx_k_Indirect_dimensions_not_supporte[] = "Indirect dimensions not supported";
 static const char __pyx_k_Invalid_mode_expected_c_or_fortr[] = "Invalid mode, expected 'c' or 'fortran', got %s";
 static const char __pyx_k_Out_of_bounds_on_buffer_access_a[] = "Out of bounds on buffer access (axis %d)";
 static const char __pyx_k_Scan_was_asked_to_run_for_negati[] = "Scan was asked to run for negative number of step %d";
 static const char __pyx_k_Unable_to_convert_item_to_object[] = "Unable to convert item to object";
 static const char __pyx_k_got_differing_extents_in_dimensi[] = "got differing extents in dimension %d (got %d and %d)";
 static const char __pyx_k_no_default___reduce___due_to_non[] = "no default __reduce__ due to non-trivial __cinit__";
@@ -2538,15 +2605,15 @@
 static PyObject *__pyx_kp_s_Can_only_create_a_buffer_that_is;
 static PyObject *__pyx_kp_s_Cannot_assign_to_read_only_memor;
 static PyObject *__pyx_kp_s_Cannot_create_writable_memory_vi;
 static PyObject *__pyx_kp_s_Cannot_index_with_type_s;
 static PyObject *__pyx_n_s_Ellipsis;
 static PyObject *__pyx_kp_s_Empty_shape_tuple_for_cython_arr;
 static PyObject *__pyx_n_s_ImportError;
-static PyObject *__pyx_kp_s_Incompatible_checksums_s_vs_0xb0;
+static PyObject *__pyx_kp_s_Incompatible_checksums_0x_x_vs_0;
 static PyObject *__pyx_n_s_IndexError;
 static PyObject *__pyx_kp_s_Indirect_dimensions_not_supporte;
 static PyObject *__pyx_n_s_InnerFunctionError;
 static PyObject *__pyx_kp_s_Invalid_mode_expected_c_or_fortr;
 static PyObject *__pyx_kp_s_Invalid_shape_in_axis_d_d;
 static PyObject *__pyx_n_s_MemoryError;
 static PyObject *__pyx_kp_s_MemoryView_of_r_at_0x_x;
@@ -2774,14 +2841,16 @@
 static PyObject *__pyx_tp_new_Enum(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new_memoryview(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_tp_new__memoryviewslice(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
 static PyObject *__pyx_float_0_0;
 static PyObject *__pyx_float_0_326;
 static PyObject *__pyx_int_0;
 static PyObject *__pyx_int_1;
+static PyObject *__pyx_int_112105877;
+static PyObject *__pyx_int_136983863;
 static PyObject *__pyx_int_184977713;
 static PyObject *__pyx_int_neg_1;
 static PyObject *__pyx_slice_;
 static PyObject *__pyx_slice__2;
 static PyObject *__pyx_tuple__3;
 static PyObject *__pyx_tuple__4;
 static PyObject *__pyx_tuple__5;
@@ -2799,24 +2868,25 @@
 static PyObject *__pyx_tuple__17;
 static PyObject *__pyx_tuple__18;
 static PyObject *__pyx_tuple__19;
 static PyObject *__pyx_tuple__20;
 static PyObject *__pyx_tuple__21;
 static PyObject *__pyx_tuple__22;
 static PyObject *__pyx_tuple__23;
-static PyObject *__pyx_tuple__25;
-static PyObject *__pyx_tuple__27;
+static PyObject *__pyx_tuple__24;
+static PyObject *__pyx_tuple__26;
 static PyObject *__pyx_tuple__28;
 static PyObject *__pyx_tuple__29;
 static PyObject *__pyx_tuple__30;
 static PyObject *__pyx_tuple__31;
 static PyObject *__pyx_tuple__32;
-static PyObject *__pyx_codeobj__24;
-static PyObject *__pyx_codeobj__26;
-static PyObject *__pyx_codeobj__33;
+static PyObject *__pyx_tuple__33;
+static PyObject *__pyx_codeobj__25;
+static PyObject *__pyx_codeobj__27;
+static PyObject *__pyx_codeobj__34;
 /* Late includes */
 
 /* "aesara/scan/scan_perform.pyx":64
  * 
  * 
  * def get_version():             # <<<<<<<<<<<<<<
  *     return 0.326
@@ -7174,15 +7244,15 @@
   __PYX_XDEC_MEMVIEW(&__pyx_v_destroy_map, 1);
   __PYX_XDEC_MEMVIEW(&__pyx_v_outer_output_ndims, 1);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":735
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":734
  * ctypedef npy_cdouble     complex_t
  * 
  * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  */
 
@@ -7191,29 +7261,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew1", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":736
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":735
  * 
  * cdef inline object PyArray_MultiIterNew1(a):
  *     return PyArray_MultiIterNew(1, <void*>a)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 736, __pyx_L1_error)
+  __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 735, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":735
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":734
  * ctypedef npy_cdouble     complex_t
  * 
  * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  */
 
@@ -7224,15 +7294,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":738
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":737
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  */
 
@@ -7241,29 +7311,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew2", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":739
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":738
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 739, __pyx_L1_error)
+  __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 738, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":738
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":737
  *     return PyArray_MultiIterNew(1, <void*>a)
  * 
  * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  */
 
@@ -7274,15 +7344,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":741
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":740
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  */
 
@@ -7291,29 +7361,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew3", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":742
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":741
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 742, __pyx_L1_error)
+  __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 741, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":741
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":740
  *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
  * 
  * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  */
 
@@ -7324,15 +7394,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":744
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":743
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  */
 
@@ -7341,29 +7411,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew4", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":745
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":744
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 745, __pyx_L1_error)
+  __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 744, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":744
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":743
  *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
  * 
  * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  */
 
@@ -7374,15 +7444,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":747
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":746
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  */
 
@@ -7391,29 +7461,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("PyArray_MultiIterNew5", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":748
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":747
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)             # <<<<<<<<<<<<<<
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 748, __pyx_L1_error)
+  __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 747, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":747
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":746
  *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
  * 
  * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  */
 
@@ -7424,212 +7494,212 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":750
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":749
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape
  */
 
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr *__pyx_v_d) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("PyDataType_SHAPE", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":751
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":750
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
  *         return <tuple>d.subarray.shape
  *     else:
  */
   __pyx_t_1 = (PyDataType_HASSUBARRAY(__pyx_v_d) != 0);
   if (__pyx_t_1) {
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":752
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":751
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape             # <<<<<<<<<<<<<<
  *     else:
  *         return ()
  */
     __Pyx_XDECREF(__pyx_r);
     __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));
     __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);
     goto __pyx_L0;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":751
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":750
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):
  *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
  *         return <tuple>d.subarray.shape
  *     else:
  */
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":754
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":753
  *         return <tuple>d.subarray.shape
  *     else:
  *         return ()             # <<<<<<<<<<<<<<
  * 
  * 
  */
   /*else*/ {
     __Pyx_XDECREF(__pyx_r);
     __Pyx_INCREF(__pyx_empty_tuple);
     __pyx_r = __pyx_empty_tuple;
     goto __pyx_L0;
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":750
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":749
  *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
  * 
  * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
  *     if PyDataType_HASSUBARRAY(d):
  *         return <tuple>d.subarray.shape
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":929
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":928
  *     int _import_umath() except -1
  * 
  * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)
  */
 
 static CYTHON_INLINE void __pyx_f_5numpy_set_array_base(PyArrayObject *__pyx_v_arr, PyObject *__pyx_v_base) {
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("set_array_base", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":930
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":929
  * 
  * cdef inline void set_array_base(ndarray arr, object base):
  *     Py_INCREF(base) # important to do this before stealing the reference below!             # <<<<<<<<<<<<<<
  *     PyArray_SetBaseObject(arr, base)
  * 
  */
   Py_INCREF(__pyx_v_base);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":931
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":930
  * cdef inline void set_array_base(ndarray arr, object base):
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)             # <<<<<<<<<<<<<<
  * 
  * cdef inline object get_array_base(ndarray arr):
  */
   (void)(PyArray_SetBaseObject(__pyx_v_arr, __pyx_v_base));
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":929
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":928
  *     int _import_umath() except -1
  * 
  * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
  *     Py_INCREF(base) # important to do this before stealing the reference below!
  *     PyArray_SetBaseObject(arr, base)
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":933
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":932
  *     PyArray_SetBaseObject(arr, base)
  * 
  * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  */
 
 static CYTHON_INLINE PyObject *__pyx_f_5numpy_get_array_base(PyArrayObject *__pyx_v_arr) {
   PyObject *__pyx_v_base;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("get_array_base", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":934
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":933
  * 
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)             # <<<<<<<<<<<<<<
  *     if base is NULL:
  *         return None
  */
   __pyx_v_base = PyArray_BASE(__pyx_v_arr);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":935
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":934
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)
  *     if base is NULL:             # <<<<<<<<<<<<<<
  *         return None
  *     return <object>base
  */
   __pyx_t_1 = ((__pyx_v_base == NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":936
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":935
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  *         return None             # <<<<<<<<<<<<<<
  *     return <object>base
  * 
  */
     __Pyx_XDECREF(__pyx_r);
     __pyx_r = Py_None; __Pyx_INCREF(Py_None);
     goto __pyx_L0;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":935
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":934
  * cdef inline object get_array_base(ndarray arr):
  *     base = PyArray_BASE(arr)
  *     if base is NULL:             # <<<<<<<<<<<<<<
  *         return None
  *     return <object>base
  */
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":937
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":936
  *     if base is NULL:
  *         return None
  *     return <object>base             # <<<<<<<<<<<<<<
  * 
  * # Versions of the import_* functions which are more suitable for
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(((PyObject *)__pyx_v_base));
   __pyx_r = ((PyObject *)__pyx_v_base);
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":933
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":932
  *     PyArray_SetBaseObject(arr, base)
  * 
  * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
  *     base = PyArray_BASE(arr)
  *     if base is NULL:
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":941
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":940
  * # Versions of the import_* functions which are more suitable for
  * # Cython code.
  * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         __pyx_import_array()
  */
 
@@ -7645,15 +7715,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_array", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":942
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":941
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
   {
@@ -7661,84 +7731,84 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":943
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":942
  * cdef inline int import_array() except -1:
  *     try:
  *         __pyx_import_array()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")
  */
-      __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 943, __pyx_L3_error)
+      __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 942, __pyx_L3_error)
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":942
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":941
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":944
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":943
  *     try:
  *         __pyx_import_array()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 944, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 943, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":945
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":944
  *         __pyx_import_array()
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_umath() except -1:
  */
-      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 945, __pyx_L5_except_error)
+      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 944, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __PYX_ERR(1, 945, __pyx_L5_except_error)
+      __PYX_ERR(1, 944, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":942
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":941
  * # Cython code.
  * cdef inline int import_array() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         __pyx_import_array()
  *     except Exception:
  */
     __Pyx_XGIVEREF(__pyx_t_1);
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":941
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":940
  * # Versions of the import_* functions which are more suitable for
  * # Cython code.
  * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         __pyx_import_array()
  */
 
@@ -7753,15 +7823,15 @@
   __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":947
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":946
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -7777,15 +7847,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_umath", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":948
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":947
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
   {
@@ -7793,84 +7863,84 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":949
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":948
  * cdef inline int import_umath() except -1:
  *     try:
  *         _import_umath()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")
  */
-      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 949, __pyx_L3_error)
+      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 948, __pyx_L3_error)
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":948
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":947
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":950
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":949
  *     try:
  *         _import_umath()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 950, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 949, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":951
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":950
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_ufunc() except -1:
  */
-      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 951, __pyx_L5_except_error)
+      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 950, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __PYX_ERR(1, 951, __pyx_L5_except_error)
+      __PYX_ERR(1, 950, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":948
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":947
  * 
  * cdef inline int import_umath() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     __Pyx_XGIVEREF(__pyx_t_1);
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":947
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":946
  *         raise ImportError("numpy.core.multiarray failed to import")
  * 
  * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -7885,15 +7955,15 @@
   __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":953
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":952
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -7909,15 +7979,15 @@
   PyObject *__pyx_t_7 = NULL;
   PyObject *__pyx_t_8 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("import_ufunc", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":954
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":953
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
   {
@@ -7925,84 +7995,84 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_1);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     /*try:*/ {
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":955
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":954
  * cdef inline int import_ufunc() except -1:
  *     try:
  *         _import_umath()             # <<<<<<<<<<<<<<
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")
  */
-      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 955, __pyx_L3_error)
+      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 954, __pyx_L3_error)
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":954
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":953
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     }
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
     goto __pyx_L8_try_end;
     __pyx_L3_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":956
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":955
  *     try:
  *         _import_umath()
  *     except Exception:             # <<<<<<<<<<<<<<
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  */
     __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
     if (__pyx_t_4) {
       __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 956, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 955, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_GOTREF(__pyx_t_7);
 
-      /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":957
+      /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":956
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef extern from *:
  */
-      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 957, __pyx_L5_except_error)
+      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 956, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_8);
       __Pyx_Raise(__pyx_t_8, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
-      __PYX_ERR(1, 957, __pyx_L5_except_error)
+      __PYX_ERR(1, 956, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":954
+    /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":953
  * 
  * cdef inline int import_ufunc() except -1:
  *     try:             # <<<<<<<<<<<<<<
  *         _import_umath()
  *     except Exception:
  */
     __Pyx_XGIVEREF(__pyx_t_1);
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
     goto __pyx_L1_error;
     __pyx_L8_try_end:;
   }
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":953
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":952
  *         raise ImportError("numpy.core.umath failed to import")
  * 
  * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
  *     try:
  *         _import_umath()
  */
 
@@ -8017,189 +8087,189 @@
   __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":967
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":966
  * 
  * 
  * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.timedelta64)`
  */
 
 static CYTHON_INLINE int __pyx_f_5numpy_is_timedelta64_object(PyObject *__pyx_v_obj) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("is_timedelta64_object", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":979
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":978
  *     bool
  *     """
  *     return PyObject_TypeCheck(obj, &PyTimedeltaArrType_Type)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyTimedeltaArrType_Type));
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":967
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":966
  * 
  * 
  * cdef inline bint is_timedelta64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.timedelta64)`
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":982
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":981
  * 
  * 
  * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.datetime64)`
  */
 
 static CYTHON_INLINE int __pyx_f_5numpy_is_datetime64_object(PyObject *__pyx_v_obj) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("is_datetime64_object", 0);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":994
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":993
  *     bool
  *     """
  *     return PyObject_TypeCheck(obj, &PyDatetimeArrType_Type)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = PyObject_TypeCheck(__pyx_v_obj, (&PyDatetimeArrType_Type));
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":982
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":981
  * 
  * 
  * cdef inline bint is_datetime64_object(object obj):             # <<<<<<<<<<<<<<
  *     """
  *     Cython equivalent of `isinstance(obj, np.datetime64)`
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":997
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":996
  * 
  * 
  * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy datetime64 object
  */
 
 static CYTHON_INLINE npy_datetime __pyx_f_5numpy_get_datetime64_value(PyObject *__pyx_v_obj) {
   npy_datetime __pyx_r;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1004
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1003
  *     also needed.  That can be found using `get_datetime64_unit`.
  *     """
  *     return (<PyDatetimeScalarObject*>obj).obval             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = ((PyDatetimeScalarObject *)__pyx_v_obj)->obval;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":997
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":996
  * 
  * 
  * cdef inline npy_datetime get_datetime64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy datetime64 object
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1007
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1006
  * 
  * 
  * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy timedelta64 object
  */
 
 static CYTHON_INLINE npy_timedelta __pyx_f_5numpy_get_timedelta64_value(PyObject *__pyx_v_obj) {
   npy_timedelta __pyx_r;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1011
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1010
  *     returns the int64 value underlying scalar numpy timedelta64 object
  *     """
  *     return (<PyTimedeltaScalarObject*>obj).obval             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = ((PyTimedeltaScalarObject *)__pyx_v_obj)->obval;
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1007
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1006
  * 
  * 
  * cdef inline npy_timedelta get_timedelta64_value(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the int64 value underlying scalar numpy timedelta64 object
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1014
+/* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1013
  * 
  * 
  * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the unit part of the dtype for a numpy datetime64 object.
  */
 
 static CYTHON_INLINE NPY_DATETIMEUNIT __pyx_f_5numpy_get_datetime64_unit(PyObject *__pyx_v_obj) {
   NPY_DATETIMEUNIT __pyx_r;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1018
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1017
  *     returns the unit part of the dtype for a numpy datetime64 object.
  *     """
  *     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base             # <<<<<<<<<<<<<<
  */
   __pyx_r = ((NPY_DATETIMEUNIT)((PyDatetimeScalarObject *)__pyx_v_obj)->obmeta.base);
   goto __pyx_L0;
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":1014
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":1013
  * 
  * 
  * cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     returns the unit part of the dtype for a numpy datetime64 object.
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":122
+/* "View.MemoryView":123
  *         cdef bint dtype_is_object
  * 
  *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
  *                   mode="c", bint allocate_buffer=True):
  * 
  */
 
@@ -8243,21 +8313,21 @@
         case  0:
         if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
         else goto __pyx_L5_argtuple_error;
         CYTHON_FALLTHROUGH;
         case  1:
         if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_itemsize)) != 0)) kw_args--;
         else {
-          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 1); __PYX_ERR(2, 122, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 1); __PYX_ERR(2, 123, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  2:
         if (likely((values[2] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_format)) != 0)) kw_args--;
         else {
-          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 2); __PYX_ERR(2, 122, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, 2); __PYX_ERR(2, 123, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  3:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_mode);
           if (value) { values[3] = value; kw_args--; }
         }
@@ -8265,15 +8335,15 @@
         case  4:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_allocate_buffer);
           if (value) { values[4] = value; kw_args--; }
         }
       }
       if (unlikely(kw_args > 0)) {
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 122, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 123, __pyx_L3_error)
       }
     } else {
       switch (PyTuple_GET_SIZE(__pyx_args)) {
         case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
         CYTHON_FALLTHROUGH;
         case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
         CYTHON_FALLTHROUGH;
@@ -8281,46 +8351,46 @@
         values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
         values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
         break;
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_shape = ((PyObject*)values[0]);
-    __pyx_v_itemsize = __Pyx_PyIndex_AsSsize_t(values[1]); if (unlikely((__pyx_v_itemsize == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 122, __pyx_L3_error)
+    __pyx_v_itemsize = __Pyx_PyIndex_AsSsize_t(values[1]); if (unlikely((__pyx_v_itemsize == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 123, __pyx_L3_error)
     __pyx_v_format = values[2];
     __pyx_v_mode = values[3];
     if (values[4]) {
-      __pyx_v_allocate_buffer = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allocate_buffer == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 123, __pyx_L3_error)
+      __pyx_v_allocate_buffer = __Pyx_PyObject_IsTrue(values[4]); if (unlikely((__pyx_v_allocate_buffer == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 124, __pyx_L3_error)
     } else {
 
-      /* "View.MemoryView":123
+      /* "View.MemoryView":124
  * 
  *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,
  *                   mode="c", bint allocate_buffer=True):             # <<<<<<<<<<<<<<
  * 
  *         cdef int idx
  */
       __pyx_v_allocate_buffer = ((int)1);
     }
   }
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 122, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 123, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("View.MemoryView.array.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return -1;
   __pyx_L4_argument_unpacking_done:;
-  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_shape), (&PyTuple_Type), 1, "shape", 1))) __PYX_ERR(2, 122, __pyx_L1_error)
+  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_shape), (&PyTuple_Type), 1, "shape", 1))) __PYX_ERR(2, 123, __pyx_L1_error)
   if (unlikely(((PyObject *)__pyx_v_format) == Py_None)) {
-    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "format"); __PYX_ERR(2, 122, __pyx_L1_error)
+    PyErr_Format(PyExc_TypeError, "Argument '%.200s' must not be None", "format"); __PYX_ERR(2, 123, __pyx_L1_error)
   }
   __pyx_r = __pyx_array___pyx_pf_15View_dot_MemoryView_5array___cinit__(((struct __pyx_array_obj *)__pyx_v_self), __pyx_v_shape, __pyx_v_itemsize, __pyx_v_format, __pyx_v_mode, __pyx_v_allocate_buffer);
 
-  /* "View.MemoryView":122
+  /* "View.MemoryView":123
  *         cdef bint dtype_is_object
  * 
  *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
  *                   mode="c", bint allocate_buffer=True):
  * 
  */
 
@@ -8354,579 +8424,579 @@
   Py_ssize_t __pyx_t_11;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__cinit__", 0);
   __Pyx_INCREF(__pyx_v_format);
 
-  /* "View.MemoryView":129
+  /* "View.MemoryView":130
  *         cdef PyObject **p
  * 
  *         self.ndim = <int> len(shape)             # <<<<<<<<<<<<<<
  *         self.itemsize = itemsize
  * 
  */
   if (unlikely(__pyx_v_shape == Py_None)) {
     PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
-    __PYX_ERR(2, 129, __pyx_L1_error)
+    __PYX_ERR(2, 130, __pyx_L1_error)
   }
-  __pyx_t_1 = PyTuple_GET_SIZE(__pyx_v_shape); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(2, 129, __pyx_L1_error)
+  __pyx_t_1 = PyTuple_GET_SIZE(__pyx_v_shape); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(2, 130, __pyx_L1_error)
   __pyx_v_self->ndim = ((int)__pyx_t_1);
 
-  /* "View.MemoryView":130
+  /* "View.MemoryView":131
  * 
  *         self.ndim = <int> len(shape)
  *         self.itemsize = itemsize             # <<<<<<<<<<<<<<
  * 
  *         if not self.ndim:
  */
   __pyx_v_self->itemsize = __pyx_v_itemsize;
 
-  /* "View.MemoryView":132
+  /* "View.MemoryView":133
  *         self.itemsize = itemsize
  * 
  *         if not self.ndim:             # <<<<<<<<<<<<<<
  *             raise ValueError("Empty shape tuple for cython.array")
  * 
  */
   __pyx_t_2 = ((!(__pyx_v_self->ndim != 0)) != 0);
   if (unlikely(__pyx_t_2)) {
 
-    /* "View.MemoryView":133
+    /* "View.MemoryView":134
  * 
  *         if not self.ndim:
  *             raise ValueError("Empty shape tuple for cython.array")             # <<<<<<<<<<<<<<
  * 
  *         if itemsize <= 0:
  */
-    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 133, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 134, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 133, __pyx_L1_error)
+    __PYX_ERR(2, 134, __pyx_L1_error)
 
-    /* "View.MemoryView":132
+    /* "View.MemoryView":133
  *         self.itemsize = itemsize
  * 
  *         if not self.ndim:             # <<<<<<<<<<<<<<
  *             raise ValueError("Empty shape tuple for cython.array")
  * 
  */
   }
 
-  /* "View.MemoryView":135
+  /* "View.MemoryView":136
  *             raise ValueError("Empty shape tuple for cython.array")
  * 
  *         if itemsize <= 0:             # <<<<<<<<<<<<<<
  *             raise ValueError("itemsize <= 0 for cython.array")
  * 
  */
   __pyx_t_2 = ((__pyx_v_itemsize <= 0) != 0);
   if (unlikely(__pyx_t_2)) {
 
-    /* "View.MemoryView":136
+    /* "View.MemoryView":137
  * 
  *         if itemsize <= 0:
  *             raise ValueError("itemsize <= 0 for cython.array")             # <<<<<<<<<<<<<<
  * 
  *         if not isinstance(format, bytes):
  */
-    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 136, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__8, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 137, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 136, __pyx_L1_error)
+    __PYX_ERR(2, 137, __pyx_L1_error)
 
-    /* "View.MemoryView":135
+    /* "View.MemoryView":136
  *             raise ValueError("Empty shape tuple for cython.array")
  * 
  *         if itemsize <= 0:             # <<<<<<<<<<<<<<
  *             raise ValueError("itemsize <= 0 for cython.array")
  * 
  */
   }
 
-  /* "View.MemoryView":138
+  /* "View.MemoryView":139
  *             raise ValueError("itemsize <= 0 for cython.array")
  * 
  *         if not isinstance(format, bytes):             # <<<<<<<<<<<<<<
  *             format = format.encode('ASCII')
  *         self._format = format  # keep a reference to the byte string
  */
   __pyx_t_2 = PyBytes_Check(__pyx_v_format); 
   __pyx_t_4 = ((!(__pyx_t_2 != 0)) != 0);
   if (__pyx_t_4) {
 
-    /* "View.MemoryView":139
+    /* "View.MemoryView":140
  * 
  *         if not isinstance(format, bytes):
  *             format = format.encode('ASCII')             # <<<<<<<<<<<<<<
  *         self._format = format  # keep a reference to the byte string
  *         self.format = self._format
  */
-    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_format, __pyx_n_s_encode); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 139, __pyx_L1_error)
+    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_format, __pyx_n_s_encode); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 140, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     __pyx_t_6 = NULL;
     if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
       __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
       if (likely(__pyx_t_6)) {
         PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
         __Pyx_INCREF(__pyx_t_6);
         __Pyx_INCREF(function);
         __Pyx_DECREF_SET(__pyx_t_5, function);
       }
     }
     __pyx_t_3 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_5, __pyx_t_6, __pyx_n_s_ASCII) : __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_n_s_ASCII);
     __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
-    if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 139, __pyx_L1_error)
+    if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 140, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
     __Pyx_DECREF_SET(__pyx_v_format, __pyx_t_3);
     __pyx_t_3 = 0;
 
-    /* "View.MemoryView":138
+    /* "View.MemoryView":139
  *             raise ValueError("itemsize <= 0 for cython.array")
  * 
  *         if not isinstance(format, bytes):             # <<<<<<<<<<<<<<
  *             format = format.encode('ASCII')
  *         self._format = format  # keep a reference to the byte string
  */
   }
 
-  /* "View.MemoryView":140
+  /* "View.MemoryView":141
  *         if not isinstance(format, bytes):
  *             format = format.encode('ASCII')
  *         self._format = format  # keep a reference to the byte string             # <<<<<<<<<<<<<<
  *         self.format = self._format
  * 
  */
-  if (!(likely(PyBytes_CheckExact(__pyx_v_format))||((__pyx_v_format) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_v_format)->tp_name), 0))) __PYX_ERR(2, 140, __pyx_L1_error)
+  if (!(likely(PyBytes_CheckExact(__pyx_v_format))||((__pyx_v_format) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_v_format)->tp_name), 0))) __PYX_ERR(2, 141, __pyx_L1_error)
   __pyx_t_3 = __pyx_v_format;
   __Pyx_INCREF(__pyx_t_3);
   __Pyx_GIVEREF(__pyx_t_3);
   __Pyx_GOTREF(__pyx_v_self->_format);
   __Pyx_DECREF(__pyx_v_self->_format);
   __pyx_v_self->_format = ((PyObject*)__pyx_t_3);
   __pyx_t_3 = 0;
 
-  /* "View.MemoryView":141
+  /* "View.MemoryView":142
  *             format = format.encode('ASCII')
  *         self._format = format  # keep a reference to the byte string
  *         self.format = self._format             # <<<<<<<<<<<<<<
  * 
  * 
  */
   if (unlikely(__pyx_v_self->_format == Py_None)) {
     PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
-    __PYX_ERR(2, 141, __pyx_L1_error)
+    __PYX_ERR(2, 142, __pyx_L1_error)
   }
-  __pyx_t_7 = __Pyx_PyBytes_AsWritableString(__pyx_v_self->_format); if (unlikely((!__pyx_t_7) && PyErr_Occurred())) __PYX_ERR(2, 141, __pyx_L1_error)
+  __pyx_t_7 = __Pyx_PyBytes_AsWritableString(__pyx_v_self->_format); if (unlikely((!__pyx_t_7) && PyErr_Occurred())) __PYX_ERR(2, 142, __pyx_L1_error)
   __pyx_v_self->format = __pyx_t_7;
 
-  /* "View.MemoryView":144
+  /* "View.MemoryView":145
  * 
  * 
  *         self._shape = <Py_ssize_t *> PyObject_Malloc(sizeof(Py_ssize_t)*self.ndim*2)             # <<<<<<<<<<<<<<
  *         self._strides = self._shape + self.ndim
  * 
  */
   __pyx_v_self->_shape = ((Py_ssize_t *)PyObject_Malloc((((sizeof(Py_ssize_t)) * __pyx_v_self->ndim) * 2)));
 
-  /* "View.MemoryView":145
+  /* "View.MemoryView":146
  * 
  *         self._shape = <Py_ssize_t *> PyObject_Malloc(sizeof(Py_ssize_t)*self.ndim*2)
  *         self._strides = self._shape + self.ndim             # <<<<<<<<<<<<<<
  * 
  *         if not self._shape:
  */
   __pyx_v_self->_strides = (__pyx_v_self->_shape + __pyx_v_self->ndim);
 
-  /* "View.MemoryView":147
+  /* "View.MemoryView":148
  *         self._strides = self._shape + self.ndim
  * 
  *         if not self._shape:             # <<<<<<<<<<<<<<
  *             raise MemoryError("unable to allocate shape and strides.")
  * 
  */
   __pyx_t_4 = ((!(__pyx_v_self->_shape != 0)) != 0);
   if (unlikely(__pyx_t_4)) {
 
-    /* "View.MemoryView":148
+    /* "View.MemoryView":149
  * 
  *         if not self._shape:
  *             raise MemoryError("unable to allocate shape and strides.")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 148, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 149, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 148, __pyx_L1_error)
+    __PYX_ERR(2, 149, __pyx_L1_error)
 
-    /* "View.MemoryView":147
+    /* "View.MemoryView":148
  *         self._strides = self._shape + self.ndim
  * 
  *         if not self._shape:             # <<<<<<<<<<<<<<
  *             raise MemoryError("unable to allocate shape and strides.")
  * 
  */
   }
 
-  /* "View.MemoryView":151
+  /* "View.MemoryView":152
  * 
  * 
  *         for idx, dim in enumerate(shape):             # <<<<<<<<<<<<<<
  *             if dim <= 0:
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
  */
   __pyx_t_8 = 0;
   __pyx_t_3 = __pyx_v_shape; __Pyx_INCREF(__pyx_t_3); __pyx_t_1 = 0;
   for (;;) {
     if (__pyx_t_1 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
     #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-    __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_1); __Pyx_INCREF(__pyx_t_5); __pyx_t_1++; if (unlikely(0 < 0)) __PYX_ERR(2, 151, __pyx_L1_error)
+    __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_1); __Pyx_INCREF(__pyx_t_5); __pyx_t_1++; if (unlikely(0 < 0)) __PYX_ERR(2, 152, __pyx_L1_error)
     #else
-    __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 151, __pyx_L1_error)
+    __pyx_t_5 = PySequence_ITEM(__pyx_t_3, __pyx_t_1); __pyx_t_1++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 152, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     #endif
-    __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 151, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 152, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
     __pyx_v_dim = __pyx_t_9;
     __pyx_v_idx = __pyx_t_8;
     __pyx_t_8 = (__pyx_t_8 + 1);
 
-    /* "View.MemoryView":152
+    /* "View.MemoryView":153
  * 
  *         for idx, dim in enumerate(shape):
  *             if dim <= 0:             # <<<<<<<<<<<<<<
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
  *             self._shape[idx] = dim
  */
     __pyx_t_4 = ((__pyx_v_dim <= 0) != 0);
     if (unlikely(__pyx_t_4)) {
 
-      /* "View.MemoryView":153
+      /* "View.MemoryView":154
  *         for idx, dim in enumerate(shape):
  *             if dim <= 0:
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))             # <<<<<<<<<<<<<<
  *             self._shape[idx] = dim
  * 
  */
-      __pyx_t_5 = __Pyx_PyInt_From_int(__pyx_v_idx); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 153, __pyx_L1_error)
+      __pyx_t_5 = __Pyx_PyInt_From_int(__pyx_v_idx); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 154, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_5);
-      __pyx_t_6 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 153, __pyx_L1_error)
+      __pyx_t_6 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 154, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_6);
-      __pyx_t_10 = PyTuple_New(2); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 153, __pyx_L1_error)
+      __pyx_t_10 = PyTuple_New(2); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 154, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_10);
       __Pyx_GIVEREF(__pyx_t_5);
       PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_5);
       __Pyx_GIVEREF(__pyx_t_6);
       PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_t_6);
       __pyx_t_5 = 0;
       __pyx_t_6 = 0;
-      __pyx_t_6 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_shape_in_axis_d_d, __pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 153, __pyx_L1_error)
+      __pyx_t_6 = __Pyx_PyString_Format(__pyx_kp_s_Invalid_shape_in_axis_d_d, __pyx_t_10); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 154, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
-      __pyx_t_10 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_6); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 153, __pyx_L1_error)
+      __pyx_t_10 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_6); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 154, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_10);
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       __Pyx_Raise(__pyx_t_10, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
-      __PYX_ERR(2, 153, __pyx_L1_error)
+      __PYX_ERR(2, 154, __pyx_L1_error)
 
-      /* "View.MemoryView":152
+      /* "View.MemoryView":153
  * 
  *         for idx, dim in enumerate(shape):
  *             if dim <= 0:             # <<<<<<<<<<<<<<
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
  *             self._shape[idx] = dim
  */
     }
 
-    /* "View.MemoryView":154
+    /* "View.MemoryView":155
  *             if dim <= 0:
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
  *             self._shape[idx] = dim             # <<<<<<<<<<<<<<
  * 
  *         cdef char order
  */
     (__pyx_v_self->_shape[__pyx_v_idx]) = __pyx_v_dim;
 
-    /* "View.MemoryView":151
+    /* "View.MemoryView":152
  * 
  * 
  *         for idx, dim in enumerate(shape):             # <<<<<<<<<<<<<<
  *             if dim <= 0:
  *                 raise ValueError("Invalid shape in axis %d: %d." % (idx, dim))
  */
   }
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-  /* "View.MemoryView":157
+  /* "View.MemoryView":158
  * 
  *         cdef char order
  *         if mode == 'fortran':             # <<<<<<<<<<<<<<
  *             order = b'F'
  *             self.mode = u'fortran'
  */
-  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_fortran, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 157, __pyx_L1_error)
+  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_fortran, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 158, __pyx_L1_error)
   if (__pyx_t_4) {
 
-    /* "View.MemoryView":158
+    /* "View.MemoryView":159
  *         cdef char order
  *         if mode == 'fortran':
  *             order = b'F'             # <<<<<<<<<<<<<<
  *             self.mode = u'fortran'
  *         elif mode == 'c':
  */
     __pyx_v_order = 'F';
 
-    /* "View.MemoryView":159
+    /* "View.MemoryView":160
  *         if mode == 'fortran':
  *             order = b'F'
  *             self.mode = u'fortran'             # <<<<<<<<<<<<<<
  *         elif mode == 'c':
  *             order = b'C'
  */
     __Pyx_INCREF(__pyx_n_u_fortran);
     __Pyx_GIVEREF(__pyx_n_u_fortran);
     __Pyx_GOTREF(__pyx_v_self->mode);
     __Pyx_DECREF(__pyx_v_self->mode);
     __pyx_v_self->mode = __pyx_n_u_fortran;
 
-    /* "View.MemoryView":157
+    /* "View.MemoryView":158
  * 
  *         cdef char order
  *         if mode == 'fortran':             # <<<<<<<<<<<<<<
  *             order = b'F'
  *             self.mode = u'fortran'
  */
     goto __pyx_L10;
   }
 
-  /* "View.MemoryView":160
+  /* "View.MemoryView":161
  *             order = b'F'
  *             self.mode = u'fortran'
  *         elif mode == 'c':             # <<<<<<<<<<<<<<
  *             order = b'C'
  *             self.mode = u'c'
  */
-  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_c, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 160, __pyx_L1_error)
+  __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_mode, __pyx_n_s_c, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(2, 161, __pyx_L1_error)
   if (likely(__pyx_t_4)) {
 
-    /* "View.MemoryView":161
+    /* "View.MemoryView":162
  *             self.mode = u'fortran'
  *         elif mode == 'c':
  *             order = b'C'             # <<<<<<<<<<<<<<
  *             self.mode = u'c'
  *         else:
  */
     __pyx_v_order = 'C';
 
-    /* "View.MemoryView":162
+    /* "View.MemoryView":163
  *         elif mode == 'c':
  *             order = b'C'
  *             self.mode = u'c'             # <<<<<<<<<<<<<<
  *         else:
  *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)
  */
     __Pyx_INCREF(__pyx_n_u_c);
     __Pyx_GIVEREF(__pyx_n_u_c);
     __Pyx_GOTREF(__pyx_v_self->mode);
     __Pyx_DECREF(__pyx_v_self->mode);
     __pyx_v_self->mode = __pyx_n_u_c;
 
-    /* "View.MemoryView":160
+    /* "View.MemoryView":161
  *             order = b'F'
  *             self.mode = u'fortran'
  *         elif mode == 'c':             # <<<<<<<<<<<<<<
  *             order = b'C'
  *             self.mode = u'c'
  */
     goto __pyx_L10;
   }
 
-  /* "View.MemoryView":164
+  /* "View.MemoryView":165
  *             self.mode = u'c'
  *         else:
  *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)             # <<<<<<<<<<<<<<
  * 
  *         self.len = fill_contig_strides_array(self._shape, self._strides,
  */
   /*else*/ {
-    __pyx_t_3 = __Pyx_PyString_FormatSafe(__pyx_kp_s_Invalid_mode_expected_c_or_fortr, __pyx_v_mode); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 164, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyString_FormatSafe(__pyx_kp_s_Invalid_mode_expected_c_or_fortr, __pyx_v_mode); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 165, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_10 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 164, __pyx_L1_error)
+    __pyx_t_10 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 165, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_10);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
     __Pyx_Raise(__pyx_t_10, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
-    __PYX_ERR(2, 164, __pyx_L1_error)
+    __PYX_ERR(2, 165, __pyx_L1_error)
   }
   __pyx_L10:;
 
-  /* "View.MemoryView":166
+  /* "View.MemoryView":167
  *             raise ValueError("Invalid mode, expected 'c' or 'fortran', got %s" % mode)
  * 
  *         self.len = fill_contig_strides_array(self._shape, self._strides,             # <<<<<<<<<<<<<<
  *                                              itemsize, self.ndim, order)
  * 
  */
   __pyx_v_self->len = __pyx_fill_contig_strides_array(__pyx_v_self->_shape, __pyx_v_self->_strides, __pyx_v_itemsize, __pyx_v_self->ndim, __pyx_v_order);
 
-  /* "View.MemoryView":169
+  /* "View.MemoryView":170
  *                                              itemsize, self.ndim, order)
  * 
  *         self.free_data = allocate_buffer             # <<<<<<<<<<<<<<
  *         self.dtype_is_object = format == b'O'
  *         if allocate_buffer:
  */
   __pyx_v_self->free_data = __pyx_v_allocate_buffer;
 
-  /* "View.MemoryView":170
+  /* "View.MemoryView":171
  * 
  *         self.free_data = allocate_buffer
  *         self.dtype_is_object = format == b'O'             # <<<<<<<<<<<<<<
  *         if allocate_buffer:
  * 
  */
-  __pyx_t_10 = PyObject_RichCompare(__pyx_v_format, __pyx_n_b_O, Py_EQ); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 170, __pyx_L1_error)
-  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 170, __pyx_L1_error)
+  __pyx_t_10 = PyObject_RichCompare(__pyx_v_format, __pyx_n_b_O, Py_EQ); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 171, __pyx_L1_error)
+  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 171, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
   __pyx_v_self->dtype_is_object = __pyx_t_4;
 
-  /* "View.MemoryView":171
+  /* "View.MemoryView":172
  *         self.free_data = allocate_buffer
  *         self.dtype_is_object = format == b'O'
  *         if allocate_buffer:             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_4 = (__pyx_v_allocate_buffer != 0);
   if (__pyx_t_4) {
 
-    /* "View.MemoryView":174
+    /* "View.MemoryView":175
  * 
  * 
  *             self.data = <char *>malloc(self.len)             # <<<<<<<<<<<<<<
  *             if not self.data:
  *                 raise MemoryError("unable to allocate array data.")
  */
     __pyx_v_self->data = ((char *)malloc(__pyx_v_self->len));
 
-    /* "View.MemoryView":175
+    /* "View.MemoryView":176
  * 
  *             self.data = <char *>malloc(self.len)
  *             if not self.data:             # <<<<<<<<<<<<<<
  *                 raise MemoryError("unable to allocate array data.")
  * 
  */
     __pyx_t_4 = ((!(__pyx_v_self->data != 0)) != 0);
     if (unlikely(__pyx_t_4)) {
 
-      /* "View.MemoryView":176
+      /* "View.MemoryView":177
  *             self.data = <char *>malloc(self.len)
  *             if not self.data:
  *                 raise MemoryError("unable to allocate array data.")             # <<<<<<<<<<<<<<
  * 
  *             if self.dtype_is_object:
  */
-      __pyx_t_10 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 176, __pyx_L1_error)
+      __pyx_t_10 = __Pyx_PyObject_Call(__pyx_builtin_MemoryError, __pyx_tuple__10, NULL); if (unlikely(!__pyx_t_10)) __PYX_ERR(2, 177, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_10);
       __Pyx_Raise(__pyx_t_10, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
-      __PYX_ERR(2, 176, __pyx_L1_error)
+      __PYX_ERR(2, 177, __pyx_L1_error)
 
-      /* "View.MemoryView":175
+      /* "View.MemoryView":176
  * 
  *             self.data = <char *>malloc(self.len)
  *             if not self.data:             # <<<<<<<<<<<<<<
  *                 raise MemoryError("unable to allocate array data.")
  * 
  */
     }
 
-    /* "View.MemoryView":178
+    /* "View.MemoryView":179
  *                 raise MemoryError("unable to allocate array data.")
  * 
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 p = <PyObject **> self.data
  *                 for i in range(self.len / itemsize):
  */
     __pyx_t_4 = (__pyx_v_self->dtype_is_object != 0);
     if (__pyx_t_4) {
 
-      /* "View.MemoryView":179
+      /* "View.MemoryView":180
  * 
  *             if self.dtype_is_object:
  *                 p = <PyObject **> self.data             # <<<<<<<<<<<<<<
  *                 for i in range(self.len / itemsize):
  *                     p[i] = Py_None
  */
       __pyx_v_p = ((PyObject **)__pyx_v_self->data);
 
-      /* "View.MemoryView":180
+      /* "View.MemoryView":181
  *             if self.dtype_is_object:
  *                 p = <PyObject **> self.data
  *                 for i in range(self.len / itemsize):             # <<<<<<<<<<<<<<
  *                     p[i] = Py_None
  *                     Py_INCREF(Py_None)
  */
       if (unlikely(__pyx_v_itemsize == 0)) {
         PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
-        __PYX_ERR(2, 180, __pyx_L1_error)
+        __PYX_ERR(2, 181, __pyx_L1_error)
       }
       else if (sizeof(Py_ssize_t) == sizeof(long) && (!(((Py_ssize_t)-1) > 0)) && unlikely(__pyx_v_itemsize == (Py_ssize_t)-1)  && unlikely(UNARY_NEG_WOULD_OVERFLOW(__pyx_v_self->len))) {
         PyErr_SetString(PyExc_OverflowError, "value too large to perform division");
-        __PYX_ERR(2, 180, __pyx_L1_error)
+        __PYX_ERR(2, 181, __pyx_L1_error)
       }
       __pyx_t_1 = __Pyx_div_Py_ssize_t(__pyx_v_self->len, __pyx_v_itemsize);
       __pyx_t_9 = __pyx_t_1;
       for (__pyx_t_11 = 0; __pyx_t_11 < __pyx_t_9; __pyx_t_11+=1) {
         __pyx_v_i = __pyx_t_11;
 
-        /* "View.MemoryView":181
+        /* "View.MemoryView":182
  *                 p = <PyObject **> self.data
  *                 for i in range(self.len / itemsize):
  *                     p[i] = Py_None             # <<<<<<<<<<<<<<
  *                     Py_INCREF(Py_None)
  * 
  */
         (__pyx_v_p[__pyx_v_i]) = Py_None;
 
-        /* "View.MemoryView":182
+        /* "View.MemoryView":183
  *                 for i in range(self.len / itemsize):
  *                     p[i] = Py_None
  *                     Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
  * 
  *     @cname('getbuffer')
  */
         Py_INCREF(Py_None);
       }
 
-      /* "View.MemoryView":178
+      /* "View.MemoryView":179
  *                 raise MemoryError("unable to allocate array data.")
  * 
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 p = <PyObject **> self.data
  *                 for i in range(self.len / itemsize):
  */
     }
 
-    /* "View.MemoryView":171
+    /* "View.MemoryView":172
  *         self.free_data = allocate_buffer
  *         self.dtype_is_object = format == b'O'
  *         if allocate_buffer:             # <<<<<<<<<<<<<<
  * 
  * 
  */
   }
 
-  /* "View.MemoryView":122
+  /* "View.MemoryView":123
  *         cdef bint dtype_is_object
  * 
  *     def __cinit__(array self, tuple shape, Py_ssize_t itemsize, format not None,             # <<<<<<<<<<<<<<
  *                   mode="c", bint allocate_buffer=True):
  * 
  */
 
@@ -8942,15 +9012,15 @@
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_XDECREF(__pyx_v_format);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":185
+/* "View.MemoryView":186
  * 
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
  *         cdef int bufmode = -1
  *         if self.mode == u"c":
  */
 
@@ -8985,249 +9055,249 @@
     PyErr_SetString(PyExc_BufferError, "PyObject_GetBuffer: view==NULL argument is obsolete");
     return -1;
   }
   __Pyx_RefNannySetupContext("__getbuffer__", 0);
   __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
   __Pyx_GIVEREF(__pyx_v_info->obj);
 
-  /* "View.MemoryView":186
+  /* "View.MemoryView":187
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         cdef int bufmode = -1             # <<<<<<<<<<<<<<
  *         if self.mode == u"c":
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  */
   __pyx_v_bufmode = -1;
 
-  /* "View.MemoryView":187
+  /* "View.MemoryView":188
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         cdef int bufmode = -1
  *         if self.mode == u"c":             # <<<<<<<<<<<<<<
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         elif self.mode == u"fortran":
  */
-  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_c, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 187, __pyx_L1_error)
+  __pyx_t_1 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_c, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 188, __pyx_L1_error)
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":188
+    /* "View.MemoryView":189
  *         cdef int bufmode = -1
  *         if self.mode == u"c":
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS             # <<<<<<<<<<<<<<
  *         elif self.mode == u"fortran":
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  */
     __pyx_v_bufmode = (PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS);
 
-    /* "View.MemoryView":187
+    /* "View.MemoryView":188
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         cdef int bufmode = -1
  *         if self.mode == u"c":             # <<<<<<<<<<<<<<
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         elif self.mode == u"fortran":
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":189
+  /* "View.MemoryView":190
  *         if self.mode == u"c":
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         elif self.mode == u"fortran":             # <<<<<<<<<<<<<<
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):
  */
-  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_fortran, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 189, __pyx_L1_error)
+  __pyx_t_2 = (__Pyx_PyUnicode_Equals(__pyx_v_self->mode, __pyx_n_u_fortran, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 190, __pyx_L1_error)
   __pyx_t_1 = (__pyx_t_2 != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":190
+    /* "View.MemoryView":191
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         elif self.mode == u"fortran":
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS             # <<<<<<<<<<<<<<
  *         if not (flags & bufmode):
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")
  */
     __pyx_v_bufmode = (PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS);
 
-    /* "View.MemoryView":189
+    /* "View.MemoryView":190
  *         if self.mode == u"c":
  *             bufmode = PyBUF_C_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         elif self.mode == u"fortran":             # <<<<<<<<<<<<<<
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):
  */
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":191
+  /* "View.MemoryView":192
  *         elif self.mode == u"fortran":
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):             # <<<<<<<<<<<<<<
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")
  *         info.buf = self.data
  */
   __pyx_t_1 = ((!((__pyx_v_flags & __pyx_v_bufmode) != 0)) != 0);
   if (unlikely(__pyx_t_1)) {
 
-    /* "View.MemoryView":192
+    /* "View.MemoryView":193
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")             # <<<<<<<<<<<<<<
  *         info.buf = self.data
  *         info.len = self.len
  */
-    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__11, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 192, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__11, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 193, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 192, __pyx_L1_error)
+    __PYX_ERR(2, 193, __pyx_L1_error)
 
-    /* "View.MemoryView":191
+    /* "View.MemoryView":192
  *         elif self.mode == u"fortran":
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):             # <<<<<<<<<<<<<<
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")
  *         info.buf = self.data
  */
   }
 
-  /* "View.MemoryView":193
+  /* "View.MemoryView":194
  *         if not (flags & bufmode):
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")
  *         info.buf = self.data             # <<<<<<<<<<<<<<
  *         info.len = self.len
  *         info.ndim = self.ndim
  */
   __pyx_t_4 = __pyx_v_self->data;
   __pyx_v_info->buf = __pyx_t_4;
 
-  /* "View.MemoryView":194
+  /* "View.MemoryView":195
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")
  *         info.buf = self.data
  *         info.len = self.len             # <<<<<<<<<<<<<<
  *         info.ndim = self.ndim
  *         info.shape = self._shape
  */
   __pyx_t_5 = __pyx_v_self->len;
   __pyx_v_info->len = __pyx_t_5;
 
-  /* "View.MemoryView":195
+  /* "View.MemoryView":196
  *         info.buf = self.data
  *         info.len = self.len
  *         info.ndim = self.ndim             # <<<<<<<<<<<<<<
  *         info.shape = self._shape
  *         info.strides = self._strides
  */
   __pyx_t_6 = __pyx_v_self->ndim;
   __pyx_v_info->ndim = __pyx_t_6;
 
-  /* "View.MemoryView":196
+  /* "View.MemoryView":197
  *         info.len = self.len
  *         info.ndim = self.ndim
  *         info.shape = self._shape             # <<<<<<<<<<<<<<
  *         info.strides = self._strides
  *         info.suboffsets = NULL
  */
   __pyx_t_7 = __pyx_v_self->_shape;
   __pyx_v_info->shape = __pyx_t_7;
 
-  /* "View.MemoryView":197
+  /* "View.MemoryView":198
  *         info.ndim = self.ndim
  *         info.shape = self._shape
  *         info.strides = self._strides             # <<<<<<<<<<<<<<
  *         info.suboffsets = NULL
  *         info.itemsize = self.itemsize
  */
   __pyx_t_7 = __pyx_v_self->_strides;
   __pyx_v_info->strides = __pyx_t_7;
 
-  /* "View.MemoryView":198
+  /* "View.MemoryView":199
  *         info.shape = self._shape
  *         info.strides = self._strides
  *         info.suboffsets = NULL             # <<<<<<<<<<<<<<
  *         info.itemsize = self.itemsize
  *         info.readonly = 0
  */
   __pyx_v_info->suboffsets = NULL;
 
-  /* "View.MemoryView":199
+  /* "View.MemoryView":200
  *         info.strides = self._strides
  *         info.suboffsets = NULL
  *         info.itemsize = self.itemsize             # <<<<<<<<<<<<<<
  *         info.readonly = 0
  * 
  */
   __pyx_t_5 = __pyx_v_self->itemsize;
   __pyx_v_info->itemsize = __pyx_t_5;
 
-  /* "View.MemoryView":200
+  /* "View.MemoryView":201
  *         info.suboffsets = NULL
  *         info.itemsize = self.itemsize
  *         info.readonly = 0             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_FORMAT:
  */
   __pyx_v_info->readonly = 0;
 
-  /* "View.MemoryView":202
+  /* "View.MemoryView":203
  *         info.readonly = 0
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             info.format = self.format
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":203
+    /* "View.MemoryView":204
  * 
  *         if flags & PyBUF_FORMAT:
  *             info.format = self.format             # <<<<<<<<<<<<<<
  *         else:
  *             info.format = NULL
  */
     __pyx_t_4 = __pyx_v_self->format;
     __pyx_v_info->format = __pyx_t_4;
 
-    /* "View.MemoryView":202
+    /* "View.MemoryView":203
  *         info.readonly = 0
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             info.format = self.format
  *         else:
  */
     goto __pyx_L5;
   }
 
-  /* "View.MemoryView":205
+  /* "View.MemoryView":206
  *             info.format = self.format
  *         else:
  *             info.format = NULL             # <<<<<<<<<<<<<<
  * 
  *         info.obj = self
  */
   /*else*/ {
     __pyx_v_info->format = NULL;
   }
   __pyx_L5:;
 
-  /* "View.MemoryView":207
+  /* "View.MemoryView":208
  *             info.format = NULL
  * 
  *         info.obj = self             # <<<<<<<<<<<<<<
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
  */
   __Pyx_INCREF(((PyObject *)__pyx_v_self));
   __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
   __Pyx_GOTREF(__pyx_v_info->obj);
   __Pyx_DECREF(__pyx_v_info->obj);
   __pyx_v_info->obj = ((PyObject *)__pyx_v_self);
 
-  /* "View.MemoryView":185
+  /* "View.MemoryView":186
  * 
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
  *         cdef int bufmode = -1
  *         if self.mode == u"c":
  */
 
@@ -9249,15 +9319,15 @@
     __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = 0;
   }
   __pyx_L2:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":211
+/* "View.MemoryView":212
  *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
  * 
  *     def __dealloc__(array self):             # <<<<<<<<<<<<<<
  *         if self.callback_free_data != NULL:
  *             self.callback_free_data(self.data)
  */
 
@@ -9273,122 +9343,122 @@
 }
 
 static void __pyx_array___pyx_pf_15View_dot_MemoryView_5array_4__dealloc__(struct __pyx_array_obj *__pyx_v_self) {
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("__dealloc__", 0);
 
-  /* "View.MemoryView":212
+  /* "View.MemoryView":213
  * 
  *     def __dealloc__(array self):
  *         if self.callback_free_data != NULL:             # <<<<<<<<<<<<<<
  *             self.callback_free_data(self.data)
  *         elif self.free_data:
  */
   __pyx_t_1 = ((__pyx_v_self->callback_free_data != NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":213
+    /* "View.MemoryView":214
  *     def __dealloc__(array self):
  *         if self.callback_free_data != NULL:
  *             self.callback_free_data(self.data)             # <<<<<<<<<<<<<<
  *         elif self.free_data:
  *             if self.dtype_is_object:
  */
     __pyx_v_self->callback_free_data(__pyx_v_self->data);
 
-    /* "View.MemoryView":212
+    /* "View.MemoryView":213
  * 
  *     def __dealloc__(array self):
  *         if self.callback_free_data != NULL:             # <<<<<<<<<<<<<<
  *             self.callback_free_data(self.data)
  *         elif self.free_data:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":214
+  /* "View.MemoryView":215
  *         if self.callback_free_data != NULL:
  *             self.callback_free_data(self.data)
  *         elif self.free_data:             # <<<<<<<<<<<<<<
  *             if self.dtype_is_object:
  *                 refcount_objects_in_slice(self.data, self._shape,
  */
   __pyx_t_1 = (__pyx_v_self->free_data != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":215
+    /* "View.MemoryView":216
  *             self.callback_free_data(self.data)
  *         elif self.free_data:
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 refcount_objects_in_slice(self.data, self._shape,
  *                                           self._strides, self.ndim, False)
  */
     __pyx_t_1 = (__pyx_v_self->dtype_is_object != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":216
+      /* "View.MemoryView":217
  *         elif self.free_data:
  *             if self.dtype_is_object:
  *                 refcount_objects_in_slice(self.data, self._shape,             # <<<<<<<<<<<<<<
  *                                           self._strides, self.ndim, False)
  *             free(self.data)
  */
       __pyx_memoryview_refcount_objects_in_slice(__pyx_v_self->data, __pyx_v_self->_shape, __pyx_v_self->_strides, __pyx_v_self->ndim, 0);
 
-      /* "View.MemoryView":215
+      /* "View.MemoryView":216
  *             self.callback_free_data(self.data)
  *         elif self.free_data:
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 refcount_objects_in_slice(self.data, self._shape,
  *                                           self._strides, self.ndim, False)
  */
     }
 
-    /* "View.MemoryView":218
+    /* "View.MemoryView":219
  *                 refcount_objects_in_slice(self.data, self._shape,
  *                                           self._strides, self.ndim, False)
  *             free(self.data)             # <<<<<<<<<<<<<<
  *         PyObject_Free(self._shape)
  * 
  */
     free(__pyx_v_self->data);
 
-    /* "View.MemoryView":214
+    /* "View.MemoryView":215
  *         if self.callback_free_data != NULL:
  *             self.callback_free_data(self.data)
  *         elif self.free_data:             # <<<<<<<<<<<<<<
  *             if self.dtype_is_object:
  *                 refcount_objects_in_slice(self.data, self._shape,
  */
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":219
+  /* "View.MemoryView":220
  *                                           self._strides, self.ndim, False)
  *             free(self.data)
  *         PyObject_Free(self._shape)             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   PyObject_Free(__pyx_v_self->_shape);
 
-  /* "View.MemoryView":211
+  /* "View.MemoryView":212
  *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")
  * 
  *     def __dealloc__(array self):             # <<<<<<<<<<<<<<
  *         if self.callback_free_data != NULL:
  *             self.callback_free_data(self.data)
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "View.MemoryView":222
+/* "View.MemoryView":223
  * 
  *     @property
  *     def memview(self):             # <<<<<<<<<<<<<<
  *         return self.get_memview()
  * 
  */
 
@@ -9410,29 +9480,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":223
+  /* "View.MemoryView":224
  *     @property
  *     def memview(self):
  *         return self.get_memview()             # <<<<<<<<<<<<<<
  * 
  *     @cname('get_memview')
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = ((struct __pyx_vtabstruct_array *)__pyx_v_self->__pyx_vtab)->get_memview(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 223, __pyx_L1_error)
+  __pyx_t_1 = ((struct __pyx_vtabstruct_array *)__pyx_v_self->__pyx_vtab)->get_memview(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 224, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":222
+  /* "View.MemoryView":223
  * 
  *     @property
  *     def memview(self):             # <<<<<<<<<<<<<<
  *         return self.get_memview()
  * 
  */
 
@@ -9443,15 +9513,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":226
+/* "View.MemoryView":227
  * 
  *     @cname('get_memview')
  *     cdef get_memview(self):             # <<<<<<<<<<<<<<
  *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
  *         return  memoryview(self, flags, self.dtype_is_object)
  */
 
@@ -9463,54 +9533,54 @@
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("get_memview", 0);
 
-  /* "View.MemoryView":227
+  /* "View.MemoryView":228
  *     @cname('get_memview')
  *     cdef get_memview(self):
  *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE             # <<<<<<<<<<<<<<
  *         return  memoryview(self, flags, self.dtype_is_object)
  * 
  */
   __pyx_v_flags = ((PyBUF_ANY_CONTIGUOUS | PyBUF_FORMAT) | PyBUF_WRITABLE);
 
-  /* "View.MemoryView":228
+  /* "View.MemoryView":229
  *     cdef get_memview(self):
  *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
  *         return  memoryview(self, flags, self.dtype_is_object)             # <<<<<<<<<<<<<<
  * 
  *     def __len__(self):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 228, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 229, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 228, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 229, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 228, __pyx_L1_error)
+  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 229, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_INCREF(((PyObject *)__pyx_v_self));
   __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
   PyTuple_SET_ITEM(__pyx_t_3, 0, ((PyObject *)__pyx_v_self));
   __Pyx_GIVEREF(__pyx_t_1);
   PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
   __Pyx_GIVEREF(__pyx_t_2);
   PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
   __pyx_t_1 = 0;
   __pyx_t_2 = 0;
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 228, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 229, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":226
+  /* "View.MemoryView":227
  * 
  *     @cname('get_memview')
  *     cdef get_memview(self):             # <<<<<<<<<<<<<<
  *         flags =  PyBUF_ANY_CONTIGUOUS|PyBUF_FORMAT|PyBUF_WRITABLE
  *         return  memoryview(self, flags, self.dtype_is_object)
  */
 
@@ -9523,15 +9593,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":230
+/* "View.MemoryView":231
  *         return  memoryview(self, flags, self.dtype_is_object)
  * 
  *     def __len__(self):             # <<<<<<<<<<<<<<
  *         return self._shape[0]
  * 
  */
 
@@ -9549,39 +9619,39 @@
 }
 
 static Py_ssize_t __pyx_array___pyx_pf_15View_dot_MemoryView_5array_6__len__(struct __pyx_array_obj *__pyx_v_self) {
   Py_ssize_t __pyx_r;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__len__", 0);
 
-  /* "View.MemoryView":231
+  /* "View.MemoryView":232
  * 
  *     def __len__(self):
  *         return self._shape[0]             # <<<<<<<<<<<<<<
  * 
  *     def __getattr__(self, attr):
  */
   __pyx_r = (__pyx_v_self->_shape[0]);
   goto __pyx_L0;
 
-  /* "View.MemoryView":230
+  /* "View.MemoryView":231
  *         return  memoryview(self, flags, self.dtype_is_object)
  * 
  *     def __len__(self):             # <<<<<<<<<<<<<<
  *         return self._shape[0]
  * 
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":233
+/* "View.MemoryView":234
  *         return self._shape[0]
  * 
  *     def __getattr__(self, attr):             # <<<<<<<<<<<<<<
  *         return getattr(self.memview, attr)
  * 
  */
 
@@ -9604,32 +9674,32 @@
   PyObject *__pyx_t_1 = NULL;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__getattr__", 0);
 
-  /* "View.MemoryView":234
+  /* "View.MemoryView":235
  * 
  *     def __getattr__(self, attr):
  *         return getattr(self.memview, attr)             # <<<<<<<<<<<<<<
  * 
  *     def __getitem__(self, item):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 234, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 235, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_GetAttr(__pyx_t_1, __pyx_v_attr); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 234, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_GetAttr(__pyx_t_1, __pyx_v_attr); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 235, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":233
+  /* "View.MemoryView":234
  *         return self._shape[0]
  * 
  *     def __getattr__(self, attr):             # <<<<<<<<<<<<<<
  *         return getattr(self.memview, attr)
  * 
  */
 
@@ -9641,15 +9711,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":236
+/* "View.MemoryView":237
  *         return getattr(self.memview, attr)
  * 
  *     def __getitem__(self, item):             # <<<<<<<<<<<<<<
  *         return self.memview[item]
  * 
  */
 
@@ -9672,32 +9742,32 @@
   PyObject *__pyx_t_1 = NULL;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__getitem__", 0);
 
-  /* "View.MemoryView":237
+  /* "View.MemoryView":238
  * 
  *     def __getitem__(self, item):
  *         return self.memview[item]             # <<<<<<<<<<<<<<
  * 
  *     def __setitem__(self, item, value):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 237, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 238, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_PyObject_GetItem(__pyx_t_1, __pyx_v_item); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 237, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_GetItem(__pyx_t_1, __pyx_v_item); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 238, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":236
+  /* "View.MemoryView":237
  *         return getattr(self.memview, attr)
  * 
  *     def __getitem__(self, item):             # <<<<<<<<<<<<<<
  *         return self.memview[item]
  * 
  */
 
@@ -9709,15 +9779,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":239
+/* "View.MemoryView":240
  *         return self.memview[item]
  * 
  *     def __setitem__(self, item, value):             # <<<<<<<<<<<<<<
  *         self.memview[item] = value
  * 
  */
 
@@ -9739,27 +9809,27 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__setitem__", 0);
 
-  /* "View.MemoryView":240
+  /* "View.MemoryView":241
  * 
  *     def __setitem__(self, item, value):
  *         self.memview[item] = value             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 240, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_memview); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 241, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  if (unlikely(PyObject_SetItem(__pyx_t_1, __pyx_v_item, __pyx_v_value) < 0)) __PYX_ERR(2, 240, __pyx_L1_error)
+  if (unlikely(PyObject_SetItem(__pyx_t_1, __pyx_v_item, __pyx_v_value) < 0)) __PYX_ERR(2, 241, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
-  /* "View.MemoryView":239
+  /* "View.MemoryView":240
  *         return self.memview[item]
  * 
  *     def __setitem__(self, item, value):             # <<<<<<<<<<<<<<
  *         self.memview[item] = value
  * 
  */
 
@@ -9884,15 +9954,15 @@
   __Pyx_AddTraceback("View.MemoryView.array.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":244
+/* "View.MemoryView":245
  * 
  * @cname("__pyx_array_new")
  * cdef array array_cwrapper(tuple shape, Py_ssize_t itemsize, char *format,             # <<<<<<<<<<<<<<
  *                           char *mode, char *buf):
  *     cdef array result
  */
 
@@ -9906,145 +9976,145 @@
   PyObject *__pyx_t_4 = NULL;
   PyObject *__pyx_t_5 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("array_cwrapper", 0);
 
-  /* "View.MemoryView":248
+  /* "View.MemoryView":249
  *     cdef array result
  * 
  *     if buf == NULL:             # <<<<<<<<<<<<<<
  *         result = array(shape, itemsize, format, mode.decode('ASCII'))
  *     else:
  */
   __pyx_t_1 = ((__pyx_v_buf == NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":249
+    /* "View.MemoryView":250
  * 
  *     if buf == NULL:
  *         result = array(shape, itemsize, format, mode.decode('ASCII'))             # <<<<<<<<<<<<<<
  *     else:
  *         result = array(shape, itemsize, format, mode.decode('ASCII'),
  */
-    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 249, __pyx_L1_error)
+    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 250, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
-    __pyx_t_3 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 249, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 250, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_4 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 249, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 250, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_5 = PyTuple_New(4); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 249, __pyx_L1_error)
+    __pyx_t_5 = PyTuple_New(4); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 250, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     __Pyx_INCREF(__pyx_v_shape);
     __Pyx_GIVEREF(__pyx_v_shape);
     PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_shape);
     __Pyx_GIVEREF(__pyx_t_2);
     PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_2);
     __Pyx_GIVEREF(__pyx_t_3);
     PyTuple_SET_ITEM(__pyx_t_5, 2, __pyx_t_3);
     __Pyx_GIVEREF(__pyx_t_4);
     PyTuple_SET_ITEM(__pyx_t_5, 3, __pyx_t_4);
     __pyx_t_2 = 0;
     __pyx_t_3 = 0;
     __pyx_t_4 = 0;
-    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_5, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 249, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_5, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 250, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
     __pyx_v_result = ((struct __pyx_array_obj *)__pyx_t_4);
     __pyx_t_4 = 0;
 
-    /* "View.MemoryView":248
+    /* "View.MemoryView":249
  *     cdef array result
  * 
  *     if buf == NULL:             # <<<<<<<<<<<<<<
  *         result = array(shape, itemsize, format, mode.decode('ASCII'))
  *     else:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":251
+  /* "View.MemoryView":252
  *         result = array(shape, itemsize, format, mode.decode('ASCII'))
  *     else:
  *         result = array(shape, itemsize, format, mode.decode('ASCII'),             # <<<<<<<<<<<<<<
  *                        allocate_buffer=False)
  *         result.data = buf
  */
   /*else*/ {
-    __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 251, __pyx_L1_error)
+    __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_itemsize); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 252, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_5 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 251, __pyx_L1_error)
+    __pyx_t_5 = __Pyx_PyBytes_FromString(__pyx_v_format); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 252, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
-    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 251, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_mode, 0, strlen(__pyx_v_mode), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 252, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_2 = PyTuple_New(4); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 251, __pyx_L1_error)
+    __pyx_t_2 = PyTuple_New(4); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 252, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_INCREF(__pyx_v_shape);
     __Pyx_GIVEREF(__pyx_v_shape);
     PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_shape);
     __Pyx_GIVEREF(__pyx_t_4);
     PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_4);
     __Pyx_GIVEREF(__pyx_t_5);
     PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_t_5);
     __Pyx_GIVEREF(__pyx_t_3);
     PyTuple_SET_ITEM(__pyx_t_2, 3, __pyx_t_3);
     __pyx_t_4 = 0;
     __pyx_t_5 = 0;
     __pyx_t_3 = 0;
 
-    /* "View.MemoryView":252
+    /* "View.MemoryView":253
  *     else:
  *         result = array(shape, itemsize, format, mode.decode('ASCII'),
  *                        allocate_buffer=False)             # <<<<<<<<<<<<<<
  *         result.data = buf
  * 
  */
-    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 252, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 253, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_allocate_buffer, Py_False) < 0) __PYX_ERR(2, 252, __pyx_L1_error)
+    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_allocate_buffer, Py_False) < 0) __PYX_ERR(2, 253, __pyx_L1_error)
 
-    /* "View.MemoryView":251
+    /* "View.MemoryView":252
  *         result = array(shape, itemsize, format, mode.decode('ASCII'))
  *     else:
  *         result = array(shape, itemsize, format, mode.decode('ASCII'),             # <<<<<<<<<<<<<<
  *                        allocate_buffer=False)
  *         result.data = buf
  */
-    __pyx_t_5 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 251, __pyx_L1_error)
+    __pyx_t_5 = __Pyx_PyObject_Call(((PyObject *)__pyx_array_type), __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 252, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
     __pyx_v_result = ((struct __pyx_array_obj *)__pyx_t_5);
     __pyx_t_5 = 0;
 
-    /* "View.MemoryView":253
+    /* "View.MemoryView":254
  *         result = array(shape, itemsize, format, mode.decode('ASCII'),
  *                        allocate_buffer=False)
  *         result.data = buf             # <<<<<<<<<<<<<<
  * 
  *     return result
  */
     __pyx_v_result->data = __pyx_v_buf;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":255
+  /* "View.MemoryView":256
  *         result.data = buf
  * 
  *     return result             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __Pyx_XDECREF(((PyObject *)__pyx_r));
   __Pyx_INCREF(((PyObject *)__pyx_v_result));
   __pyx_r = __pyx_v_result;
   goto __pyx_L0;
 
-  /* "View.MemoryView":244
+  /* "View.MemoryView":245
  * 
  * @cname("__pyx_array_new")
  * cdef array array_cwrapper(tuple shape, Py_ssize_t itemsize, char *format,             # <<<<<<<<<<<<<<
  *                           char *mode, char *buf):
  *     cdef array result
  */
 
@@ -10059,15 +10129,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_result);
   __Pyx_XGIVEREF((PyObject *)__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":281
+/* "View.MemoryView":282
  * cdef class Enum(object):
  *     cdef object name
  *     def __init__(self, name):             # <<<<<<<<<<<<<<
  *         self.name = name
  *     def __repr__(self):
  */
 
@@ -10096,26 +10166,26 @@
       kw_args = PyDict_Size(__pyx_kwds);
       switch (pos_args) {
         case  0:
         if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_name)) != 0)) kw_args--;
         else goto __pyx_L5_argtuple_error;
       }
       if (unlikely(kw_args > 0)) {
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(2, 281, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__init__") < 0)) __PYX_ERR(2, 282, __pyx_L3_error)
       }
     } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
       goto __pyx_L5_argtuple_error;
     } else {
       values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
     }
     __pyx_v_name = values[0];
   }
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 281, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("__init__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 282, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("View.MemoryView.Enum.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return -1;
   __pyx_L4_argument_unpacking_done:;
   __pyx_r = __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(((struct __pyx_MemviewEnum_obj *)__pyx_v_self), __pyx_v_name);
 
@@ -10125,42 +10195,42 @@
 }
 
 static int __pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum___init__(struct __pyx_MemviewEnum_obj *__pyx_v_self, PyObject *__pyx_v_name) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__init__", 0);
 
-  /* "View.MemoryView":282
+  /* "View.MemoryView":283
  *     cdef object name
  *     def __init__(self, name):
  *         self.name = name             # <<<<<<<<<<<<<<
  *     def __repr__(self):
  *         return self.name
  */
   __Pyx_INCREF(__pyx_v_name);
   __Pyx_GIVEREF(__pyx_v_name);
   __Pyx_GOTREF(__pyx_v_self->name);
   __Pyx_DECREF(__pyx_v_self->name);
   __pyx_v_self->name = __pyx_v_name;
 
-  /* "View.MemoryView":281
+  /* "View.MemoryView":282
  * cdef class Enum(object):
  *     cdef object name
  *     def __init__(self, name):             # <<<<<<<<<<<<<<
  *         self.name = name
  *     def __repr__(self):
  */
 
   /* function exit code */
   __pyx_r = 0;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":283
+/* "View.MemoryView":284
  *     def __init__(self, name):
  *         self.name = name
  *     def __repr__(self):             # <<<<<<<<<<<<<<
  *         return self.name
  * 
  */
 
@@ -10178,27 +10248,27 @@
 }
 
 static PyObject *__pyx_MemviewEnum___pyx_pf_15View_dot_MemoryView_4Enum_2__repr__(struct __pyx_MemviewEnum_obj *__pyx_v_self) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__repr__", 0);
 
-  /* "View.MemoryView":284
+  /* "View.MemoryView":285
  *         self.name = name
  *     def __repr__(self):
  *         return self.name             # <<<<<<<<<<<<<<
  * 
  * cdef generic = Enum("<strided and direct or indirect>")
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(__pyx_v_self->name);
   __pyx_r = __pyx_v_self->name;
   goto __pyx_L0;
 
-  /* "View.MemoryView":283
+  /* "View.MemoryView":284
  *     def __init__(self, name):
  *         self.name = name
  *     def __repr__(self):             # <<<<<<<<<<<<<<
  *         return self.name
  * 
  */
 
@@ -10473,15 +10543,15 @@
   __Pyx_RefNannySetupContext("__setstate_cython__", 0);
 
   /* "(tree fragment)":17
  *         return __pyx_unpickle_Enum, (type(self), 0xb068931, state)
  * def __setstate_cython__(self, __pyx_state):
  *     __pyx_unpickle_Enum__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
  */
-  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(2, 17, __pyx_L1_error)
+  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(2, 17, __pyx_L1_error)
   __pyx_t_1 = __pyx_unpickle_Enum__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 17, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
 
   /* "(tree fragment)":16
  *     else:
  *         return __pyx_unpickle_Enum, (type(self), 0xb068931, state)
@@ -10498,98 +10568,98 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":298
+/* "View.MemoryView":299
  * 
  * @cname('__pyx_align_pointer')
  * cdef void *align_pointer(void *memory, size_t alignment) nogil:             # <<<<<<<<<<<<<<
  *     "Align pointer memory on a given boundary"
  *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory
  */
 
 static void *__pyx_align_pointer(void *__pyx_v_memory, size_t __pyx_v_alignment) {
   Py_intptr_t __pyx_v_aligned_p;
   size_t __pyx_v_offset;
   void *__pyx_r;
   int __pyx_t_1;
 
-  /* "View.MemoryView":300
+  /* "View.MemoryView":301
  * cdef void *align_pointer(void *memory, size_t alignment) nogil:
  *     "Align pointer memory on a given boundary"
  *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory             # <<<<<<<<<<<<<<
  *     cdef size_t offset
  * 
  */
   __pyx_v_aligned_p = ((Py_intptr_t)__pyx_v_memory);
 
-  /* "View.MemoryView":304
+  /* "View.MemoryView":305
  * 
  *     with cython.cdivision(True):
  *         offset = aligned_p % alignment             # <<<<<<<<<<<<<<
  * 
  *     if offset > 0:
  */
   __pyx_v_offset = (__pyx_v_aligned_p % __pyx_v_alignment);
 
-  /* "View.MemoryView":306
+  /* "View.MemoryView":307
  *         offset = aligned_p % alignment
  * 
  *     if offset > 0:             # <<<<<<<<<<<<<<
  *         aligned_p += alignment - offset
  * 
  */
   __pyx_t_1 = ((__pyx_v_offset > 0) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":307
+    /* "View.MemoryView":308
  * 
  *     if offset > 0:
  *         aligned_p += alignment - offset             # <<<<<<<<<<<<<<
  * 
  *     return <void *> aligned_p
  */
     __pyx_v_aligned_p = (__pyx_v_aligned_p + (__pyx_v_alignment - __pyx_v_offset));
 
-    /* "View.MemoryView":306
+    /* "View.MemoryView":307
  *         offset = aligned_p % alignment
  * 
  *     if offset > 0:             # <<<<<<<<<<<<<<
  *         aligned_p += alignment - offset
  * 
  */
   }
 
-  /* "View.MemoryView":309
+  /* "View.MemoryView":310
  *         aligned_p += alignment - offset
  * 
  *     return <void *> aligned_p             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = ((void *)__pyx_v_aligned_p);
   goto __pyx_L0;
 
-  /* "View.MemoryView":298
+  /* "View.MemoryView":299
  * 
  * @cname('__pyx_align_pointer')
  * cdef void *align_pointer(void *memory, size_t alignment) nogil:             # <<<<<<<<<<<<<<
  *     "Align pointer memory on a given boundary"
  *     cdef Py_intptr_t aligned_p = <Py_intptr_t> memory
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":345
+/* "View.MemoryView":346
  *     cdef __Pyx_TypeInfo *typeinfo
  * 
  *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):             # <<<<<<<<<<<<<<
  *         self.obj = obj
  *         self.flags = flags
  */
 
@@ -10626,47 +10696,47 @@
         case  0:
         if (likely((values[0] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_obj)) != 0)) kw_args--;
         else goto __pyx_L5_argtuple_error;
         CYTHON_FALLTHROUGH;
         case  1:
         if (likely((values[1] = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_flags)) != 0)) kw_args--;
         else {
-          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, 1); __PYX_ERR(2, 345, __pyx_L3_error)
+          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, 1); __PYX_ERR(2, 346, __pyx_L3_error)
         }
         CYTHON_FALLTHROUGH;
         case  2:
         if (kw_args > 0) {
           PyObject* value = __Pyx_PyDict_GetItemStr(__pyx_kwds, __pyx_n_s_dtype_is_object);
           if (value) { values[2] = value; kw_args--; }
         }
       }
       if (unlikely(kw_args > 0)) {
-        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 345, __pyx_L3_error)
+        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(2, 346, __pyx_L3_error)
       }
     } else {
       switch (PyTuple_GET_SIZE(__pyx_args)) {
         case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
         CYTHON_FALLTHROUGH;
         case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
         values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
         break;
         default: goto __pyx_L5_argtuple_error;
       }
     }
     __pyx_v_obj = values[0];
-    __pyx_v_flags = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_flags == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 345, __pyx_L3_error)
+    __pyx_v_flags = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_flags == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 346, __pyx_L3_error)
     if (values[2]) {
-      __pyx_v_dtype_is_object = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_dtype_is_object == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 345, __pyx_L3_error)
+      __pyx_v_dtype_is_object = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_dtype_is_object == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 346, __pyx_L3_error)
     } else {
       __pyx_v_dtype_is_object = ((int)0);
     }
   }
   goto __pyx_L4_argument_unpacking_done;
   __pyx_L5_argtuple_error:;
-  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 345, __pyx_L3_error)
+  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(2, 346, __pyx_L3_error)
   __pyx_L3_error:;
   __Pyx_AddTraceback("View.MemoryView.memoryview.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __Pyx_RefNannyFinishContext();
   return -1;
   __pyx_L4_argument_unpacking_done:;
   __pyx_r = __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview___cinit__(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_obj, __pyx_v_flags, __pyx_v_dtype_is_object);
 
@@ -10683,37 +10753,37 @@
   int __pyx_t_3;
   int __pyx_t_4;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__cinit__", 0);
 
-  /* "View.MemoryView":346
+  /* "View.MemoryView":347
  * 
  *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):
  *         self.obj = obj             # <<<<<<<<<<<<<<
  *         self.flags = flags
  *         if type(self) is memoryview or obj is not None:
  */
   __Pyx_INCREF(__pyx_v_obj);
   __Pyx_GIVEREF(__pyx_v_obj);
   __Pyx_GOTREF(__pyx_v_self->obj);
   __Pyx_DECREF(__pyx_v_self->obj);
   __pyx_v_self->obj = __pyx_v_obj;
 
-  /* "View.MemoryView":347
+  /* "View.MemoryView":348
  *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):
  *         self.obj = obj
  *         self.flags = flags             # <<<<<<<<<<<<<<
  *         if type(self) is memoryview or obj is not None:
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  */
   __pyx_v_self->flags = __pyx_v_flags;
 
-  /* "View.MemoryView":348
+  /* "View.MemoryView":349
  *         self.obj = obj
  *         self.flags = flags
  *         if type(self) is memoryview or obj is not None:             # <<<<<<<<<<<<<<
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  *             if <PyObject *> self.view.obj == NULL:
  */
   __pyx_t_2 = (((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))) == ((PyObject *)__pyx_memoryview_type));
@@ -10725,231 +10795,250 @@
   }
   __pyx_t_3 = (__pyx_v_obj != Py_None);
   __pyx_t_2 = (__pyx_t_3 != 0);
   __pyx_t_1 = __pyx_t_2;
   __pyx_L4_bool_binop_done:;
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":349
+    /* "View.MemoryView":350
  *         self.flags = flags
  *         if type(self) is memoryview or obj is not None:
  *             __Pyx_GetBuffer(obj, &self.view, flags)             # <<<<<<<<<<<<<<
  *             if <PyObject *> self.view.obj == NULL:
  *                 (<__pyx_buffer *> &self.view).obj = Py_None
  */
-    __pyx_t_4 = __Pyx_GetBuffer(__pyx_v_obj, (&__pyx_v_self->view), __pyx_v_flags); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 349, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_GetBuffer(__pyx_v_obj, (&__pyx_v_self->view), __pyx_v_flags); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(2, 350, __pyx_L1_error)
 
-    /* "View.MemoryView":350
+    /* "View.MemoryView":351
  *         if type(self) is memoryview or obj is not None:
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  *             if <PyObject *> self.view.obj == NULL:             # <<<<<<<<<<<<<<
  *                 (<__pyx_buffer *> &self.view).obj = Py_None
  *                 Py_INCREF(Py_None)
  */
     __pyx_t_1 = ((((PyObject *)__pyx_v_self->view.obj) == NULL) != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":351
+      /* "View.MemoryView":352
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  *             if <PyObject *> self.view.obj == NULL:
  *                 (<__pyx_buffer *> &self.view).obj = Py_None             # <<<<<<<<<<<<<<
  *                 Py_INCREF(Py_None)
  * 
  */
       ((Py_buffer *)(&__pyx_v_self->view))->obj = Py_None;
 
-      /* "View.MemoryView":352
+      /* "View.MemoryView":353
  *             if <PyObject *> self.view.obj == NULL:
  *                 (<__pyx_buffer *> &self.view).obj = Py_None
  *                 Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
  * 
- *         global __pyx_memoryview_thread_locks_used
+ *         if not __PYX_CYTHON_ATOMICS_ENABLED():
  */
       Py_INCREF(Py_None);
 
-      /* "View.MemoryView":350
+      /* "View.MemoryView":351
  *         if type(self) is memoryview or obj is not None:
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  *             if <PyObject *> self.view.obj == NULL:             # <<<<<<<<<<<<<<
  *                 (<__pyx_buffer *> &self.view).obj = Py_None
  *                 Py_INCREF(Py_None)
  */
     }
 
-    /* "View.MemoryView":348
+    /* "View.MemoryView":349
  *         self.obj = obj
  *         self.flags = flags
  *         if type(self) is memoryview or obj is not None:             # <<<<<<<<<<<<<<
  *             __Pyx_GetBuffer(obj, &self.view, flags)
  *             if <PyObject *> self.view.obj == NULL:
  */
   }
 
   /* "View.MemoryView":355
+ *                 Py_INCREF(Py_None)
  * 
- *         global __pyx_memoryview_thread_locks_used
- *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
- *             __pyx_memoryview_thread_locks_used += 1
+ *         if not __PYX_CYTHON_ATOMICS_ENABLED():             # <<<<<<<<<<<<<<
+ *             global __pyx_memoryview_thread_locks_used
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
  */
-  __pyx_t_1 = ((__pyx_memoryview_thread_locks_used < 8) != 0);
+  __pyx_t_1 = ((!(__PYX_CYTHON_ATOMICS_ENABLED() != 0)) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":356
- *         global __pyx_memoryview_thread_locks_used
- *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]             # <<<<<<<<<<<<<<
- *             __pyx_memoryview_thread_locks_used += 1
- *         if self.lock is NULL:
- */
-    __pyx_v_self->lock = (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]);
-
     /* "View.MemoryView":357
- *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
- *             __pyx_memoryview_thread_locks_used += 1             # <<<<<<<<<<<<<<
- *         if self.lock is NULL:
- *             self.lock = PyThread_allocate_lock()
+ *         if not __PYX_CYTHON_ATOMICS_ENABLED():
+ *             global __pyx_memoryview_thread_locks_used
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
+ *                 __pyx_memoryview_thread_locks_used += 1
  */
-    __pyx_memoryview_thread_locks_used = (__pyx_memoryview_thread_locks_used + 1);
+    __pyx_t_1 = ((__pyx_memoryview_thread_locks_used < 8) != 0);
+    if (__pyx_t_1) {
 
-    /* "View.MemoryView":355
- * 
- *         global __pyx_memoryview_thread_locks_used
- *         if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
- *             __pyx_memoryview_thread_locks_used += 1
+      /* "View.MemoryView":358
+ *             global __pyx_memoryview_thread_locks_used
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]             # <<<<<<<<<<<<<<
+ *                 __pyx_memoryview_thread_locks_used += 1
+ *             if self.lock is NULL:
  */
-  }
+      __pyx_v_self->lock = (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]);
 
-  /* "View.MemoryView":358
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
- *             __pyx_memoryview_thread_locks_used += 1
- *         if self.lock is NULL:             # <<<<<<<<<<<<<<
- *             self.lock = PyThread_allocate_lock()
+      /* "View.MemoryView":359
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
+ *                 __pyx_memoryview_thread_locks_used += 1             # <<<<<<<<<<<<<<
  *             if self.lock is NULL:
+ *                 self.lock = PyThread_allocate_lock()
  */
-  __pyx_t_1 = ((__pyx_v_self->lock == NULL) != 0);
-  if (__pyx_t_1) {
+      __pyx_memoryview_thread_locks_used = (__pyx_memoryview_thread_locks_used + 1);
 
-    /* "View.MemoryView":359
- *             __pyx_memoryview_thread_locks_used += 1
- *         if self.lock is NULL:
- *             self.lock = PyThread_allocate_lock()             # <<<<<<<<<<<<<<
- *             if self.lock is NULL:
- *                 raise MemoryError
+      /* "View.MemoryView":357
+ *         if not __PYX_CYTHON_ATOMICS_ENABLED():
+ *             global __pyx_memoryview_thread_locks_used
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:             # <<<<<<<<<<<<<<
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
+ *                 __pyx_memoryview_thread_locks_used += 1
  */
-    __pyx_v_self->lock = PyThread_allocate_lock();
+    }
 
     /* "View.MemoryView":360
- *         if self.lock is NULL:
- *             self.lock = PyThread_allocate_lock()
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
+ *                 __pyx_memoryview_thread_locks_used += 1
  *             if self.lock is NULL:             # <<<<<<<<<<<<<<
- *                 raise MemoryError
- * 
+ *                 self.lock = PyThread_allocate_lock()
+ *                 if self.lock is NULL:
  */
     __pyx_t_1 = ((__pyx_v_self->lock == NULL) != 0);
-    if (unlikely(__pyx_t_1)) {
+    if (__pyx_t_1) {
 
       /* "View.MemoryView":361
- *             self.lock = PyThread_allocate_lock()
+ *                 __pyx_memoryview_thread_locks_used += 1
  *             if self.lock is NULL:
- *                 raise MemoryError             # <<<<<<<<<<<<<<
+ *                 self.lock = PyThread_allocate_lock()             # <<<<<<<<<<<<<<
+ *                 if self.lock is NULL:
+ *                     raise MemoryError
+ */
+      __pyx_v_self->lock = PyThread_allocate_lock();
+
+      /* "View.MemoryView":362
+ *             if self.lock is NULL:
+ *                 self.lock = PyThread_allocate_lock()
+ *                 if self.lock is NULL:             # <<<<<<<<<<<<<<
+ *                     raise MemoryError
+ * 
+ */
+      __pyx_t_1 = ((__pyx_v_self->lock == NULL) != 0);
+      if (unlikely(__pyx_t_1)) {
+
+        /* "View.MemoryView":363
+ *                 self.lock = PyThread_allocate_lock()
+ *                 if self.lock is NULL:
+ *                     raise MemoryError             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_FORMAT:
  */
-      PyErr_NoMemory(); __PYX_ERR(2, 361, __pyx_L1_error)
+        PyErr_NoMemory(); __PYX_ERR(2, 363, __pyx_L1_error)
+
+        /* "View.MemoryView":362
+ *             if self.lock is NULL:
+ *                 self.lock = PyThread_allocate_lock()
+ *                 if self.lock is NULL:             # <<<<<<<<<<<<<<
+ *                     raise MemoryError
+ * 
+ */
+      }
 
       /* "View.MemoryView":360
- *         if self.lock is NULL:
- *             self.lock = PyThread_allocate_lock()
+ *                 self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
+ *                 __pyx_memoryview_thread_locks_used += 1
  *             if self.lock is NULL:             # <<<<<<<<<<<<<<
- *                 raise MemoryError
- * 
+ *                 self.lock = PyThread_allocate_lock()
+ *                 if self.lock is NULL:
  */
     }
 
-    /* "View.MemoryView":358
- *             self.lock = __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]
- *             __pyx_memoryview_thread_locks_used += 1
- *         if self.lock is NULL:             # <<<<<<<<<<<<<<
- *             self.lock = PyThread_allocate_lock()
- *             if self.lock is NULL:
+    /* "View.MemoryView":355
+ *                 Py_INCREF(Py_None)
+ * 
+ *         if not __PYX_CYTHON_ATOMICS_ENABLED():             # <<<<<<<<<<<<<<
+ *             global __pyx_memoryview_thread_locks_used
+ *             if __pyx_memoryview_thread_locks_used < THREAD_LOCKS_PREALLOCATED:
  */
   }
 
-  /* "View.MemoryView":363
- *                 raise MemoryError
+  /* "View.MemoryView":365
+ *                     raise MemoryError
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":364
+    /* "View.MemoryView":366
  * 
  *         if flags & PyBUF_FORMAT:
  *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')             # <<<<<<<<<<<<<<
  *         else:
  *             self.dtype_is_object = dtype_is_object
  */
     __pyx_t_2 = (((__pyx_v_self->view.format[0]) == 'O') != 0);
     if (__pyx_t_2) {
     } else {
       __pyx_t_1 = __pyx_t_2;
-      goto __pyx_L11_bool_binop_done;
+      goto __pyx_L12_bool_binop_done;
     }
     __pyx_t_2 = (((__pyx_v_self->view.format[1]) == '\x00') != 0);
     __pyx_t_1 = __pyx_t_2;
-    __pyx_L11_bool_binop_done:;
+    __pyx_L12_bool_binop_done:;
     __pyx_v_self->dtype_is_object = __pyx_t_1;
 
-    /* "View.MemoryView":363
- *                 raise MemoryError
+    /* "View.MemoryView":365
+ *                     raise MemoryError
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
  *         else:
  */
-    goto __pyx_L10;
+    goto __pyx_L11;
   }
 
-  /* "View.MemoryView":366
+  /* "View.MemoryView":368
  *             self.dtype_is_object = (self.view.format[0] == b'O' and self.view.format[1] == b'\0')
  *         else:
  *             self.dtype_is_object = dtype_is_object             # <<<<<<<<<<<<<<
  * 
  *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(
  */
   /*else*/ {
     __pyx_v_self->dtype_is_object = __pyx_v_dtype_is_object;
   }
-  __pyx_L10:;
+  __pyx_L11:;
 
-  /* "View.MemoryView":368
+  /* "View.MemoryView":370
  *             self.dtype_is_object = dtype_is_object
  * 
  *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(             # <<<<<<<<<<<<<<
  *                   <void *> &self.acquisition_count[0], sizeof(__pyx_atomic_int))
  *         self.typeinfo = NULL
  */
   __pyx_v_self->acquisition_count_aligned_p = ((__pyx_atomic_int *)__pyx_align_pointer(((void *)(&(__pyx_v_self->acquisition_count[0]))), (sizeof(__pyx_atomic_int))));
 
-  /* "View.MemoryView":370
+  /* "View.MemoryView":372
  *         self.acquisition_count_aligned_p = <__pyx_atomic_int *> align_pointer(
  *                   <void *> &self.acquisition_count[0], sizeof(__pyx_atomic_int))
  *         self.typeinfo = NULL             # <<<<<<<<<<<<<<
  * 
  *     def __dealloc__(memoryview self):
  */
   __pyx_v_self->typeinfo = NULL;
 
-  /* "View.MemoryView":345
+  /* "View.MemoryView":346
  *     cdef __Pyx_TypeInfo *typeinfo
  * 
  *     def __cinit__(memoryview self, object obj, int flags, bint dtype_is_object=False):             # <<<<<<<<<<<<<<
  *         self.obj = obj
  *         self.flags = flags
  */
 
@@ -10960,15 +11049,15 @@
   __Pyx_AddTraceback("View.MemoryView.memoryview.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = -1;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":372
+/* "View.MemoryView":374
  *         self.typeinfo = NULL
  * 
  *     def __dealloc__(memoryview self):             # <<<<<<<<<<<<<<
  *         if self.obj is not None:
  *             __Pyx_ReleaseBuffer(&self.view)
  */
 
@@ -10991,215 +11080,215 @@
   int __pyx_t_3;
   int __pyx_t_4;
   int __pyx_t_5;
   PyThread_type_lock __pyx_t_6;
   PyThread_type_lock __pyx_t_7;
   __Pyx_RefNannySetupContext("__dealloc__", 0);
 
-  /* "View.MemoryView":373
+  /* "View.MemoryView":375
  * 
  *     def __dealloc__(memoryview self):
  *         if self.obj is not None:             # <<<<<<<<<<<<<<
  *             __Pyx_ReleaseBuffer(&self.view)
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:
  */
   __pyx_t_1 = (__pyx_v_self->obj != Py_None);
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":374
+    /* "View.MemoryView":376
  *     def __dealloc__(memoryview self):
  *         if self.obj is not None:
  *             __Pyx_ReleaseBuffer(&self.view)             # <<<<<<<<<<<<<<
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:
  * 
  */
     __Pyx_ReleaseBuffer((&__pyx_v_self->view));
 
-    /* "View.MemoryView":373
+    /* "View.MemoryView":375
  * 
  *     def __dealloc__(memoryview self):
  *         if self.obj is not None:             # <<<<<<<<<<<<<<
  *             __Pyx_ReleaseBuffer(&self.view)
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":375
+  /* "View.MemoryView":377
  *         if self.obj is not None:
  *             __Pyx_ReleaseBuffer(&self.view)
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:             # <<<<<<<<<<<<<<
  * 
  *             (<__pyx_buffer *> &self.view).obj = NULL
  */
   __pyx_t_2 = ((((Py_buffer *)(&__pyx_v_self->view))->obj == Py_None) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":377
+    /* "View.MemoryView":379
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:
  * 
  *             (<__pyx_buffer *> &self.view).obj = NULL             # <<<<<<<<<<<<<<
  *             Py_DECREF(Py_None)
  * 
  */
     ((Py_buffer *)(&__pyx_v_self->view))->obj = NULL;
 
-    /* "View.MemoryView":378
+    /* "View.MemoryView":380
  * 
  *             (<__pyx_buffer *> &self.view).obj = NULL
  *             Py_DECREF(Py_None)             # <<<<<<<<<<<<<<
  * 
  *         cdef int i
  */
     Py_DECREF(Py_None);
 
-    /* "View.MemoryView":375
+    /* "View.MemoryView":377
  *         if self.obj is not None:
  *             __Pyx_ReleaseBuffer(&self.view)
  *         elif (<__pyx_buffer *> &self.view).obj == Py_None:             # <<<<<<<<<<<<<<
  * 
  *             (<__pyx_buffer *> &self.view).obj = NULL
  */
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":382
+  /* "View.MemoryView":384
  *         cdef int i
  *         global __pyx_memoryview_thread_locks_used
  *         if self.lock != NULL:             # <<<<<<<<<<<<<<
  *             for i in range(__pyx_memoryview_thread_locks_used):
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  */
   __pyx_t_2 = ((__pyx_v_self->lock != NULL) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":383
+    /* "View.MemoryView":385
  *         global __pyx_memoryview_thread_locks_used
  *         if self.lock != NULL:
  *             for i in range(__pyx_memoryview_thread_locks_used):             # <<<<<<<<<<<<<<
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  *                     __pyx_memoryview_thread_locks_used -= 1
  */
     __pyx_t_3 = __pyx_memoryview_thread_locks_used;
     __pyx_t_4 = __pyx_t_3;
     for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
       __pyx_v_i = __pyx_t_5;
 
-      /* "View.MemoryView":384
+      /* "View.MemoryView":386
  *         if self.lock != NULL:
  *             for i in range(__pyx_memoryview_thread_locks_used):
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:             # <<<<<<<<<<<<<<
  *                     __pyx_memoryview_thread_locks_used -= 1
  *                     if i != __pyx_memoryview_thread_locks_used:
  */
       __pyx_t_2 = (((__pyx_memoryview_thread_locks[__pyx_v_i]) == __pyx_v_self->lock) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":385
+        /* "View.MemoryView":387
  *             for i in range(__pyx_memoryview_thread_locks_used):
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  *                     __pyx_memoryview_thread_locks_used -= 1             # <<<<<<<<<<<<<<
  *                     if i != __pyx_memoryview_thread_locks_used:
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
  */
         __pyx_memoryview_thread_locks_used = (__pyx_memoryview_thread_locks_used - 1);
 
-        /* "View.MemoryView":386
+        /* "View.MemoryView":388
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  *                     __pyx_memoryview_thread_locks_used -= 1
  *                     if i != __pyx_memoryview_thread_locks_used:             # <<<<<<<<<<<<<<
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
  *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
  */
         __pyx_t_2 = ((__pyx_v_i != __pyx_memoryview_thread_locks_used) != 0);
         if (__pyx_t_2) {
 
-          /* "View.MemoryView":388
+          /* "View.MemoryView":390
  *                     if i != __pyx_memoryview_thread_locks_used:
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
  *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])             # <<<<<<<<<<<<<<
  *                     break
  *             else:
  */
           __pyx_t_6 = (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]);
           __pyx_t_7 = (__pyx_memoryview_thread_locks[__pyx_v_i]);
 
-          /* "View.MemoryView":387
+          /* "View.MemoryView":389
  *                     __pyx_memoryview_thread_locks_used -= 1
  *                     if i != __pyx_memoryview_thread_locks_used:
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (             # <<<<<<<<<<<<<<
  *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
  *                     break
  */
           (__pyx_memoryview_thread_locks[__pyx_v_i]) = __pyx_t_6;
           (__pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used]) = __pyx_t_7;
 
-          /* "View.MemoryView":386
+          /* "View.MemoryView":388
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  *                     __pyx_memoryview_thread_locks_used -= 1
  *                     if i != __pyx_memoryview_thread_locks_used:             # <<<<<<<<<<<<<<
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
  *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
  */
         }
 
-        /* "View.MemoryView":389
+        /* "View.MemoryView":391
  *                         __pyx_memoryview_thread_locks[i], __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used] = (
  *                             __pyx_memoryview_thread_locks[__pyx_memoryview_thread_locks_used], __pyx_memoryview_thread_locks[i])
  *                     break             # <<<<<<<<<<<<<<
  *             else:
  *                 PyThread_free_lock(self.lock)
  */
         goto __pyx_L6_break;
 
-        /* "View.MemoryView":384
+        /* "View.MemoryView":386
  *         if self.lock != NULL:
  *             for i in range(__pyx_memoryview_thread_locks_used):
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:             # <<<<<<<<<<<<<<
  *                     __pyx_memoryview_thread_locks_used -= 1
  *                     if i != __pyx_memoryview_thread_locks_used:
  */
       }
     }
     /*else*/ {
 
-      /* "View.MemoryView":391
+      /* "View.MemoryView":393
  *                     break
  *             else:
  *                 PyThread_free_lock(self.lock)             # <<<<<<<<<<<<<<
  * 
  *     cdef char *get_item_pointer(memoryview self, object index) except NULL:
  */
       PyThread_free_lock(__pyx_v_self->lock);
     }
     __pyx_L6_break:;
 
-    /* "View.MemoryView":382
+    /* "View.MemoryView":384
  *         cdef int i
  *         global __pyx_memoryview_thread_locks_used
  *         if self.lock != NULL:             # <<<<<<<<<<<<<<
  *             for i in range(__pyx_memoryview_thread_locks_used):
  *                 if __pyx_memoryview_thread_locks[i] is self.lock:
  */
   }
 
-  /* "View.MemoryView":372
+  /* "View.MemoryView":374
  *         self.typeinfo = NULL
  * 
  *     def __dealloc__(memoryview self):             # <<<<<<<<<<<<<<
  *         if self.obj is not None:
  *             __Pyx_ReleaseBuffer(&self.view)
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "View.MemoryView":393
+/* "View.MemoryView":395
  *                 PyThread_free_lock(self.lock)
  * 
  *     cdef char *get_item_pointer(memoryview self, object index) except NULL:             # <<<<<<<<<<<<<<
  *         cdef Py_ssize_t dim
  *         cdef char *itemp = <char *> self.view.buf
  */
 
@@ -11217,107 +11306,107 @@
   Py_ssize_t __pyx_t_6;
   char *__pyx_t_7;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("get_item_pointer", 0);
 
-  /* "View.MemoryView":395
+  /* "View.MemoryView":397
  *     cdef char *get_item_pointer(memoryview self, object index) except NULL:
  *         cdef Py_ssize_t dim
  *         cdef char *itemp = <char *> self.view.buf             # <<<<<<<<<<<<<<
  * 
  *         for dim, idx in enumerate(index):
  */
   __pyx_v_itemp = ((char *)__pyx_v_self->view.buf);
 
-  /* "View.MemoryView":397
+  /* "View.MemoryView":399
  *         cdef char *itemp = <char *> self.view.buf
  * 
  *         for dim, idx in enumerate(index):             # <<<<<<<<<<<<<<
  *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
  * 
  */
   __pyx_t_1 = 0;
   if (likely(PyList_CheckExact(__pyx_v_index)) || PyTuple_CheckExact(__pyx_v_index)) {
     __pyx_t_2 = __pyx_v_index; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
     __pyx_t_4 = NULL;
   } else {
-    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 397, __pyx_L1_error)
+    __pyx_t_3 = -1; __pyx_t_2 = PyObject_GetIter(__pyx_v_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 399, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
-    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 397, __pyx_L1_error)
+    __pyx_t_4 = Py_TYPE(__pyx_t_2)->tp_iternext; if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 399, __pyx_L1_error)
   }
   for (;;) {
     if (likely(!__pyx_t_4)) {
       if (likely(PyList_CheckExact(__pyx_t_2))) {
         if (__pyx_t_3 >= PyList_GET_SIZE(__pyx_t_2)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 397, __pyx_L1_error)
+        __pyx_t_5 = PyList_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 399, __pyx_L1_error)
         #else
-        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 397, __pyx_L1_error)
+        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 399, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_5);
         #endif
       } else {
         if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 397, __pyx_L1_error)
+        __pyx_t_5 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_5); __pyx_t_3++; if (unlikely(0 < 0)) __PYX_ERR(2, 399, __pyx_L1_error)
         #else
-        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 397, __pyx_L1_error)
+        __pyx_t_5 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 399, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_5);
         #endif
       }
     } else {
       __pyx_t_5 = __pyx_t_4(__pyx_t_2);
       if (unlikely(!__pyx_t_5)) {
         PyObject* exc_type = PyErr_Occurred();
         if (exc_type) {
           if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
-          else __PYX_ERR(2, 397, __pyx_L1_error)
+          else __PYX_ERR(2, 399, __pyx_L1_error)
         }
         break;
       }
       __Pyx_GOTREF(__pyx_t_5);
     }
     __Pyx_XDECREF_SET(__pyx_v_idx, __pyx_t_5);
     __pyx_t_5 = 0;
     __pyx_v_dim = __pyx_t_1;
     __pyx_t_1 = (__pyx_t_1 + 1);
 
-    /* "View.MemoryView":398
+    /* "View.MemoryView":400
  * 
  *         for dim, idx in enumerate(index):
  *             itemp = pybuffer_index(&self.view, itemp, idx, dim)             # <<<<<<<<<<<<<<
  * 
  *         return itemp
  */
-    __pyx_t_6 = __Pyx_PyIndex_AsSsize_t(__pyx_v_idx); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 398, __pyx_L1_error)
-    __pyx_t_7 = __pyx_pybuffer_index((&__pyx_v_self->view), __pyx_v_itemp, __pyx_t_6, __pyx_v_dim); if (unlikely(__pyx_t_7 == ((char *)NULL))) __PYX_ERR(2, 398, __pyx_L1_error)
+    __pyx_t_6 = __Pyx_PyIndex_AsSsize_t(__pyx_v_idx); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 400, __pyx_L1_error)
+    __pyx_t_7 = __pyx_pybuffer_index((&__pyx_v_self->view), __pyx_v_itemp, __pyx_t_6, __pyx_v_dim); if (unlikely(__pyx_t_7 == ((char *)NULL))) __PYX_ERR(2, 400, __pyx_L1_error)
     __pyx_v_itemp = __pyx_t_7;
 
-    /* "View.MemoryView":397
+    /* "View.MemoryView":399
  *         cdef char *itemp = <char *> self.view.buf
  * 
  *         for dim, idx in enumerate(index):             # <<<<<<<<<<<<<<
  *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
  * 
  */
   }
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
-  /* "View.MemoryView":400
+  /* "View.MemoryView":402
  *             itemp = pybuffer_index(&self.view, itemp, idx, dim)
  * 
  *         return itemp             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = __pyx_v_itemp;
   goto __pyx_L0;
 
-  /* "View.MemoryView":393
+  /* "View.MemoryView":395
  *                 PyThread_free_lock(self.lock)
  * 
  *     cdef char *get_item_pointer(memoryview self, object index) except NULL:             # <<<<<<<<<<<<<<
  *         cdef Py_ssize_t dim
  *         cdef char *itemp = <char *> self.view.buf
  */
 
@@ -11329,15 +11418,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XDECREF(__pyx_v_idx);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":403
+/* "View.MemoryView":405
  * 
  * 
  *     def __getitem__(memoryview self, object index):             # <<<<<<<<<<<<<<
  *         if index is Ellipsis:
  *             return self
  */
 
@@ -11367,143 +11456,143 @@
   PyObject *__pyx_t_5 = NULL;
   char *__pyx_t_6;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__getitem__", 0);
 
-  /* "View.MemoryView":404
+  /* "View.MemoryView":406
  * 
  *     def __getitem__(memoryview self, object index):
  *         if index is Ellipsis:             # <<<<<<<<<<<<<<
  *             return self
  * 
  */
   __pyx_t_1 = (__pyx_v_index == __pyx_builtin_Ellipsis);
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":405
+    /* "View.MemoryView":407
  *     def __getitem__(memoryview self, object index):
  *         if index is Ellipsis:
  *             return self             # <<<<<<<<<<<<<<
  * 
  *         have_slices, indices = _unellipsify(index, self.view.ndim)
  */
     __Pyx_XDECREF(__pyx_r);
     __Pyx_INCREF(((PyObject *)__pyx_v_self));
     __pyx_r = ((PyObject *)__pyx_v_self);
     goto __pyx_L0;
 
-    /* "View.MemoryView":404
+    /* "View.MemoryView":406
  * 
  *     def __getitem__(memoryview self, object index):
  *         if index is Ellipsis:             # <<<<<<<<<<<<<<
  *             return self
  * 
  */
   }
 
-  /* "View.MemoryView":407
+  /* "View.MemoryView":409
  *             return self
  * 
  *         have_slices, indices = _unellipsify(index, self.view.ndim)             # <<<<<<<<<<<<<<
  * 
  *         cdef char *itemp
  */
-  __pyx_t_3 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 407, __pyx_L1_error)
+  __pyx_t_3 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 409, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   if (likely(__pyx_t_3 != Py_None)) {
     PyObject* sequence = __pyx_t_3;
     Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
     if (unlikely(size != 2)) {
       if (size > 2) __Pyx_RaiseTooManyValuesError(2);
       else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
-      __PYX_ERR(2, 407, __pyx_L1_error)
+      __PYX_ERR(2, 409, __pyx_L1_error)
     }
     #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
     __pyx_t_4 = PyTuple_GET_ITEM(sequence, 0); 
     __pyx_t_5 = PyTuple_GET_ITEM(sequence, 1); 
     __Pyx_INCREF(__pyx_t_4);
     __Pyx_INCREF(__pyx_t_5);
     #else
-    __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 407, __pyx_L1_error)
+    __pyx_t_4 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 409, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 407, __pyx_L1_error)
+    __pyx_t_5 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 409, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     #endif
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   } else {
-    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 407, __pyx_L1_error)
+    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 409, __pyx_L1_error)
   }
   __pyx_v_have_slices = __pyx_t_4;
   __pyx_t_4 = 0;
   __pyx_v_indices = __pyx_t_5;
   __pyx_t_5 = 0;
 
-  /* "View.MemoryView":410
+  /* "View.MemoryView":412
  * 
  *         cdef char *itemp
  *         if have_slices:             # <<<<<<<<<<<<<<
  *             return memview_slice(self, indices)
  *         else:
  */
-  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 410, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 412, __pyx_L1_error)
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":411
+    /* "View.MemoryView":413
  *         cdef char *itemp
  *         if have_slices:
  *             return memview_slice(self, indices)             # <<<<<<<<<<<<<<
  *         else:
  *             itemp = self.get_item_pointer(indices)
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_3 = ((PyObject *)__pyx_memview_slice(__pyx_v_self, __pyx_v_indices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 411, __pyx_L1_error)
+    __pyx_t_3 = ((PyObject *)__pyx_memview_slice(__pyx_v_self, __pyx_v_indices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 413, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __pyx_r = __pyx_t_3;
     __pyx_t_3 = 0;
     goto __pyx_L0;
 
-    /* "View.MemoryView":410
+    /* "View.MemoryView":412
  * 
  *         cdef char *itemp
  *         if have_slices:             # <<<<<<<<<<<<<<
  *             return memview_slice(self, indices)
  *         else:
  */
   }
 
-  /* "View.MemoryView":413
+  /* "View.MemoryView":415
  *             return memview_slice(self, indices)
  *         else:
  *             itemp = self.get_item_pointer(indices)             # <<<<<<<<<<<<<<
  *             return self.convert_item_to_object(itemp)
  * 
  */
   /*else*/ {
-    __pyx_t_6 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_indices); if (unlikely(__pyx_t_6 == ((char *)NULL))) __PYX_ERR(2, 413, __pyx_L1_error)
+    __pyx_t_6 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_indices); if (unlikely(__pyx_t_6 == ((char *)NULL))) __PYX_ERR(2, 415, __pyx_L1_error)
     __pyx_v_itemp = __pyx_t_6;
 
-    /* "View.MemoryView":414
+    /* "View.MemoryView":416
  *         else:
  *             itemp = self.get_item_pointer(indices)
  *             return self.convert_item_to_object(itemp)             # <<<<<<<<<<<<<<
  * 
  *     def __setitem__(memoryview self, object index, object value):
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->convert_item_to_object(__pyx_v_self, __pyx_v_itemp); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 414, __pyx_L1_error)
+    __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->convert_item_to_object(__pyx_v_self, __pyx_v_itemp); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 416, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __pyx_r = __pyx_t_3;
     __pyx_t_3 = 0;
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":403
+  /* "View.MemoryView":405
  * 
  * 
  *     def __getitem__(memoryview self, object index):             # <<<<<<<<<<<<<<
  *         if index is Ellipsis:
  *             return self
  */
 
@@ -11518,15 +11607,15 @@
   __Pyx_XDECREF(__pyx_v_have_slices);
   __Pyx_XDECREF(__pyx_v_indices);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":416
+/* "View.MemoryView":418
  *             return self.convert_item_to_object(itemp)
  * 
  *     def __setitem__(memoryview self, object index, object value):             # <<<<<<<<<<<<<<
  *         if self.view.readonly:
  *             raise TypeError("Cannot assign to read-only memoryview")
  */
 
@@ -11554,182 +11643,182 @@
   PyObject *__pyx_t_4 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__setitem__", 0);
   __Pyx_INCREF(__pyx_v_index);
 
-  /* "View.MemoryView":417
+  /* "View.MemoryView":419
  * 
  *     def __setitem__(memoryview self, object index, object value):
  *         if self.view.readonly:             # <<<<<<<<<<<<<<
  *             raise TypeError("Cannot assign to read-only memoryview")
  * 
  */
   __pyx_t_1 = (__pyx_v_self->view.readonly != 0);
   if (unlikely(__pyx_t_1)) {
 
-    /* "View.MemoryView":418
+    /* "View.MemoryView":420
  *     def __setitem__(memoryview self, object index, object value):
  *         if self.view.readonly:
  *             raise TypeError("Cannot assign to read-only memoryview")             # <<<<<<<<<<<<<<
  * 
  *         have_slices, index = _unellipsify(index, self.view.ndim)
  */
-    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__14, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 418, __pyx_L1_error)
+    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__14, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 420, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_Raise(__pyx_t_2, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __PYX_ERR(2, 418, __pyx_L1_error)
+    __PYX_ERR(2, 420, __pyx_L1_error)
 
-    /* "View.MemoryView":417
+    /* "View.MemoryView":419
  * 
  *     def __setitem__(memoryview self, object index, object value):
  *         if self.view.readonly:             # <<<<<<<<<<<<<<
  *             raise TypeError("Cannot assign to read-only memoryview")
  * 
  */
   }
 
-  /* "View.MemoryView":420
+  /* "View.MemoryView":422
  *             raise TypeError("Cannot assign to read-only memoryview")
  * 
  *         have_slices, index = _unellipsify(index, self.view.ndim)             # <<<<<<<<<<<<<<
  * 
  *         if have_slices:
  */
-  __pyx_t_2 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 420, __pyx_L1_error)
+  __pyx_t_2 = _unellipsify(__pyx_v_index, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 422, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   if (likely(__pyx_t_2 != Py_None)) {
     PyObject* sequence = __pyx_t_2;
     Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
     if (unlikely(size != 2)) {
       if (size > 2) __Pyx_RaiseTooManyValuesError(2);
       else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
-      __PYX_ERR(2, 420, __pyx_L1_error)
+      __PYX_ERR(2, 422, __pyx_L1_error)
     }
     #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
     __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
     __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
     __Pyx_INCREF(__pyx_t_3);
     __Pyx_INCREF(__pyx_t_4);
     #else
-    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 420, __pyx_L1_error)
+    __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 422, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 420, __pyx_L1_error)
+    __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 422, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     #endif
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   } else {
-    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 420, __pyx_L1_error)
+    __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(2, 422, __pyx_L1_error)
   }
   __pyx_v_have_slices = __pyx_t_3;
   __pyx_t_3 = 0;
   __Pyx_DECREF_SET(__pyx_v_index, __pyx_t_4);
   __pyx_t_4 = 0;
 
-  /* "View.MemoryView":422
+  /* "View.MemoryView":424
  *         have_slices, index = _unellipsify(index, self.view.ndim)
  * 
  *         if have_slices:             # <<<<<<<<<<<<<<
  *             obj = self.is_slice(value)
  *             if obj:
  */
-  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 422, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_have_slices); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 424, __pyx_L1_error)
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":423
+    /* "View.MemoryView":425
  * 
  *         if have_slices:
  *             obj = self.is_slice(value)             # <<<<<<<<<<<<<<
  *             if obj:
  *                 self.setitem_slice_assignment(self[index], obj)
  */
-    __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->is_slice(__pyx_v_self, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 423, __pyx_L1_error)
+    __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->is_slice(__pyx_v_self, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 425, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __pyx_v_obj = __pyx_t_2;
     __pyx_t_2 = 0;
 
-    /* "View.MemoryView":424
+    /* "View.MemoryView":426
  *         if have_slices:
  *             obj = self.is_slice(value)
  *             if obj:             # <<<<<<<<<<<<<<
  *                 self.setitem_slice_assignment(self[index], obj)
  *             else:
  */
-    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_obj); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 424, __pyx_L1_error)
+    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_obj); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 426, __pyx_L1_error)
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":425
+      /* "View.MemoryView":427
  *             obj = self.is_slice(value)
  *             if obj:
  *                 self.setitem_slice_assignment(self[index], obj)             # <<<<<<<<<<<<<<
  *             else:
  *                 self.setitem_slice_assign_scalar(self[index], value)
  */
-      __pyx_t_2 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 425, __pyx_L1_error)
+      __pyx_t_2 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 427, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_2);
-      __pyx_t_4 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assignment(__pyx_v_self, __pyx_t_2, __pyx_v_obj); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 425, __pyx_L1_error)
+      __pyx_t_4 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assignment(__pyx_v_self, __pyx_t_2, __pyx_v_obj); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 427, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_4);
       __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
       __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
 
-      /* "View.MemoryView":424
+      /* "View.MemoryView":426
  *         if have_slices:
  *             obj = self.is_slice(value)
  *             if obj:             # <<<<<<<<<<<<<<
  *                 self.setitem_slice_assignment(self[index], obj)
  *             else:
  */
       goto __pyx_L5;
     }
 
-    /* "View.MemoryView":427
+    /* "View.MemoryView":429
  *                 self.setitem_slice_assignment(self[index], obj)
  *             else:
  *                 self.setitem_slice_assign_scalar(self[index], value)             # <<<<<<<<<<<<<<
  *         else:
  *             self.setitem_indexed(index, value)
  */
     /*else*/ {
-      __pyx_t_4 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 427, __pyx_L1_error)
+      __pyx_t_4 = __Pyx_PyObject_GetItem(((PyObject *)__pyx_v_self), __pyx_v_index); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 429, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_4);
-      if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_memoryview_type))))) __PYX_ERR(2, 427, __pyx_L1_error)
-      __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assign_scalar(__pyx_v_self, ((struct __pyx_memoryview_obj *)__pyx_t_4), __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 427, __pyx_L1_error)
+      if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_memoryview_type))))) __PYX_ERR(2, 429, __pyx_L1_error)
+      __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_slice_assign_scalar(__pyx_v_self, ((struct __pyx_memoryview_obj *)__pyx_t_4), __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 429, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_2);
       __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
       __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
     }
     __pyx_L5:;
 
-    /* "View.MemoryView":422
+    /* "View.MemoryView":424
  *         have_slices, index = _unellipsify(index, self.view.ndim)
  * 
  *         if have_slices:             # <<<<<<<<<<<<<<
  *             obj = self.is_slice(value)
  *             if obj:
  */
     goto __pyx_L4;
   }
 
-  /* "View.MemoryView":429
+  /* "View.MemoryView":431
  *                 self.setitem_slice_assign_scalar(self[index], value)
  *         else:
  *             self.setitem_indexed(index, value)             # <<<<<<<<<<<<<<
  * 
  *     cdef is_slice(self, obj):
  */
   /*else*/ {
-    __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_indexed(__pyx_v_self, __pyx_v_index, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 429, __pyx_L1_error)
+    __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->setitem_indexed(__pyx_v_self, __pyx_v_index, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 431, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   }
   __pyx_L4:;
 
-  /* "View.MemoryView":416
+  /* "View.MemoryView":418
  *             return self.convert_item_to_object(itemp)
  * 
  *     def __setitem__(memoryview self, object index, object value):             # <<<<<<<<<<<<<<
  *         if self.view.readonly:
  *             raise TypeError("Cannot assign to read-only memoryview")
  */
 
@@ -11746,15 +11835,15 @@
   __Pyx_XDECREF(__pyx_v_have_slices);
   __Pyx_XDECREF(__pyx_v_obj);
   __Pyx_XDECREF(__pyx_v_index);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":431
+/* "View.MemoryView":433
  *             self.setitem_indexed(index, value)
  * 
  *     cdef is_slice(self, obj):             # <<<<<<<<<<<<<<
  *         if not isinstance(obj, memoryview):
  *             try:
  */
 
@@ -11772,26 +11861,26 @@
   int __pyx_t_9;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("is_slice", 0);
   __Pyx_INCREF(__pyx_v_obj);
 
-  /* "View.MemoryView":432
+  /* "View.MemoryView":434
  * 
  *     cdef is_slice(self, obj):
  *         if not isinstance(obj, memoryview):             # <<<<<<<<<<<<<<
  *             try:
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  */
   __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_obj, __pyx_memoryview_type); 
   __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":433
+    /* "View.MemoryView":435
  *     cdef is_slice(self, obj):
  *         if not isinstance(obj, memoryview):
  *             try:             # <<<<<<<<<<<<<<
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  *                                  self.dtype_is_object)
  */
     {
@@ -11799,59 +11888,59 @@
       __Pyx_PyThreadState_assign
       __Pyx_ExceptionSave(&__pyx_t_3, &__pyx_t_4, &__pyx_t_5);
       __Pyx_XGOTREF(__pyx_t_3);
       __Pyx_XGOTREF(__pyx_t_4);
       __Pyx_XGOTREF(__pyx_t_5);
       /*try:*/ {
 
-        /* "View.MemoryView":434
+        /* "View.MemoryView":436
  *         if not isinstance(obj, memoryview):
  *             try:
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,             # <<<<<<<<<<<<<<
  *                                  self.dtype_is_object)
  *             except TypeError:
  */
-        __pyx_t_6 = __Pyx_PyInt_From_int(((__pyx_v_self->flags & (~PyBUF_WRITABLE)) | PyBUF_ANY_CONTIGUOUS)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 434, __pyx_L4_error)
+        __pyx_t_6 = __Pyx_PyInt_From_int(((__pyx_v_self->flags & (~PyBUF_WRITABLE)) | PyBUF_ANY_CONTIGUOUS)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 436, __pyx_L4_error)
         __Pyx_GOTREF(__pyx_t_6);
 
-        /* "View.MemoryView":435
+        /* "View.MemoryView":437
  *             try:
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  *                                  self.dtype_is_object)             # <<<<<<<<<<<<<<
  *             except TypeError:
  *                 return None
  */
-        __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 435, __pyx_L4_error)
+        __pyx_t_7 = __Pyx_PyBool_FromLong(__pyx_v_self->dtype_is_object); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 437, __pyx_L4_error)
         __Pyx_GOTREF(__pyx_t_7);
 
-        /* "View.MemoryView":434
+        /* "View.MemoryView":436
  *         if not isinstance(obj, memoryview):
  *             try:
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,             # <<<<<<<<<<<<<<
  *                                  self.dtype_is_object)
  *             except TypeError:
  */
-        __pyx_t_8 = PyTuple_New(3); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 434, __pyx_L4_error)
+        __pyx_t_8 = PyTuple_New(3); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 436, __pyx_L4_error)
         __Pyx_GOTREF(__pyx_t_8);
         __Pyx_INCREF(__pyx_v_obj);
         __Pyx_GIVEREF(__pyx_v_obj);
         PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_obj);
         __Pyx_GIVEREF(__pyx_t_6);
         PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_t_6);
         __Pyx_GIVEREF(__pyx_t_7);
         PyTuple_SET_ITEM(__pyx_t_8, 2, __pyx_t_7);
         __pyx_t_6 = 0;
         __pyx_t_7 = 0;
-        __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 434, __pyx_L4_error)
+        __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_8, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 436, __pyx_L4_error)
         __Pyx_GOTREF(__pyx_t_7);
         __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         __Pyx_DECREF_SET(__pyx_v_obj, __pyx_t_7);
         __pyx_t_7 = 0;
 
-        /* "View.MemoryView":433
+        /* "View.MemoryView":435
  *     cdef is_slice(self, obj):
  *         if not isinstance(obj, memoryview):
  *             try:             # <<<<<<<<<<<<<<
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  *                                  self.dtype_is_object)
  */
       }
@@ -11860,30 +11949,30 @@
       __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
       goto __pyx_L9_try_end;
       __pyx_L4_error:;
       __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
       __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
       __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
 
-      /* "View.MemoryView":436
+      /* "View.MemoryView":438
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  *                                  self.dtype_is_object)
  *             except TypeError:             # <<<<<<<<<<<<<<
  *                 return None
  * 
  */
       __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
       if (__pyx_t_9) {
         __Pyx_AddTraceback("View.MemoryView.memoryview.is_slice", __pyx_clineno, __pyx_lineno, __pyx_filename);
-        if (__Pyx_GetException(&__pyx_t_7, &__pyx_t_8, &__pyx_t_6) < 0) __PYX_ERR(2, 436, __pyx_L6_except_error)
+        if (__Pyx_GetException(&__pyx_t_7, &__pyx_t_8, &__pyx_t_6) < 0) __PYX_ERR(2, 438, __pyx_L6_except_error)
         __Pyx_GOTREF(__pyx_t_7);
         __Pyx_GOTREF(__pyx_t_8);
         __Pyx_GOTREF(__pyx_t_6);
 
-        /* "View.MemoryView":437
+        /* "View.MemoryView":439
  *                                  self.dtype_is_object)
  *             except TypeError:
  *                 return None             # <<<<<<<<<<<<<<
  * 
  *         return obj
  */
         __Pyx_XDECREF(__pyx_r);
@@ -11892,15 +11981,15 @@
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
         goto __pyx_L7_except_return;
       }
       goto __pyx_L6_except_error;
       __pyx_L6_except_error:;
 
-      /* "View.MemoryView":433
+      /* "View.MemoryView":435
  *     cdef is_slice(self, obj):
  *         if not isinstance(obj, memoryview):
  *             try:             # <<<<<<<<<<<<<<
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  *                                  self.dtype_is_object)
  */
       __Pyx_XGIVEREF(__pyx_t_3);
@@ -11913,36 +12002,36 @@
       __Pyx_XGIVEREF(__pyx_t_4);
       __Pyx_XGIVEREF(__pyx_t_5);
       __Pyx_ExceptionReset(__pyx_t_3, __pyx_t_4, __pyx_t_5);
       goto __pyx_L0;
       __pyx_L9_try_end:;
     }
 
-    /* "View.MemoryView":432
+    /* "View.MemoryView":434
  * 
  *     cdef is_slice(self, obj):
  *         if not isinstance(obj, memoryview):             # <<<<<<<<<<<<<<
  *             try:
  *                 obj = memoryview(obj, self.flags & ~PyBUF_WRITABLE | PyBUF_ANY_CONTIGUOUS,
  */
   }
 
-  /* "View.MemoryView":439
+  /* "View.MemoryView":441
  *                 return None
  * 
  *         return obj             # <<<<<<<<<<<<<<
  * 
  *     cdef setitem_slice_assignment(self, dst, src):
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(__pyx_v_obj);
   __pyx_r = __pyx_v_obj;
   goto __pyx_L0;
 
-  /* "View.MemoryView":431
+  /* "View.MemoryView":433
  *             self.setitem_indexed(index, value)
  * 
  *     cdef is_slice(self, obj):             # <<<<<<<<<<<<<<
  *         if not isinstance(obj, memoryview):
  *             try:
  */
 
@@ -11956,15 +12045,15 @@
   __pyx_L0:;
   __Pyx_XDECREF(__pyx_v_obj);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":441
+/* "View.MemoryView":443
  *         return obj
  * 
  *     cdef setitem_slice_assignment(self, dst, src):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice dst_slice
  *         cdef __Pyx_memviewslice src_slice
  */
 
@@ -11980,60 +12069,60 @@
   int __pyx_t_5;
   int __pyx_t_6;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("setitem_slice_assignment", 0);
 
-  /* "View.MemoryView":445
+  /* "View.MemoryView":447
  *         cdef __Pyx_memviewslice src_slice
  * 
  *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],             # <<<<<<<<<<<<<<
  *                                  get_slice_from_memview(dst, &dst_slice)[0],
  *                                  src.ndim, dst.ndim, self.dtype_is_object)
  */
-  if (!(likely(((__pyx_v_src) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_src, __pyx_memoryview_type))))) __PYX_ERR(2, 445, __pyx_L1_error)
-  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_src), (&__pyx_v_src_slice)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 445, __pyx_L1_error)
+  if (!(likely(((__pyx_v_src) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_src, __pyx_memoryview_type))))) __PYX_ERR(2, 447, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_src), (&__pyx_v_src_slice)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 447, __pyx_L1_error)
 
-  /* "View.MemoryView":446
+  /* "View.MemoryView":448
  * 
  *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],
  *                                  get_slice_from_memview(dst, &dst_slice)[0],             # <<<<<<<<<<<<<<
  *                                  src.ndim, dst.ndim, self.dtype_is_object)
  * 
  */
-  if (!(likely(((__pyx_v_dst) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_dst, __pyx_memoryview_type))))) __PYX_ERR(2, 446, __pyx_L1_error)
-  __pyx_t_2 = __pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_dst), (&__pyx_v_dst_slice)); if (unlikely(__pyx_t_2 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 446, __pyx_L1_error)
+  if (!(likely(((__pyx_v_dst) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_dst, __pyx_memoryview_type))))) __PYX_ERR(2, 448, __pyx_L1_error)
+  __pyx_t_2 = __pyx_memoryview_get_slice_from_memoryview(((struct __pyx_memoryview_obj *)__pyx_v_dst), (&__pyx_v_dst_slice)); if (unlikely(__pyx_t_2 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 448, __pyx_L1_error)
 
-  /* "View.MemoryView":447
+  /* "View.MemoryView":449
  *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],
  *                                  get_slice_from_memview(dst, &dst_slice)[0],
  *                                  src.ndim, dst.ndim, self.dtype_is_object)             # <<<<<<<<<<<<<<
  * 
  *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):
  */
-  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_src, __pyx_n_s_ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 447, __pyx_L1_error)
+  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_src, __pyx_n_s_ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 449, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
-  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 447, __pyx_L1_error)
+  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 449, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_dst, __pyx_n_s_ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 447, __pyx_L1_error)
+  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_dst, __pyx_n_s_ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 449, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
-  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 447, __pyx_L1_error)
+  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(2, 449, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-  /* "View.MemoryView":445
+  /* "View.MemoryView":447
  *         cdef __Pyx_memviewslice src_slice
  * 
  *         memoryview_copy_contents(get_slice_from_memview(src, &src_slice)[0],             # <<<<<<<<<<<<<<
  *                                  get_slice_from_memview(dst, &dst_slice)[0],
  *                                  src.ndim, dst.ndim, self.dtype_is_object)
  */
-  __pyx_t_6 = __pyx_memoryview_copy_contents((__pyx_t_1[0]), (__pyx_t_2[0]), __pyx_t_4, __pyx_t_5, __pyx_v_self->dtype_is_object); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 445, __pyx_L1_error)
+  __pyx_t_6 = __pyx_memoryview_copy_contents((__pyx_t_1[0]), (__pyx_t_2[0]), __pyx_t_4, __pyx_t_5, __pyx_v_self->dtype_is_object); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 447, __pyx_L1_error)
 
-  /* "View.MemoryView":441
+  /* "View.MemoryView":443
  *         return obj
  * 
  *     cdef setitem_slice_assignment(self, dst, src):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice dst_slice
  *         cdef __Pyx_memviewslice src_slice
  */
 
@@ -12046,15 +12135,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":449
+/* "View.MemoryView":451
  *                                  src.ndim, dst.ndim, self.dtype_is_object)
  * 
  *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):             # <<<<<<<<<<<<<<
  *         cdef int array[128]
  *         cdef void *tmp = NULL
  */
 
@@ -12079,204 +12168,204 @@
   PyObject *__pyx_t_11 = NULL;
   PyObject *__pyx_t_12 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("setitem_slice_assign_scalar", 0);
 
-  /* "View.MemoryView":451
+  /* "View.MemoryView":453
  *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):
  *         cdef int array[128]
  *         cdef void *tmp = NULL             # <<<<<<<<<<<<<<
  *         cdef void *item
  * 
  */
   __pyx_v_tmp = NULL;
 
-  /* "View.MemoryView":456
+  /* "View.MemoryView":458
  *         cdef __Pyx_memviewslice *dst_slice
  *         cdef __Pyx_memviewslice tmp_slice
  *         dst_slice = get_slice_from_memview(dst, &tmp_slice)             # <<<<<<<<<<<<<<
  * 
  *         if <size_t>self.view.itemsize > sizeof(array):
  */
-  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_dst, (&__pyx_v_tmp_slice)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 456, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_dst, (&__pyx_v_tmp_slice)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 458, __pyx_L1_error)
   __pyx_v_dst_slice = __pyx_t_1;
 
-  /* "View.MemoryView":458
+  /* "View.MemoryView":460
  *         dst_slice = get_slice_from_memview(dst, &tmp_slice)
  * 
  *         if <size_t>self.view.itemsize > sizeof(array):             # <<<<<<<<<<<<<<
  *             tmp = PyMem_Malloc(self.view.itemsize)
  *             if tmp == NULL:
  */
   __pyx_t_2 = ((((size_t)__pyx_v_self->view.itemsize) > (sizeof(__pyx_v_array))) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":459
+    /* "View.MemoryView":461
  * 
  *         if <size_t>self.view.itemsize > sizeof(array):
  *             tmp = PyMem_Malloc(self.view.itemsize)             # <<<<<<<<<<<<<<
  *             if tmp == NULL:
  *                 raise MemoryError
  */
     __pyx_v_tmp = PyMem_Malloc(__pyx_v_self->view.itemsize);
 
-    /* "View.MemoryView":460
+    /* "View.MemoryView":462
  *         if <size_t>self.view.itemsize > sizeof(array):
  *             tmp = PyMem_Malloc(self.view.itemsize)
  *             if tmp == NULL:             # <<<<<<<<<<<<<<
  *                 raise MemoryError
  *             item = tmp
  */
     __pyx_t_2 = ((__pyx_v_tmp == NULL) != 0);
     if (unlikely(__pyx_t_2)) {
 
-      /* "View.MemoryView":461
+      /* "View.MemoryView":463
  *             tmp = PyMem_Malloc(self.view.itemsize)
  *             if tmp == NULL:
  *                 raise MemoryError             # <<<<<<<<<<<<<<
  *             item = tmp
  *         else:
  */
-      PyErr_NoMemory(); __PYX_ERR(2, 461, __pyx_L1_error)
+      PyErr_NoMemory(); __PYX_ERR(2, 463, __pyx_L1_error)
 
-      /* "View.MemoryView":460
+      /* "View.MemoryView":462
  *         if <size_t>self.view.itemsize > sizeof(array):
  *             tmp = PyMem_Malloc(self.view.itemsize)
  *             if tmp == NULL:             # <<<<<<<<<<<<<<
  *                 raise MemoryError
  *             item = tmp
  */
     }
 
-    /* "View.MemoryView":462
+    /* "View.MemoryView":464
  *             if tmp == NULL:
  *                 raise MemoryError
  *             item = tmp             # <<<<<<<<<<<<<<
  *         else:
  *             item = <void *> array
  */
     __pyx_v_item = __pyx_v_tmp;
 
-    /* "View.MemoryView":458
+    /* "View.MemoryView":460
  *         dst_slice = get_slice_from_memview(dst, &tmp_slice)
  * 
  *         if <size_t>self.view.itemsize > sizeof(array):             # <<<<<<<<<<<<<<
  *             tmp = PyMem_Malloc(self.view.itemsize)
  *             if tmp == NULL:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":464
+  /* "View.MemoryView":466
  *             item = tmp
  *         else:
  *             item = <void *> array             # <<<<<<<<<<<<<<
  * 
  *         try:
  */
   /*else*/ {
     __pyx_v_item = ((void *)__pyx_v_array);
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":466
+  /* "View.MemoryView":468
  *             item = <void *> array
  * 
  *         try:             # <<<<<<<<<<<<<<
  *             if self.dtype_is_object:
  *                 (<PyObject **> item)[0] = <PyObject *> value
  */
   /*try:*/ {
 
-    /* "View.MemoryView":467
+    /* "View.MemoryView":469
  * 
  *         try:
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 (<PyObject **> item)[0] = <PyObject *> value
  *             else:
  */
     __pyx_t_2 = (__pyx_v_self->dtype_is_object != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":468
+      /* "View.MemoryView":470
  *         try:
  *             if self.dtype_is_object:
  *                 (<PyObject **> item)[0] = <PyObject *> value             # <<<<<<<<<<<<<<
  *             else:
  *                 self.assign_item_from_object(<char *> item, value)
  */
       (((PyObject **)__pyx_v_item)[0]) = ((PyObject *)__pyx_v_value);
 
-      /* "View.MemoryView":467
+      /* "View.MemoryView":469
  * 
  *         try:
  *             if self.dtype_is_object:             # <<<<<<<<<<<<<<
  *                 (<PyObject **> item)[0] = <PyObject *> value
  *             else:
  */
       goto __pyx_L8;
     }
 
-    /* "View.MemoryView":470
+    /* "View.MemoryView":472
  *                 (<PyObject **> item)[0] = <PyObject *> value
  *             else:
  *                 self.assign_item_from_object(<char *> item, value)             # <<<<<<<<<<<<<<
  * 
  * 
  */
     /*else*/ {
-      __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, ((char *)__pyx_v_item), __pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 470, __pyx_L6_error)
+      __pyx_t_3 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, ((char *)__pyx_v_item), __pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 472, __pyx_L6_error)
       __Pyx_GOTREF(__pyx_t_3);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
     }
     __pyx_L8:;
 
-    /* "View.MemoryView":474
+    /* "View.MemoryView":476
  * 
  * 
  *             if self.view.suboffsets != NULL:             # <<<<<<<<<<<<<<
  *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
  *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
  */
     __pyx_t_2 = ((__pyx_v_self->view.suboffsets != NULL) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":475
+      /* "View.MemoryView":477
  * 
  *             if self.view.suboffsets != NULL:
  *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)             # <<<<<<<<<<<<<<
  *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
  *                                 item, self.dtype_is_object)
  */
-      __pyx_t_3 = assert_direct_dimensions(__pyx_v_self->view.suboffsets, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 475, __pyx_L6_error)
+      __pyx_t_3 = assert_direct_dimensions(__pyx_v_self->view.suboffsets, __pyx_v_self->view.ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 477, __pyx_L6_error)
       __Pyx_GOTREF(__pyx_t_3);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-      /* "View.MemoryView":474
+      /* "View.MemoryView":476
  * 
  * 
  *             if self.view.suboffsets != NULL:             # <<<<<<<<<<<<<<
  *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
  *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,
  */
     }
 
-    /* "View.MemoryView":476
+    /* "View.MemoryView":478
  *             if self.view.suboffsets != NULL:
  *                 assert_direct_dimensions(self.view.suboffsets, self.view.ndim)
  *             slice_assign_scalar(dst_slice, dst.view.ndim, self.view.itemsize,             # <<<<<<<<<<<<<<
  *                                 item, self.dtype_is_object)
  *         finally:
  */
     __pyx_memoryview_slice_assign_scalar(__pyx_v_dst_slice, __pyx_v_dst->view.ndim, __pyx_v_self->view.itemsize, __pyx_v_item, __pyx_v_self->dtype_is_object);
   }
 
-  /* "View.MemoryView":479
+  /* "View.MemoryView":481
  *                                 item, self.dtype_is_object)
  *         finally:
  *             PyMem_Free(tmp)             # <<<<<<<<<<<<<<
  * 
  *     cdef setitem_indexed(self, index, value):
  */
   /*finally:*/ {
@@ -12315,15 +12404,15 @@
       __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0;
       __pyx_lineno = __pyx_t_4; __pyx_clineno = __pyx_t_5; __pyx_filename = __pyx_t_6;
       goto __pyx_L1_error;
     }
     __pyx_L7:;
   }
 
-  /* "View.MemoryView":449
+  /* "View.MemoryView":451
  *                                  src.ndim, dst.ndim, self.dtype_is_object)
  * 
  *     cdef setitem_slice_assign_scalar(self, memoryview dst, value):             # <<<<<<<<<<<<<<
  *         cdef int array[128]
  *         cdef void *tmp = NULL
  */
 
@@ -12336,15 +12425,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":481
+/* "View.MemoryView":483
  *             PyMem_Free(tmp)
  * 
  *     cdef setitem_indexed(self, index, value):             # <<<<<<<<<<<<<<
  *         cdef char *itemp = self.get_item_pointer(index)
  *         self.assign_item_from_object(itemp, value)
  */
 
@@ -12355,36 +12444,36 @@
   char *__pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("setitem_indexed", 0);
 
-  /* "View.MemoryView":482
+  /* "View.MemoryView":484
  * 
  *     cdef setitem_indexed(self, index, value):
  *         cdef char *itemp = self.get_item_pointer(index)             # <<<<<<<<<<<<<<
  *         self.assign_item_from_object(itemp, value)
  * 
  */
-  __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_index); if (unlikely(__pyx_t_1 == ((char *)NULL))) __PYX_ERR(2, 482, __pyx_L1_error)
+  __pyx_t_1 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->get_item_pointer(__pyx_v_self, __pyx_v_index); if (unlikely(__pyx_t_1 == ((char *)NULL))) __PYX_ERR(2, 484, __pyx_L1_error)
   __pyx_v_itemp = __pyx_t_1;
 
-  /* "View.MemoryView":483
+  /* "View.MemoryView":485
  *     cdef setitem_indexed(self, index, value):
  *         cdef char *itemp = self.get_item_pointer(index)
  *         self.assign_item_from_object(itemp, value)             # <<<<<<<<<<<<<<
  * 
  *     cdef convert_item_to_object(self, char *itemp):
  */
-  __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 483, __pyx_L1_error)
+  __pyx_t_2 = ((struct __pyx_vtabstruct_memoryview *)__pyx_v_self->__pyx_vtab)->assign_item_from_object(__pyx_v_self, __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 485, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
-  /* "View.MemoryView":481
+  /* "View.MemoryView":483
  *             PyMem_Free(tmp)
  * 
  *     cdef setitem_indexed(self, index, value):             # <<<<<<<<<<<<<<
  *         cdef char *itemp = self.get_item_pointer(index)
  *         self.assign_item_from_object(itemp, value)
  */
 
@@ -12397,15 +12486,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":485
+/* "View.MemoryView":487
  *         self.assign_item_from_object(itemp, value)
  * 
  *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  */
 
@@ -12427,39 +12516,39 @@
   size_t __pyx_t_10;
   int __pyx_t_11;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("convert_item_to_object", 0);
 
-  /* "View.MemoryView":488
+  /* "View.MemoryView":490
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  *         import struct             # <<<<<<<<<<<<<<
  *         cdef bytes bytesitem
  * 
  */
-  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 488, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 490, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_v_struct = __pyx_t_1;
   __pyx_t_1 = 0;
 
-  /* "View.MemoryView":491
+  /* "View.MemoryView":493
  *         cdef bytes bytesitem
  * 
  *         bytesitem = itemp[:self.view.itemsize]             # <<<<<<<<<<<<<<
  *         try:
  *             result = struct.unpack(self.view.format, bytesitem)
  */
-  __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(__pyx_v_itemp + 0, __pyx_v_self->view.itemsize - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 491, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyBytes_FromStringAndSize(__pyx_v_itemp + 0, __pyx_v_self->view.itemsize - 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 493, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_v_bytesitem = ((PyObject*)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "View.MemoryView":492
+  /* "View.MemoryView":494
  * 
  *         bytesitem = itemp[:self.view.itemsize]
  *         try:             # <<<<<<<<<<<<<<
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:
  */
   {
@@ -12467,24 +12556,24 @@
     __Pyx_PyThreadState_assign
     __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
     __Pyx_XGOTREF(__pyx_t_2);
     __Pyx_XGOTREF(__pyx_t_3);
     __Pyx_XGOTREF(__pyx_t_4);
     /*try:*/ {
 
-      /* "View.MemoryView":493
+      /* "View.MemoryView":495
  *         bytesitem = itemp[:self.view.itemsize]
  *         try:
  *             result = struct.unpack(self.view.format, bytesitem)             # <<<<<<<<<<<<<<
  *         except struct.error:
  *             raise ValueError("Unable to convert item to object")
  */
-      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_unpack); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 493, __pyx_L3_error)
+      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_unpack); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 495, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_5);
-      __pyx_t_6 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 493, __pyx_L3_error)
+      __pyx_t_6 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 495, __pyx_L3_error)
       __Pyx_GOTREF(__pyx_t_6);
       __pyx_t_7 = NULL;
       __pyx_t_8 = 0;
       if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
         __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_5);
         if (likely(__pyx_t_7)) {
           PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
@@ -12493,94 +12582,94 @@
           __Pyx_DECREF_SET(__pyx_t_5, function);
           __pyx_t_8 = 1;
         }
       }
       #if CYTHON_FAST_PYCALL
       if (PyFunction_Check(__pyx_t_5)) {
         PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_t_6, __pyx_v_bytesitem};
-        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 493, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 495, __pyx_L3_error)
         __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       } else
       #endif
       #if CYTHON_FAST_PYCCALL
       if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
         PyObject *__pyx_temp[3] = {__pyx_t_7, __pyx_t_6, __pyx_v_bytesitem};
-        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 493, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_8, 2+__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 495, __pyx_L3_error)
         __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
       } else
       #endif
       {
-        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 493, __pyx_L3_error)
+        __pyx_t_9 = PyTuple_New(2+__pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 495, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_9);
         if (__pyx_t_7) {
           __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __pyx_t_7 = NULL;
         }
         __Pyx_GIVEREF(__pyx_t_6);
         PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_6);
         __Pyx_INCREF(__pyx_v_bytesitem);
         __Pyx_GIVEREF(__pyx_v_bytesitem);
         PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_v_bytesitem);
         __pyx_t_6 = 0;
-        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 493, __pyx_L3_error)
+        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_9, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 495, __pyx_L3_error)
         __Pyx_GOTREF(__pyx_t_1);
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       }
       __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
       __pyx_v_result = __pyx_t_1;
       __pyx_t_1 = 0;
 
-      /* "View.MemoryView":492
+      /* "View.MemoryView":494
  * 
  *         bytesitem = itemp[:self.view.itemsize]
  *         try:             # <<<<<<<<<<<<<<
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:
  */
     }
 
-    /* "View.MemoryView":497
+    /* "View.MemoryView":499
  *             raise ValueError("Unable to convert item to object")
  *         else:
  *             if len(self.view.format) == 1:             # <<<<<<<<<<<<<<
  *                 return result[0]
  *             return result
  */
     /*else:*/ {
       __pyx_t_10 = strlen(__pyx_v_self->view.format); 
       __pyx_t_11 = ((__pyx_t_10 == 1) != 0);
       if (__pyx_t_11) {
 
-        /* "View.MemoryView":498
+        /* "View.MemoryView":500
  *         else:
  *             if len(self.view.format) == 1:
  *                 return result[0]             # <<<<<<<<<<<<<<
  *             return result
  * 
  */
         __Pyx_XDECREF(__pyx_r);
-        __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_result, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 498, __pyx_L5_except_error)
+        __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_result, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 500, __pyx_L5_except_error)
         __Pyx_GOTREF(__pyx_t_1);
         __pyx_r = __pyx_t_1;
         __pyx_t_1 = 0;
         goto __pyx_L6_except_return;
 
-        /* "View.MemoryView":497
+        /* "View.MemoryView":499
  *             raise ValueError("Unable to convert item to object")
  *         else:
  *             if len(self.view.format) == 1:             # <<<<<<<<<<<<<<
  *                 return result[0]
  *             return result
  */
       }
 
-      /* "View.MemoryView":499
+      /* "View.MemoryView":501
  *             if len(self.view.format) == 1:
  *                 return result[0]
  *             return result             # <<<<<<<<<<<<<<
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):
  */
       __Pyx_XDECREF(__pyx_r);
@@ -12591,52 +12680,52 @@
     __pyx_L3_error:;
     __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
     __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
     __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
     __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
 
-    /* "View.MemoryView":494
+    /* "View.MemoryView":496
  *         try:
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:             # <<<<<<<<<<<<<<
  *             raise ValueError("Unable to convert item to object")
  *         else:
  */
     __Pyx_ErrFetch(&__pyx_t_1, &__pyx_t_5, &__pyx_t_9);
-    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_error); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 494, __pyx_L5_except_error)
+    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_error); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 496, __pyx_L5_except_error)
     __Pyx_GOTREF(__pyx_t_6);
     __pyx_t_8 = __Pyx_PyErr_GivenExceptionMatches(__pyx_t_1, __pyx_t_6);
     __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
     __Pyx_ErrRestore(__pyx_t_1, __pyx_t_5, __pyx_t_9);
     __pyx_t_1 = 0; __pyx_t_5 = 0; __pyx_t_9 = 0;
     if (__pyx_t_8) {
       __Pyx_AddTraceback("View.MemoryView.memoryview.convert_item_to_object", __pyx_clineno, __pyx_lineno, __pyx_filename);
-      if (__Pyx_GetException(&__pyx_t_9, &__pyx_t_5, &__pyx_t_1) < 0) __PYX_ERR(2, 494, __pyx_L5_except_error)
+      if (__Pyx_GetException(&__pyx_t_9, &__pyx_t_5, &__pyx_t_1) < 0) __PYX_ERR(2, 496, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_9);
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_GOTREF(__pyx_t_1);
 
-      /* "View.MemoryView":495
+      /* "View.MemoryView":497
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:
  *             raise ValueError("Unable to convert item to object")             # <<<<<<<<<<<<<<
  *         else:
  *             if len(self.view.format) == 1:
  */
-      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 495, __pyx_L5_except_error)
+      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 497, __pyx_L5_except_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_Raise(__pyx_t_6, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
-      __PYX_ERR(2, 495, __pyx_L5_except_error)
+      __PYX_ERR(2, 497, __pyx_L5_except_error)
     }
     goto __pyx_L5_except_error;
     __pyx_L5_except_error:;
 
-    /* "View.MemoryView":492
+    /* "View.MemoryView":494
  * 
  *         bytesitem = itemp[:self.view.itemsize]
  *         try:             # <<<<<<<<<<<<<<
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:
  */
     __Pyx_XGIVEREF(__pyx_t_2);
@@ -12648,15 +12737,15 @@
     __Pyx_XGIVEREF(__pyx_t_2);
     __Pyx_XGIVEREF(__pyx_t_3);
     __Pyx_XGIVEREF(__pyx_t_4);
     __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":485
+  /* "View.MemoryView":487
  *         self.assign_item_from_object(itemp, value)
  * 
  *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  */
 
@@ -12674,15 +12763,15 @@
   __Pyx_XDECREF(__pyx_v_bytesitem);
   __Pyx_XDECREF(__pyx_v_result);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":501
+/* "View.MemoryView":503
  *             return result
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  */
 
@@ -12708,88 +12797,88 @@
   char *__pyx_t_13;
   char *__pyx_t_14;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("assign_item_from_object", 0);
 
-  /* "View.MemoryView":504
+  /* "View.MemoryView":506
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  *         import struct             # <<<<<<<<<<<<<<
  *         cdef char c
  *         cdef bytes bytesvalue
  */
-  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 504, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_Import(__pyx_n_s_struct, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 506, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_v_struct = __pyx_t_1;
   __pyx_t_1 = 0;
 
-  /* "View.MemoryView":509
+  /* "View.MemoryView":511
  *         cdef Py_ssize_t i
  * 
  *         if isinstance(value, tuple):             # <<<<<<<<<<<<<<
  *             bytesvalue = struct.pack(self.view.format, *value)
  *         else:
  */
   __pyx_t_2 = PyTuple_Check(__pyx_v_value); 
   __pyx_t_3 = (__pyx_t_2 != 0);
   if (__pyx_t_3) {
 
-    /* "View.MemoryView":510
+    /* "View.MemoryView":512
  * 
  *         if isinstance(value, tuple):
  *             bytesvalue = struct.pack(self.view.format, *value)             # <<<<<<<<<<<<<<
  *         else:
  *             bytesvalue = struct.pack(self.view.format, value)
  */
-    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
-    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
     __Pyx_GIVEREF(__pyx_t_4);
     PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4);
     __pyx_t_4 = 0;
-    __pyx_t_4 = __Pyx_PySequence_Tuple(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PySequence_Tuple(__pyx_v_value); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_6 = PyNumber_Add(__pyx_t_5, __pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_6 = PyNumber_Add(__pyx_t_5, __pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
     __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 510, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_6, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
-    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 510, __pyx_L1_error)
+    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 512, __pyx_L1_error)
     __pyx_v_bytesvalue = ((PyObject*)__pyx_t_4);
     __pyx_t_4 = 0;
 
-    /* "View.MemoryView":509
+    /* "View.MemoryView":511
  *         cdef Py_ssize_t i
  * 
  *         if isinstance(value, tuple):             # <<<<<<<<<<<<<<
  *             bytesvalue = struct.pack(self.view.format, *value)
  *         else:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":512
+  /* "View.MemoryView":514
  *             bytesvalue = struct.pack(self.view.format, *value)
  *         else:
  *             bytesvalue = struct.pack(self.view.format, value)             # <<<<<<<<<<<<<<
  * 
  *         for i, c in enumerate(bytesvalue):
  */
   /*else*/ {
-    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 512, __pyx_L1_error)
+    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_v_struct, __pyx_n_s_pack); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 514, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
-    __pyx_t_1 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 512, __pyx_L1_error)
+    __pyx_t_1 = __Pyx_PyBytes_FromString(__pyx_v_self->view.format); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 514, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_1);
     __pyx_t_5 = NULL;
     __pyx_t_7 = 0;
     if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
       __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
       if (likely(__pyx_t_5)) {
         PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
@@ -12798,102 +12887,102 @@
         __Pyx_DECREF_SET(__pyx_t_6, function);
         __pyx_t_7 = 1;
       }
     }
     #if CYTHON_FAST_PYCALL
     if (PyFunction_Check(__pyx_t_6)) {
       PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_1, __pyx_v_value};
-      __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
+      __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 514, __pyx_L1_error)
       __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
       __Pyx_GOTREF(__pyx_t_4);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
     } else
     #endif
     #if CYTHON_FAST_PYCCALL
     if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
       PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_t_1, __pyx_v_value};
-      __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
+      __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 514, __pyx_L1_error)
       __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
       __Pyx_GOTREF(__pyx_t_4);
       __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
     } else
     #endif
     {
-      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 512, __pyx_L1_error)
+      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 514, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_8);
       if (__pyx_t_5) {
         __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_5); __pyx_t_5 = NULL;
       }
       __Pyx_GIVEREF(__pyx_t_1);
       PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_1);
       __Pyx_INCREF(__pyx_v_value);
       __Pyx_GIVEREF(__pyx_v_value);
       PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_v_value);
       __pyx_t_1 = 0;
-      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_8, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 512, __pyx_L1_error)
+      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_8, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 514, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_4);
       __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
     }
     __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
-    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 512, __pyx_L1_error)
+    if (!(likely(PyBytes_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_4)->tp_name), 0))) __PYX_ERR(2, 514, __pyx_L1_error)
     __pyx_v_bytesvalue = ((PyObject*)__pyx_t_4);
     __pyx_t_4 = 0;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":514
+  /* "View.MemoryView":516
  *             bytesvalue = struct.pack(self.view.format, value)
  * 
  *         for i, c in enumerate(bytesvalue):             # <<<<<<<<<<<<<<
  *             itemp[i] = c
  * 
  */
   __pyx_t_9 = 0;
   if (unlikely(__pyx_v_bytesvalue == Py_None)) {
     PyErr_SetString(PyExc_TypeError, "'NoneType' is not iterable");
-    __PYX_ERR(2, 514, __pyx_L1_error)
+    __PYX_ERR(2, 516, __pyx_L1_error)
   }
   __Pyx_INCREF(__pyx_v_bytesvalue);
   __pyx_t_10 = __pyx_v_bytesvalue;
   __pyx_t_12 = PyBytes_AS_STRING(__pyx_t_10);
   __pyx_t_13 = (__pyx_t_12 + PyBytes_GET_SIZE(__pyx_t_10));
   for (__pyx_t_14 = __pyx_t_12; __pyx_t_14 < __pyx_t_13; __pyx_t_14++) {
     __pyx_t_11 = __pyx_t_14;
     __pyx_v_c = (__pyx_t_11[0]);
 
-    /* "View.MemoryView":515
+    /* "View.MemoryView":517
  * 
  *         for i, c in enumerate(bytesvalue):
  *             itemp[i] = c             # <<<<<<<<<<<<<<
  * 
  *     @cname('getbuffer')
  */
     __pyx_v_i = __pyx_t_9;
 
-    /* "View.MemoryView":514
+    /* "View.MemoryView":516
  *             bytesvalue = struct.pack(self.view.format, value)
  * 
  *         for i, c in enumerate(bytesvalue):             # <<<<<<<<<<<<<<
  *             itemp[i] = c
  * 
  */
     __pyx_t_9 = (__pyx_t_9 + 1);
 
-    /* "View.MemoryView":515
+    /* "View.MemoryView":517
  * 
  *         for i, c in enumerate(bytesvalue):
  *             itemp[i] = c             # <<<<<<<<<<<<<<
  * 
  *     @cname('getbuffer')
  */
     (__pyx_v_itemp[__pyx_v_i]) = __pyx_v_c;
   }
   __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
 
-  /* "View.MemoryView":501
+  /* "View.MemoryView":503
  *             return result
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
  *         """Only used if instantiated manually by the user, or if Cython doesn't
  *         know how to convert the type"""
  */
 
@@ -12913,15 +13002,15 @@
   __Pyx_XDECREF(__pyx_v_struct);
   __Pyx_XDECREF(__pyx_v_bytesvalue);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":518
+/* "View.MemoryView":520
  * 
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
  *         if flags & PyBUF_WRITABLE and self.view.readonly:
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  */
 
@@ -12956,15 +13045,15 @@
     PyErr_SetString(PyExc_BufferError, "PyObject_GetBuffer: view==NULL argument is obsolete");
     return -1;
   }
   __Pyx_RefNannySetupContext("__getbuffer__", 0);
   __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
   __Pyx_GIVEREF(__pyx_v_info->obj);
 
-  /* "View.MemoryView":519
+  /* "View.MemoryView":521
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         if flags & PyBUF_WRITABLE and self.view.readonly:             # <<<<<<<<<<<<<<
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  * 
  */
   __pyx_t_2 = ((__pyx_v_flags & PyBUF_WRITABLE) != 0);
@@ -12974,268 +13063,268 @@
     goto __pyx_L4_bool_binop_done;
   }
   __pyx_t_2 = (__pyx_v_self->view.readonly != 0);
   __pyx_t_1 = __pyx_t_2;
   __pyx_L4_bool_binop_done:;
   if (unlikely(__pyx_t_1)) {
 
-    /* "View.MemoryView":520
+    /* "View.MemoryView":522
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         if flags & PyBUF_WRITABLE and self.view.readonly:
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_ND:
  */
-    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 520, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 522, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 520, __pyx_L1_error)
+    __PYX_ERR(2, 522, __pyx_L1_error)
 
-    /* "View.MemoryView":519
+    /* "View.MemoryView":521
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         if flags & PyBUF_WRITABLE and self.view.readonly:             # <<<<<<<<<<<<<<
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  * 
  */
   }
 
-  /* "View.MemoryView":522
+  /* "View.MemoryView":524
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  * 
  *         if flags & PyBUF_ND:             # <<<<<<<<<<<<<<
  *             info.shape = self.view.shape
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_ND) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":523
+    /* "View.MemoryView":525
  * 
  *         if flags & PyBUF_ND:
  *             info.shape = self.view.shape             # <<<<<<<<<<<<<<
  *         else:
  *             info.shape = NULL
  */
     __pyx_t_4 = __pyx_v_self->view.shape;
     __pyx_v_info->shape = __pyx_t_4;
 
-    /* "View.MemoryView":522
+    /* "View.MemoryView":524
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  * 
  *         if flags & PyBUF_ND:             # <<<<<<<<<<<<<<
  *             info.shape = self.view.shape
  *         else:
  */
     goto __pyx_L6;
   }
 
-  /* "View.MemoryView":525
+  /* "View.MemoryView":527
  *             info.shape = self.view.shape
  *         else:
  *             info.shape = NULL             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_STRIDES:
  */
   /*else*/ {
     __pyx_v_info->shape = NULL;
   }
   __pyx_L6:;
 
-  /* "View.MemoryView":527
+  /* "View.MemoryView":529
  *             info.shape = NULL
  * 
  *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
  *             info.strides = self.view.strides
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_STRIDES) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":528
+    /* "View.MemoryView":530
  * 
  *         if flags & PyBUF_STRIDES:
  *             info.strides = self.view.strides             # <<<<<<<<<<<<<<
  *         else:
  *             info.strides = NULL
  */
     __pyx_t_4 = __pyx_v_self->view.strides;
     __pyx_v_info->strides = __pyx_t_4;
 
-    /* "View.MemoryView":527
+    /* "View.MemoryView":529
  *             info.shape = NULL
  * 
  *         if flags & PyBUF_STRIDES:             # <<<<<<<<<<<<<<
  *             info.strides = self.view.strides
  *         else:
  */
     goto __pyx_L7;
   }
 
-  /* "View.MemoryView":530
+  /* "View.MemoryView":532
  *             info.strides = self.view.strides
  *         else:
  *             info.strides = NULL             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_INDIRECT:
  */
   /*else*/ {
     __pyx_v_info->strides = NULL;
   }
   __pyx_L7:;
 
-  /* "View.MemoryView":532
+  /* "View.MemoryView":534
  *             info.strides = NULL
  * 
  *         if flags & PyBUF_INDIRECT:             # <<<<<<<<<<<<<<
  *             info.suboffsets = self.view.suboffsets
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_INDIRECT) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":533
+    /* "View.MemoryView":535
  * 
  *         if flags & PyBUF_INDIRECT:
  *             info.suboffsets = self.view.suboffsets             # <<<<<<<<<<<<<<
  *         else:
  *             info.suboffsets = NULL
  */
     __pyx_t_4 = __pyx_v_self->view.suboffsets;
     __pyx_v_info->suboffsets = __pyx_t_4;
 
-    /* "View.MemoryView":532
+    /* "View.MemoryView":534
  *             info.strides = NULL
  * 
  *         if flags & PyBUF_INDIRECT:             # <<<<<<<<<<<<<<
  *             info.suboffsets = self.view.suboffsets
  *         else:
  */
     goto __pyx_L8;
   }
 
-  /* "View.MemoryView":535
+  /* "View.MemoryView":537
  *             info.suboffsets = self.view.suboffsets
  *         else:
  *             info.suboffsets = NULL             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_FORMAT:
  */
   /*else*/ {
     __pyx_v_info->suboffsets = NULL;
   }
   __pyx_L8:;
 
-  /* "View.MemoryView":537
+  /* "View.MemoryView":539
  *             info.suboffsets = NULL
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             info.format = self.view.format
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_flags & PyBUF_FORMAT) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":538
+    /* "View.MemoryView":540
  * 
  *         if flags & PyBUF_FORMAT:
  *             info.format = self.view.format             # <<<<<<<<<<<<<<
  *         else:
  *             info.format = NULL
  */
     __pyx_t_5 = __pyx_v_self->view.format;
     __pyx_v_info->format = __pyx_t_5;
 
-    /* "View.MemoryView":537
+    /* "View.MemoryView":539
  *             info.suboffsets = NULL
  * 
  *         if flags & PyBUF_FORMAT:             # <<<<<<<<<<<<<<
  *             info.format = self.view.format
  *         else:
  */
     goto __pyx_L9;
   }
 
-  /* "View.MemoryView":540
+  /* "View.MemoryView":542
  *             info.format = self.view.format
  *         else:
  *             info.format = NULL             # <<<<<<<<<<<<<<
  * 
  *         info.buf = self.view.buf
  */
   /*else*/ {
     __pyx_v_info->format = NULL;
   }
   __pyx_L9:;
 
-  /* "View.MemoryView":542
+  /* "View.MemoryView":544
  *             info.format = NULL
  * 
  *         info.buf = self.view.buf             # <<<<<<<<<<<<<<
  *         info.ndim = self.view.ndim
  *         info.itemsize = self.view.itemsize
  */
   __pyx_t_6 = __pyx_v_self->view.buf;
   __pyx_v_info->buf = __pyx_t_6;
 
-  /* "View.MemoryView":543
+  /* "View.MemoryView":545
  * 
  *         info.buf = self.view.buf
  *         info.ndim = self.view.ndim             # <<<<<<<<<<<<<<
  *         info.itemsize = self.view.itemsize
  *         info.len = self.view.len
  */
   __pyx_t_7 = __pyx_v_self->view.ndim;
   __pyx_v_info->ndim = __pyx_t_7;
 
-  /* "View.MemoryView":544
+  /* "View.MemoryView":546
  *         info.buf = self.view.buf
  *         info.ndim = self.view.ndim
  *         info.itemsize = self.view.itemsize             # <<<<<<<<<<<<<<
  *         info.len = self.view.len
  *         info.readonly = self.view.readonly
  */
   __pyx_t_8 = __pyx_v_self->view.itemsize;
   __pyx_v_info->itemsize = __pyx_t_8;
 
-  /* "View.MemoryView":545
+  /* "View.MemoryView":547
  *         info.ndim = self.view.ndim
  *         info.itemsize = self.view.itemsize
  *         info.len = self.view.len             # <<<<<<<<<<<<<<
  *         info.readonly = self.view.readonly
  *         info.obj = self
  */
   __pyx_t_8 = __pyx_v_self->view.len;
   __pyx_v_info->len = __pyx_t_8;
 
-  /* "View.MemoryView":546
+  /* "View.MemoryView":548
  *         info.itemsize = self.view.itemsize
  *         info.len = self.view.len
  *         info.readonly = self.view.readonly             # <<<<<<<<<<<<<<
  *         info.obj = self
  * 
  */
   __pyx_t_1 = __pyx_v_self->view.readonly;
   __pyx_v_info->readonly = __pyx_t_1;
 
-  /* "View.MemoryView":547
+  /* "View.MemoryView":549
  *         info.len = self.view.len
  *         info.readonly = self.view.readonly
  *         info.obj = self             # <<<<<<<<<<<<<<
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")
  */
   __Pyx_INCREF(((PyObject *)__pyx_v_self));
   __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
   __Pyx_GOTREF(__pyx_v_info->obj);
   __Pyx_DECREF(__pyx_v_info->obj);
   __pyx_v_info->obj = ((PyObject *)__pyx_v_self);
 
-  /* "View.MemoryView":518
+  /* "View.MemoryView":520
  * 
  *     @cname('getbuffer')
  *     def __getbuffer__(self, Py_buffer *info, int flags):             # <<<<<<<<<<<<<<
  *         if flags & PyBUF_WRITABLE and self.view.readonly:
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")
  */
 
@@ -13257,15 +13346,15 @@
     __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = 0;
   }
   __pyx_L2:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":553
+/* "View.MemoryView":555
  * 
  *     @property
  *     def T(self):             # <<<<<<<<<<<<<<
  *         cdef _memoryviewslice result = memoryview_copy(self)
  *         transpose_memslice(&result.from_slice)
  */
 
@@ -13289,49 +13378,49 @@
   PyObject *__pyx_t_1 = NULL;
   int __pyx_t_2;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":554
+  /* "View.MemoryView":556
  *     @property
  *     def T(self):
  *         cdef _memoryviewslice result = memoryview_copy(self)             # <<<<<<<<<<<<<<
  *         transpose_memslice(&result.from_slice)
  *         return result
  */
-  __pyx_t_1 = __pyx_memoryview_copy_object(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 554, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_copy_object(__pyx_v_self); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 556, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_memoryviewslice_type))))) __PYX_ERR(2, 554, __pyx_L1_error)
+  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_memoryviewslice_type))))) __PYX_ERR(2, 556, __pyx_L1_error)
   __pyx_v_result = ((struct __pyx_memoryviewslice_obj *)__pyx_t_1);
   __pyx_t_1 = 0;
 
-  /* "View.MemoryView":555
+  /* "View.MemoryView":557
  *     def T(self):
  *         cdef _memoryviewslice result = memoryview_copy(self)
  *         transpose_memslice(&result.from_slice)             # <<<<<<<<<<<<<<
  *         return result
  * 
  */
-  __pyx_t_2 = __pyx_memslice_transpose((&__pyx_v_result->from_slice)); if (unlikely(__pyx_t_2 == ((int)0))) __PYX_ERR(2, 555, __pyx_L1_error)
+  __pyx_t_2 = __pyx_memslice_transpose((&__pyx_v_result->from_slice)); if (unlikely(__pyx_t_2 == ((int)0))) __PYX_ERR(2, 557, __pyx_L1_error)
 
-  /* "View.MemoryView":556
+  /* "View.MemoryView":558
  *         cdef _memoryviewslice result = memoryview_copy(self)
  *         transpose_memslice(&result.from_slice)
  *         return result             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(((PyObject *)__pyx_v_result));
   __pyx_r = ((PyObject *)__pyx_v_result);
   goto __pyx_L0;
 
-  /* "View.MemoryView":553
+  /* "View.MemoryView":555
  * 
  *     @property
  *     def T(self):             # <<<<<<<<<<<<<<
  *         cdef _memoryviewslice result = memoryview_copy(self)
  *         transpose_memslice(&result.from_slice)
  */
 
@@ -13343,15 +13432,15 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_result);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":559
+/* "View.MemoryView":561
  * 
  *     @property
  *     def base(self):             # <<<<<<<<<<<<<<
  *         return self.obj
  * 
  */
 
@@ -13369,42 +13458,42 @@
 }
 
 static PyObject *__pyx_pf_15View_dot_MemoryView_10memoryview_4base___get__(struct __pyx_memoryview_obj *__pyx_v_self) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":560
+  /* "View.MemoryView":562
  *     @property
  *     def base(self):
  *         return self.obj             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(__pyx_v_self->obj);
   __pyx_r = __pyx_v_self->obj;
   goto __pyx_L0;
 
-  /* "View.MemoryView":559
+  /* "View.MemoryView":561
  * 
  *     @property
  *     def base(self):             # <<<<<<<<<<<<<<
  *         return self.obj
  * 
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":563
+/* "View.MemoryView":565
  * 
  *     @property
  *     def shape(self):             # <<<<<<<<<<<<<<
  *         return tuple([length for length in self.view.shape[:self.view.ndim]])
  * 
  */
 
@@ -13431,41 +13520,41 @@
   Py_ssize_t *__pyx_t_4;
   PyObject *__pyx_t_5 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":564
+  /* "View.MemoryView":566
  *     @property
  *     def shape(self):
  *         return tuple([length for length in self.view.shape[:self.view.ndim]])             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 564, __pyx_L1_error)
+  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 566, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_t_3 = (__pyx_v_self->view.shape + __pyx_v_self->view.ndim);
   for (__pyx_t_4 = __pyx_v_self->view.shape; __pyx_t_4 < __pyx_t_3; __pyx_t_4++) {
     __pyx_t_2 = __pyx_t_4;
     __pyx_v_length = (__pyx_t_2[0]);
-    __pyx_t_5 = PyInt_FromSsize_t(__pyx_v_length); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 564, __pyx_L1_error)
+    __pyx_t_5 = PyInt_FromSsize_t(__pyx_v_length); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 566, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_5);
-    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(2, 564, __pyx_L1_error)
+    if (unlikely(__Pyx_ListComp_Append(__pyx_t_1, (PyObject*)__pyx_t_5))) __PYX_ERR(2, 566, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
   }
-  __pyx_t_5 = PyList_AsTuple(((PyObject*)__pyx_t_1)); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 564, __pyx_L1_error)
+  __pyx_t_5 = PyList_AsTuple(((PyObject*)__pyx_t_1)); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 566, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __pyx_r = __pyx_t_5;
   __pyx_t_5 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":563
+  /* "View.MemoryView":565
  * 
  *     @property
  *     def shape(self):             # <<<<<<<<<<<<<<
  *         return tuple([length for length in self.view.shape[:self.view.ndim]])
  * 
  */
 
@@ -13477,15 +13566,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":567
+/* "View.MemoryView":569
  * 
  *     @property
  *     def strides(self):             # <<<<<<<<<<<<<<
  *         if self.view.strides == NULL:
  * 
  */
 
@@ -13513,73 +13602,73 @@
   Py_ssize_t *__pyx_t_5;
   PyObject *__pyx_t_6 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":568
+  /* "View.MemoryView":570
  *     @property
  *     def strides(self):
  *         if self.view.strides == NULL:             # <<<<<<<<<<<<<<
  * 
  *             raise ValueError("Buffer view does not expose strides")
  */
   __pyx_t_1 = ((__pyx_v_self->view.strides == NULL) != 0);
   if (unlikely(__pyx_t_1)) {
 
-    /* "View.MemoryView":570
+    /* "View.MemoryView":572
  *         if self.view.strides == NULL:
  * 
  *             raise ValueError("Buffer view does not expose strides")             # <<<<<<<<<<<<<<
  * 
  *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])
  */
-    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 570, __pyx_L1_error)
+    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 572, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_Raise(__pyx_t_2, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __PYX_ERR(2, 570, __pyx_L1_error)
+    __PYX_ERR(2, 572, __pyx_L1_error)
 
-    /* "View.MemoryView":568
+    /* "View.MemoryView":570
  *     @property
  *     def strides(self):
  *         if self.view.strides == NULL:             # <<<<<<<<<<<<<<
  * 
  *             raise ValueError("Buffer view does not expose strides")
  */
   }
 
-  /* "View.MemoryView":572
+  /* "View.MemoryView":574
  *             raise ValueError("Buffer view does not expose strides")
  * 
  *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 572, __pyx_L1_error)
+  __pyx_t_2 = PyList_New(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 574, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_t_4 = (__pyx_v_self->view.strides + __pyx_v_self->view.ndim);
   for (__pyx_t_5 = __pyx_v_self->view.strides; __pyx_t_5 < __pyx_t_4; __pyx_t_5++) {
     __pyx_t_3 = __pyx_t_5;
     __pyx_v_stride = (__pyx_t_3[0]);
-    __pyx_t_6 = PyInt_FromSsize_t(__pyx_v_stride); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 572, __pyx_L1_error)
+    __pyx_t_6 = PyInt_FromSsize_t(__pyx_v_stride); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 574, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_6);
-    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_6))) __PYX_ERR(2, 572, __pyx_L1_error)
+    if (unlikely(__Pyx_ListComp_Append(__pyx_t_2, (PyObject*)__pyx_t_6))) __PYX_ERR(2, 574, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
   }
-  __pyx_t_6 = PyList_AsTuple(((PyObject*)__pyx_t_2)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 572, __pyx_L1_error)
+  __pyx_t_6 = PyList_AsTuple(((PyObject*)__pyx_t_2)); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 574, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_6);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   __pyx_r = __pyx_t_6;
   __pyx_t_6 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":567
+  /* "View.MemoryView":569
  * 
  *     @property
  *     def strides(self):             # <<<<<<<<<<<<<<
  *         if self.view.strides == NULL:
  * 
  */
 
@@ -13591,15 +13680,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":575
+/* "View.MemoryView":577
  * 
  *     @property
  *     def suboffsets(self):             # <<<<<<<<<<<<<<
  *         if self.view.suboffsets == NULL:
  *             return (-1,) * self.view.ndim
  */
 
@@ -13627,77 +13716,77 @@
   Py_ssize_t *__pyx_t_5;
   Py_ssize_t *__pyx_t_6;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":576
+  /* "View.MemoryView":578
  *     @property
  *     def suboffsets(self):
  *         if self.view.suboffsets == NULL:             # <<<<<<<<<<<<<<
  *             return (-1,) * self.view.ndim
  * 
  */
   __pyx_t_1 = ((__pyx_v_self->view.suboffsets == NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":577
+    /* "View.MemoryView":579
  *     def suboffsets(self):
  *         if self.view.suboffsets == NULL:
  *             return (-1,) * self.view.ndim             # <<<<<<<<<<<<<<
  * 
  *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 577, __pyx_L1_error)
+    __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 579, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
-    __pyx_t_3 = PyNumber_Multiply(__pyx_tuple__18, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 577, __pyx_L1_error)
+    __pyx_t_3 = PyNumber_Multiply(__pyx_tuple__18, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 579, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
     __pyx_r = __pyx_t_3;
     __pyx_t_3 = 0;
     goto __pyx_L0;
 
-    /* "View.MemoryView":576
+    /* "View.MemoryView":578
  *     @property
  *     def suboffsets(self):
  *         if self.view.suboffsets == NULL:             # <<<<<<<<<<<<<<
  *             return (-1,) * self.view.ndim
  * 
  */
   }
 
-  /* "View.MemoryView":579
+  /* "View.MemoryView":581
  *             return (-1,) * self.view.ndim
  * 
  *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 579, __pyx_L1_error)
+  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 581, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __pyx_t_5 = (__pyx_v_self->view.suboffsets + __pyx_v_self->view.ndim);
   for (__pyx_t_6 = __pyx_v_self->view.suboffsets; __pyx_t_6 < __pyx_t_5; __pyx_t_6++) {
     __pyx_t_4 = __pyx_t_6;
     __pyx_v_suboffset = (__pyx_t_4[0]);
-    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_suboffset); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 579, __pyx_L1_error)
+    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_suboffset); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 581, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
-    if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_t_2))) __PYX_ERR(2, 579, __pyx_L1_error)
+    if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_t_2))) __PYX_ERR(2, 581, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   }
-  __pyx_t_2 = PyList_AsTuple(((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 579, __pyx_L1_error)
+  __pyx_t_2 = PyList_AsTuple(((PyObject*)__pyx_t_3)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 581, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":575
+  /* "View.MemoryView":577
  * 
  *     @property
  *     def suboffsets(self):             # <<<<<<<<<<<<<<
  *         if self.view.suboffsets == NULL:
  *             return (-1,) * self.view.ndim
  */
 
@@ -13709,15 +13798,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":582
+/* "View.MemoryView":584
  * 
  *     @property
  *     def ndim(self):             # <<<<<<<<<<<<<<
  *         return self.view.ndim
  * 
  */
 
@@ -13739,29 +13828,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":583
+  /* "View.MemoryView":585
  *     @property
  *     def ndim(self):
  *         return self.view.ndim             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 583, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->view.ndim); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 585, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":582
+  /* "View.MemoryView":584
  * 
  *     @property
  *     def ndim(self):             # <<<<<<<<<<<<<<
  *         return self.view.ndim
  * 
  */
 
@@ -13772,15 +13861,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":586
+/* "View.MemoryView":588
  * 
  *     @property
  *     def itemsize(self):             # <<<<<<<<<<<<<<
  *         return self.view.itemsize
  * 
  */
 
@@ -13802,29 +13891,29 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":587
+  /* "View.MemoryView":589
  *     @property
  *     def itemsize(self):
  *         return self.view.itemsize             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 587, __pyx_L1_error)
+  __pyx_t_1 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 589, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":586
+  /* "View.MemoryView":588
  * 
  *     @property
  *     def itemsize(self):             # <<<<<<<<<<<<<<
  *         return self.view.itemsize
  * 
  */
 
@@ -13835,15 +13924,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":590
+/* "View.MemoryView":592
  * 
  *     @property
  *     def nbytes(self):             # <<<<<<<<<<<<<<
  *         return self.size * self.view.itemsize
  * 
  */
 
@@ -13867,35 +13956,35 @@
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":591
+  /* "View.MemoryView":593
  *     @property
  *     def nbytes(self):
  *         return self.size * self.view.itemsize             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 591, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 593, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 591, __pyx_L1_error)
+  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_self->view.itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 593, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 591, __pyx_L1_error)
+  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 593, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   __pyx_r = __pyx_t_3;
   __pyx_t_3 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":590
+  /* "View.MemoryView":592
  * 
  *     @property
  *     def nbytes(self):             # <<<<<<<<<<<<<<
  *         return self.size * self.view.itemsize
  * 
  */
 
@@ -13908,15 +13997,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":594
+/* "View.MemoryView":596
  * 
  *     @property
  *     def size(self):             # <<<<<<<<<<<<<<
  *         if self._size is None:
  *             result = 1
  */
 
@@ -13945,98 +14034,98 @@
   Py_ssize_t *__pyx_t_5;
   PyObject *__pyx_t_6 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":595
+  /* "View.MemoryView":597
  *     @property
  *     def size(self):
  *         if self._size is None:             # <<<<<<<<<<<<<<
  *             result = 1
  * 
  */
   __pyx_t_1 = (__pyx_v_self->_size == Py_None);
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":596
+    /* "View.MemoryView":598
  *     def size(self):
  *         if self._size is None:
  *             result = 1             # <<<<<<<<<<<<<<
  * 
  *             for length in self.view.shape[:self.view.ndim]:
  */
     __Pyx_INCREF(__pyx_int_1);
     __pyx_v_result = __pyx_int_1;
 
-    /* "View.MemoryView":598
+    /* "View.MemoryView":600
  *             result = 1
  * 
  *             for length in self.view.shape[:self.view.ndim]:             # <<<<<<<<<<<<<<
  *                 result *= length
  * 
  */
     __pyx_t_4 = (__pyx_v_self->view.shape + __pyx_v_self->view.ndim);
     for (__pyx_t_5 = __pyx_v_self->view.shape; __pyx_t_5 < __pyx_t_4; __pyx_t_5++) {
       __pyx_t_3 = __pyx_t_5;
-      __pyx_t_6 = PyInt_FromSsize_t((__pyx_t_3[0])); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 598, __pyx_L1_error)
+      __pyx_t_6 = PyInt_FromSsize_t((__pyx_t_3[0])); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 600, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_XDECREF_SET(__pyx_v_length, __pyx_t_6);
       __pyx_t_6 = 0;
 
-      /* "View.MemoryView":599
+      /* "View.MemoryView":601
  * 
  *             for length in self.view.shape[:self.view.ndim]:
  *                 result *= length             # <<<<<<<<<<<<<<
  * 
  *             self._size = result
  */
-      __pyx_t_6 = PyNumber_InPlaceMultiply(__pyx_v_result, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 599, __pyx_L1_error)
+      __pyx_t_6 = PyNumber_InPlaceMultiply(__pyx_v_result, __pyx_v_length); if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 601, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_6);
       __Pyx_DECREF_SET(__pyx_v_result, __pyx_t_6);
       __pyx_t_6 = 0;
     }
 
-    /* "View.MemoryView":601
+    /* "View.MemoryView":603
  *                 result *= length
  * 
  *             self._size = result             # <<<<<<<<<<<<<<
  * 
  *         return self._size
  */
     __Pyx_INCREF(__pyx_v_result);
     __Pyx_GIVEREF(__pyx_v_result);
     __Pyx_GOTREF(__pyx_v_self->_size);
     __Pyx_DECREF(__pyx_v_self->_size);
     __pyx_v_self->_size = __pyx_v_result;
 
-    /* "View.MemoryView":595
+    /* "View.MemoryView":597
  *     @property
  *     def size(self):
  *         if self._size is None:             # <<<<<<<<<<<<<<
  *             result = 1
  * 
  */
   }
 
-  /* "View.MemoryView":603
+  /* "View.MemoryView":605
  *             self._size = result
  * 
  *         return self._size             # <<<<<<<<<<<<<<
  * 
  *     def __len__(self):
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(__pyx_v_self->_size);
   __pyx_r = __pyx_v_self->_size;
   goto __pyx_L0;
 
-  /* "View.MemoryView":594
+  /* "View.MemoryView":596
  * 
  *     @property
  *     def size(self):             # <<<<<<<<<<<<<<
  *         if self._size is None:
  *             result = 1
  */
 
@@ -14049,15 +14138,15 @@
   __Pyx_XDECREF(__pyx_v_result);
   __Pyx_XDECREF(__pyx_v_length);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":605
+/* "View.MemoryView":607
  *         return self._size
  * 
  *     def __len__(self):             # <<<<<<<<<<<<<<
  *         if self.view.ndim >= 1:
  *             return self.view.shape[0]
  */
 
@@ -14076,68 +14165,68 @@
 
 static Py_ssize_t __pyx_memoryview___pyx_pf_15View_dot_MemoryView_10memoryview_10__len__(struct __pyx_memoryview_obj *__pyx_v_self) {
   Py_ssize_t __pyx_r;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("__len__", 0);
 
-  /* "View.MemoryView":606
+  /* "View.MemoryView":608
  * 
  *     def __len__(self):
  *         if self.view.ndim >= 1:             # <<<<<<<<<<<<<<
  *             return self.view.shape[0]
  * 
  */
   __pyx_t_1 = ((__pyx_v_self->view.ndim >= 1) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":607
+    /* "View.MemoryView":609
  *     def __len__(self):
  *         if self.view.ndim >= 1:
  *             return self.view.shape[0]             # <<<<<<<<<<<<<<
  * 
  *         return 0
  */
     __pyx_r = (__pyx_v_self->view.shape[0]);
     goto __pyx_L0;
 
-    /* "View.MemoryView":606
+    /* "View.MemoryView":608
  * 
  *     def __len__(self):
  *         if self.view.ndim >= 1:             # <<<<<<<<<<<<<<
  *             return self.view.shape[0]
  * 
  */
   }
 
-  /* "View.MemoryView":609
+  /* "View.MemoryView":611
  *             return self.view.shape[0]
  * 
  *         return 0             # <<<<<<<<<<<<<<
  * 
  *     def __repr__(self):
  */
   __pyx_r = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":605
+  /* "View.MemoryView":607
  *         return self._size
  * 
  *     def __len__(self):             # <<<<<<<<<<<<<<
  *         if self.view.ndim >= 1:
  *             return self.view.shape[0]
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":611
+/* "View.MemoryView":613
  *         return 0
  * 
  *     def __repr__(self):             # <<<<<<<<<<<<<<
  *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
  *                                                id(self))
  */
 
@@ -14161,64 +14250,64 @@
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__repr__", 0);
 
-  /* "View.MemoryView":612
+  /* "View.MemoryView":614
  * 
  *     def __repr__(self):
  *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,             # <<<<<<<<<<<<<<
  *                                                id(self))
  * 
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 612, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 614, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 612, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 614, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 612, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 614, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
-  /* "View.MemoryView":613
+  /* "View.MemoryView":615
  *     def __repr__(self):
  *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
  *                                                id(self))             # <<<<<<<<<<<<<<
  * 
  *     def __str__(self):
  */
-  __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_id, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 613, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_builtin_id, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 615, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
 
-  /* "View.MemoryView":612
+  /* "View.MemoryView":614
  * 
  *     def __repr__(self):
  *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,             # <<<<<<<<<<<<<<
  *                                                id(self))
  * 
  */
-  __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 612, __pyx_L1_error)
+  __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 614, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_GIVEREF(__pyx_t_1);
   PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
   __Pyx_GIVEREF(__pyx_t_2);
   PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_2);
   __pyx_t_1 = 0;
   __pyx_t_2 = 0;
-  __pyx_t_2 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_at_0x_x, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 612, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_at_0x_x, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 614, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":611
+  /* "View.MemoryView":613
  *         return 0
  * 
  *     def __repr__(self):             # <<<<<<<<<<<<<<
  *         return "<MemoryView of %r at 0x%x>" % (self.base.__class__.__name__,
  *                                                id(self))
  */
 
@@ -14231,15 +14320,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":615
+/* "View.MemoryView":617
  *                                                id(self))
  * 
  *     def __str__(self):             # <<<<<<<<<<<<<<
  *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)
  * 
  */
 
@@ -14262,43 +14351,43 @@
   PyObject *__pyx_t_1 = NULL;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__str__", 0);
 
-  /* "View.MemoryView":616
+  /* "View.MemoryView":618
  * 
  *     def __str__(self):
  *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 616, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 618, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 616, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_class); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 618, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 616, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_name_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 618, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 616, __pyx_L1_error)
+  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 618, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_1);
   PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
   __pyx_t_1 = 0;
-  __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_object, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 616, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_MemoryView_of_r_object, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 618, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":615
+  /* "View.MemoryView":617
  *                                                id(self))
  * 
  *     def __str__(self):             # <<<<<<<<<<<<<<
  *         return "<MemoryView of %r object>" % (self.base.__class__.__name__,)
  * 
  */
 
@@ -14310,15 +14399,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":619
+/* "View.MemoryView":621
  * 
  * 
  *     def is_c_contig(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  */
 
@@ -14343,39 +14432,39 @@
   __Pyx_memviewslice *__pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("is_c_contig", 0);
 
-  /* "View.MemoryView":622
+  /* "View.MemoryView":624
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  *         mslice = get_slice_from_memview(self, &tmp)             # <<<<<<<<<<<<<<
  *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
  * 
  */
-  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 622, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 624, __pyx_L1_error)
   __pyx_v_mslice = __pyx_t_1;
 
-  /* "View.MemoryView":623
+  /* "View.MemoryView":625
  *         cdef __Pyx_memviewslice tmp
  *         mslice = get_slice_from_memview(self, &tmp)
  *         return slice_is_contig(mslice[0], 'C', self.view.ndim)             # <<<<<<<<<<<<<<
  * 
  *     def is_f_contig(self):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'C', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 623, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'C', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 625, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":619
+  /* "View.MemoryView":621
  * 
  * 
  *     def is_c_contig(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  */
 
@@ -14386,15 +14475,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":625
+/* "View.MemoryView":627
  *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
  * 
  *     def is_f_contig(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  */
 
@@ -14419,39 +14508,39 @@
   __Pyx_memviewslice *__pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("is_f_contig", 0);
 
-  /* "View.MemoryView":628
+  /* "View.MemoryView":630
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  *         mslice = get_slice_from_memview(self, &tmp)             # <<<<<<<<<<<<<<
  *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
  * 
  */
-  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 628, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_get_slice_from_memoryview(__pyx_v_self, (&__pyx_v_tmp)); if (unlikely(__pyx_t_1 == ((__Pyx_memviewslice *)NULL))) __PYX_ERR(2, 630, __pyx_L1_error)
   __pyx_v_mslice = __pyx_t_1;
 
-  /* "View.MemoryView":629
+  /* "View.MemoryView":631
  *         cdef __Pyx_memviewslice tmp
  *         mslice = get_slice_from_memview(self, &tmp)
  *         return slice_is_contig(mslice[0], 'F', self.view.ndim)             # <<<<<<<<<<<<<<
  * 
  *     def copy(self):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'F', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 629, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_memviewslice_is_contig((__pyx_v_mslice[0]), 'F', __pyx_v_self->view.ndim)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 631, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":625
+  /* "View.MemoryView":627
  *         return slice_is_contig(mslice[0], 'C', self.view.ndim)
  * 
  *     def is_f_contig(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice *mslice
  *         cdef __Pyx_memviewslice tmp
  */
 
@@ -14462,15 +14551,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":631
+/* "View.MemoryView":633
  *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
  * 
  *     def copy(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice mslice
  *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
  */
 
@@ -14495,57 +14584,57 @@
   __Pyx_memviewslice __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("copy", 0);
 
-  /* "View.MemoryView":633
+  /* "View.MemoryView":635
  *     def copy(self):
  *         cdef __Pyx_memviewslice mslice
  *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS             # <<<<<<<<<<<<<<
  * 
  *         slice_copy(self, &mslice)
  */
   __pyx_v_flags = (__pyx_v_self->flags & (~PyBUF_F_CONTIGUOUS));
 
-  /* "View.MemoryView":635
+  /* "View.MemoryView":637
  *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
  * 
  *         slice_copy(self, &mslice)             # <<<<<<<<<<<<<<
  *         mslice = slice_copy_contig(&mslice, "c", self.view.ndim,
  *                                    self.view.itemsize,
  */
   __pyx_memoryview_slice_copy(__pyx_v_self, (&__pyx_v_mslice));
 
-  /* "View.MemoryView":636
+  /* "View.MemoryView":638
  * 
  *         slice_copy(self, &mslice)
  *         mslice = slice_copy_contig(&mslice, "c", self.view.ndim,             # <<<<<<<<<<<<<<
  *                                    self.view.itemsize,
  *                                    flags|PyBUF_C_CONTIGUOUS,
  */
-  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_mslice), ((char *)"c"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_C_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 636, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_mslice), ((char *)"c"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_C_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 638, __pyx_L1_error)
   __pyx_v_mslice = __pyx_t_1;
 
-  /* "View.MemoryView":641
+  /* "View.MemoryView":643
  *                                    self.dtype_is_object)
  * 
  *         return memoryview_copy_from_slice(self, &mslice)             # <<<<<<<<<<<<<<
  * 
  *     def copy_fortran(self):
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_mslice)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 641, __pyx_L1_error)
+  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_mslice)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 643, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":631
+  /* "View.MemoryView":633
  *         return slice_is_contig(mslice[0], 'F', self.view.ndim)
  * 
  *     def copy(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice mslice
  *         cdef int flags = self.flags & ~PyBUF_F_CONTIGUOUS
  */
 
@@ -14556,15 +14645,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":643
+/* "View.MemoryView":645
  *         return memoryview_copy_from_slice(self, &mslice)
  * 
  *     def copy_fortran(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice src, dst
  *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
  */
 
@@ -14590,57 +14679,57 @@
   __Pyx_memviewslice __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("copy_fortran", 0);
 
-  /* "View.MemoryView":645
+  /* "View.MemoryView":647
  *     def copy_fortran(self):
  *         cdef __Pyx_memviewslice src, dst
  *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS             # <<<<<<<<<<<<<<
  * 
  *         slice_copy(self, &src)
  */
   __pyx_v_flags = (__pyx_v_self->flags & (~PyBUF_C_CONTIGUOUS));
 
-  /* "View.MemoryView":647
+  /* "View.MemoryView":649
  *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
  * 
  *         slice_copy(self, &src)             # <<<<<<<<<<<<<<
  *         dst = slice_copy_contig(&src, "fortran", self.view.ndim,
  *                                 self.view.itemsize,
  */
   __pyx_memoryview_slice_copy(__pyx_v_self, (&__pyx_v_src));
 
-  /* "View.MemoryView":648
+  /* "View.MemoryView":650
  * 
  *         slice_copy(self, &src)
  *         dst = slice_copy_contig(&src, "fortran", self.view.ndim,             # <<<<<<<<<<<<<<
  *                                 self.view.itemsize,
  *                                 flags|PyBUF_F_CONTIGUOUS,
  */
-  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_src), ((char *)"fortran"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_F_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 648, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_copy_new_contig((&__pyx_v_src), ((char *)"fortran"), __pyx_v_self->view.ndim, __pyx_v_self->view.itemsize, (__pyx_v_flags | PyBUF_F_CONTIGUOUS), __pyx_v_self->dtype_is_object); if (unlikely(PyErr_Occurred())) __PYX_ERR(2, 650, __pyx_L1_error)
   __pyx_v_dst = __pyx_t_1;
 
-  /* "View.MemoryView":653
+  /* "View.MemoryView":655
  *                                 self.dtype_is_object)
  * 
  *         return memoryview_copy_from_slice(self, &dst)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_dst)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 653, __pyx_L1_error)
+  __pyx_t_2 = __pyx_memoryview_copy_object_from_slice(__pyx_v_self, (&__pyx_v_dst)); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 655, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __pyx_r = __pyx_t_2;
   __pyx_t_2 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":643
+  /* "View.MemoryView":645
  *         return memoryview_copy_from_slice(self, &mslice)
  * 
  *     def copy_fortran(self):             # <<<<<<<<<<<<<<
  *         cdef __Pyx_memviewslice src, dst
  *         cdef int flags = self.flags & ~PyBUF_C_CONTIGUOUS
  */
 
@@ -14764,15 +14853,15 @@
   __Pyx_AddTraceback("View.MemoryView.memoryview.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":657
+/* "View.MemoryView":659
  * 
  * @cname('__pyx_memoryview_new')
  * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):             # <<<<<<<<<<<<<<
  *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
  *     result.typeinfo = typeinfo
  */
 
@@ -14784,64 +14873,64 @@
   PyObject *__pyx_t_2 = NULL;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("memoryview_cwrapper", 0);
 
-  /* "View.MemoryView":658
+  /* "View.MemoryView":660
  * @cname('__pyx_memoryview_new')
  * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):
  *     cdef memoryview result = memoryview(o, flags, dtype_is_object)             # <<<<<<<<<<<<<<
  *     result.typeinfo = typeinfo
  *     return result
  */
-  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 658, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 660, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 658, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 660, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 658, __pyx_L1_error)
+  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 660, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_INCREF(__pyx_v_o);
   __Pyx_GIVEREF(__pyx_v_o);
   PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_o);
   __Pyx_GIVEREF(__pyx_t_1);
   PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
   __Pyx_GIVEREF(__pyx_t_2);
   PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
   __pyx_t_1 = 0;
   __pyx_t_2 = 0;
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 658, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryview_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 660, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_v_result = ((struct __pyx_memoryview_obj *)__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":659
+  /* "View.MemoryView":661
  * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):
  *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
  *     result.typeinfo = typeinfo             # <<<<<<<<<<<<<<
  *     return result
  * 
  */
   __pyx_v_result->typeinfo = __pyx_v_typeinfo;
 
-  /* "View.MemoryView":660
+  /* "View.MemoryView":662
  *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
  *     result.typeinfo = typeinfo
  *     return result             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_check')
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(((PyObject *)__pyx_v_result));
   __pyx_r = ((PyObject *)__pyx_v_result);
   goto __pyx_L0;
 
-  /* "View.MemoryView":657
+  /* "View.MemoryView":659
  * 
  * @cname('__pyx_memoryview_new')
  * cdef memoryview_cwrapper(object o, int flags, bint dtype_is_object, __Pyx_TypeInfo *typeinfo):             # <<<<<<<<<<<<<<
  *     cdef memoryview result = memoryview(o, flags, dtype_is_object)
  *     result.typeinfo = typeinfo
  */
 
@@ -14855,54 +14944,54 @@
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_result);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":663
+/* "View.MemoryView":665
  * 
  * @cname('__pyx_memoryview_check')
  * cdef inline bint memoryview_check(object o):             # <<<<<<<<<<<<<<
  *     return isinstance(o, memoryview)
  * 
  */
 
 static CYTHON_INLINE int __pyx_memoryview_check(PyObject *__pyx_v_o) {
   int __pyx_r;
   __Pyx_RefNannyDeclarations
   int __pyx_t_1;
   __Pyx_RefNannySetupContext("memoryview_check", 0);
 
-  /* "View.MemoryView":664
+  /* "View.MemoryView":666
  * @cname('__pyx_memoryview_check')
  * cdef inline bint memoryview_check(object o):
  *     return isinstance(o, memoryview)             # <<<<<<<<<<<<<<
  * 
  * cdef tuple _unellipsify(object index, int ndim):
  */
   __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_o, __pyx_memoryview_type); 
   __pyx_r = __pyx_t_1;
   goto __pyx_L0;
 
-  /* "View.MemoryView":663
+  /* "View.MemoryView":665
  * 
  * @cname('__pyx_memoryview_check')
  * cdef inline bint memoryview_check(object o):             # <<<<<<<<<<<<<<
  *     return isinstance(o, memoryview)
  * 
  */
 
   /* function exit code */
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":666
+/* "View.MemoryView":668
  *     return isinstance(o, memoryview)
  * 
  * cdef tuple _unellipsify(object index, int ndim):             # <<<<<<<<<<<<<<
  *     """
  *     Replace all ellipses with full slices and fill incomplete indices with
  */
 
@@ -14928,243 +15017,243 @@
   int __pyx_t_10;
   PyObject *__pyx_t_11 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("_unellipsify", 0);
 
-  /* "View.MemoryView":671
+  /* "View.MemoryView":673
  *     full slices.
  *     """
  *     if not isinstance(index, tuple):             # <<<<<<<<<<<<<<
  *         tup = (index,)
  *     else:
  */
   __pyx_t_1 = PyTuple_Check(__pyx_v_index); 
   __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":672
+    /* "View.MemoryView":674
  *     """
  *     if not isinstance(index, tuple):
  *         tup = (index,)             # <<<<<<<<<<<<<<
  *     else:
  *         tup = index
  */
-    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 672, __pyx_L1_error)
+    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 674, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_INCREF(__pyx_v_index);
     __Pyx_GIVEREF(__pyx_v_index);
     PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_index);
     __pyx_v_tup = __pyx_t_3;
     __pyx_t_3 = 0;
 
-    /* "View.MemoryView":671
+    /* "View.MemoryView":673
  *     full slices.
  *     """
  *     if not isinstance(index, tuple):             # <<<<<<<<<<<<<<
  *         tup = (index,)
  *     else:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":674
+  /* "View.MemoryView":676
  *         tup = (index,)
  *     else:
  *         tup = index             # <<<<<<<<<<<<<<
  * 
  *     result = []
  */
   /*else*/ {
     __Pyx_INCREF(__pyx_v_index);
     __pyx_v_tup = __pyx_v_index;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":676
+  /* "View.MemoryView":678
  *         tup = index
  * 
  *     result = []             # <<<<<<<<<<<<<<
  *     have_slices = False
  *     seen_ellipsis = False
  */
-  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 676, __pyx_L1_error)
+  __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 678, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __pyx_v_result = ((PyObject*)__pyx_t_3);
   __pyx_t_3 = 0;
 
-  /* "View.MemoryView":677
+  /* "View.MemoryView":679
  * 
  *     result = []
  *     have_slices = False             # <<<<<<<<<<<<<<
  *     seen_ellipsis = False
  *     for idx, item in enumerate(tup):
  */
   __pyx_v_have_slices = 0;
 
-  /* "View.MemoryView":678
+  /* "View.MemoryView":680
  *     result = []
  *     have_slices = False
  *     seen_ellipsis = False             # <<<<<<<<<<<<<<
  *     for idx, item in enumerate(tup):
  *         if item is Ellipsis:
  */
   __pyx_v_seen_ellipsis = 0;
 
-  /* "View.MemoryView":679
+  /* "View.MemoryView":681
  *     have_slices = False
  *     seen_ellipsis = False
  *     for idx, item in enumerate(tup):             # <<<<<<<<<<<<<<
  *         if item is Ellipsis:
  *             if not seen_ellipsis:
  */
   __Pyx_INCREF(__pyx_int_0);
   __pyx_t_3 = __pyx_int_0;
   if (likely(PyList_CheckExact(__pyx_v_tup)) || PyTuple_CheckExact(__pyx_v_tup)) {
     __pyx_t_4 = __pyx_v_tup; __Pyx_INCREF(__pyx_t_4); __pyx_t_5 = 0;
     __pyx_t_6 = NULL;
   } else {
-    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_tup); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 679, __pyx_L1_error)
+    __pyx_t_5 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_v_tup); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 681, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
-    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 679, __pyx_L1_error)
+    __pyx_t_6 = Py_TYPE(__pyx_t_4)->tp_iternext; if (unlikely(!__pyx_t_6)) __PYX_ERR(2, 681, __pyx_L1_error)
   }
   for (;;) {
     if (likely(!__pyx_t_6)) {
       if (likely(PyList_CheckExact(__pyx_t_4))) {
         if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_4)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 679, __pyx_L1_error)
+        __pyx_t_7 = PyList_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 681, __pyx_L1_error)
         #else
-        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 679, __pyx_L1_error)
+        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 681, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
         #endif
       } else {
         if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_4)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 679, __pyx_L1_error)
+        __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_5); __Pyx_INCREF(__pyx_t_7); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(2, 681, __pyx_L1_error)
         #else
-        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 679, __pyx_L1_error)
+        __pyx_t_7 = PySequence_ITEM(__pyx_t_4, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 681, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
         #endif
       }
     } else {
       __pyx_t_7 = __pyx_t_6(__pyx_t_4);
       if (unlikely(!__pyx_t_7)) {
         PyObject* exc_type = PyErr_Occurred();
         if (exc_type) {
           if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
-          else __PYX_ERR(2, 679, __pyx_L1_error)
+          else __PYX_ERR(2, 681, __pyx_L1_error)
         }
         break;
       }
       __Pyx_GOTREF(__pyx_t_7);
     }
     __Pyx_XDECREF_SET(__pyx_v_item, __pyx_t_7);
     __pyx_t_7 = 0;
     __Pyx_INCREF(__pyx_t_3);
     __Pyx_XDECREF_SET(__pyx_v_idx, __pyx_t_3);
-    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_t_3, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 679, __pyx_L1_error)
+    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_t_3, __pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 681, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_7);
     __Pyx_DECREF(__pyx_t_3);
     __pyx_t_3 = __pyx_t_7;
     __pyx_t_7 = 0;
 
-    /* "View.MemoryView":680
+    /* "View.MemoryView":682
  *     seen_ellipsis = False
  *     for idx, item in enumerate(tup):
  *         if item is Ellipsis:             # <<<<<<<<<<<<<<
  *             if not seen_ellipsis:
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
  */
     __pyx_t_2 = (__pyx_v_item == __pyx_builtin_Ellipsis);
     __pyx_t_1 = (__pyx_t_2 != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":681
+      /* "View.MemoryView":683
  *     for idx, item in enumerate(tup):
  *         if item is Ellipsis:
  *             if not seen_ellipsis:             # <<<<<<<<<<<<<<
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
  *                 seen_ellipsis = True
  */
       __pyx_t_1 = ((!(__pyx_v_seen_ellipsis != 0)) != 0);
       if (__pyx_t_1) {
 
-        /* "View.MemoryView":682
+        /* "View.MemoryView":684
  *         if item is Ellipsis:
  *             if not seen_ellipsis:
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))             # <<<<<<<<<<<<<<
  *                 seen_ellipsis = True
  *             else:
  */
-        __pyx_t_8 = PyObject_Length(__pyx_v_tup); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(2, 682, __pyx_L1_error)
-        __pyx_t_7 = PyList_New(1 * ((((__pyx_v_ndim - __pyx_t_8) + 1)<0) ? 0:((__pyx_v_ndim - __pyx_t_8) + 1))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 682, __pyx_L1_error)
+        __pyx_t_8 = PyObject_Length(__pyx_v_tup); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(2, 684, __pyx_L1_error)
+        __pyx_t_7 = PyList_New(1 * ((((__pyx_v_ndim - __pyx_t_8) + 1)<0) ? 0:((__pyx_v_ndim - __pyx_t_8) + 1))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 684, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
         { Py_ssize_t __pyx_temp;
           for (__pyx_temp=0; __pyx_temp < ((__pyx_v_ndim - __pyx_t_8) + 1); __pyx_temp++) {
             __Pyx_INCREF(__pyx_slice__2);
             __Pyx_GIVEREF(__pyx_slice__2);
             PyList_SET_ITEM(__pyx_t_7, __pyx_temp, __pyx_slice__2);
           }
         }
-        __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_7); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 682, __pyx_L1_error)
+        __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_7); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 684, __pyx_L1_error)
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
 
-        /* "View.MemoryView":683
+        /* "View.MemoryView":685
  *             if not seen_ellipsis:
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
  *                 seen_ellipsis = True             # <<<<<<<<<<<<<<
  *             else:
  *                 result.append(slice(None))
  */
         __pyx_v_seen_ellipsis = 1;
 
-        /* "View.MemoryView":681
+        /* "View.MemoryView":683
  *     for idx, item in enumerate(tup):
  *         if item is Ellipsis:
  *             if not seen_ellipsis:             # <<<<<<<<<<<<<<
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
  *                 seen_ellipsis = True
  */
         goto __pyx_L7;
       }
 
-      /* "View.MemoryView":685
+      /* "View.MemoryView":687
  *                 seen_ellipsis = True
  *             else:
  *                 result.append(slice(None))             # <<<<<<<<<<<<<<
  *             have_slices = True
  *         else:
  */
       /*else*/ {
-        __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_slice__2); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 685, __pyx_L1_error)
+        __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_slice__2); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 687, __pyx_L1_error)
       }
       __pyx_L7:;
 
-      /* "View.MemoryView":686
+      /* "View.MemoryView":688
  *             else:
  *                 result.append(slice(None))
  *             have_slices = True             # <<<<<<<<<<<<<<
  *         else:
  *             if not isinstance(item, slice) and not PyIndex_Check(item):
  */
       __pyx_v_have_slices = 1;
 
-      /* "View.MemoryView":680
+      /* "View.MemoryView":682
  *     seen_ellipsis = False
  *     for idx, item in enumerate(tup):
  *         if item is Ellipsis:             # <<<<<<<<<<<<<<
  *             if not seen_ellipsis:
  *                 result.extend([slice(None)] * (ndim - len(tup) + 1))
  */
       goto __pyx_L6;
     }
 
-    /* "View.MemoryView":688
+    /* "View.MemoryView":690
  *             have_slices = True
  *         else:
  *             if not isinstance(item, slice) and not PyIndex_Check(item):             # <<<<<<<<<<<<<<
  *                 raise TypeError("Cannot index with type '%s'" % type(item))
  * 
  */
     /*else*/ {
@@ -15176,40 +15265,40 @@
         goto __pyx_L9_bool_binop_done;
       }
       __pyx_t_10 = ((!(PyIndex_Check(__pyx_v_item) != 0)) != 0);
       __pyx_t_1 = __pyx_t_10;
       __pyx_L9_bool_binop_done:;
       if (unlikely(__pyx_t_1)) {
 
-        /* "View.MemoryView":689
+        /* "View.MemoryView":691
  *         else:
  *             if not isinstance(item, slice) and not PyIndex_Check(item):
  *                 raise TypeError("Cannot index with type '%s'" % type(item))             # <<<<<<<<<<<<<<
  * 
  *             have_slices = have_slices or isinstance(item, slice)
  */
-        __pyx_t_7 = __Pyx_PyString_FormatSafe(__pyx_kp_s_Cannot_index_with_type_s, ((PyObject *)Py_TYPE(__pyx_v_item))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 689, __pyx_L1_error)
+        __pyx_t_7 = __Pyx_PyString_FormatSafe(__pyx_kp_s_Cannot_index_with_type_s, ((PyObject *)Py_TYPE(__pyx_v_item))); if (unlikely(!__pyx_t_7)) __PYX_ERR(2, 691, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_7);
-        __pyx_t_11 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_11)) __PYX_ERR(2, 689, __pyx_L1_error)
+        __pyx_t_11 = __Pyx_PyObject_CallOneArg(__pyx_builtin_TypeError, __pyx_t_7); if (unlikely(!__pyx_t_11)) __PYX_ERR(2, 691, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_11);
         __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
         __Pyx_Raise(__pyx_t_11, 0, 0, 0);
         __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
-        __PYX_ERR(2, 689, __pyx_L1_error)
+        __PYX_ERR(2, 691, __pyx_L1_error)
 
-        /* "View.MemoryView":688
+        /* "View.MemoryView":690
  *             have_slices = True
  *         else:
  *             if not isinstance(item, slice) and not PyIndex_Check(item):             # <<<<<<<<<<<<<<
  *                 raise TypeError("Cannot index with type '%s'" % type(item))
  * 
  */
       }
 
-      /* "View.MemoryView":691
+      /* "View.MemoryView":693
  *                 raise TypeError("Cannot index with type '%s'" % type(item))
  * 
  *             have_slices = have_slices or isinstance(item, slice)             # <<<<<<<<<<<<<<
  *             result.append(item)
  * 
  */
       __pyx_t_10 = (__pyx_v_have_slices != 0);
@@ -15220,120 +15309,120 @@
       }
       __pyx_t_10 = PySlice_Check(__pyx_v_item); 
       __pyx_t_2 = (__pyx_t_10 != 0);
       __pyx_t_1 = __pyx_t_2;
       __pyx_L11_bool_binop_done:;
       __pyx_v_have_slices = __pyx_t_1;
 
-      /* "View.MemoryView":692
+      /* "View.MemoryView":694
  * 
  *             have_slices = have_slices or isinstance(item, slice)
  *             result.append(item)             # <<<<<<<<<<<<<<
  * 
  *     nslices = ndim - len(result)
  */
-      __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_v_item); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 692, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyList_Append(__pyx_v_result, __pyx_v_item); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 694, __pyx_L1_error)
     }
     __pyx_L6:;
 
-    /* "View.MemoryView":679
+    /* "View.MemoryView":681
  *     have_slices = False
  *     seen_ellipsis = False
  *     for idx, item in enumerate(tup):             # <<<<<<<<<<<<<<
  *         if item is Ellipsis:
  *             if not seen_ellipsis:
  */
   }
   __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-  /* "View.MemoryView":694
+  /* "View.MemoryView":696
  *             result.append(item)
  * 
  *     nslices = ndim - len(result)             # <<<<<<<<<<<<<<
  *     if nslices:
  *         result.extend([slice(None)] * nslices)
  */
-  __pyx_t_5 = PyList_GET_SIZE(__pyx_v_result); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(2, 694, __pyx_L1_error)
+  __pyx_t_5 = PyList_GET_SIZE(__pyx_v_result); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(2, 696, __pyx_L1_error)
   __pyx_v_nslices = (__pyx_v_ndim - __pyx_t_5);
 
-  /* "View.MemoryView":695
+  /* "View.MemoryView":697
  * 
  *     nslices = ndim - len(result)
  *     if nslices:             # <<<<<<<<<<<<<<
  *         result.extend([slice(None)] * nslices)
  * 
  */
   __pyx_t_1 = (__pyx_v_nslices != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":696
+    /* "View.MemoryView":698
  *     nslices = ndim - len(result)
  *     if nslices:
  *         result.extend([slice(None)] * nslices)             # <<<<<<<<<<<<<<
  * 
  *     return have_slices or nslices, tuple(result)
  */
-    __pyx_t_3 = PyList_New(1 * ((__pyx_v_nslices<0) ? 0:__pyx_v_nslices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 696, __pyx_L1_error)
+    __pyx_t_3 = PyList_New(1 * ((__pyx_v_nslices<0) ? 0:__pyx_v_nslices)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 698, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     { Py_ssize_t __pyx_temp;
       for (__pyx_temp=0; __pyx_temp < __pyx_v_nslices; __pyx_temp++) {
         __Pyx_INCREF(__pyx_slice__2);
         __Pyx_GIVEREF(__pyx_slice__2);
         PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_slice__2);
       }
     }
-    __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_3); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 696, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyList_Extend(__pyx_v_result, __pyx_t_3); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 698, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-    /* "View.MemoryView":695
+    /* "View.MemoryView":697
  * 
  *     nslices = ndim - len(result)
  *     if nslices:             # <<<<<<<<<<<<<<
  *         result.extend([slice(None)] * nslices)
  * 
  */
   }
 
-  /* "View.MemoryView":698
+  /* "View.MemoryView":700
  *         result.extend([slice(None)] * nslices)
  * 
  *     return have_slices or nslices, tuple(result)             # <<<<<<<<<<<<<<
  * 
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
  */
   __Pyx_XDECREF(__pyx_r);
   if (!__pyx_v_have_slices) {
   } else {
-    __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_have_slices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 698, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyBool_FromLong(__pyx_v_have_slices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 700, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __pyx_t_3 = __pyx_t_4;
     __pyx_t_4 = 0;
     goto __pyx_L14_bool_binop_done;
   }
-  __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_nslices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 698, __pyx_L1_error)
+  __pyx_t_4 = PyInt_FromSsize_t(__pyx_v_nslices); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 700, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
   __pyx_t_3 = __pyx_t_4;
   __pyx_t_4 = 0;
   __pyx_L14_bool_binop_done:;
-  __pyx_t_4 = PyList_AsTuple(__pyx_v_result); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 698, __pyx_L1_error)
+  __pyx_t_4 = PyList_AsTuple(__pyx_v_result); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 700, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
-  __pyx_t_11 = PyTuple_New(2); if (unlikely(!__pyx_t_11)) __PYX_ERR(2, 698, __pyx_L1_error)
+  __pyx_t_11 = PyTuple_New(2); if (unlikely(!__pyx_t_11)) __PYX_ERR(2, 700, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_11);
   __Pyx_GIVEREF(__pyx_t_3);
   PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_3);
   __Pyx_GIVEREF(__pyx_t_4);
   PyTuple_SET_ITEM(__pyx_t_11, 1, __pyx_t_4);
   __pyx_t_3 = 0;
   __pyx_t_4 = 0;
   __pyx_r = ((PyObject*)__pyx_t_11);
   __pyx_t_11 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":666
+  /* "View.MemoryView":668
  *     return isinstance(o, memoryview)
  * 
  * cdef tuple _unellipsify(object index, int ndim):             # <<<<<<<<<<<<<<
  *     """
  *     Replace all ellipses with full slices and fill incomplete indices with
  */
 
@@ -15351,15 +15440,15 @@
   __Pyx_XDECREF(__pyx_v_idx);
   __Pyx_XDECREF(__pyx_v_item);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":700
+/* "View.MemoryView":702
  *     return have_slices or nslices, tuple(result)
  * 
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):             # <<<<<<<<<<<<<<
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:
  */
 
@@ -15373,60 +15462,60 @@
   int __pyx_t_4;
   PyObject *__pyx_t_5 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("assert_direct_dimensions", 0);
 
-  /* "View.MemoryView":701
+  /* "View.MemoryView":703
  * 
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
  *     for suboffset in suboffsets[:ndim]:             # <<<<<<<<<<<<<<
  *         if suboffset >= 0:
  *             raise ValueError("Indirect dimensions not supported")
  */
   __pyx_t_2 = (__pyx_v_suboffsets + __pyx_v_ndim);
   for (__pyx_t_3 = __pyx_v_suboffsets; __pyx_t_3 < __pyx_t_2; __pyx_t_3++) {
     __pyx_t_1 = __pyx_t_3;
     __pyx_v_suboffset = (__pyx_t_1[0]);
 
-    /* "View.MemoryView":702
+    /* "View.MemoryView":704
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:             # <<<<<<<<<<<<<<
  *             raise ValueError("Indirect dimensions not supported")
  * 
  */
     __pyx_t_4 = ((__pyx_v_suboffset >= 0) != 0);
     if (unlikely(__pyx_t_4)) {
 
-      /* "View.MemoryView":703
+      /* "View.MemoryView":705
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:
  *             raise ValueError("Indirect dimensions not supported")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__21, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 703, __pyx_L1_error)
+      __pyx_t_5 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__21, NULL); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 705, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_5);
       __Pyx_Raise(__pyx_t_5, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
-      __PYX_ERR(2, 703, __pyx_L1_error)
+      __PYX_ERR(2, 705, __pyx_L1_error)
 
-      /* "View.MemoryView":702
+      /* "View.MemoryView":704
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:             # <<<<<<<<<<<<<<
  *             raise ValueError("Indirect dimensions not supported")
  * 
  */
     }
   }
 
-  /* "View.MemoryView":700
+  /* "View.MemoryView":702
  *     return have_slices or nslices, tuple(result)
  * 
  * cdef assert_direct_dimensions(Py_ssize_t *suboffsets, int ndim):             # <<<<<<<<<<<<<<
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:
  */
 
@@ -15439,15 +15528,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":710
+/* "View.MemoryView":712
  * 
  * @cname('__pyx_memview_slice')
  * cdef memoryview memview_slice(memoryview memview, object indices):             # <<<<<<<<<<<<<<
  *     cdef int new_ndim = 0, suboffset_dim = -1, dim
  *     cdef bint negative_step
  */
 
@@ -15483,529 +15572,529 @@
   int __pyx_t_11;
   Py_ssize_t __pyx_t_12;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("memview_slice", 0);
 
-  /* "View.MemoryView":711
+  /* "View.MemoryView":713
  * @cname('__pyx_memview_slice')
  * cdef memoryview memview_slice(memoryview memview, object indices):
  *     cdef int new_ndim = 0, suboffset_dim = -1, dim             # <<<<<<<<<<<<<<
  *     cdef bint negative_step
  *     cdef __Pyx_memviewslice src, dst
  */
   __pyx_v_new_ndim = 0;
   __pyx_v_suboffset_dim = -1;
 
-  /* "View.MemoryView":718
+  /* "View.MemoryView":720
  * 
  * 
  *     memset(&dst, 0, sizeof(dst))             # <<<<<<<<<<<<<<
  * 
  *     cdef _memoryviewslice memviewsliceobj
  */
   (void)(memset((&__pyx_v_dst), 0, (sizeof(__pyx_v_dst))));
 
-  /* "View.MemoryView":722
+  /* "View.MemoryView":724
  *     cdef _memoryviewslice memviewsliceobj
  * 
  *     assert memview.view.ndim > 0             # <<<<<<<<<<<<<<
  * 
  *     if isinstance(memview, _memoryviewslice):
  */
   #ifndef CYTHON_WITHOUT_ASSERTIONS
   if (unlikely(!Py_OptimizeFlag)) {
     if (unlikely(!((__pyx_v_memview->view.ndim > 0) != 0))) {
       PyErr_SetNone(PyExc_AssertionError);
-      __PYX_ERR(2, 722, __pyx_L1_error)
+      __PYX_ERR(2, 724, __pyx_L1_error)
     }
   }
   #endif
 
-  /* "View.MemoryView":724
+  /* "View.MemoryView":726
  *     assert memview.view.ndim > 0
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         memviewsliceobj = memview
  *         p_src = &memviewsliceobj.from_slice
  */
   __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":725
+    /* "View.MemoryView":727
  * 
  *     if isinstance(memview, _memoryviewslice):
  *         memviewsliceobj = memview             # <<<<<<<<<<<<<<
  *         p_src = &memviewsliceobj.from_slice
  *     else:
  */
-    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 725, __pyx_L1_error)
+    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 727, __pyx_L1_error)
     __pyx_t_3 = ((PyObject *)__pyx_v_memview);
     __Pyx_INCREF(__pyx_t_3);
     __pyx_v_memviewsliceobj = ((struct __pyx_memoryviewslice_obj *)__pyx_t_3);
     __pyx_t_3 = 0;
 
-    /* "View.MemoryView":726
+    /* "View.MemoryView":728
  *     if isinstance(memview, _memoryviewslice):
  *         memviewsliceobj = memview
  *         p_src = &memviewsliceobj.from_slice             # <<<<<<<<<<<<<<
  *     else:
  *         slice_copy(memview, &src)
  */
     __pyx_v_p_src = (&__pyx_v_memviewsliceobj->from_slice);
 
-    /* "View.MemoryView":724
+    /* "View.MemoryView":726
  *     assert memview.view.ndim > 0
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         memviewsliceobj = memview
  *         p_src = &memviewsliceobj.from_slice
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":728
+  /* "View.MemoryView":730
  *         p_src = &memviewsliceobj.from_slice
  *     else:
  *         slice_copy(memview, &src)             # <<<<<<<<<<<<<<
  *         p_src = &src
  * 
  */
   /*else*/ {
     __pyx_memoryview_slice_copy(__pyx_v_memview, (&__pyx_v_src));
 
-    /* "View.MemoryView":729
+    /* "View.MemoryView":731
  *     else:
  *         slice_copy(memview, &src)
  *         p_src = &src             # <<<<<<<<<<<<<<
  * 
  * 
  */
     __pyx_v_p_src = (&__pyx_v_src);
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":735
+  /* "View.MemoryView":737
  * 
  * 
  *     dst.memview = p_src.memview             # <<<<<<<<<<<<<<
  *     dst.data = p_src.data
  * 
  */
   __pyx_t_4 = __pyx_v_p_src->memview;
   __pyx_v_dst.memview = __pyx_t_4;
 
-  /* "View.MemoryView":736
+  /* "View.MemoryView":738
  * 
  *     dst.memview = p_src.memview
  *     dst.data = p_src.data             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_5 = __pyx_v_p_src->data;
   __pyx_v_dst.data = __pyx_t_5;
 
-  /* "View.MemoryView":741
+  /* "View.MemoryView":743
  * 
  * 
  *     cdef __Pyx_memviewslice *p_dst = &dst             # <<<<<<<<<<<<<<
  *     cdef int *p_suboffset_dim = &suboffset_dim
  *     cdef Py_ssize_t start, stop, step
  */
   __pyx_v_p_dst = (&__pyx_v_dst);
 
-  /* "View.MemoryView":742
+  /* "View.MemoryView":744
  * 
  *     cdef __Pyx_memviewslice *p_dst = &dst
  *     cdef int *p_suboffset_dim = &suboffset_dim             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t start, stop, step
  *     cdef bint have_start, have_stop, have_step
  */
   __pyx_v_p_suboffset_dim = (&__pyx_v_suboffset_dim);
 
-  /* "View.MemoryView":746
+  /* "View.MemoryView":748
  *     cdef bint have_start, have_stop, have_step
  * 
  *     for dim, index in enumerate(indices):             # <<<<<<<<<<<<<<
  *         if PyIndex_Check(index):
  *             slice_memviewslice(
  */
   __pyx_t_6 = 0;
   if (likely(PyList_CheckExact(__pyx_v_indices)) || PyTuple_CheckExact(__pyx_v_indices)) {
     __pyx_t_3 = __pyx_v_indices; __Pyx_INCREF(__pyx_t_3); __pyx_t_7 = 0;
     __pyx_t_8 = NULL;
   } else {
-    __pyx_t_7 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_indices); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 746, __pyx_L1_error)
+    __pyx_t_7 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_indices); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 748, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_8 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 746, __pyx_L1_error)
+    __pyx_t_8 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_8)) __PYX_ERR(2, 748, __pyx_L1_error)
   }
   for (;;) {
     if (likely(!__pyx_t_8)) {
       if (likely(PyList_CheckExact(__pyx_t_3))) {
         if (__pyx_t_7 >= PyList_GET_SIZE(__pyx_t_3)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_9 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 746, __pyx_L1_error)
+        __pyx_t_9 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 748, __pyx_L1_error)
         #else
-        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 746, __pyx_L1_error)
+        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 748, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_9);
         #endif
       } else {
         if (__pyx_t_7 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
         #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
-        __pyx_t_9 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 746, __pyx_L1_error)
+        __pyx_t_9 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_7); __Pyx_INCREF(__pyx_t_9); __pyx_t_7++; if (unlikely(0 < 0)) __PYX_ERR(2, 748, __pyx_L1_error)
         #else
-        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 746, __pyx_L1_error)
+        __pyx_t_9 = PySequence_ITEM(__pyx_t_3, __pyx_t_7); __pyx_t_7++; if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 748, __pyx_L1_error)
         __Pyx_GOTREF(__pyx_t_9);
         #endif
       }
     } else {
       __pyx_t_9 = __pyx_t_8(__pyx_t_3);
       if (unlikely(!__pyx_t_9)) {
         PyObject* exc_type = PyErr_Occurred();
         if (exc_type) {
           if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
-          else __PYX_ERR(2, 746, __pyx_L1_error)
+          else __PYX_ERR(2, 748, __pyx_L1_error)
         }
         break;
       }
       __Pyx_GOTREF(__pyx_t_9);
     }
     __Pyx_XDECREF_SET(__pyx_v_index, __pyx_t_9);
     __pyx_t_9 = 0;
     __pyx_v_dim = __pyx_t_6;
     __pyx_t_6 = (__pyx_t_6 + 1);
 
-    /* "View.MemoryView":747
+    /* "View.MemoryView":749
  * 
  *     for dim, index in enumerate(indices):
  *         if PyIndex_Check(index):             # <<<<<<<<<<<<<<
  *             slice_memviewslice(
  *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
  */
     __pyx_t_2 = (PyIndex_Check(__pyx_v_index) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":751
+      /* "View.MemoryView":753
  *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
  *                 dim, new_ndim, p_suboffset_dim,
  *                 index, 0, 0, # start, stop, step             # <<<<<<<<<<<<<<
  *                 0, 0, 0, # have_{start,stop,step}
  *                 False)
  */
-      __pyx_t_10 = __Pyx_PyIndex_AsSsize_t(__pyx_v_index); if (unlikely((__pyx_t_10 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 751, __pyx_L1_error)
+      __pyx_t_10 = __Pyx_PyIndex_AsSsize_t(__pyx_v_index); if (unlikely((__pyx_t_10 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 753, __pyx_L1_error)
 
-      /* "View.MemoryView":748
+      /* "View.MemoryView":750
  *     for dim, index in enumerate(indices):
  *         if PyIndex_Check(index):
  *             slice_memviewslice(             # <<<<<<<<<<<<<<
  *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
  *                 dim, new_ndim, p_suboffset_dim,
  */
-      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_t_10, 0, 0, 0, 0, 0, 0); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(2, 748, __pyx_L1_error)
+      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_t_10, 0, 0, 0, 0, 0, 0); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(2, 750, __pyx_L1_error)
 
-      /* "View.MemoryView":747
+      /* "View.MemoryView":749
  * 
  *     for dim, index in enumerate(indices):
  *         if PyIndex_Check(index):             # <<<<<<<<<<<<<<
  *             slice_memviewslice(
  *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
  */
       goto __pyx_L6;
     }
 
-    /* "View.MemoryView":754
+    /* "View.MemoryView":756
  *                 0, 0, 0, # have_{start,stop,step}
  *                 False)
  *         elif index is None:             # <<<<<<<<<<<<<<
  *             p_dst.shape[new_ndim] = 1
  *             p_dst.strides[new_ndim] = 0
  */
     __pyx_t_2 = (__pyx_v_index == Py_None);
     __pyx_t_1 = (__pyx_t_2 != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":755
+      /* "View.MemoryView":757
  *                 False)
  *         elif index is None:
  *             p_dst.shape[new_ndim] = 1             # <<<<<<<<<<<<<<
  *             p_dst.strides[new_ndim] = 0
  *             p_dst.suboffsets[new_ndim] = -1
  */
       (__pyx_v_p_dst->shape[__pyx_v_new_ndim]) = 1;
 
-      /* "View.MemoryView":756
+      /* "View.MemoryView":758
  *         elif index is None:
  *             p_dst.shape[new_ndim] = 1
  *             p_dst.strides[new_ndim] = 0             # <<<<<<<<<<<<<<
  *             p_dst.suboffsets[new_ndim] = -1
  *             new_ndim += 1
  */
       (__pyx_v_p_dst->strides[__pyx_v_new_ndim]) = 0;
 
-      /* "View.MemoryView":757
+      /* "View.MemoryView":759
  *             p_dst.shape[new_ndim] = 1
  *             p_dst.strides[new_ndim] = 0
  *             p_dst.suboffsets[new_ndim] = -1             # <<<<<<<<<<<<<<
  *             new_ndim += 1
  *         else:
  */
       (__pyx_v_p_dst->suboffsets[__pyx_v_new_ndim]) = -1L;
 
-      /* "View.MemoryView":758
+      /* "View.MemoryView":760
  *             p_dst.strides[new_ndim] = 0
  *             p_dst.suboffsets[new_ndim] = -1
  *             new_ndim += 1             # <<<<<<<<<<<<<<
  *         else:
  *             start = index.start or 0
  */
       __pyx_v_new_ndim = (__pyx_v_new_ndim + 1);
 
-      /* "View.MemoryView":754
+      /* "View.MemoryView":756
  *                 0, 0, 0, # have_{start,stop,step}
  *                 False)
  *         elif index is None:             # <<<<<<<<<<<<<<
  *             p_dst.shape[new_ndim] = 1
  *             p_dst.strides[new_ndim] = 0
  */
       goto __pyx_L6;
     }
 
-    /* "View.MemoryView":760
+    /* "View.MemoryView":762
  *             new_ndim += 1
  *         else:
  *             start = index.start or 0             # <<<<<<<<<<<<<<
  *             stop = index.stop or 0
  *             step = index.step or 0
  */
     /*else*/ {
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 760, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 762, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
-      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 760, __pyx_L1_error)
+      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 762, __pyx_L1_error)
       if (!__pyx_t_1) {
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       } else {
-        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 760, __pyx_L1_error)
+        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 762, __pyx_L1_error)
         __pyx_t_10 = __pyx_t_12;
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         goto __pyx_L7_bool_binop_done;
       }
       __pyx_t_10 = 0;
       __pyx_L7_bool_binop_done:;
       __pyx_v_start = __pyx_t_10;
 
-      /* "View.MemoryView":761
+      /* "View.MemoryView":763
  *         else:
  *             start = index.start or 0
  *             stop = index.stop or 0             # <<<<<<<<<<<<<<
  *             step = index.step or 0
  * 
  */
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 761, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 763, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
-      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 761, __pyx_L1_error)
+      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 763, __pyx_L1_error)
       if (!__pyx_t_1) {
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       } else {
-        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 761, __pyx_L1_error)
+        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 763, __pyx_L1_error)
         __pyx_t_10 = __pyx_t_12;
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         goto __pyx_L9_bool_binop_done;
       }
       __pyx_t_10 = 0;
       __pyx_L9_bool_binop_done:;
       __pyx_v_stop = __pyx_t_10;
 
-      /* "View.MemoryView":762
+      /* "View.MemoryView":764
  *             start = index.start or 0
  *             stop = index.stop or 0
  *             step = index.step or 0             # <<<<<<<<<<<<<<
  * 
  *             have_start = index.start is not None
  */
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 762, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 764, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
-      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 762, __pyx_L1_error)
+      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_9); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(2, 764, __pyx_L1_error)
       if (!__pyx_t_1) {
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       } else {
-        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 762, __pyx_L1_error)
+        __pyx_t_12 = __Pyx_PyIndex_AsSsize_t(__pyx_t_9); if (unlikely((__pyx_t_12 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 764, __pyx_L1_error)
         __pyx_t_10 = __pyx_t_12;
         __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
         goto __pyx_L11_bool_binop_done;
       }
       __pyx_t_10 = 0;
       __pyx_L11_bool_binop_done:;
       __pyx_v_step = __pyx_t_10;
 
-      /* "View.MemoryView":764
+      /* "View.MemoryView":766
  *             step = index.step or 0
  * 
  *             have_start = index.start is not None             # <<<<<<<<<<<<<<
  *             have_stop = index.stop is not None
  *             have_step = index.step is not None
  */
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 764, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_start); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 766, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __pyx_t_1 = (__pyx_t_9 != Py_None);
       __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       __pyx_v_have_start = __pyx_t_1;
 
-      /* "View.MemoryView":765
+      /* "View.MemoryView":767
  * 
  *             have_start = index.start is not None
  *             have_stop = index.stop is not None             # <<<<<<<<<<<<<<
  *             have_step = index.step is not None
  * 
  */
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 765, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_stop); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 767, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __pyx_t_1 = (__pyx_t_9 != Py_None);
       __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       __pyx_v_have_stop = __pyx_t_1;
 
-      /* "View.MemoryView":766
+      /* "View.MemoryView":768
  *             have_start = index.start is not None
  *             have_stop = index.stop is not None
  *             have_step = index.step is not None             # <<<<<<<<<<<<<<
  * 
  *             slice_memviewslice(
  */
-      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 766, __pyx_L1_error)
+      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_index, __pyx_n_s_step); if (unlikely(!__pyx_t_9)) __PYX_ERR(2, 768, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_9);
       __pyx_t_1 = (__pyx_t_9 != Py_None);
       __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
       __pyx_v_have_step = __pyx_t_1;
 
-      /* "View.MemoryView":768
+      /* "View.MemoryView":770
  *             have_step = index.step is not None
  * 
  *             slice_memviewslice(             # <<<<<<<<<<<<<<
  *                 p_dst, p_src.shape[dim], p_src.strides[dim], p_src.suboffsets[dim],
  *                 dim, new_ndim, p_suboffset_dim,
  */
-      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_v_start, __pyx_v_stop, __pyx_v_step, __pyx_v_have_start, __pyx_v_have_stop, __pyx_v_have_step, 1); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(2, 768, __pyx_L1_error)
+      __pyx_t_11 = __pyx_memoryview_slice_memviewslice(__pyx_v_p_dst, (__pyx_v_p_src->shape[__pyx_v_dim]), (__pyx_v_p_src->strides[__pyx_v_dim]), (__pyx_v_p_src->suboffsets[__pyx_v_dim]), __pyx_v_dim, __pyx_v_new_ndim, __pyx_v_p_suboffset_dim, __pyx_v_start, __pyx_v_stop, __pyx_v_step, __pyx_v_have_start, __pyx_v_have_stop, __pyx_v_have_step, 1); if (unlikely(__pyx_t_11 == ((int)-1))) __PYX_ERR(2, 770, __pyx_L1_error)
 
-      /* "View.MemoryView":774
+      /* "View.MemoryView":776
  *                 have_start, have_stop, have_step,
  *                 True)
  *             new_ndim += 1             # <<<<<<<<<<<<<<
  * 
  *     if isinstance(memview, _memoryviewslice):
  */
       __pyx_v_new_ndim = (__pyx_v_new_ndim + 1);
     }
     __pyx_L6:;
 
-    /* "View.MemoryView":746
+    /* "View.MemoryView":748
  *     cdef bint have_start, have_stop, have_step
  * 
  *     for dim, index in enumerate(indices):             # <<<<<<<<<<<<<<
  *         if PyIndex_Check(index):
  *             slice_memviewslice(
  */
   }
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
 
-  /* "View.MemoryView":776
+  /* "View.MemoryView":778
  *             new_ndim += 1
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         return memoryview_fromslice(dst, new_ndim,
  *                                     memviewsliceobj.to_object_func,
  */
   __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":777
+    /* "View.MemoryView":779
  * 
  *     if isinstance(memview, _memoryviewslice):
  *         return memoryview_fromslice(dst, new_ndim,             # <<<<<<<<<<<<<<
  *                                     memviewsliceobj.to_object_func,
  *                                     memviewsliceobj.to_dtype_func,
  */
     __Pyx_XDECREF(((PyObject *)__pyx_r));
 
-    /* "View.MemoryView":778
+    /* "View.MemoryView":780
  *     if isinstance(memview, _memoryviewslice):
  *         return memoryview_fromslice(dst, new_ndim,
  *                                     memviewsliceobj.to_object_func,             # <<<<<<<<<<<<<<
  *                                     memviewsliceobj.to_dtype_func,
  *                                     memview.dtype_is_object)
  */
-    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 778, __pyx_L1_error) }
+    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 780, __pyx_L1_error) }
 
-    /* "View.MemoryView":779
+    /* "View.MemoryView":781
  *         return memoryview_fromslice(dst, new_ndim,
  *                                     memviewsliceobj.to_object_func,
  *                                     memviewsliceobj.to_dtype_func,             # <<<<<<<<<<<<<<
  *                                     memview.dtype_is_object)
  *     else:
  */
-    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 779, __pyx_L1_error) }
+    if (unlikely(!__pyx_v_memviewsliceobj)) { __Pyx_RaiseUnboundLocalError("memviewsliceobj"); __PYX_ERR(2, 781, __pyx_L1_error) }
 
-    /* "View.MemoryView":777
+    /* "View.MemoryView":779
  * 
  *     if isinstance(memview, _memoryviewslice):
  *         return memoryview_fromslice(dst, new_ndim,             # <<<<<<<<<<<<<<
  *                                     memviewsliceobj.to_object_func,
  *                                     memviewsliceobj.to_dtype_func,
  */
-    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, __pyx_v_memviewsliceobj->to_object_func, __pyx_v_memviewsliceobj->to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 777, __pyx_L1_error)
+    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, __pyx_v_memviewsliceobj->to_object_func, __pyx_v_memviewsliceobj->to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 779, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 777, __pyx_L1_error)
+    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 779, __pyx_L1_error)
     __pyx_r = ((struct __pyx_memoryview_obj *)__pyx_t_3);
     __pyx_t_3 = 0;
     goto __pyx_L0;
 
-    /* "View.MemoryView":776
+    /* "View.MemoryView":778
  *             new_ndim += 1
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         return memoryview_fromslice(dst, new_ndim,
  *                                     memviewsliceobj.to_object_func,
  */
   }
 
-  /* "View.MemoryView":782
+  /* "View.MemoryView":784
  *                                     memview.dtype_is_object)
  *     else:
  *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,             # <<<<<<<<<<<<<<
  *                                     memview.dtype_is_object)
  * 
  */
   /*else*/ {
     __Pyx_XDECREF(((PyObject *)__pyx_r));
 
-    /* "View.MemoryView":783
+    /* "View.MemoryView":785
  *     else:
  *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,
  *                                     memview.dtype_is_object)             # <<<<<<<<<<<<<<
  * 
  * 
  */
-    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, NULL, NULL, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 782, __pyx_L1_error)
+    __pyx_t_3 = __pyx_memoryview_fromslice(__pyx_v_dst, __pyx_v_new_ndim, NULL, NULL, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 784, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
 
-    /* "View.MemoryView":782
+    /* "View.MemoryView":784
  *                                     memview.dtype_is_object)
  *     else:
  *         return memoryview_fromslice(dst, new_ndim, NULL, NULL,             # <<<<<<<<<<<<<<
  *                                     memview.dtype_is_object)
  * 
  */
-    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 782, __pyx_L1_error)
+    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_memoryview_type))))) __PYX_ERR(2, 784, __pyx_L1_error)
     __pyx_r = ((struct __pyx_memoryview_obj *)__pyx_t_3);
     __pyx_t_3 = 0;
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":710
+  /* "View.MemoryView":712
  * 
  * @cname('__pyx_memview_slice')
  * cdef memoryview memview_slice(memoryview memview, object indices):             # <<<<<<<<<<<<<<
  *     cdef int new_ndim = 0, suboffset_dim = -1, dim
  *     cdef bint negative_step
  */
 
@@ -16019,15 +16108,15 @@
   __Pyx_XDECREF((PyObject *)__pyx_v_memviewsliceobj);
   __Pyx_XDECREF(__pyx_v_index);
   __Pyx_XGIVEREF((PyObject *)__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":807
+/* "View.MemoryView":809
  * 
  * @cname('__pyx_memoryview_slice_memviewslice')
  * cdef int slice_memviewslice(             # <<<<<<<<<<<<<<
  *         __Pyx_memviewslice *dst,
  *         Py_ssize_t shape, Py_ssize_t stride, Py_ssize_t suboffset,
  */
 
@@ -16038,95 +16127,95 @@
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
 
-  /* "View.MemoryView":827
+  /* "View.MemoryView":829
  *     cdef bint negative_step
  * 
  *     if not is_slice:             # <<<<<<<<<<<<<<
  * 
  *         if start < 0:
  */
   __pyx_t_1 = ((!(__pyx_v_is_slice != 0)) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":829
+    /* "View.MemoryView":831
  *     if not is_slice:
  * 
  *         if start < 0:             # <<<<<<<<<<<<<<
  *             start += shape
  *         if not 0 <= start < shape:
  */
     __pyx_t_1 = ((__pyx_v_start < 0) != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":830
+      /* "View.MemoryView":832
  * 
  *         if start < 0:
  *             start += shape             # <<<<<<<<<<<<<<
  *         if not 0 <= start < shape:
  *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
  */
       __pyx_v_start = (__pyx_v_start + __pyx_v_shape);
 
-      /* "View.MemoryView":829
+      /* "View.MemoryView":831
  *     if not is_slice:
  * 
  *         if start < 0:             # <<<<<<<<<<<<<<
  *             start += shape
  *         if not 0 <= start < shape:
  */
     }
 
-    /* "View.MemoryView":831
+    /* "View.MemoryView":833
  *         if start < 0:
  *             start += shape
  *         if not 0 <= start < shape:             # <<<<<<<<<<<<<<
  *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
  *     else:
  */
     __pyx_t_1 = (0 <= __pyx_v_start);
     if (__pyx_t_1) {
       __pyx_t_1 = (__pyx_v_start < __pyx_v_shape);
     }
     __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":832
+      /* "View.MemoryView":834
  *             start += shape
  *         if not 0 <= start < shape:
  *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)             # <<<<<<<<<<<<<<
  *     else:
  * 
  */
-      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"Index out of bounds (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 832, __pyx_L1_error)
+      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"Index out of bounds (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 834, __pyx_L1_error)
 
-      /* "View.MemoryView":831
+      /* "View.MemoryView":833
  *         if start < 0:
  *             start += shape
  *         if not 0 <= start < shape:             # <<<<<<<<<<<<<<
  *             _err_dim(IndexError, "Index out of bounds (axis %d)", dim)
  *     else:
  */
     }
 
-    /* "View.MemoryView":827
+    /* "View.MemoryView":829
  *     cdef bint negative_step
  * 
  *     if not is_slice:             # <<<<<<<<<<<<<<
  * 
  *         if start < 0:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":835
+  /* "View.MemoryView":837
  *     else:
  * 
  *         negative_step = have_step != 0 and step < 0             # <<<<<<<<<<<<<<
  * 
  *         if have_step and step == 0:
  */
   /*else*/ {
@@ -16137,15 +16226,15 @@
       goto __pyx_L6_bool_binop_done;
     }
     __pyx_t_1 = ((__pyx_v_step < 0) != 0);
     __pyx_t_2 = __pyx_t_1;
     __pyx_L6_bool_binop_done:;
     __pyx_v_negative_step = __pyx_t_2;
 
-    /* "View.MemoryView":837
+    /* "View.MemoryView":839
  *         negative_step = have_step != 0 and step < 0
  * 
  *         if have_step and step == 0:             # <<<<<<<<<<<<<<
  *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)
  * 
  */
     __pyx_t_1 = (__pyx_v_have_step != 0);
@@ -16155,639 +16244,639 @@
       goto __pyx_L9_bool_binop_done;
     }
     __pyx_t_1 = ((__pyx_v_step == 0) != 0);
     __pyx_t_2 = __pyx_t_1;
     __pyx_L9_bool_binop_done:;
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":838
+      /* "View.MemoryView":840
  * 
  *         if have_step and step == 0:
  *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)             # <<<<<<<<<<<<<<
  * 
  * 
  */
-      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Step may not be zero (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 838, __pyx_L1_error)
+      __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Step may not be zero (axis %d)"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 840, __pyx_L1_error)
 
-      /* "View.MemoryView":837
+      /* "View.MemoryView":839
  *         negative_step = have_step != 0 and step < 0
  * 
  *         if have_step and step == 0:             # <<<<<<<<<<<<<<
  *             _err_dim(ValueError, "Step may not be zero (axis %d)", dim)
  * 
  */
     }
 
-    /* "View.MemoryView":841
+    /* "View.MemoryView":843
  * 
  * 
  *         if have_start:             # <<<<<<<<<<<<<<
  *             if start < 0:
  *                 start += shape
  */
     __pyx_t_2 = (__pyx_v_have_start != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":842
+      /* "View.MemoryView":844
  * 
  *         if have_start:
  *             if start < 0:             # <<<<<<<<<<<<<<
  *                 start += shape
  *                 if start < 0:
  */
       __pyx_t_2 = ((__pyx_v_start < 0) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":843
+        /* "View.MemoryView":845
  *         if have_start:
  *             if start < 0:
  *                 start += shape             # <<<<<<<<<<<<<<
  *                 if start < 0:
  *                     start = 0
  */
         __pyx_v_start = (__pyx_v_start + __pyx_v_shape);
 
-        /* "View.MemoryView":844
+        /* "View.MemoryView":846
  *             if start < 0:
  *                 start += shape
  *                 if start < 0:             # <<<<<<<<<<<<<<
  *                     start = 0
  *             elif start >= shape:
  */
         __pyx_t_2 = ((__pyx_v_start < 0) != 0);
         if (__pyx_t_2) {
 
-          /* "View.MemoryView":845
+          /* "View.MemoryView":847
  *                 start += shape
  *                 if start < 0:
  *                     start = 0             # <<<<<<<<<<<<<<
  *             elif start >= shape:
  *                 if negative_step:
  */
           __pyx_v_start = 0;
 
-          /* "View.MemoryView":844
+          /* "View.MemoryView":846
  *             if start < 0:
  *                 start += shape
  *                 if start < 0:             # <<<<<<<<<<<<<<
  *                     start = 0
  *             elif start >= shape:
  */
         }
 
-        /* "View.MemoryView":842
+        /* "View.MemoryView":844
  * 
  *         if have_start:
  *             if start < 0:             # <<<<<<<<<<<<<<
  *                 start += shape
  *                 if start < 0:
  */
         goto __pyx_L12;
       }
 
-      /* "View.MemoryView":846
+      /* "View.MemoryView":848
  *                 if start < 0:
  *                     start = 0
  *             elif start >= shape:             # <<<<<<<<<<<<<<
  *                 if negative_step:
  *                     start = shape - 1
  */
       __pyx_t_2 = ((__pyx_v_start >= __pyx_v_shape) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":847
+        /* "View.MemoryView":849
  *                     start = 0
  *             elif start >= shape:
  *                 if negative_step:             # <<<<<<<<<<<<<<
  *                     start = shape - 1
  *                 else:
  */
         __pyx_t_2 = (__pyx_v_negative_step != 0);
         if (__pyx_t_2) {
 
-          /* "View.MemoryView":848
+          /* "View.MemoryView":850
  *             elif start >= shape:
  *                 if negative_step:
  *                     start = shape - 1             # <<<<<<<<<<<<<<
  *                 else:
  *                     start = shape
  */
           __pyx_v_start = (__pyx_v_shape - 1);
 
-          /* "View.MemoryView":847
+          /* "View.MemoryView":849
  *                     start = 0
  *             elif start >= shape:
  *                 if negative_step:             # <<<<<<<<<<<<<<
  *                     start = shape - 1
  *                 else:
  */
           goto __pyx_L14;
         }
 
-        /* "View.MemoryView":850
+        /* "View.MemoryView":852
  *                     start = shape - 1
  *                 else:
  *                     start = shape             # <<<<<<<<<<<<<<
  *         else:
  *             if negative_step:
  */
         /*else*/ {
           __pyx_v_start = __pyx_v_shape;
         }
         __pyx_L14:;
 
-        /* "View.MemoryView":846
+        /* "View.MemoryView":848
  *                 if start < 0:
  *                     start = 0
  *             elif start >= shape:             # <<<<<<<<<<<<<<
  *                 if negative_step:
  *                     start = shape - 1
  */
       }
       __pyx_L12:;
 
-      /* "View.MemoryView":841
+      /* "View.MemoryView":843
  * 
  * 
  *         if have_start:             # <<<<<<<<<<<<<<
  *             if start < 0:
  *                 start += shape
  */
       goto __pyx_L11;
     }
 
-    /* "View.MemoryView":852
+    /* "View.MemoryView":854
  *                     start = shape
  *         else:
  *             if negative_step:             # <<<<<<<<<<<<<<
  *                 start = shape - 1
  *             else:
  */
     /*else*/ {
       __pyx_t_2 = (__pyx_v_negative_step != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":853
+        /* "View.MemoryView":855
  *         else:
  *             if negative_step:
  *                 start = shape - 1             # <<<<<<<<<<<<<<
  *             else:
  *                 start = 0
  */
         __pyx_v_start = (__pyx_v_shape - 1);
 
-        /* "View.MemoryView":852
+        /* "View.MemoryView":854
  *                     start = shape
  *         else:
  *             if negative_step:             # <<<<<<<<<<<<<<
  *                 start = shape - 1
  *             else:
  */
         goto __pyx_L15;
       }
 
-      /* "View.MemoryView":855
+      /* "View.MemoryView":857
  *                 start = shape - 1
  *             else:
  *                 start = 0             # <<<<<<<<<<<<<<
  * 
  *         if have_stop:
  */
       /*else*/ {
         __pyx_v_start = 0;
       }
       __pyx_L15:;
     }
     __pyx_L11:;
 
-    /* "View.MemoryView":857
+    /* "View.MemoryView":859
  *                 start = 0
  * 
  *         if have_stop:             # <<<<<<<<<<<<<<
  *             if stop < 0:
  *                 stop += shape
  */
     __pyx_t_2 = (__pyx_v_have_stop != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":858
+      /* "View.MemoryView":860
  * 
  *         if have_stop:
  *             if stop < 0:             # <<<<<<<<<<<<<<
  *                 stop += shape
  *                 if stop < 0:
  */
       __pyx_t_2 = ((__pyx_v_stop < 0) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":859
+        /* "View.MemoryView":861
  *         if have_stop:
  *             if stop < 0:
  *                 stop += shape             # <<<<<<<<<<<<<<
  *                 if stop < 0:
  *                     stop = 0
  */
         __pyx_v_stop = (__pyx_v_stop + __pyx_v_shape);
 
-        /* "View.MemoryView":860
+        /* "View.MemoryView":862
  *             if stop < 0:
  *                 stop += shape
  *                 if stop < 0:             # <<<<<<<<<<<<<<
  *                     stop = 0
  *             elif stop > shape:
  */
         __pyx_t_2 = ((__pyx_v_stop < 0) != 0);
         if (__pyx_t_2) {
 
-          /* "View.MemoryView":861
+          /* "View.MemoryView":863
  *                 stop += shape
  *                 if stop < 0:
  *                     stop = 0             # <<<<<<<<<<<<<<
  *             elif stop > shape:
  *                 stop = shape
  */
           __pyx_v_stop = 0;
 
-          /* "View.MemoryView":860
+          /* "View.MemoryView":862
  *             if stop < 0:
  *                 stop += shape
  *                 if stop < 0:             # <<<<<<<<<<<<<<
  *                     stop = 0
  *             elif stop > shape:
  */
         }
 
-        /* "View.MemoryView":858
+        /* "View.MemoryView":860
  * 
  *         if have_stop:
  *             if stop < 0:             # <<<<<<<<<<<<<<
  *                 stop += shape
  *                 if stop < 0:
  */
         goto __pyx_L17;
       }
 
-      /* "View.MemoryView":862
+      /* "View.MemoryView":864
  *                 if stop < 0:
  *                     stop = 0
  *             elif stop > shape:             # <<<<<<<<<<<<<<
  *                 stop = shape
  *         else:
  */
       __pyx_t_2 = ((__pyx_v_stop > __pyx_v_shape) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":863
+        /* "View.MemoryView":865
  *                     stop = 0
  *             elif stop > shape:
  *                 stop = shape             # <<<<<<<<<<<<<<
  *         else:
  *             if negative_step:
  */
         __pyx_v_stop = __pyx_v_shape;
 
-        /* "View.MemoryView":862
+        /* "View.MemoryView":864
  *                 if stop < 0:
  *                     stop = 0
  *             elif stop > shape:             # <<<<<<<<<<<<<<
  *                 stop = shape
  *         else:
  */
       }
       __pyx_L17:;
 
-      /* "View.MemoryView":857
+      /* "View.MemoryView":859
  *                 start = 0
  * 
  *         if have_stop:             # <<<<<<<<<<<<<<
  *             if stop < 0:
  *                 stop += shape
  */
       goto __pyx_L16;
     }
 
-    /* "View.MemoryView":865
+    /* "View.MemoryView":867
  *                 stop = shape
  *         else:
  *             if negative_step:             # <<<<<<<<<<<<<<
  *                 stop = -1
  *             else:
  */
     /*else*/ {
       __pyx_t_2 = (__pyx_v_negative_step != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":866
+        /* "View.MemoryView":868
  *         else:
  *             if negative_step:
  *                 stop = -1             # <<<<<<<<<<<<<<
  *             else:
  *                 stop = shape
  */
         __pyx_v_stop = -1L;
 
-        /* "View.MemoryView":865
+        /* "View.MemoryView":867
  *                 stop = shape
  *         else:
  *             if negative_step:             # <<<<<<<<<<<<<<
  *                 stop = -1
  *             else:
  */
         goto __pyx_L19;
       }
 
-      /* "View.MemoryView":868
+      /* "View.MemoryView":870
  *                 stop = -1
  *             else:
  *                 stop = shape             # <<<<<<<<<<<<<<
  * 
  *         if not have_step:
  */
       /*else*/ {
         __pyx_v_stop = __pyx_v_shape;
       }
       __pyx_L19:;
     }
     __pyx_L16:;
 
-    /* "View.MemoryView":870
+    /* "View.MemoryView":872
  *                 stop = shape
  * 
  *         if not have_step:             # <<<<<<<<<<<<<<
  *             step = 1
  * 
  */
     __pyx_t_2 = ((!(__pyx_v_have_step != 0)) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":871
+      /* "View.MemoryView":873
  * 
  *         if not have_step:
  *             step = 1             # <<<<<<<<<<<<<<
  * 
  * 
  */
       __pyx_v_step = 1;
 
-      /* "View.MemoryView":870
+      /* "View.MemoryView":872
  *                 stop = shape
  * 
  *         if not have_step:             # <<<<<<<<<<<<<<
  *             step = 1
  * 
  */
     }
 
-    /* "View.MemoryView":875
+    /* "View.MemoryView":877
  * 
  *         with cython.cdivision(True):
  *             new_shape = (stop - start) // step             # <<<<<<<<<<<<<<
  * 
  *             if (stop - start) - step * new_shape:
  */
     __pyx_v_new_shape = ((__pyx_v_stop - __pyx_v_start) / __pyx_v_step);
 
-    /* "View.MemoryView":877
+    /* "View.MemoryView":879
  *             new_shape = (stop - start) // step
  * 
  *             if (stop - start) - step * new_shape:             # <<<<<<<<<<<<<<
  *                 new_shape += 1
  * 
  */
     __pyx_t_2 = (((__pyx_v_stop - __pyx_v_start) - (__pyx_v_step * __pyx_v_new_shape)) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":878
+      /* "View.MemoryView":880
  * 
  *             if (stop - start) - step * new_shape:
  *                 new_shape += 1             # <<<<<<<<<<<<<<
  * 
  *         if new_shape < 0:
  */
       __pyx_v_new_shape = (__pyx_v_new_shape + 1);
 
-      /* "View.MemoryView":877
+      /* "View.MemoryView":879
  *             new_shape = (stop - start) // step
  * 
  *             if (stop - start) - step * new_shape:             # <<<<<<<<<<<<<<
  *                 new_shape += 1
  * 
  */
     }
 
-    /* "View.MemoryView":880
+    /* "View.MemoryView":882
  *                 new_shape += 1
  * 
  *         if new_shape < 0:             # <<<<<<<<<<<<<<
  *             new_shape = 0
  * 
  */
     __pyx_t_2 = ((__pyx_v_new_shape < 0) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":881
+      /* "View.MemoryView":883
  * 
  *         if new_shape < 0:
  *             new_shape = 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
       __pyx_v_new_shape = 0;
 
-      /* "View.MemoryView":880
+      /* "View.MemoryView":882
  *                 new_shape += 1
  * 
  *         if new_shape < 0:             # <<<<<<<<<<<<<<
  *             new_shape = 0
  * 
  */
     }
 
-    /* "View.MemoryView":884
+    /* "View.MemoryView":886
  * 
  * 
  *         dst.strides[new_ndim] = stride * step             # <<<<<<<<<<<<<<
  *         dst.shape[new_ndim] = new_shape
  *         dst.suboffsets[new_ndim] = suboffset
  */
     (__pyx_v_dst->strides[__pyx_v_new_ndim]) = (__pyx_v_stride * __pyx_v_step);
 
-    /* "View.MemoryView":885
+    /* "View.MemoryView":887
  * 
  *         dst.strides[new_ndim] = stride * step
  *         dst.shape[new_ndim] = new_shape             # <<<<<<<<<<<<<<
  *         dst.suboffsets[new_ndim] = suboffset
  * 
  */
     (__pyx_v_dst->shape[__pyx_v_new_ndim]) = __pyx_v_new_shape;
 
-    /* "View.MemoryView":886
+    /* "View.MemoryView":888
  *         dst.strides[new_ndim] = stride * step
  *         dst.shape[new_ndim] = new_shape
  *         dst.suboffsets[new_ndim] = suboffset             # <<<<<<<<<<<<<<
  * 
  * 
  */
     (__pyx_v_dst->suboffsets[__pyx_v_new_ndim]) = __pyx_v_suboffset;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":889
+  /* "View.MemoryView":891
  * 
  * 
  *     if suboffset_dim[0] < 0:             # <<<<<<<<<<<<<<
  *         dst.data += start * stride
  *     else:
  */
   __pyx_t_2 = (((__pyx_v_suboffset_dim[0]) < 0) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":890
+    /* "View.MemoryView":892
  * 
  *     if suboffset_dim[0] < 0:
  *         dst.data += start * stride             # <<<<<<<<<<<<<<
  *     else:
  *         dst.suboffsets[suboffset_dim[0]] += start * stride
  */
     __pyx_v_dst->data = (__pyx_v_dst->data + (__pyx_v_start * __pyx_v_stride));
 
-    /* "View.MemoryView":889
+    /* "View.MemoryView":891
  * 
  * 
  *     if suboffset_dim[0] < 0:             # <<<<<<<<<<<<<<
  *         dst.data += start * stride
  *     else:
  */
     goto __pyx_L23;
   }
 
-  /* "View.MemoryView":892
+  /* "View.MemoryView":894
  *         dst.data += start * stride
  *     else:
  *         dst.suboffsets[suboffset_dim[0]] += start * stride             # <<<<<<<<<<<<<<
  * 
  *     if suboffset >= 0:
  */
   /*else*/ {
     __pyx_t_3 = (__pyx_v_suboffset_dim[0]);
     (__pyx_v_dst->suboffsets[__pyx_t_3]) = ((__pyx_v_dst->suboffsets[__pyx_t_3]) + (__pyx_v_start * __pyx_v_stride));
   }
   __pyx_L23:;
 
-  /* "View.MemoryView":894
+  /* "View.MemoryView":896
  *         dst.suboffsets[suboffset_dim[0]] += start * stride
  * 
  *     if suboffset >= 0:             # <<<<<<<<<<<<<<
  *         if not is_slice:
  *             if new_ndim == 0:
  */
   __pyx_t_2 = ((__pyx_v_suboffset >= 0) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":895
+    /* "View.MemoryView":897
  * 
  *     if suboffset >= 0:
  *         if not is_slice:             # <<<<<<<<<<<<<<
  *             if new_ndim == 0:
  *                 dst.data = (<char **> dst.data)[0] + suboffset
  */
     __pyx_t_2 = ((!(__pyx_v_is_slice != 0)) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":896
+      /* "View.MemoryView":898
  *     if suboffset >= 0:
  *         if not is_slice:
  *             if new_ndim == 0:             # <<<<<<<<<<<<<<
  *                 dst.data = (<char **> dst.data)[0] + suboffset
  *             else:
  */
       __pyx_t_2 = ((__pyx_v_new_ndim == 0) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":897
+        /* "View.MemoryView":899
  *         if not is_slice:
  *             if new_ndim == 0:
  *                 dst.data = (<char **> dst.data)[0] + suboffset             # <<<<<<<<<<<<<<
  *             else:
  *                 _err_dim(IndexError, "All dimensions preceding dimension %d "
  */
         __pyx_v_dst->data = ((((char **)__pyx_v_dst->data)[0]) + __pyx_v_suboffset);
 
-        /* "View.MemoryView":896
+        /* "View.MemoryView":898
  *     if suboffset >= 0:
  *         if not is_slice:
  *             if new_ndim == 0:             # <<<<<<<<<<<<<<
  *                 dst.data = (<char **> dst.data)[0] + suboffset
  *             else:
  */
         goto __pyx_L26;
       }
 
-      /* "View.MemoryView":899
+      /* "View.MemoryView":901
  *                 dst.data = (<char **> dst.data)[0] + suboffset
  *             else:
  *                 _err_dim(IndexError, "All dimensions preceding dimension %d "             # <<<<<<<<<<<<<<
  *                                      "must be indexed and not sliced", dim)
  *         else:
  */
       /*else*/ {
 
-        /* "View.MemoryView":900
+        /* "View.MemoryView":902
  *             else:
  *                 _err_dim(IndexError, "All dimensions preceding dimension %d "
  *                                      "must be indexed and not sliced", dim)             # <<<<<<<<<<<<<<
  *         else:
  *             suboffset_dim[0] = new_ndim
  */
-        __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"All dimensions preceding dimension %d must be indexed and not sliced"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 899, __pyx_L1_error)
+        __pyx_t_3 = __pyx_memoryview_err_dim(__pyx_builtin_IndexError, ((char *)"All dimensions preceding dimension %d must be indexed and not sliced"), __pyx_v_dim); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 901, __pyx_L1_error)
       }
       __pyx_L26:;
 
-      /* "View.MemoryView":895
+      /* "View.MemoryView":897
  * 
  *     if suboffset >= 0:
  *         if not is_slice:             # <<<<<<<<<<<<<<
  *             if new_ndim == 0:
  *                 dst.data = (<char **> dst.data)[0] + suboffset
  */
       goto __pyx_L25;
     }
 
-    /* "View.MemoryView":902
+    /* "View.MemoryView":904
  *                                      "must be indexed and not sliced", dim)
  *         else:
  *             suboffset_dim[0] = new_ndim             # <<<<<<<<<<<<<<
  * 
  *     return 0
  */
     /*else*/ {
       (__pyx_v_suboffset_dim[0]) = __pyx_v_new_ndim;
     }
     __pyx_L25:;
 
-    /* "View.MemoryView":894
+    /* "View.MemoryView":896
  *         dst.suboffsets[suboffset_dim[0]] += start * stride
  * 
  *     if suboffset >= 0:             # <<<<<<<<<<<<<<
  *         if not is_slice:
  *             if new_ndim == 0:
  */
   }
 
-  /* "View.MemoryView":904
+  /* "View.MemoryView":906
  *             suboffset_dim[0] = new_ndim
  * 
  *     return 0             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":807
+  /* "View.MemoryView":809
  * 
  * @cname('__pyx_memoryview_slice_memviewslice')
  * cdef int slice_memviewslice(             # <<<<<<<<<<<<<<
  *         __Pyx_memviewslice *dst,
  *         Py_ssize_t shape, Py_ssize_t stride, Py_ssize_t suboffset,
  */
 
@@ -16803,15 +16892,15 @@
     #endif
   }
   __pyx_r = -1;
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":910
+/* "View.MemoryView":912
  * 
  * @cname('__pyx_pybuffer_index')
  * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,             # <<<<<<<<<<<<<<
  *                           Py_ssize_t dim) except NULL:
  *     cdef Py_ssize_t shape, stride, suboffset = -1
  */
 
@@ -16828,280 +16917,280 @@
   PyObject *__pyx_t_3 = NULL;
   PyObject *__pyx_t_4 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("pybuffer_index", 0);
 
-  /* "View.MemoryView":912
+  /* "View.MemoryView":914
  * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,
  *                           Py_ssize_t dim) except NULL:
  *     cdef Py_ssize_t shape, stride, suboffset = -1             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t itemsize = view.itemsize
  *     cdef char *resultp
  */
   __pyx_v_suboffset = -1L;
 
-  /* "View.MemoryView":913
+  /* "View.MemoryView":915
  *                           Py_ssize_t dim) except NULL:
  *     cdef Py_ssize_t shape, stride, suboffset = -1
  *     cdef Py_ssize_t itemsize = view.itemsize             # <<<<<<<<<<<<<<
  *     cdef char *resultp
  * 
  */
   __pyx_t_1 = __pyx_v_view->itemsize;
   __pyx_v_itemsize = __pyx_t_1;
 
-  /* "View.MemoryView":916
+  /* "View.MemoryView":918
  *     cdef char *resultp
  * 
  *     if view.ndim == 0:             # <<<<<<<<<<<<<<
  *         shape = view.len / itemsize
  *         stride = itemsize
  */
   __pyx_t_2 = ((__pyx_v_view->ndim == 0) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":917
+    /* "View.MemoryView":919
  * 
  *     if view.ndim == 0:
  *         shape = view.len / itemsize             # <<<<<<<<<<<<<<
  *         stride = itemsize
  *     else:
  */
     if (unlikely(__pyx_v_itemsize == 0)) {
       PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
-      __PYX_ERR(2, 917, __pyx_L1_error)
+      __PYX_ERR(2, 919, __pyx_L1_error)
     }
     else if (sizeof(Py_ssize_t) == sizeof(long) && (!(((Py_ssize_t)-1) > 0)) && unlikely(__pyx_v_itemsize == (Py_ssize_t)-1)  && unlikely(UNARY_NEG_WOULD_OVERFLOW(__pyx_v_view->len))) {
       PyErr_SetString(PyExc_OverflowError, "value too large to perform division");
-      __PYX_ERR(2, 917, __pyx_L1_error)
+      __PYX_ERR(2, 919, __pyx_L1_error)
     }
     __pyx_v_shape = __Pyx_div_Py_ssize_t(__pyx_v_view->len, __pyx_v_itemsize);
 
-    /* "View.MemoryView":918
+    /* "View.MemoryView":920
  *     if view.ndim == 0:
  *         shape = view.len / itemsize
  *         stride = itemsize             # <<<<<<<<<<<<<<
  *     else:
  *         shape = view.shape[dim]
  */
     __pyx_v_stride = __pyx_v_itemsize;
 
-    /* "View.MemoryView":916
+    /* "View.MemoryView":918
  *     cdef char *resultp
  * 
  *     if view.ndim == 0:             # <<<<<<<<<<<<<<
  *         shape = view.len / itemsize
  *         stride = itemsize
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":920
+  /* "View.MemoryView":922
  *         stride = itemsize
  *     else:
  *         shape = view.shape[dim]             # <<<<<<<<<<<<<<
  *         stride = view.strides[dim]
  *         if view.suboffsets != NULL:
  */
   /*else*/ {
     __pyx_v_shape = (__pyx_v_view->shape[__pyx_v_dim]);
 
-    /* "View.MemoryView":921
+    /* "View.MemoryView":923
  *     else:
  *         shape = view.shape[dim]
  *         stride = view.strides[dim]             # <<<<<<<<<<<<<<
  *         if view.suboffsets != NULL:
  *             suboffset = view.suboffsets[dim]
  */
     __pyx_v_stride = (__pyx_v_view->strides[__pyx_v_dim]);
 
-    /* "View.MemoryView":922
+    /* "View.MemoryView":924
  *         shape = view.shape[dim]
  *         stride = view.strides[dim]
  *         if view.suboffsets != NULL:             # <<<<<<<<<<<<<<
  *             suboffset = view.suboffsets[dim]
  * 
  */
     __pyx_t_2 = ((__pyx_v_view->suboffsets != NULL) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":923
+      /* "View.MemoryView":925
  *         stride = view.strides[dim]
  *         if view.suboffsets != NULL:
  *             suboffset = view.suboffsets[dim]             # <<<<<<<<<<<<<<
  * 
  *     if index < 0:
  */
       __pyx_v_suboffset = (__pyx_v_view->suboffsets[__pyx_v_dim]);
 
-      /* "View.MemoryView":922
+      /* "View.MemoryView":924
  *         shape = view.shape[dim]
  *         stride = view.strides[dim]
  *         if view.suboffsets != NULL:             # <<<<<<<<<<<<<<
  *             suboffset = view.suboffsets[dim]
  * 
  */
     }
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":925
+  /* "View.MemoryView":927
  *             suboffset = view.suboffsets[dim]
  * 
  *     if index < 0:             # <<<<<<<<<<<<<<
  *         index += view.shape[dim]
  *         if index < 0:
  */
   __pyx_t_2 = ((__pyx_v_index < 0) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":926
+    /* "View.MemoryView":928
  * 
  *     if index < 0:
  *         index += view.shape[dim]             # <<<<<<<<<<<<<<
  *         if index < 0:
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  */
     __pyx_v_index = (__pyx_v_index + (__pyx_v_view->shape[__pyx_v_dim]));
 
-    /* "View.MemoryView":927
+    /* "View.MemoryView":929
  *     if index < 0:
  *         index += view.shape[dim]
  *         if index < 0:             # <<<<<<<<<<<<<<
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  */
     __pyx_t_2 = ((__pyx_v_index < 0) != 0);
     if (unlikely(__pyx_t_2)) {
 
-      /* "View.MemoryView":928
+      /* "View.MemoryView":930
  *         index += view.shape[dim]
  *         if index < 0:
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)             # <<<<<<<<<<<<<<
  * 
  *     if index >= shape:
  */
-      __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 928, __pyx_L1_error)
+      __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 930, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_3);
-      __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 928, __pyx_L1_error)
+      __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 930, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_4);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_IndexError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 928, __pyx_L1_error)
+      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_IndexError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 930, __pyx_L1_error)
       __Pyx_GOTREF(__pyx_t_3);
       __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
       __Pyx_Raise(__pyx_t_3, 0, 0, 0);
       __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-      __PYX_ERR(2, 928, __pyx_L1_error)
+      __PYX_ERR(2, 930, __pyx_L1_error)
 
-      /* "View.MemoryView":927
+      /* "View.MemoryView":929
  *     if index < 0:
  *         index += view.shape[dim]
  *         if index < 0:             # <<<<<<<<<<<<<<
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  */
     }
 
-    /* "View.MemoryView":925
+    /* "View.MemoryView":927
  *             suboffset = view.suboffsets[dim]
  * 
  *     if index < 0:             # <<<<<<<<<<<<<<
  *         index += view.shape[dim]
  *         if index < 0:
  */
   }
 
-  /* "View.MemoryView":930
+  /* "View.MemoryView":932
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  *     if index >= shape:             # <<<<<<<<<<<<<<
  *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  */
   __pyx_t_2 = ((__pyx_v_index >= __pyx_v_shape) != 0);
   if (unlikely(__pyx_t_2)) {
 
-    /* "View.MemoryView":931
+    /* "View.MemoryView":933
  * 
  *     if index >= shape:
  *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)             # <<<<<<<<<<<<<<
  * 
  *     resultp = bufp + index * stride
  */
-    __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 931, __pyx_L1_error)
+    __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 933, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
-    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 931, __pyx_L1_error)
+    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Out_of_bounds_on_buffer_access_a, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 933, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_4);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_IndexError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 931, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_builtin_IndexError, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 933, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
     __Pyx_Raise(__pyx_t_3, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    __PYX_ERR(2, 931, __pyx_L1_error)
+    __PYX_ERR(2, 933, __pyx_L1_error)
 
-    /* "View.MemoryView":930
+    /* "View.MemoryView":932
  *             raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  *     if index >= shape:             # <<<<<<<<<<<<<<
  *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  */
   }
 
-  /* "View.MemoryView":933
+  /* "View.MemoryView":935
  *         raise IndexError("Out of bounds on buffer access (axis %d)" % dim)
  * 
  *     resultp = bufp + index * stride             # <<<<<<<<<<<<<<
  *     if suboffset >= 0:
  *         resultp = (<char **> resultp)[0] + suboffset
  */
   __pyx_v_resultp = (__pyx_v_bufp + (__pyx_v_index * __pyx_v_stride));
 
-  /* "View.MemoryView":934
+  /* "View.MemoryView":936
  * 
  *     resultp = bufp + index * stride
  *     if suboffset >= 0:             # <<<<<<<<<<<<<<
  *         resultp = (<char **> resultp)[0] + suboffset
  * 
  */
   __pyx_t_2 = ((__pyx_v_suboffset >= 0) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":935
+    /* "View.MemoryView":937
  *     resultp = bufp + index * stride
  *     if suboffset >= 0:
  *         resultp = (<char **> resultp)[0] + suboffset             # <<<<<<<<<<<<<<
  * 
  *     return resultp
  */
     __pyx_v_resultp = ((((char **)__pyx_v_resultp)[0]) + __pyx_v_suboffset);
 
-    /* "View.MemoryView":934
+    /* "View.MemoryView":936
  * 
  *     resultp = bufp + index * stride
  *     if suboffset >= 0:             # <<<<<<<<<<<<<<
  *         resultp = (<char **> resultp)[0] + suboffset
  * 
  */
   }
 
-  /* "View.MemoryView":937
+  /* "View.MemoryView":939
  *         resultp = (<char **> resultp)[0] + suboffset
  * 
  *     return resultp             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = __pyx_v_resultp;
   goto __pyx_L0;
 
-  /* "View.MemoryView":910
+  /* "View.MemoryView":912
  * 
  * @cname('__pyx_pybuffer_index')
  * cdef char *pybuffer_index(Py_buffer *view, char *bufp, Py_ssize_t index,             # <<<<<<<<<<<<<<
  *                           Py_ssize_t dim) except NULL:
  *     cdef Py_ssize_t shape, stride, suboffset = -1
  */
 
@@ -17112,15 +17201,15 @@
   __Pyx_AddTraceback("View.MemoryView.pybuffer_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":943
+/* "View.MemoryView":945
  * 
  * @cname('__pyx_memslice_transpose')
  * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:             # <<<<<<<<<<<<<<
  *     cdef int ndim = memslice.memview.view.ndim
  * 
  */
 
@@ -17140,90 +17229,90 @@
   int __pyx_t_7;
   int __pyx_t_8;
   int __pyx_t_9;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
 
-  /* "View.MemoryView":944
+  /* "View.MemoryView":946
  * @cname('__pyx_memslice_transpose')
  * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:
  *     cdef int ndim = memslice.memview.view.ndim             # <<<<<<<<<<<<<<
  * 
  *     cdef Py_ssize_t *shape = memslice.shape
  */
   __pyx_t_1 = __pyx_v_memslice->memview->view.ndim;
   __pyx_v_ndim = __pyx_t_1;
 
-  /* "View.MemoryView":946
+  /* "View.MemoryView":948
  *     cdef int ndim = memslice.memview.view.ndim
  * 
  *     cdef Py_ssize_t *shape = memslice.shape             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t *strides = memslice.strides
  * 
  */
   __pyx_t_2 = __pyx_v_memslice->shape;
   __pyx_v_shape = __pyx_t_2;
 
-  /* "View.MemoryView":947
+  /* "View.MemoryView":949
  * 
  *     cdef Py_ssize_t *shape = memslice.shape
  *     cdef Py_ssize_t *strides = memslice.strides             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_2 = __pyx_v_memslice->strides;
   __pyx_v_strides = __pyx_t_2;
 
-  /* "View.MemoryView":951
+  /* "View.MemoryView":953
  * 
  *     cdef int i, j
  *     for i in range(ndim / 2):             # <<<<<<<<<<<<<<
  *         j = ndim - 1 - i
  *         strides[i], strides[j] = strides[j], strides[i]
  */
   __pyx_t_3 = __Pyx_div_long(__pyx_v_ndim, 2);
   __pyx_t_4 = __pyx_t_3;
   for (__pyx_t_1 = 0; __pyx_t_1 < __pyx_t_4; __pyx_t_1+=1) {
     __pyx_v_i = __pyx_t_1;
 
-    /* "View.MemoryView":952
+    /* "View.MemoryView":954
  *     cdef int i, j
  *     for i in range(ndim / 2):
  *         j = ndim - 1 - i             # <<<<<<<<<<<<<<
  *         strides[i], strides[j] = strides[j], strides[i]
  *         shape[i], shape[j] = shape[j], shape[i]
  */
     __pyx_v_j = ((__pyx_v_ndim - 1) - __pyx_v_i);
 
-    /* "View.MemoryView":953
+    /* "View.MemoryView":955
  *     for i in range(ndim / 2):
  *         j = ndim - 1 - i
  *         strides[i], strides[j] = strides[j], strides[i]             # <<<<<<<<<<<<<<
  *         shape[i], shape[j] = shape[j], shape[i]
  * 
  */
     __pyx_t_5 = (__pyx_v_strides[__pyx_v_j]);
     __pyx_t_6 = (__pyx_v_strides[__pyx_v_i]);
     (__pyx_v_strides[__pyx_v_i]) = __pyx_t_5;
     (__pyx_v_strides[__pyx_v_j]) = __pyx_t_6;
 
-    /* "View.MemoryView":954
+    /* "View.MemoryView":956
  *         j = ndim - 1 - i
  *         strides[i], strides[j] = strides[j], strides[i]
  *         shape[i], shape[j] = shape[j], shape[i]             # <<<<<<<<<<<<<<
  * 
  *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:
  */
     __pyx_t_6 = (__pyx_v_shape[__pyx_v_j]);
     __pyx_t_5 = (__pyx_v_shape[__pyx_v_i]);
     (__pyx_v_shape[__pyx_v_i]) = __pyx_t_6;
     (__pyx_v_shape[__pyx_v_j]) = __pyx_t_5;
 
-    /* "View.MemoryView":956
+    /* "View.MemoryView":958
  *         shape[i], shape[j] = shape[j], shape[i]
  * 
  *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:             # <<<<<<<<<<<<<<
  *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
  * 
  */
     __pyx_t_8 = (((__pyx_v_memslice->suboffsets[__pyx_v_i]) >= 0) != 0);
@@ -17233,44 +17322,44 @@
       goto __pyx_L6_bool_binop_done;
     }
     __pyx_t_8 = (((__pyx_v_memslice->suboffsets[__pyx_v_j]) >= 0) != 0);
     __pyx_t_7 = __pyx_t_8;
     __pyx_L6_bool_binop_done:;
     if (__pyx_t_7) {
 
-      /* "View.MemoryView":957
+      /* "View.MemoryView":959
  * 
  *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:
  *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")             # <<<<<<<<<<<<<<
  * 
  *     return 1
  */
-      __pyx_t_9 = __pyx_memoryview_err(__pyx_builtin_ValueError, ((char *)"Cannot transpose memoryview with indirect dimensions")); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 957, __pyx_L1_error)
+      __pyx_t_9 = __pyx_memoryview_err(__pyx_builtin_ValueError, ((char *)"Cannot transpose memoryview with indirect dimensions")); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(2, 959, __pyx_L1_error)
 
-      /* "View.MemoryView":956
+      /* "View.MemoryView":958
  *         shape[i], shape[j] = shape[j], shape[i]
  * 
  *         if memslice.suboffsets[i] >= 0 or memslice.suboffsets[j] >= 0:             # <<<<<<<<<<<<<<
  *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
  * 
  */
     }
   }
 
-  /* "View.MemoryView":959
+  /* "View.MemoryView":961
  *             _err(ValueError, "Cannot transpose memoryview with indirect dimensions")
  * 
  *     return 1             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = 1;
   goto __pyx_L0;
 
-  /* "View.MemoryView":943
+  /* "View.MemoryView":945
  * 
  * @cname('__pyx_memslice_transpose')
  * cdef int transpose_memslice(__Pyx_memviewslice *memslice) nogil except 0:             # <<<<<<<<<<<<<<
  *     cdef int ndim = memslice.memview.view.ndim
  * 
  */
 
@@ -17286,15 +17375,15 @@
     #endif
   }
   __pyx_r = 0;
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":976
+/* "View.MemoryView":978
  *     cdef int (*to_dtype_func)(char *, object) except 0
  * 
  *     def __dealloc__(self):             # <<<<<<<<<<<<<<
  *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
  * 
  */
 
@@ -17309,36 +17398,36 @@
   __Pyx_RefNannyFinishContext();
 }
 
 static void __pyx_memoryviewslice___pyx_pf_15View_dot_MemoryView_16_memoryviewslice___dealloc__(struct __pyx_memoryviewslice_obj *__pyx_v_self) {
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__dealloc__", 0);
 
-  /* "View.MemoryView":977
+  /* "View.MemoryView":979
  * 
  *     def __dealloc__(self):
  *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)             # <<<<<<<<<<<<<<
  * 
  *     cdef convert_item_to_object(self, char *itemp):
  */
   __PYX_XDEC_MEMVIEW((&__pyx_v_self->from_slice), 1);
 
-  /* "View.MemoryView":976
+  /* "View.MemoryView":978
  *     cdef int (*to_dtype_func)(char *, object) except 0
  * 
  *     def __dealloc__(self):             # <<<<<<<<<<<<<<
  *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
  * 
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "View.MemoryView":979
+/* "View.MemoryView":981
  *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
  * 
  *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
  *         if self.to_object_func != NULL:
  *             return self.to_object_func(itemp)
  */
 
@@ -17348,64 +17437,64 @@
   int __pyx_t_1;
   PyObject *__pyx_t_2 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("convert_item_to_object", 0);
 
-  /* "View.MemoryView":980
+  /* "View.MemoryView":982
  * 
  *     cdef convert_item_to_object(self, char *itemp):
  *         if self.to_object_func != NULL:             # <<<<<<<<<<<<<<
  *             return self.to_object_func(itemp)
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_self->to_object_func != NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":981
+    /* "View.MemoryView":983
  *     cdef convert_item_to_object(self, char *itemp):
  *         if self.to_object_func != NULL:
  *             return self.to_object_func(itemp)             # <<<<<<<<<<<<<<
  *         else:
  *             return memoryview.convert_item_to_object(self, itemp)
  */
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_2 = __pyx_v_self->to_object_func(__pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 981, __pyx_L1_error)
+    __pyx_t_2 = __pyx_v_self->to_object_func(__pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 983, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __pyx_r = __pyx_t_2;
     __pyx_t_2 = 0;
     goto __pyx_L0;
 
-    /* "View.MemoryView":980
+    /* "View.MemoryView":982
  * 
  *     cdef convert_item_to_object(self, char *itemp):
  *         if self.to_object_func != NULL:             # <<<<<<<<<<<<<<
  *             return self.to_object_func(itemp)
  *         else:
  */
   }
 
-  /* "View.MemoryView":983
+  /* "View.MemoryView":985
  *             return self.to_object_func(itemp)
  *         else:
  *             return memoryview.convert_item_to_object(self, itemp)             # <<<<<<<<<<<<<<
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):
  */
   /*else*/ {
     __Pyx_XDECREF(__pyx_r);
-    __pyx_t_2 = __pyx_memoryview_convert_item_to_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 983, __pyx_L1_error)
+    __pyx_t_2 = __pyx_memoryview_convert_item_to_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 985, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __pyx_r = __pyx_t_2;
     __pyx_t_2 = 0;
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":979
+  /* "View.MemoryView":981
  *         __PYX_XDEC_MEMVIEW(&self.from_slice, 1)
  * 
  *     cdef convert_item_to_object(self, char *itemp):             # <<<<<<<<<<<<<<
  *         if self.to_object_func != NULL:
  *             return self.to_object_func(itemp)
  */
 
@@ -17416,15 +17505,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":985
+/* "View.MemoryView":987
  *             return memoryview.convert_item_to_object(self, itemp)
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
  *         if self.to_dtype_func != NULL:
  *             self.to_dtype_func(itemp, value)
  */
 
@@ -17435,58 +17524,58 @@
   int __pyx_t_2;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("assign_item_from_object", 0);
 
-  /* "View.MemoryView":986
+  /* "View.MemoryView":988
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):
  *         if self.to_dtype_func != NULL:             # <<<<<<<<<<<<<<
  *             self.to_dtype_func(itemp, value)
  *         else:
  */
   __pyx_t_1 = ((__pyx_v_self->to_dtype_func != NULL) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":987
+    /* "View.MemoryView":989
  *     cdef assign_item_from_object(self, char *itemp, object value):
  *         if self.to_dtype_func != NULL:
  *             self.to_dtype_func(itemp, value)             # <<<<<<<<<<<<<<
  *         else:
  *             memoryview.assign_item_from_object(self, itemp, value)
  */
-    __pyx_t_2 = __pyx_v_self->to_dtype_func(__pyx_v_itemp, __pyx_v_value); if (unlikely(__pyx_t_2 == ((int)0))) __PYX_ERR(2, 987, __pyx_L1_error)
+    __pyx_t_2 = __pyx_v_self->to_dtype_func(__pyx_v_itemp, __pyx_v_value); if (unlikely(__pyx_t_2 == ((int)0))) __PYX_ERR(2, 989, __pyx_L1_error)
 
-    /* "View.MemoryView":986
+    /* "View.MemoryView":988
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):
  *         if self.to_dtype_func != NULL:             # <<<<<<<<<<<<<<
  *             self.to_dtype_func(itemp, value)
  *         else:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":989
+  /* "View.MemoryView":991
  *             self.to_dtype_func(itemp, value)
  *         else:
  *             memoryview.assign_item_from_object(self, itemp, value)             # <<<<<<<<<<<<<<
  * 
  *     @property
  */
   /*else*/ {
-    __pyx_t_3 = __pyx_memoryview_assign_item_from_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 989, __pyx_L1_error)
+    __pyx_t_3 = __pyx_memoryview_assign_item_from_object(((struct __pyx_memoryview_obj *)__pyx_v_self), __pyx_v_itemp, __pyx_v_value); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 991, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":985
+  /* "View.MemoryView":987
  *             return memoryview.convert_item_to_object(self, itemp)
  * 
  *     cdef assign_item_from_object(self, char *itemp, object value):             # <<<<<<<<<<<<<<
  *         if self.to_dtype_func != NULL:
  *             self.to_dtype_func(itemp, value)
  */
 
@@ -17499,15 +17588,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":992
+/* "View.MemoryView":994
  * 
  *     @property
  *     def base(self):             # <<<<<<<<<<<<<<
  *         return self.from_object
  * 
  */
 
@@ -17525,27 +17614,27 @@
 }
 
 static PyObject *__pyx_pf_15View_dot_MemoryView_16_memoryviewslice_4base___get__(struct __pyx_memoryviewslice_obj *__pyx_v_self) {
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
   __Pyx_RefNannySetupContext("__get__", 0);
 
-  /* "View.MemoryView":993
+  /* "View.MemoryView":995
  *     @property
  *     def base(self):
  *         return self.from_object             # <<<<<<<<<<<<<<
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(__pyx_v_self->from_object);
   __pyx_r = __pyx_v_self->from_object;
   goto __pyx_L0;
 
-  /* "View.MemoryView":992
+  /* "View.MemoryView":994
  * 
  *     @property
  *     def base(self):             # <<<<<<<<<<<<<<
  *         return self.from_object
  * 
  */
 
@@ -17665,15 +17754,15 @@
   __Pyx_AddTraceback("View.MemoryView._memoryviewslice.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":999
+/* "View.MemoryView":1001
  * 
  * @cname('__pyx_memoryview_fromslice')
  * cdef memoryview_fromslice(__Pyx_memviewslice memviewslice,             # <<<<<<<<<<<<<<
  *                           int ndim,
  *                           object (*to_object_func)(char *),
  */
 
@@ -17693,351 +17782,351 @@
   Py_ssize_t *__pyx_t_8;
   Py_ssize_t __pyx_t_9;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("memoryview_fromslice", 0);
 
-  /* "View.MemoryView":1007
+  /* "View.MemoryView":1009
  *     cdef _memoryviewslice result
  * 
  *     if <PyObject *> memviewslice.memview == Py_None:             # <<<<<<<<<<<<<<
  *         return None
  * 
  */
   __pyx_t_1 = ((((PyObject *)__pyx_v_memviewslice.memview) == Py_None) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1008
+    /* "View.MemoryView":1010
  * 
  *     if <PyObject *> memviewslice.memview == Py_None:
  *         return None             # <<<<<<<<<<<<<<
  * 
  * 
  */
     __Pyx_XDECREF(__pyx_r);
     __pyx_r = Py_None; __Pyx_INCREF(Py_None);
     goto __pyx_L0;
 
-    /* "View.MemoryView":1007
+    /* "View.MemoryView":1009
  *     cdef _memoryviewslice result
  * 
  *     if <PyObject *> memviewslice.memview == Py_None:             # <<<<<<<<<<<<<<
  *         return None
  * 
  */
   }
 
-  /* "View.MemoryView":1013
+  /* "View.MemoryView":1015
  * 
  * 
  *     result = _memoryviewslice(None, 0, dtype_is_object)             # <<<<<<<<<<<<<<
  * 
  *     result.from_slice = memviewslice
  */
-  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1013, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyBool_FromLong(__pyx_v_dtype_is_object); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1015, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1013, __pyx_L1_error)
+  __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1015, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_INCREF(Py_None);
   __Pyx_GIVEREF(Py_None);
   PyTuple_SET_ITEM(__pyx_t_3, 0, Py_None);
   __Pyx_INCREF(__pyx_int_0);
   __Pyx_GIVEREF(__pyx_int_0);
   PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_int_0);
   __Pyx_GIVEREF(__pyx_t_2);
   PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_2);
   __pyx_t_2 = 0;
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryviewslice_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1013, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_memoryviewslice_type), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1015, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __pyx_v_result = ((struct __pyx_memoryviewslice_obj *)__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":1015
+  /* "View.MemoryView":1017
  *     result = _memoryviewslice(None, 0, dtype_is_object)
  * 
  *     result.from_slice = memviewslice             # <<<<<<<<<<<<<<
  *     __PYX_INC_MEMVIEW(&memviewslice, 1)
  * 
  */
   __pyx_v_result->from_slice = __pyx_v_memviewslice;
 
-  /* "View.MemoryView":1016
+  /* "View.MemoryView":1018
  * 
  *     result.from_slice = memviewslice
  *     __PYX_INC_MEMVIEW(&memviewslice, 1)             # <<<<<<<<<<<<<<
  * 
  *     result.from_object = (<memoryview> memviewslice.memview).base
  */
   __PYX_INC_MEMVIEW((&__pyx_v_memviewslice), 1);
 
-  /* "View.MemoryView":1018
+  /* "View.MemoryView":1020
  *     __PYX_INC_MEMVIEW(&memviewslice, 1)
  * 
  *     result.from_object = (<memoryview> memviewslice.memview).base             # <<<<<<<<<<<<<<
  *     result.typeinfo = memviewslice.memview.typeinfo
  * 
  */
-  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_memviewslice.memview), __pyx_n_s_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1018, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_memviewslice.memview), __pyx_n_s_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1020, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __Pyx_GOTREF(__pyx_v_result->from_object);
   __Pyx_DECREF(__pyx_v_result->from_object);
   __pyx_v_result->from_object = __pyx_t_2;
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":1019
+  /* "View.MemoryView":1021
  * 
  *     result.from_object = (<memoryview> memviewslice.memview).base
  *     result.typeinfo = memviewslice.memview.typeinfo             # <<<<<<<<<<<<<<
  * 
  *     result.view = memviewslice.memview.view
  */
   __pyx_t_4 = __pyx_v_memviewslice.memview->typeinfo;
   __pyx_v_result->__pyx_base.typeinfo = __pyx_t_4;
 
-  /* "View.MemoryView":1021
+  /* "View.MemoryView":1023
  *     result.typeinfo = memviewslice.memview.typeinfo
  * 
  *     result.view = memviewslice.memview.view             # <<<<<<<<<<<<<<
  *     result.view.buf = <void *> memviewslice.data
  *     result.view.ndim = ndim
  */
   __pyx_t_5 = __pyx_v_memviewslice.memview->view;
   __pyx_v_result->__pyx_base.view = __pyx_t_5;
 
-  /* "View.MemoryView":1022
+  /* "View.MemoryView":1024
  * 
  *     result.view = memviewslice.memview.view
  *     result.view.buf = <void *> memviewslice.data             # <<<<<<<<<<<<<<
  *     result.view.ndim = ndim
  *     (<__pyx_buffer *> &result.view).obj = Py_None
  */
   __pyx_v_result->__pyx_base.view.buf = ((void *)__pyx_v_memviewslice.data);
 
-  /* "View.MemoryView":1023
+  /* "View.MemoryView":1025
  *     result.view = memviewslice.memview.view
  *     result.view.buf = <void *> memviewslice.data
  *     result.view.ndim = ndim             # <<<<<<<<<<<<<<
  *     (<__pyx_buffer *> &result.view).obj = Py_None
  *     Py_INCREF(Py_None)
  */
   __pyx_v_result->__pyx_base.view.ndim = __pyx_v_ndim;
 
-  /* "View.MemoryView":1024
+  /* "View.MemoryView":1026
  *     result.view.buf = <void *> memviewslice.data
  *     result.view.ndim = ndim
  *     (<__pyx_buffer *> &result.view).obj = Py_None             # <<<<<<<<<<<<<<
  *     Py_INCREF(Py_None)
  * 
  */
   ((Py_buffer *)(&__pyx_v_result->__pyx_base.view))->obj = Py_None;
 
-  /* "View.MemoryView":1025
+  /* "View.MemoryView":1027
  *     result.view.ndim = ndim
  *     (<__pyx_buffer *> &result.view).obj = Py_None
  *     Py_INCREF(Py_None)             # <<<<<<<<<<<<<<
  * 
  *     if (<memoryview>memviewslice.memview).flags & PyBUF_WRITABLE:
  */
   Py_INCREF(Py_None);
 
-  /* "View.MemoryView":1027
+  /* "View.MemoryView":1029
  *     Py_INCREF(Py_None)
  * 
  *     if (<memoryview>memviewslice.memview).flags & PyBUF_WRITABLE:             # <<<<<<<<<<<<<<
  *         result.flags = PyBUF_RECORDS
  *     else:
  */
   __pyx_t_1 = ((((struct __pyx_memoryview_obj *)__pyx_v_memviewslice.memview)->flags & PyBUF_WRITABLE) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1028
+    /* "View.MemoryView":1030
  * 
  *     if (<memoryview>memviewslice.memview).flags & PyBUF_WRITABLE:
  *         result.flags = PyBUF_RECORDS             # <<<<<<<<<<<<<<
  *     else:
  *         result.flags = PyBUF_RECORDS_RO
  */
     __pyx_v_result->__pyx_base.flags = PyBUF_RECORDS;
 
-    /* "View.MemoryView":1027
+    /* "View.MemoryView":1029
  *     Py_INCREF(Py_None)
  * 
  *     if (<memoryview>memviewslice.memview).flags & PyBUF_WRITABLE:             # <<<<<<<<<<<<<<
  *         result.flags = PyBUF_RECORDS
  *     else:
  */
     goto __pyx_L4;
   }
 
-  /* "View.MemoryView":1030
+  /* "View.MemoryView":1032
  *         result.flags = PyBUF_RECORDS
  *     else:
  *         result.flags = PyBUF_RECORDS_RO             # <<<<<<<<<<<<<<
  * 
  *     result.view.shape = <Py_ssize_t *> result.from_slice.shape
  */
   /*else*/ {
     __pyx_v_result->__pyx_base.flags = PyBUF_RECORDS_RO;
   }
   __pyx_L4:;
 
-  /* "View.MemoryView":1032
+  /* "View.MemoryView":1034
  *         result.flags = PyBUF_RECORDS_RO
  * 
  *     result.view.shape = <Py_ssize_t *> result.from_slice.shape             # <<<<<<<<<<<<<<
  *     result.view.strides = <Py_ssize_t *> result.from_slice.strides
  * 
  */
   __pyx_v_result->__pyx_base.view.shape = ((Py_ssize_t *)__pyx_v_result->from_slice.shape);
 
-  /* "View.MemoryView":1033
+  /* "View.MemoryView":1035
  * 
  *     result.view.shape = <Py_ssize_t *> result.from_slice.shape
  *     result.view.strides = <Py_ssize_t *> result.from_slice.strides             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_v_result->__pyx_base.view.strides = ((Py_ssize_t *)__pyx_v_result->from_slice.strides);
 
-  /* "View.MemoryView":1036
+  /* "View.MemoryView":1038
  * 
  * 
  *     result.view.suboffsets = NULL             # <<<<<<<<<<<<<<
  *     for suboffset in result.from_slice.suboffsets[:ndim]:
  *         if suboffset >= 0:
  */
   __pyx_v_result->__pyx_base.view.suboffsets = NULL;
 
-  /* "View.MemoryView":1037
+  /* "View.MemoryView":1039
  * 
  *     result.view.suboffsets = NULL
  *     for suboffset in result.from_slice.suboffsets[:ndim]:             # <<<<<<<<<<<<<<
  *         if suboffset >= 0:
  *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
  */
   __pyx_t_7 = (__pyx_v_result->from_slice.suboffsets + __pyx_v_ndim);
   for (__pyx_t_8 = __pyx_v_result->from_slice.suboffsets; __pyx_t_8 < __pyx_t_7; __pyx_t_8++) {
     __pyx_t_6 = __pyx_t_8;
     __pyx_v_suboffset = (__pyx_t_6[0]);
 
-    /* "View.MemoryView":1038
+    /* "View.MemoryView":1040
  *     result.view.suboffsets = NULL
  *     for suboffset in result.from_slice.suboffsets[:ndim]:
  *         if suboffset >= 0:             # <<<<<<<<<<<<<<
  *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
  *             break
  */
     __pyx_t_1 = ((__pyx_v_suboffset >= 0) != 0);
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":1039
+      /* "View.MemoryView":1041
  *     for suboffset in result.from_slice.suboffsets[:ndim]:
  *         if suboffset >= 0:
  *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets             # <<<<<<<<<<<<<<
  *             break
  * 
  */
       __pyx_v_result->__pyx_base.view.suboffsets = ((Py_ssize_t *)__pyx_v_result->from_slice.suboffsets);
 
-      /* "View.MemoryView":1040
+      /* "View.MemoryView":1042
  *         if suboffset >= 0:
  *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
  *             break             # <<<<<<<<<<<<<<
  * 
  *     result.view.len = result.view.itemsize
  */
       goto __pyx_L6_break;
 
-      /* "View.MemoryView":1038
+      /* "View.MemoryView":1040
  *     result.view.suboffsets = NULL
  *     for suboffset in result.from_slice.suboffsets[:ndim]:
  *         if suboffset >= 0:             # <<<<<<<<<<<<<<
  *             result.view.suboffsets = <Py_ssize_t *> result.from_slice.suboffsets
  *             break
  */
     }
   }
   __pyx_L6_break:;
 
-  /* "View.MemoryView":1042
+  /* "View.MemoryView":1044
  *             break
  * 
  *     result.view.len = result.view.itemsize             # <<<<<<<<<<<<<<
  *     for length in result.view.shape[:ndim]:
  *         result.view.len *= length
  */
   __pyx_t_9 = __pyx_v_result->__pyx_base.view.itemsize;
   __pyx_v_result->__pyx_base.view.len = __pyx_t_9;
 
-  /* "View.MemoryView":1043
+  /* "View.MemoryView":1045
  * 
  *     result.view.len = result.view.itemsize
  *     for length in result.view.shape[:ndim]:             # <<<<<<<<<<<<<<
  *         result.view.len *= length
  * 
  */
   __pyx_t_7 = (__pyx_v_result->__pyx_base.view.shape + __pyx_v_ndim);
   for (__pyx_t_8 = __pyx_v_result->__pyx_base.view.shape; __pyx_t_8 < __pyx_t_7; __pyx_t_8++) {
     __pyx_t_6 = __pyx_t_8;
-    __pyx_t_2 = PyInt_FromSsize_t((__pyx_t_6[0])); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1043, __pyx_L1_error)
+    __pyx_t_2 = PyInt_FromSsize_t((__pyx_t_6[0])); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1045, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_XDECREF_SET(__pyx_v_length, __pyx_t_2);
     __pyx_t_2 = 0;
 
-    /* "View.MemoryView":1044
+    /* "View.MemoryView":1046
  *     result.view.len = result.view.itemsize
  *     for length in result.view.shape[:ndim]:
  *         result.view.len *= length             # <<<<<<<<<<<<<<
  * 
  *     result.to_object_func = to_object_func
  */
-    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_result->__pyx_base.view.len); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1044, __pyx_L1_error)
+    __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_result->__pyx_base.view.len); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1046, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
-    __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_t_2, __pyx_v_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1044, __pyx_L1_error)
+    __pyx_t_3 = PyNumber_InPlaceMultiply(__pyx_t_2, __pyx_v_length); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1046, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_t_3); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 1044, __pyx_L1_error)
+    __pyx_t_9 = __Pyx_PyIndex_AsSsize_t(__pyx_t_3); if (unlikely((__pyx_t_9 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(2, 1046, __pyx_L1_error)
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
     __pyx_v_result->__pyx_base.view.len = __pyx_t_9;
   }
 
-  /* "View.MemoryView":1046
+  /* "View.MemoryView":1048
  *         result.view.len *= length
  * 
  *     result.to_object_func = to_object_func             # <<<<<<<<<<<<<<
  *     result.to_dtype_func = to_dtype_func
  * 
  */
   __pyx_v_result->to_object_func = __pyx_v_to_object_func;
 
-  /* "View.MemoryView":1047
+  /* "View.MemoryView":1049
  * 
  *     result.to_object_func = to_object_func
  *     result.to_dtype_func = to_dtype_func             # <<<<<<<<<<<<<<
  * 
  *     return result
  */
   __pyx_v_result->to_dtype_func = __pyx_v_to_dtype_func;
 
-  /* "View.MemoryView":1049
+  /* "View.MemoryView":1051
  *     result.to_dtype_func = to_dtype_func
  * 
  *     return result             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_get_slice_from_memoryview')
  */
   __Pyx_XDECREF(__pyx_r);
   __Pyx_INCREF(((PyObject *)__pyx_v_result));
   __pyx_r = ((PyObject *)__pyx_v_result);
   goto __pyx_L0;
 
-  /* "View.MemoryView":999
+  /* "View.MemoryView":1001
  * 
  * @cname('__pyx_memoryview_fromslice')
  * cdef memoryview_fromslice(__Pyx_memviewslice memviewslice,             # <<<<<<<<<<<<<<
  *                           int ndim,
  *                           object (*to_object_func)(char *),
  */
 
@@ -18051,15 +18140,15 @@
   __Pyx_XDECREF((PyObject *)__pyx_v_result);
   __Pyx_XDECREF(__pyx_v_length);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":1052
+/* "View.MemoryView":1054
  * 
  * @cname('__pyx_memoryview_get_slice_from_memoryview')
  * cdef __Pyx_memviewslice *get_slice_from_memview(memoryview memview,             # <<<<<<<<<<<<<<
  *                                                    __Pyx_memviewslice *mslice) except NULL:
  *     cdef _memoryviewslice obj
  */
 
@@ -18071,79 +18160,79 @@
   int __pyx_t_2;
   PyObject *__pyx_t_3 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("get_slice_from_memview", 0);
 
-  /* "View.MemoryView":1055
+  /* "View.MemoryView":1057
  *                                                    __Pyx_memviewslice *mslice) except NULL:
  *     cdef _memoryviewslice obj
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         obj = memview
  *         return &obj.from_slice
  */
   __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1056
+    /* "View.MemoryView":1058
  *     cdef _memoryviewslice obj
  *     if isinstance(memview, _memoryviewslice):
  *         obj = memview             # <<<<<<<<<<<<<<
  *         return &obj.from_slice
  *     else:
  */
-    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 1056, __pyx_L1_error)
+    if (!(likely(((((PyObject *)__pyx_v_memview)) == Py_None) || likely(__Pyx_TypeTest(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type))))) __PYX_ERR(2, 1058, __pyx_L1_error)
     __pyx_t_3 = ((PyObject *)__pyx_v_memview);
     __Pyx_INCREF(__pyx_t_3);
     __pyx_v_obj = ((struct __pyx_memoryviewslice_obj *)__pyx_t_3);
     __pyx_t_3 = 0;
 
-    /* "View.MemoryView":1057
+    /* "View.MemoryView":1059
  *     if isinstance(memview, _memoryviewslice):
  *         obj = memview
  *         return &obj.from_slice             # <<<<<<<<<<<<<<
  *     else:
  *         slice_copy(memview, mslice)
  */
     __pyx_r = (&__pyx_v_obj->from_slice);
     goto __pyx_L0;
 
-    /* "View.MemoryView":1055
+    /* "View.MemoryView":1057
  *                                                    __Pyx_memviewslice *mslice) except NULL:
  *     cdef _memoryviewslice obj
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         obj = memview
  *         return &obj.from_slice
  */
   }
 
-  /* "View.MemoryView":1059
+  /* "View.MemoryView":1061
  *         return &obj.from_slice
  *     else:
  *         slice_copy(memview, mslice)             # <<<<<<<<<<<<<<
  *         return mslice
  * 
  */
   /*else*/ {
     __pyx_memoryview_slice_copy(__pyx_v_memview, __pyx_v_mslice);
 
-    /* "View.MemoryView":1060
+    /* "View.MemoryView":1062
  *     else:
  *         slice_copy(memview, mslice)
  *         return mslice             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_slice_copy')
  */
     __pyx_r = __pyx_v_mslice;
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":1052
+  /* "View.MemoryView":1054
  * 
  * @cname('__pyx_memoryview_get_slice_from_memoryview')
  * cdef __Pyx_memviewslice *get_slice_from_memview(memoryview memview,             # <<<<<<<<<<<<<<
  *                                                    __Pyx_memviewslice *mslice) except NULL:
  *     cdef _memoryviewslice obj
  */
 
@@ -18154,15 +18243,15 @@
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XDECREF((PyObject *)__pyx_v_obj);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":1063
+/* "View.MemoryView":1065
  * 
  * @cname('__pyx_memoryview_slice_copy')
  * cdef void slice_copy(memoryview memview, __Pyx_memviewslice *dst):             # <<<<<<<<<<<<<<
  *     cdef int dim
  *     cdef (Py_ssize_t*) shape, strides, suboffsets
  */
 
@@ -18175,120 +18264,120 @@
   Py_ssize_t *__pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_t_4;
   Py_ssize_t __pyx_t_5;
   __Pyx_RefNannySetupContext("slice_copy", 0);
 
-  /* "View.MemoryView":1067
+  /* "View.MemoryView":1069
  *     cdef (Py_ssize_t*) shape, strides, suboffsets
  * 
  *     shape = memview.view.shape             # <<<<<<<<<<<<<<
  *     strides = memview.view.strides
  *     suboffsets = memview.view.suboffsets
  */
   __pyx_t_1 = __pyx_v_memview->view.shape;
   __pyx_v_shape = __pyx_t_1;
 
-  /* "View.MemoryView":1068
+  /* "View.MemoryView":1070
  * 
  *     shape = memview.view.shape
  *     strides = memview.view.strides             # <<<<<<<<<<<<<<
  *     suboffsets = memview.view.suboffsets
  * 
  */
   __pyx_t_1 = __pyx_v_memview->view.strides;
   __pyx_v_strides = __pyx_t_1;
 
-  /* "View.MemoryView":1069
+  /* "View.MemoryView":1071
  *     shape = memview.view.shape
  *     strides = memview.view.strides
  *     suboffsets = memview.view.suboffsets             # <<<<<<<<<<<<<<
  * 
  *     dst.memview = <__pyx_memoryview *> memview
  */
   __pyx_t_1 = __pyx_v_memview->view.suboffsets;
   __pyx_v_suboffsets = __pyx_t_1;
 
-  /* "View.MemoryView":1071
+  /* "View.MemoryView":1073
  *     suboffsets = memview.view.suboffsets
  * 
  *     dst.memview = <__pyx_memoryview *> memview             # <<<<<<<<<<<<<<
  *     dst.data = <char *> memview.view.buf
  * 
  */
   __pyx_v_dst->memview = ((struct __pyx_memoryview_obj *)__pyx_v_memview);
 
-  /* "View.MemoryView":1072
+  /* "View.MemoryView":1074
  * 
  *     dst.memview = <__pyx_memoryview *> memview
  *     dst.data = <char *> memview.view.buf             # <<<<<<<<<<<<<<
  * 
  *     for dim in range(memview.view.ndim):
  */
   __pyx_v_dst->data = ((char *)__pyx_v_memview->view.buf);
 
-  /* "View.MemoryView":1074
+  /* "View.MemoryView":1076
  *     dst.data = <char *> memview.view.buf
  * 
  *     for dim in range(memview.view.ndim):             # <<<<<<<<<<<<<<
  *         dst.shape[dim] = shape[dim]
  *         dst.strides[dim] = strides[dim]
  */
   __pyx_t_2 = __pyx_v_memview->view.ndim;
   __pyx_t_3 = __pyx_t_2;
   for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
     __pyx_v_dim = __pyx_t_4;
 
-    /* "View.MemoryView":1075
+    /* "View.MemoryView":1077
  * 
  *     for dim in range(memview.view.ndim):
  *         dst.shape[dim] = shape[dim]             # <<<<<<<<<<<<<<
  *         dst.strides[dim] = strides[dim]
  *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1
  */
     (__pyx_v_dst->shape[__pyx_v_dim]) = (__pyx_v_shape[__pyx_v_dim]);
 
-    /* "View.MemoryView":1076
+    /* "View.MemoryView":1078
  *     for dim in range(memview.view.ndim):
  *         dst.shape[dim] = shape[dim]
  *         dst.strides[dim] = strides[dim]             # <<<<<<<<<<<<<<
  *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1
  * 
  */
     (__pyx_v_dst->strides[__pyx_v_dim]) = (__pyx_v_strides[__pyx_v_dim]);
 
-    /* "View.MemoryView":1077
+    /* "View.MemoryView":1079
  *         dst.shape[dim] = shape[dim]
  *         dst.strides[dim] = strides[dim]
  *         dst.suboffsets[dim] = suboffsets[dim] if suboffsets else -1             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_copy_object')
  */
     if ((__pyx_v_suboffsets != 0)) {
       __pyx_t_5 = (__pyx_v_suboffsets[__pyx_v_dim]);
     } else {
       __pyx_t_5 = -1L;
     }
     (__pyx_v_dst->suboffsets[__pyx_v_dim]) = __pyx_t_5;
   }
 
-  /* "View.MemoryView":1063
+  /* "View.MemoryView":1065
  * 
  * @cname('__pyx_memoryview_slice_copy')
  * cdef void slice_copy(memoryview memview, __Pyx_memviewslice *dst):             # <<<<<<<<<<<<<<
  *     cdef int dim
  *     cdef (Py_ssize_t*) shape, strides, suboffsets
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "View.MemoryView":1080
+/* "View.MemoryView":1082
  * 
  * @cname('__pyx_memoryview_copy_object')
  * cdef memoryview_copy(memoryview memview):             # <<<<<<<<<<<<<<
  *     "Create a new memoryview object"
  *     cdef __Pyx_memviewslice memviewslice
  */
 
@@ -18298,38 +18387,38 @@
   __Pyx_RefNannyDeclarations
   PyObject *__pyx_t_1 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("memoryview_copy", 0);
 
-  /* "View.MemoryView":1083
+  /* "View.MemoryView":1085
  *     "Create a new memoryview object"
  *     cdef __Pyx_memviewslice memviewslice
  *     slice_copy(memview, &memviewslice)             # <<<<<<<<<<<<<<
  *     return memoryview_copy_from_slice(memview, &memviewslice)
  * 
  */
   __pyx_memoryview_slice_copy(__pyx_v_memview, (&__pyx_v_memviewslice));
 
-  /* "View.MemoryView":1084
+  /* "View.MemoryView":1086
  *     cdef __Pyx_memviewslice memviewslice
  *     slice_copy(memview, &memviewslice)
  *     return memoryview_copy_from_slice(memview, &memviewslice)             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_copy_object_from_slice')
  */
   __Pyx_XDECREF(__pyx_r);
-  __pyx_t_1 = __pyx_memoryview_copy_object_from_slice(__pyx_v_memview, (&__pyx_v_memviewslice)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1084, __pyx_L1_error)
+  __pyx_t_1 = __pyx_memoryview_copy_object_from_slice(__pyx_v_memview, (&__pyx_v_memviewslice)); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1086, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_r = __pyx_t_1;
   __pyx_t_1 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1080
+  /* "View.MemoryView":1082
  * 
  * @cname('__pyx_memoryview_copy_object')
  * cdef memoryview_copy(memoryview memview):             # <<<<<<<<<<<<<<
  *     "Create a new memoryview object"
  *     cdef __Pyx_memviewslice memviewslice
  */
 
@@ -18340,15 +18429,15 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":1087
+/* "View.MemoryView":1089
  * 
  * @cname('__pyx_memoryview_copy_object_from_slice')
  * cdef memoryview_copy_from_slice(memoryview memview, __Pyx_memviewslice *memviewslice):             # <<<<<<<<<<<<<<
  *     """
  *     Create a new memoryview object from a given memoryview object and slice.
  */
 
@@ -18363,99 +18452,99 @@
   int (*__pyx_t_4)(char *, PyObject *);
   PyObject *__pyx_t_5 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("memoryview_copy_from_slice", 0);
 
-  /* "View.MemoryView":1094
+  /* "View.MemoryView":1096
  *     cdef int (*to_dtype_func)(char *, object) except 0
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         to_object_func = (<_memoryviewslice> memview).to_object_func
  *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
  */
   __pyx_t_1 = __Pyx_TypeCheck(((PyObject *)__pyx_v_memview), __pyx_memoryviewslice_type); 
   __pyx_t_2 = (__pyx_t_1 != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1095
+    /* "View.MemoryView":1097
  * 
  *     if isinstance(memview, _memoryviewslice):
  *         to_object_func = (<_memoryviewslice> memview).to_object_func             # <<<<<<<<<<<<<<
  *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
  *     else:
  */
     __pyx_t_3 = ((struct __pyx_memoryviewslice_obj *)__pyx_v_memview)->to_object_func;
     __pyx_v_to_object_func = __pyx_t_3;
 
-    /* "View.MemoryView":1096
+    /* "View.MemoryView":1098
  *     if isinstance(memview, _memoryviewslice):
  *         to_object_func = (<_memoryviewslice> memview).to_object_func
  *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func             # <<<<<<<<<<<<<<
  *     else:
  *         to_object_func = NULL
  */
     __pyx_t_4 = ((struct __pyx_memoryviewslice_obj *)__pyx_v_memview)->to_dtype_func;
     __pyx_v_to_dtype_func = __pyx_t_4;
 
-    /* "View.MemoryView":1094
+    /* "View.MemoryView":1096
  *     cdef int (*to_dtype_func)(char *, object) except 0
  * 
  *     if isinstance(memview, _memoryviewslice):             # <<<<<<<<<<<<<<
  *         to_object_func = (<_memoryviewslice> memview).to_object_func
  *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":1098
+  /* "View.MemoryView":1100
  *         to_dtype_func = (<_memoryviewslice> memview).to_dtype_func
  *     else:
  *         to_object_func = NULL             # <<<<<<<<<<<<<<
  *         to_dtype_func = NULL
  * 
  */
   /*else*/ {
     __pyx_v_to_object_func = NULL;
 
-    /* "View.MemoryView":1099
+    /* "View.MemoryView":1101
  *     else:
  *         to_object_func = NULL
  *         to_dtype_func = NULL             # <<<<<<<<<<<<<<
  * 
  *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,
  */
     __pyx_v_to_dtype_func = NULL;
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":1101
+  /* "View.MemoryView":1103
  *         to_dtype_func = NULL
  * 
  *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,             # <<<<<<<<<<<<<<
  *                                 to_object_func, to_dtype_func,
  *                                 memview.dtype_is_object)
  */
   __Pyx_XDECREF(__pyx_r);
 
-  /* "View.MemoryView":1103
+  /* "View.MemoryView":1105
  *     return memoryview_fromslice(memviewslice[0], memview.view.ndim,
  *                                 to_object_func, to_dtype_func,
  *                                 memview.dtype_is_object)             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_5 = __pyx_memoryview_fromslice((__pyx_v_memviewslice[0]), __pyx_v_memview->view.ndim, __pyx_v_to_object_func, __pyx_v_to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 1101, __pyx_L1_error)
+  __pyx_t_5 = __pyx_memoryview_fromslice((__pyx_v_memviewslice[0]), __pyx_v_memview->view.ndim, __pyx_v_to_object_func, __pyx_v_to_dtype_func, __pyx_v_memview->dtype_is_object); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 1103, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_5);
   __pyx_r = __pyx_t_5;
   __pyx_t_5 = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1087
+  /* "View.MemoryView":1089
  * 
  * @cname('__pyx_memoryview_copy_object_from_slice')
  * cdef memoryview_copy_from_slice(memoryview memview, __Pyx_memviewslice *memviewslice):             # <<<<<<<<<<<<<<
  *     """
  *     Create a new memoryview object from a given memoryview object and slice.
  */
 
@@ -18466,81 +18555,81 @@
   __pyx_r = 0;
   __pyx_L0:;
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
   return __pyx_r;
 }
 
-/* "View.MemoryView":1109
+/* "View.MemoryView":1111
  * 
  * 
  * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:             # <<<<<<<<<<<<<<
  *     if arg < 0:
  *         return -arg
  */
 
 static Py_ssize_t abs_py_ssize_t(Py_ssize_t __pyx_v_arg) {
   Py_ssize_t __pyx_r;
   int __pyx_t_1;
 
-  /* "View.MemoryView":1110
+  /* "View.MemoryView":1112
  * 
  * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
  *     if arg < 0:             # <<<<<<<<<<<<<<
  *         return -arg
  *     else:
  */
   __pyx_t_1 = ((__pyx_v_arg < 0) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1111
+    /* "View.MemoryView":1113
  * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
  *     if arg < 0:
  *         return -arg             # <<<<<<<<<<<<<<
  *     else:
  *         return arg
  */
     __pyx_r = (-__pyx_v_arg);
     goto __pyx_L0;
 
-    /* "View.MemoryView":1110
+    /* "View.MemoryView":1112
  * 
  * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:
  *     if arg < 0:             # <<<<<<<<<<<<<<
  *         return -arg
  *     else:
  */
   }
 
-  /* "View.MemoryView":1113
+  /* "View.MemoryView":1115
  *         return -arg
  *     else:
  *         return arg             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_get_best_slice_order')
  */
   /*else*/ {
     __pyx_r = __pyx_v_arg;
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":1109
+  /* "View.MemoryView":1111
  * 
  * 
  * cdef Py_ssize_t abs_py_ssize_t(Py_ssize_t arg) nogil:             # <<<<<<<<<<<<<<
  *     if arg < 0:
  *         return -arg
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1116
+/* "View.MemoryView":1118
  * 
  * @cname('__pyx_get_best_slice_order')
  * cdef char get_best_order(__Pyx_memviewslice *mslice, int ndim) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     Figure out the best memory access order for a given slice.
  */
 
@@ -18550,187 +18639,187 @@
   Py_ssize_t __pyx_v_f_stride;
   char __pyx_r;
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_t_4;
 
-  /* "View.MemoryView":1121
+  /* "View.MemoryView":1123
  *     """
  *     cdef int i
  *     cdef Py_ssize_t c_stride = 0             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t f_stride = 0
  * 
  */
   __pyx_v_c_stride = 0;
 
-  /* "View.MemoryView":1122
+  /* "View.MemoryView":1124
  *     cdef int i
  *     cdef Py_ssize_t c_stride = 0
  *     cdef Py_ssize_t f_stride = 0             # <<<<<<<<<<<<<<
  * 
  *     for i in range(ndim - 1, -1, -1):
  */
   __pyx_v_f_stride = 0;
 
-  /* "View.MemoryView":1124
+  /* "View.MemoryView":1126
  *     cdef Py_ssize_t f_stride = 0
  * 
  *     for i in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
  *         if mslice.shape[i] > 1:
  *             c_stride = mslice.strides[i]
  */
   for (__pyx_t_1 = (__pyx_v_ndim - 1); __pyx_t_1 > -1; __pyx_t_1-=1) {
     __pyx_v_i = __pyx_t_1;
 
-    /* "View.MemoryView":1125
+    /* "View.MemoryView":1127
  * 
  *     for i in range(ndim - 1, -1, -1):
  *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
  *             c_stride = mslice.strides[i]
  *             break
  */
     __pyx_t_2 = (((__pyx_v_mslice->shape[__pyx_v_i]) > 1) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1126
+      /* "View.MemoryView":1128
  *     for i in range(ndim - 1, -1, -1):
  *         if mslice.shape[i] > 1:
  *             c_stride = mslice.strides[i]             # <<<<<<<<<<<<<<
  *             break
  * 
  */
       __pyx_v_c_stride = (__pyx_v_mslice->strides[__pyx_v_i]);
 
-      /* "View.MemoryView":1127
+      /* "View.MemoryView":1129
  *         if mslice.shape[i] > 1:
  *             c_stride = mslice.strides[i]
  *             break             # <<<<<<<<<<<<<<
  * 
  *     for i in range(ndim):
  */
       goto __pyx_L4_break;
 
-      /* "View.MemoryView":1125
+      /* "View.MemoryView":1127
  * 
  *     for i in range(ndim - 1, -1, -1):
  *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
  *             c_stride = mslice.strides[i]
  *             break
  */
     }
   }
   __pyx_L4_break:;
 
-  /* "View.MemoryView":1129
+  /* "View.MemoryView":1131
  *             break
  * 
  *     for i in range(ndim):             # <<<<<<<<<<<<<<
  *         if mslice.shape[i] > 1:
  *             f_stride = mslice.strides[i]
  */
   __pyx_t_1 = __pyx_v_ndim;
   __pyx_t_3 = __pyx_t_1;
   for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
     __pyx_v_i = __pyx_t_4;
 
-    /* "View.MemoryView":1130
+    /* "View.MemoryView":1132
  * 
  *     for i in range(ndim):
  *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
  *             f_stride = mslice.strides[i]
  *             break
  */
     __pyx_t_2 = (((__pyx_v_mslice->shape[__pyx_v_i]) > 1) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1131
+      /* "View.MemoryView":1133
  *     for i in range(ndim):
  *         if mslice.shape[i] > 1:
  *             f_stride = mslice.strides[i]             # <<<<<<<<<<<<<<
  *             break
  * 
  */
       __pyx_v_f_stride = (__pyx_v_mslice->strides[__pyx_v_i]);
 
-      /* "View.MemoryView":1132
+      /* "View.MemoryView":1134
  *         if mslice.shape[i] > 1:
  *             f_stride = mslice.strides[i]
  *             break             # <<<<<<<<<<<<<<
  * 
  *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):
  */
       goto __pyx_L7_break;
 
-      /* "View.MemoryView":1130
+      /* "View.MemoryView":1132
  * 
  *     for i in range(ndim):
  *         if mslice.shape[i] > 1:             # <<<<<<<<<<<<<<
  *             f_stride = mslice.strides[i]
  *             break
  */
     }
   }
   __pyx_L7_break:;
 
-  /* "View.MemoryView":1134
+  /* "View.MemoryView":1136
  *             break
  * 
  *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):             # <<<<<<<<<<<<<<
  *         return 'C'
  *     else:
  */
   __pyx_t_2 = ((abs_py_ssize_t(__pyx_v_c_stride) <= abs_py_ssize_t(__pyx_v_f_stride)) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1135
+    /* "View.MemoryView":1137
  * 
  *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):
  *         return 'C'             # <<<<<<<<<<<<<<
  *     else:
  *         return 'F'
  */
     __pyx_r = 'C';
     goto __pyx_L0;
 
-    /* "View.MemoryView":1134
+    /* "View.MemoryView":1136
  *             break
  * 
  *     if abs_py_ssize_t(c_stride) <= abs_py_ssize_t(f_stride):             # <<<<<<<<<<<<<<
  *         return 'C'
  *     else:
  */
   }
 
-  /* "View.MemoryView":1137
+  /* "View.MemoryView":1139
  *         return 'C'
  *     else:
  *         return 'F'             # <<<<<<<<<<<<<<
  * 
  * @cython.cdivision(True)
  */
   /*else*/ {
     __pyx_r = 'F';
     goto __pyx_L0;
   }
 
-  /* "View.MemoryView":1116
+  /* "View.MemoryView":1118
  * 
  * @cname('__pyx_get_best_slice_order')
  * cdef char get_best_order(__Pyx_memviewslice *mslice, int ndim) nogil:             # <<<<<<<<<<<<<<
  *     """
  *     Figure out the best memory access order for a given slice.
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1140
+/* "View.MemoryView":1142
  * 
  * @cython.cdivision(True)
  * cdef void _copy_strided_to_strided(char *src_data, Py_ssize_t *src_strides,             # <<<<<<<<<<<<<<
  *                                    char *dst_data, Py_ssize_t *dst_strides,
  *                                    Py_ssize_t *src_shape, Py_ssize_t *dst_shape,
  */
 
@@ -18743,61 +18832,61 @@
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   Py_ssize_t __pyx_t_4;
   Py_ssize_t __pyx_t_5;
   Py_ssize_t __pyx_t_6;
 
-  /* "View.MemoryView":1147
+  /* "View.MemoryView":1149
  * 
  *     cdef Py_ssize_t i
  *     cdef Py_ssize_t src_extent = src_shape[0]             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t dst_extent = dst_shape[0]
  *     cdef Py_ssize_t src_stride = src_strides[0]
  */
   __pyx_v_src_extent = (__pyx_v_src_shape[0]);
 
-  /* "View.MemoryView":1148
+  /* "View.MemoryView":1150
  *     cdef Py_ssize_t i
  *     cdef Py_ssize_t src_extent = src_shape[0]
  *     cdef Py_ssize_t dst_extent = dst_shape[0]             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t src_stride = src_strides[0]
  *     cdef Py_ssize_t dst_stride = dst_strides[0]
  */
   __pyx_v_dst_extent = (__pyx_v_dst_shape[0]);
 
-  /* "View.MemoryView":1149
+  /* "View.MemoryView":1151
  *     cdef Py_ssize_t src_extent = src_shape[0]
  *     cdef Py_ssize_t dst_extent = dst_shape[0]
  *     cdef Py_ssize_t src_stride = src_strides[0]             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t dst_stride = dst_strides[0]
  * 
  */
   __pyx_v_src_stride = (__pyx_v_src_strides[0]);
 
-  /* "View.MemoryView":1150
+  /* "View.MemoryView":1152
  *     cdef Py_ssize_t dst_extent = dst_shape[0]
  *     cdef Py_ssize_t src_stride = src_strides[0]
  *     cdef Py_ssize_t dst_stride = dst_strides[0]             # <<<<<<<<<<<<<<
  * 
  *     if ndim == 1:
  */
   __pyx_v_dst_stride = (__pyx_v_dst_strides[0]);
 
-  /* "View.MemoryView":1152
+  /* "View.MemoryView":1154
  *     cdef Py_ssize_t dst_stride = dst_strides[0]
  * 
  *     if ndim == 1:             # <<<<<<<<<<<<<<
  *        if (src_stride > 0 and dst_stride > 0 and
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  */
   __pyx_t_1 = ((__pyx_v_ndim == 1) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1153
+    /* "View.MemoryView":1155
  * 
  *     if ndim == 1:
  *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  *            memcpy(dst_data, src_data, itemsize * dst_extent)
  */
     __pyx_t_2 = ((__pyx_v_src_stride > 0) != 0);
@@ -18809,195 +18898,195 @@
     __pyx_t_2 = ((__pyx_v_dst_stride > 0) != 0);
     if (__pyx_t_2) {
     } else {
       __pyx_t_1 = __pyx_t_2;
       goto __pyx_L5_bool_binop_done;
     }
 
-    /* "View.MemoryView":1154
+    /* "View.MemoryView":1156
  *     if ndim == 1:
  *        if (src_stride > 0 and dst_stride > 0 and
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):             # <<<<<<<<<<<<<<
  *            memcpy(dst_data, src_data, itemsize * dst_extent)
  *        else:
  */
     __pyx_t_2 = (((size_t)__pyx_v_src_stride) == __pyx_v_itemsize);
     if (__pyx_t_2) {
       __pyx_t_2 = (__pyx_v_itemsize == ((size_t)__pyx_v_dst_stride));
     }
     __pyx_t_3 = (__pyx_t_2 != 0);
     __pyx_t_1 = __pyx_t_3;
     __pyx_L5_bool_binop_done:;
 
-    /* "View.MemoryView":1153
+    /* "View.MemoryView":1155
  * 
  *     if ndim == 1:
  *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  *            memcpy(dst_data, src_data, itemsize * dst_extent)
  */
     if (__pyx_t_1) {
 
-      /* "View.MemoryView":1155
+      /* "View.MemoryView":1157
  *        if (src_stride > 0 and dst_stride > 0 and
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  *            memcpy(dst_data, src_data, itemsize * dst_extent)             # <<<<<<<<<<<<<<
  *        else:
  *            for i in range(dst_extent):
  */
       (void)(memcpy(__pyx_v_dst_data, __pyx_v_src_data, (__pyx_v_itemsize * __pyx_v_dst_extent)));
 
-      /* "View.MemoryView":1153
+      /* "View.MemoryView":1155
  * 
  *     if ndim == 1:
  *        if (src_stride > 0 and dst_stride > 0 and             # <<<<<<<<<<<<<<
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  *            memcpy(dst_data, src_data, itemsize * dst_extent)
  */
       goto __pyx_L4;
     }
 
-    /* "View.MemoryView":1157
+    /* "View.MemoryView":1159
  *            memcpy(dst_data, src_data, itemsize * dst_extent)
  *        else:
  *            for i in range(dst_extent):             # <<<<<<<<<<<<<<
  *                memcpy(dst_data, src_data, itemsize)
  *                src_data += src_stride
  */
     /*else*/ {
       __pyx_t_4 = __pyx_v_dst_extent;
       __pyx_t_5 = __pyx_t_4;
       for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
         __pyx_v_i = __pyx_t_6;
 
-        /* "View.MemoryView":1158
+        /* "View.MemoryView":1160
  *        else:
  *            for i in range(dst_extent):
  *                memcpy(dst_data, src_data, itemsize)             # <<<<<<<<<<<<<<
  *                src_data += src_stride
  *                dst_data += dst_stride
  */
         (void)(memcpy(__pyx_v_dst_data, __pyx_v_src_data, __pyx_v_itemsize));
 
-        /* "View.MemoryView":1159
+        /* "View.MemoryView":1161
  *            for i in range(dst_extent):
  *                memcpy(dst_data, src_data, itemsize)
  *                src_data += src_stride             # <<<<<<<<<<<<<<
  *                dst_data += dst_stride
  *     else:
  */
         __pyx_v_src_data = (__pyx_v_src_data + __pyx_v_src_stride);
 
-        /* "View.MemoryView":1160
+        /* "View.MemoryView":1162
  *                memcpy(dst_data, src_data, itemsize)
  *                src_data += src_stride
  *                dst_data += dst_stride             # <<<<<<<<<<<<<<
  *     else:
  *         for i in range(dst_extent):
  */
         __pyx_v_dst_data = (__pyx_v_dst_data + __pyx_v_dst_stride);
       }
     }
     __pyx_L4:;
 
-    /* "View.MemoryView":1152
+    /* "View.MemoryView":1154
  *     cdef Py_ssize_t dst_stride = dst_strides[0]
  * 
  *     if ndim == 1:             # <<<<<<<<<<<<<<
  *        if (src_stride > 0 and dst_stride > 0 and
  *            <size_t> src_stride == itemsize == <size_t> dst_stride):
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":1162
+  /* "View.MemoryView":1164
  *                dst_data += dst_stride
  *     else:
  *         for i in range(dst_extent):             # <<<<<<<<<<<<<<
  *             _copy_strided_to_strided(src_data, src_strides + 1,
  *                                      dst_data, dst_strides + 1,
  */
   /*else*/ {
     __pyx_t_4 = __pyx_v_dst_extent;
     __pyx_t_5 = __pyx_t_4;
     for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
       __pyx_v_i = __pyx_t_6;
 
-      /* "View.MemoryView":1163
+      /* "View.MemoryView":1165
  *     else:
  *         for i in range(dst_extent):
  *             _copy_strided_to_strided(src_data, src_strides + 1,             # <<<<<<<<<<<<<<
  *                                      dst_data, dst_strides + 1,
  *                                      src_shape + 1, dst_shape + 1,
  */
       _copy_strided_to_strided(__pyx_v_src_data, (__pyx_v_src_strides + 1), __pyx_v_dst_data, (__pyx_v_dst_strides + 1), (__pyx_v_src_shape + 1), (__pyx_v_dst_shape + 1), (__pyx_v_ndim - 1), __pyx_v_itemsize);
 
-      /* "View.MemoryView":1167
+      /* "View.MemoryView":1169
  *                                      src_shape + 1, dst_shape + 1,
  *                                      ndim - 1, itemsize)
  *             src_data += src_stride             # <<<<<<<<<<<<<<
  *             dst_data += dst_stride
  * 
  */
       __pyx_v_src_data = (__pyx_v_src_data + __pyx_v_src_stride);
 
-      /* "View.MemoryView":1168
+      /* "View.MemoryView":1170
  *                                      ndim - 1, itemsize)
  *             src_data += src_stride
  *             dst_data += dst_stride             # <<<<<<<<<<<<<<
  * 
  * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,
  */
       __pyx_v_dst_data = (__pyx_v_dst_data + __pyx_v_dst_stride);
     }
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":1140
+  /* "View.MemoryView":1142
  * 
  * @cython.cdivision(True)
  * cdef void _copy_strided_to_strided(char *src_data, Py_ssize_t *src_strides,             # <<<<<<<<<<<<<<
  *                                    char *dst_data, Py_ssize_t *dst_strides,
  *                                    Py_ssize_t *src_shape, Py_ssize_t *dst_shape,
  */
 
   /* function exit code */
 }
 
-/* "View.MemoryView":1170
+/* "View.MemoryView":1172
  *             dst_data += dst_stride
  * 
  * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
  *                                   __Pyx_memviewslice *dst,
  *                                   int ndim, size_t itemsize) nogil:
  */
 
 static void copy_strided_to_strided(__Pyx_memviewslice *__pyx_v_src, __Pyx_memviewslice *__pyx_v_dst, int __pyx_v_ndim, size_t __pyx_v_itemsize) {
 
-  /* "View.MemoryView":1173
+  /* "View.MemoryView":1175
  *                                   __Pyx_memviewslice *dst,
  *                                   int ndim, size_t itemsize) nogil:
  *     _copy_strided_to_strided(src.data, src.strides, dst.data, dst.strides,             # <<<<<<<<<<<<<<
  *                              src.shape, dst.shape, ndim, itemsize)
  * 
  */
   _copy_strided_to_strided(__pyx_v_src->data, __pyx_v_src->strides, __pyx_v_dst->data, __pyx_v_dst->strides, __pyx_v_src->shape, __pyx_v_dst->shape, __pyx_v_ndim, __pyx_v_itemsize);
 
-  /* "View.MemoryView":1170
+  /* "View.MemoryView":1172
  *             dst_data += dst_stride
  * 
  * cdef void copy_strided_to_strided(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
  *                                   __Pyx_memviewslice *dst,
  *                                   int ndim, size_t itemsize) nogil:
  */
 
   /* function exit code */
 }
 
-/* "View.MemoryView":1177
+/* "View.MemoryView":1179
  * 
  * @cname('__pyx_memoryview_slice_get_size')
  * cdef Py_ssize_t slice_get_size(__Pyx_memviewslice *src, int ndim) nogil:             # <<<<<<<<<<<<<<
  *     "Return the size of the memory occupied by the slice in number of bytes"
  *     cdef Py_ssize_t shape, size = src.memview.view.itemsize
  */
 
@@ -19006,70 +19095,70 @@
   Py_ssize_t __pyx_v_size;
   Py_ssize_t __pyx_r;
   Py_ssize_t __pyx_t_1;
   Py_ssize_t *__pyx_t_2;
   Py_ssize_t *__pyx_t_3;
   Py_ssize_t *__pyx_t_4;
 
-  /* "View.MemoryView":1179
+  /* "View.MemoryView":1181
  * cdef Py_ssize_t slice_get_size(__Pyx_memviewslice *src, int ndim) nogil:
  *     "Return the size of the memory occupied by the slice in number of bytes"
  *     cdef Py_ssize_t shape, size = src.memview.view.itemsize             # <<<<<<<<<<<<<<
  * 
  *     for shape in src.shape[:ndim]:
  */
   __pyx_t_1 = __pyx_v_src->memview->view.itemsize;
   __pyx_v_size = __pyx_t_1;
 
-  /* "View.MemoryView":1181
+  /* "View.MemoryView":1183
  *     cdef Py_ssize_t shape, size = src.memview.view.itemsize
  * 
  *     for shape in src.shape[:ndim]:             # <<<<<<<<<<<<<<
  *         size *= shape
  * 
  */
   __pyx_t_3 = (__pyx_v_src->shape + __pyx_v_ndim);
   for (__pyx_t_4 = __pyx_v_src->shape; __pyx_t_4 < __pyx_t_3; __pyx_t_4++) {
     __pyx_t_2 = __pyx_t_4;
     __pyx_v_shape = (__pyx_t_2[0]);
 
-    /* "View.MemoryView":1182
+    /* "View.MemoryView":1184
  * 
  *     for shape in src.shape[:ndim]:
  *         size *= shape             # <<<<<<<<<<<<<<
  * 
  *     return size
  */
     __pyx_v_size = (__pyx_v_size * __pyx_v_shape);
   }
 
-  /* "View.MemoryView":1184
+  /* "View.MemoryView":1186
  *         size *= shape
  * 
  *     return size             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_fill_contig_strides_array')
  */
   __pyx_r = __pyx_v_size;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1177
+  /* "View.MemoryView":1179
  * 
  * @cname('__pyx_memoryview_slice_get_size')
  * cdef Py_ssize_t slice_get_size(__Pyx_memviewslice *src, int ndim) nogil:             # <<<<<<<<<<<<<<
  *     "Return the size of the memory occupied by the slice in number of bytes"
  *     cdef Py_ssize_t shape, size = src.memview.view.itemsize
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1187
+/* "View.MemoryView":1189
  * 
  * @cname('__pyx_fill_contig_strides_array')
  * cdef Py_ssize_t fill_contig_strides_array(             # <<<<<<<<<<<<<<
  *                 Py_ssize_t *shape, Py_ssize_t *strides, Py_ssize_t stride,
  *                 int ndim, char order) nogil:
  */
 
@@ -19077,121 +19166,121 @@
   int __pyx_v_idx;
   Py_ssize_t __pyx_r;
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
   int __pyx_t_4;
 
-  /* "View.MemoryView":1196
+  /* "View.MemoryView":1198
  *     cdef int idx
  * 
  *     if order == 'F':             # <<<<<<<<<<<<<<
  *         for idx in range(ndim):
  *             strides[idx] = stride
  */
   __pyx_t_1 = ((__pyx_v_order == 'F') != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1197
+    /* "View.MemoryView":1199
  * 
  *     if order == 'F':
  *         for idx in range(ndim):             # <<<<<<<<<<<<<<
  *             strides[idx] = stride
  *             stride *= shape[idx]
  */
     __pyx_t_2 = __pyx_v_ndim;
     __pyx_t_3 = __pyx_t_2;
     for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
       __pyx_v_idx = __pyx_t_4;
 
-      /* "View.MemoryView":1198
+      /* "View.MemoryView":1200
  *     if order == 'F':
  *         for idx in range(ndim):
  *             strides[idx] = stride             # <<<<<<<<<<<<<<
  *             stride *= shape[idx]
  *     else:
  */
       (__pyx_v_strides[__pyx_v_idx]) = __pyx_v_stride;
 
-      /* "View.MemoryView":1199
+      /* "View.MemoryView":1201
  *         for idx in range(ndim):
  *             strides[idx] = stride
  *             stride *= shape[idx]             # <<<<<<<<<<<<<<
  *     else:
  *         for idx in range(ndim - 1, -1, -1):
  */
       __pyx_v_stride = (__pyx_v_stride * (__pyx_v_shape[__pyx_v_idx]));
     }
 
-    /* "View.MemoryView":1196
+    /* "View.MemoryView":1198
  *     cdef int idx
  * 
  *     if order == 'F':             # <<<<<<<<<<<<<<
  *         for idx in range(ndim):
  *             strides[idx] = stride
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":1201
+  /* "View.MemoryView":1203
  *             stride *= shape[idx]
  *     else:
  *         for idx in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
  *             strides[idx] = stride
  *             stride *= shape[idx]
  */
   /*else*/ {
     for (__pyx_t_2 = (__pyx_v_ndim - 1); __pyx_t_2 > -1; __pyx_t_2-=1) {
       __pyx_v_idx = __pyx_t_2;
 
-      /* "View.MemoryView":1202
+      /* "View.MemoryView":1204
  *     else:
  *         for idx in range(ndim - 1, -1, -1):
  *             strides[idx] = stride             # <<<<<<<<<<<<<<
  *             stride *= shape[idx]
  * 
  */
       (__pyx_v_strides[__pyx_v_idx]) = __pyx_v_stride;
 
-      /* "View.MemoryView":1203
+      /* "View.MemoryView":1205
  *         for idx in range(ndim - 1, -1, -1):
  *             strides[idx] = stride
  *             stride *= shape[idx]             # <<<<<<<<<<<<<<
  * 
  *     return stride
  */
       __pyx_v_stride = (__pyx_v_stride * (__pyx_v_shape[__pyx_v_idx]));
     }
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":1205
+  /* "View.MemoryView":1207
  *             stride *= shape[idx]
  * 
  *     return stride             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_copy_data_to_temp')
  */
   __pyx_r = __pyx_v_stride;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1187
+  /* "View.MemoryView":1189
  * 
  * @cname('__pyx_fill_contig_strides_array')
  * cdef Py_ssize_t fill_contig_strides_array(             # <<<<<<<<<<<<<<
  *                 Py_ssize_t *shape, Py_ssize_t *strides, Py_ssize_t stride,
  *                 int ndim, char order) nogil:
  */
 
   /* function exit code */
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1208
+/* "View.MemoryView":1210
  * 
  * @cname('__pyx_memoryview_copy_data_to_temp')
  * cdef void *copy_data_to_temp(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
  *                              __Pyx_memviewslice *tmpslice,
  *                              char order,
  */
 
@@ -19207,222 +19296,222 @@
   struct __pyx_memoryview_obj *__pyx_t_4;
   int __pyx_t_5;
   int __pyx_t_6;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
 
-  /* "View.MemoryView":1219
+  /* "View.MemoryView":1221
  *     cdef void *result
  * 
  *     cdef size_t itemsize = src.memview.view.itemsize             # <<<<<<<<<<<<<<
  *     cdef size_t size = slice_get_size(src, ndim)
  * 
  */
   __pyx_t_1 = __pyx_v_src->memview->view.itemsize;
   __pyx_v_itemsize = __pyx_t_1;
 
-  /* "View.MemoryView":1220
+  /* "View.MemoryView":1222
  * 
  *     cdef size_t itemsize = src.memview.view.itemsize
  *     cdef size_t size = slice_get_size(src, ndim)             # <<<<<<<<<<<<<<
  * 
  *     result = malloc(size)
  */
   __pyx_v_size = __pyx_memoryview_slice_get_size(__pyx_v_src, __pyx_v_ndim);
 
-  /* "View.MemoryView":1222
+  /* "View.MemoryView":1224
  *     cdef size_t size = slice_get_size(src, ndim)
  * 
  *     result = malloc(size)             # <<<<<<<<<<<<<<
  *     if not result:
  *         _err(MemoryError, NULL)
  */
   __pyx_v_result = malloc(__pyx_v_size);
 
-  /* "View.MemoryView":1223
+  /* "View.MemoryView":1225
  * 
  *     result = malloc(size)
  *     if not result:             # <<<<<<<<<<<<<<
  *         _err(MemoryError, NULL)
  * 
  */
   __pyx_t_2 = ((!(__pyx_v_result != 0)) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1224
+    /* "View.MemoryView":1226
  *     result = malloc(size)
  *     if not result:
  *         _err(MemoryError, NULL)             # <<<<<<<<<<<<<<
  * 
  * 
  */
-    __pyx_t_3 = __pyx_memoryview_err(__pyx_builtin_MemoryError, NULL); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 1224, __pyx_L1_error)
+    __pyx_t_3 = __pyx_memoryview_err(__pyx_builtin_MemoryError, NULL); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(2, 1226, __pyx_L1_error)
 
-    /* "View.MemoryView":1223
+    /* "View.MemoryView":1225
  * 
  *     result = malloc(size)
  *     if not result:             # <<<<<<<<<<<<<<
  *         _err(MemoryError, NULL)
  * 
  */
   }
 
-  /* "View.MemoryView":1227
+  /* "View.MemoryView":1229
  * 
  * 
  *     tmpslice.data = <char *> result             # <<<<<<<<<<<<<<
  *     tmpslice.memview = src.memview
  *     for i in range(ndim):
  */
   __pyx_v_tmpslice->data = ((char *)__pyx_v_result);
 
-  /* "View.MemoryView":1228
+  /* "View.MemoryView":1230
  * 
  *     tmpslice.data = <char *> result
  *     tmpslice.memview = src.memview             # <<<<<<<<<<<<<<
  *     for i in range(ndim):
  *         tmpslice.shape[i] = src.shape[i]
  */
   __pyx_t_4 = __pyx_v_src->memview;
   __pyx_v_tmpslice->memview = __pyx_t_4;
 
-  /* "View.MemoryView":1229
+  /* "View.MemoryView":1231
  *     tmpslice.data = <char *> result
  *     tmpslice.memview = src.memview
  *     for i in range(ndim):             # <<<<<<<<<<<<<<
  *         tmpslice.shape[i] = src.shape[i]
  *         tmpslice.suboffsets[i] = -1
  */
   __pyx_t_3 = __pyx_v_ndim;
   __pyx_t_5 = __pyx_t_3;
   for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
     __pyx_v_i = __pyx_t_6;
 
-    /* "View.MemoryView":1230
+    /* "View.MemoryView":1232
  *     tmpslice.memview = src.memview
  *     for i in range(ndim):
  *         tmpslice.shape[i] = src.shape[i]             # <<<<<<<<<<<<<<
  *         tmpslice.suboffsets[i] = -1
  * 
  */
     (__pyx_v_tmpslice->shape[__pyx_v_i]) = (__pyx_v_src->shape[__pyx_v_i]);
 
-    /* "View.MemoryView":1231
+    /* "View.MemoryView":1233
  *     for i in range(ndim):
  *         tmpslice.shape[i] = src.shape[i]
  *         tmpslice.suboffsets[i] = -1             # <<<<<<<<<<<<<<
  * 
  *     fill_contig_strides_array(&tmpslice.shape[0], &tmpslice.strides[0], itemsize,
  */
     (__pyx_v_tmpslice->suboffsets[__pyx_v_i]) = -1L;
   }
 
-  /* "View.MemoryView":1233
+  /* "View.MemoryView":1235
  *         tmpslice.suboffsets[i] = -1
  * 
  *     fill_contig_strides_array(&tmpslice.shape[0], &tmpslice.strides[0], itemsize,             # <<<<<<<<<<<<<<
  *                               ndim, order)
  * 
  */
   (void)(__pyx_fill_contig_strides_array((&(__pyx_v_tmpslice->shape[0])), (&(__pyx_v_tmpslice->strides[0])), __pyx_v_itemsize, __pyx_v_ndim, __pyx_v_order));
 
-  /* "View.MemoryView":1237
+  /* "View.MemoryView":1239
  * 
  * 
  *     for i in range(ndim):             # <<<<<<<<<<<<<<
  *         if tmpslice.shape[i] == 1:
  *             tmpslice.strides[i] = 0
  */
   __pyx_t_3 = __pyx_v_ndim;
   __pyx_t_5 = __pyx_t_3;
   for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
     __pyx_v_i = __pyx_t_6;
 
-    /* "View.MemoryView":1238
+    /* "View.MemoryView":1240
  * 
  *     for i in range(ndim):
  *         if tmpslice.shape[i] == 1:             # <<<<<<<<<<<<<<
  *             tmpslice.strides[i] = 0
  * 
  */
     __pyx_t_2 = (((__pyx_v_tmpslice->shape[__pyx_v_i]) == 1) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1239
+      /* "View.MemoryView":1241
  *     for i in range(ndim):
  *         if tmpslice.shape[i] == 1:
  *             tmpslice.strides[i] = 0             # <<<<<<<<<<<<<<
  * 
  *     if slice_is_contig(src[0], order, ndim):
  */
       (__pyx_v_tmpslice->strides[__pyx_v_i]) = 0;
 
-      /* "View.MemoryView":1238
+      /* "View.MemoryView":1240
  * 
  *     for i in range(ndim):
  *         if tmpslice.shape[i] == 1:             # <<<<<<<<<<<<<<
  *             tmpslice.strides[i] = 0
  * 
  */
     }
   }
 
-  /* "View.MemoryView":1241
+  /* "View.MemoryView":1243
  *             tmpslice.strides[i] = 0
  * 
  *     if slice_is_contig(src[0], order, ndim):             # <<<<<<<<<<<<<<
  *         memcpy(result, src.data, size)
  *     else:
  */
   __pyx_t_2 = (__pyx_memviewslice_is_contig((__pyx_v_src[0]), __pyx_v_order, __pyx_v_ndim) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1242
+    /* "View.MemoryView":1244
  * 
  *     if slice_is_contig(src[0], order, ndim):
  *         memcpy(result, src.data, size)             # <<<<<<<<<<<<<<
  *     else:
  *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)
  */
     (void)(memcpy(__pyx_v_result, __pyx_v_src->data, __pyx_v_size));
 
-    /* "View.MemoryView":1241
+    /* "View.MemoryView":1243
  *             tmpslice.strides[i] = 0
  * 
  *     if slice_is_contig(src[0], order, ndim):             # <<<<<<<<<<<<<<
  *         memcpy(result, src.data, size)
  *     else:
  */
     goto __pyx_L9;
   }
 
-  /* "View.MemoryView":1244
+  /* "View.MemoryView":1246
  *         memcpy(result, src.data, size)
  *     else:
  *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)             # <<<<<<<<<<<<<<
  * 
  *     return result
  */
   /*else*/ {
     copy_strided_to_strided(__pyx_v_src, __pyx_v_tmpslice, __pyx_v_ndim, __pyx_v_itemsize);
   }
   __pyx_L9:;
 
-  /* "View.MemoryView":1246
+  /* "View.MemoryView":1248
  *         copy_strided_to_strided(src, tmpslice, ndim, itemsize)
  * 
  *     return result             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_r = __pyx_v_result;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1208
+  /* "View.MemoryView":1210
  * 
  * @cname('__pyx_memoryview_copy_data_to_temp')
  * cdef void *copy_data_to_temp(__Pyx_memviewslice *src,             # <<<<<<<<<<<<<<
  *                              __Pyx_memviewslice *tmpslice,
  *                              char order,
  */
 
@@ -19438,15 +19527,15 @@
     #endif
   }
   __pyx_r = NULL;
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1251
+/* "View.MemoryView":1253
  * 
  * @cname('__pyx_memoryview_err_extents')
  * cdef int _err_extents(int i, Py_ssize_t extent1,             # <<<<<<<<<<<<<<
  *                              Py_ssize_t extent2) except -1 with gil:
  *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
  */
 
@@ -19461,57 +19550,57 @@
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   #ifdef WITH_THREAD
   PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
   #endif
   __Pyx_RefNannySetupContext("_err_extents", 0);
 
-  /* "View.MemoryView":1254
+  /* "View.MemoryView":1256
  *                              Py_ssize_t extent2) except -1 with gil:
  *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
  *                                                         (i, extent1, extent2))             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_err_dim')
  */
-  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1254, __pyx_L1_error)
+  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_i); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1256, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
-  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_extent1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1254, __pyx_L1_error)
+  __pyx_t_2 = PyInt_FromSsize_t(__pyx_v_extent1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1256, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_extent2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1254, __pyx_L1_error)
+  __pyx_t_3 = PyInt_FromSsize_t(__pyx_v_extent2); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1256, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
-  __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1254, __pyx_L1_error)
+  __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1256, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
   __Pyx_GIVEREF(__pyx_t_1);
   PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1);
   __Pyx_GIVEREF(__pyx_t_2);
   PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_3);
   PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_t_3);
   __pyx_t_1 = 0;
   __pyx_t_2 = 0;
   __pyx_t_3 = 0;
 
-  /* "View.MemoryView":1253
+  /* "View.MemoryView":1255
  * cdef int _err_extents(int i, Py_ssize_t extent1,
  *                              Py_ssize_t extent2) except -1 with gil:
  *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %             # <<<<<<<<<<<<<<
  *                                                         (i, extent1, extent2))
  * 
  */
-  __pyx_t_3 = __Pyx_PyString_Format(__pyx_kp_s_got_differing_extents_in_dimensi, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1253, __pyx_L1_error)
+  __pyx_t_3 = __Pyx_PyString_Format(__pyx_kp_s_got_differing_extents_in_dimensi, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1255, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
   __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1253, __pyx_L1_error)
+  __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_builtin_ValueError, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1255, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __Pyx_Raise(__pyx_t_4, 0, 0, 0);
   __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-  __PYX_ERR(2, 1253, __pyx_L1_error)
+  __PYX_ERR(2, 1255, __pyx_L1_error)
 
-  /* "View.MemoryView":1251
+  /* "View.MemoryView":1253
  * 
  * @cname('__pyx_memoryview_err_extents')
  * cdef int _err_extents(int i, Py_ssize_t extent1,             # <<<<<<<<<<<<<<
  *                              Py_ssize_t extent2) except -1 with gil:
  *     raise ValueError("got differing extents in dimension %d (got %d and %d)" %
  */
 
@@ -19526,15 +19615,15 @@
   __Pyx_RefNannyFinishContext();
   #ifdef WITH_THREAD
   __Pyx_PyGILState_Release(__pyx_gilstate_save);
   #endif
   return __pyx_r;
 }
 
-/* "View.MemoryView":1257
+/* "View.MemoryView":1259
  * 
  * @cname('__pyx_memoryview_err_dim')
  * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:             # <<<<<<<<<<<<<<
  *     raise error(msg.decode('ascii') % dim)
  * 
  */
 
@@ -19550,26 +19639,26 @@
   int __pyx_clineno = 0;
   #ifdef WITH_THREAD
   PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
   #endif
   __Pyx_RefNannySetupContext("_err_dim", 0);
   __Pyx_INCREF(__pyx_v_error);
 
-  /* "View.MemoryView":1258
+  /* "View.MemoryView":1260
  * @cname('__pyx_memoryview_err_dim')
  * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:
  *     raise error(msg.decode('ascii') % dim)             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_err')
  */
-  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1258, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1260, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1258, __pyx_L1_error)
+  __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dim); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1260, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_3);
-  __pyx_t_4 = PyUnicode_Format(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1258, __pyx_L1_error)
+  __pyx_t_4 = PyUnicode_Format(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 1260, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_4);
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __Pyx_INCREF(__pyx_v_error);
   __pyx_t_3 = __pyx_v_error; __pyx_t_2 = NULL;
   if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
     __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
@@ -19579,22 +19668,22 @@
       __Pyx_INCREF(function);
       __Pyx_DECREF_SET(__pyx_t_3, function);
     }
   }
   __pyx_t_1 = (__pyx_t_2) ? __Pyx_PyObject_Call2Args(__pyx_t_3, __pyx_t_2, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4);
   __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
   __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-  if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1258, __pyx_L1_error)
+  if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 1260, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
   __Pyx_Raise(__pyx_t_1, 0, 0, 0);
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-  __PYX_ERR(2, 1258, __pyx_L1_error)
+  __PYX_ERR(2, 1260, __pyx_L1_error)
 
-  /* "View.MemoryView":1257
+  /* "View.MemoryView":1259
  * 
  * @cname('__pyx_memoryview_err_dim')
  * cdef int _err_dim(object error, char *msg, int dim) except -1 with gil:             # <<<<<<<<<<<<<<
  *     raise error(msg.decode('ascii') % dim)
  * 
  */
 
@@ -19610,15 +19699,15 @@
   __Pyx_RefNannyFinishContext();
   #ifdef WITH_THREAD
   __Pyx_PyGILState_Release(__pyx_gilstate_save);
   #endif
   return __pyx_r;
 }
 
-/* "View.MemoryView":1261
+/* "View.MemoryView":1263
  * 
  * @cname('__pyx_memoryview_err')
  * cdef int _err(object error, char *msg) except -1 with gil:             # <<<<<<<<<<<<<<
  *     if msg != NULL:
  *         raise error(msg.decode('ascii'))
  */
 
@@ -19635,32 +19724,32 @@
   int __pyx_clineno = 0;
   #ifdef WITH_THREAD
   PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
   #endif
   __Pyx_RefNannySetupContext("_err", 0);
   __Pyx_INCREF(__pyx_v_error);
 
-  /* "View.MemoryView":1262
+  /* "View.MemoryView":1264
  * @cname('__pyx_memoryview_err')
  * cdef int _err(object error, char *msg) except -1 with gil:
  *     if msg != NULL:             # <<<<<<<<<<<<<<
  *         raise error(msg.decode('ascii'))
  *     else:
  */
   __pyx_t_1 = ((__pyx_v_msg != NULL) != 0);
   if (unlikely(__pyx_t_1)) {
 
-    /* "View.MemoryView":1263
+    /* "View.MemoryView":1265
  * cdef int _err(object error, char *msg) except -1 with gil:
  *     if msg != NULL:
  *         raise error(msg.decode('ascii'))             # <<<<<<<<<<<<<<
  *     else:
  *         raise error
  */
-    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1263, __pyx_L1_error)
+    __pyx_t_3 = __Pyx_decode_c_string(__pyx_v_msg, 0, strlen(__pyx_v_msg), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 1265, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_3);
     __Pyx_INCREF(__pyx_v_error);
     __pyx_t_4 = __pyx_v_error; __pyx_t_5 = NULL;
     if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
       __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
       if (likely(__pyx_t_5)) {
         PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
@@ -19668,43 +19757,43 @@
         __Pyx_INCREF(function);
         __Pyx_DECREF_SET(__pyx_t_4, function);
       }
     }
     __pyx_t_2 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_4, __pyx_t_5, __pyx_t_3) : __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3);
     __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
     __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
-    if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1263, __pyx_L1_error)
+    if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 1265, __pyx_L1_error)
     __Pyx_GOTREF(__pyx_t_2);
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
     __Pyx_Raise(__pyx_t_2, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __PYX_ERR(2, 1263, __pyx_L1_error)
+    __PYX_ERR(2, 1265, __pyx_L1_error)
 
-    /* "View.MemoryView":1262
+    /* "View.MemoryView":1264
  * @cname('__pyx_memoryview_err')
  * cdef int _err(object error, char *msg) except -1 with gil:
  *     if msg != NULL:             # <<<<<<<<<<<<<<
  *         raise error(msg.decode('ascii'))
  *     else:
  */
   }
 
-  /* "View.MemoryView":1265
+  /* "View.MemoryView":1267
  *         raise error(msg.decode('ascii'))
  *     else:
  *         raise error             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_copy_contents')
  */
   /*else*/ {
     __Pyx_Raise(__pyx_v_error, 0, 0, 0);
-    __PYX_ERR(2, 1265, __pyx_L1_error)
+    __PYX_ERR(2, 1267, __pyx_L1_error)
   }
 
-  /* "View.MemoryView":1261
+  /* "View.MemoryView":1263
  * 
  * @cname('__pyx_memoryview_err')
  * cdef int _err(object error, char *msg) except -1 with gil:             # <<<<<<<<<<<<<<
  *     if msg != NULL:
  *         raise error(msg.decode('ascii'))
  */
 
@@ -19720,15 +19809,15 @@
   __Pyx_RefNannyFinishContext();
   #ifdef WITH_THREAD
   __Pyx_PyGILState_Release(__pyx_gilstate_save);
   #endif
   return __pyx_r;
 }
 
-/* "View.MemoryView":1268
+/* "View.MemoryView":1270
  * 
  * @cname('__pyx_memoryview_copy_contents')
  * cdef int memoryview_copy_contents(__Pyx_memviewslice src,             # <<<<<<<<<<<<<<
  *                                   __Pyx_memviewslice dst,
  *                                   int src_ndim, int dst_ndim,
  */
 
@@ -19750,119 +19839,119 @@
   int __pyx_t_6;
   void *__pyx_t_7;
   int __pyx_t_8;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
 
-  /* "View.MemoryView":1276
+  /* "View.MemoryView":1278
  *     Check for overlapping memory and verify the shapes.
  *     """
  *     cdef void *tmpdata = NULL             # <<<<<<<<<<<<<<
  *     cdef size_t itemsize = src.memview.view.itemsize
  *     cdef int i
  */
   __pyx_v_tmpdata = NULL;
 
-  /* "View.MemoryView":1277
+  /* "View.MemoryView":1279
  *     """
  *     cdef void *tmpdata = NULL
  *     cdef size_t itemsize = src.memview.view.itemsize             # <<<<<<<<<<<<<<
  *     cdef int i
  *     cdef char order = get_best_order(&src, src_ndim)
  */
   __pyx_t_1 = __pyx_v_src.memview->view.itemsize;
   __pyx_v_itemsize = __pyx_t_1;
 
-  /* "View.MemoryView":1279
+  /* "View.MemoryView":1281
  *     cdef size_t itemsize = src.memview.view.itemsize
  *     cdef int i
  *     cdef char order = get_best_order(&src, src_ndim)             # <<<<<<<<<<<<<<
  *     cdef bint broadcasting = False
  *     cdef bint direct_copy = False
  */
   __pyx_v_order = __pyx_get_best_slice_order((&__pyx_v_src), __pyx_v_src_ndim);
 
-  /* "View.MemoryView":1280
+  /* "View.MemoryView":1282
  *     cdef int i
  *     cdef char order = get_best_order(&src, src_ndim)
  *     cdef bint broadcasting = False             # <<<<<<<<<<<<<<
  *     cdef bint direct_copy = False
  *     cdef __Pyx_memviewslice tmp
  */
   __pyx_v_broadcasting = 0;
 
-  /* "View.MemoryView":1281
+  /* "View.MemoryView":1283
  *     cdef char order = get_best_order(&src, src_ndim)
  *     cdef bint broadcasting = False
  *     cdef bint direct_copy = False             # <<<<<<<<<<<<<<
  *     cdef __Pyx_memviewslice tmp
  * 
  */
   __pyx_v_direct_copy = 0;
 
-  /* "View.MemoryView":1284
+  /* "View.MemoryView":1286
  *     cdef __Pyx_memviewslice tmp
  * 
  *     if src_ndim < dst_ndim:             # <<<<<<<<<<<<<<
  *         broadcast_leading(&src, src_ndim, dst_ndim)
  *     elif dst_ndim < src_ndim:
  */
   __pyx_t_2 = ((__pyx_v_src_ndim < __pyx_v_dst_ndim) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1285
+    /* "View.MemoryView":1287
  * 
  *     if src_ndim < dst_ndim:
  *         broadcast_leading(&src, src_ndim, dst_ndim)             # <<<<<<<<<<<<<<
  *     elif dst_ndim < src_ndim:
  *         broadcast_leading(&dst, dst_ndim, src_ndim)
  */
     __pyx_memoryview_broadcast_leading((&__pyx_v_src), __pyx_v_src_ndim, __pyx_v_dst_ndim);
 
-    /* "View.MemoryView":1284
+    /* "View.MemoryView":1286
  *     cdef __Pyx_memviewslice tmp
  * 
  *     if src_ndim < dst_ndim:             # <<<<<<<<<<<<<<
  *         broadcast_leading(&src, src_ndim, dst_ndim)
  *     elif dst_ndim < src_ndim:
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":1286
+  /* "View.MemoryView":1288
  *     if src_ndim < dst_ndim:
  *         broadcast_leading(&src, src_ndim, dst_ndim)
  *     elif dst_ndim < src_ndim:             # <<<<<<<<<<<<<<
  *         broadcast_leading(&dst, dst_ndim, src_ndim)
  * 
  */
   __pyx_t_2 = ((__pyx_v_dst_ndim < __pyx_v_src_ndim) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1287
+    /* "View.MemoryView":1289
  *         broadcast_leading(&src, src_ndim, dst_ndim)
  *     elif dst_ndim < src_ndim:
  *         broadcast_leading(&dst, dst_ndim, src_ndim)             # <<<<<<<<<<<<<<
  * 
  *     cdef int ndim = max(src_ndim, dst_ndim)
  */
     __pyx_memoryview_broadcast_leading((&__pyx_v_dst), __pyx_v_dst_ndim, __pyx_v_src_ndim);
 
-    /* "View.MemoryView":1286
+    /* "View.MemoryView":1288
  *     if src_ndim < dst_ndim:
  *         broadcast_leading(&src, src_ndim, dst_ndim)
  *     elif dst_ndim < src_ndim:             # <<<<<<<<<<<<<<
  *         broadcast_leading(&dst, dst_ndim, src_ndim)
  * 
  */
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":1289
+  /* "View.MemoryView":1291
  *         broadcast_leading(&dst, dst_ndim, src_ndim)
  * 
  *     cdef int ndim = max(src_ndim, dst_ndim)             # <<<<<<<<<<<<<<
  * 
  *     for i in range(ndim):
  */
   __pyx_t_3 = __pyx_v_dst_ndim;
@@ -19870,420 +19959,420 @@
   if (((__pyx_t_3 > __pyx_t_4) != 0)) {
     __pyx_t_5 = __pyx_t_3;
   } else {
     __pyx_t_5 = __pyx_t_4;
   }
   __pyx_v_ndim = __pyx_t_5;
 
-  /* "View.MemoryView":1291
+  /* "View.MemoryView":1293
  *     cdef int ndim = max(src_ndim, dst_ndim)
  * 
  *     for i in range(ndim):             # <<<<<<<<<<<<<<
  *         if src.shape[i] != dst.shape[i]:
  *             if src.shape[i] == 1:
  */
   __pyx_t_5 = __pyx_v_ndim;
   __pyx_t_3 = __pyx_t_5;
   for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
     __pyx_v_i = __pyx_t_4;
 
-    /* "View.MemoryView":1292
+    /* "View.MemoryView":1294
  * 
  *     for i in range(ndim):
  *         if src.shape[i] != dst.shape[i]:             # <<<<<<<<<<<<<<
  *             if src.shape[i] == 1:
  *                 broadcasting = True
  */
     __pyx_t_2 = (((__pyx_v_src.shape[__pyx_v_i]) != (__pyx_v_dst.shape[__pyx_v_i])) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1293
+      /* "View.MemoryView":1295
  *     for i in range(ndim):
  *         if src.shape[i] != dst.shape[i]:
  *             if src.shape[i] == 1:             # <<<<<<<<<<<<<<
  *                 broadcasting = True
  *                 src.strides[i] = 0
  */
       __pyx_t_2 = (((__pyx_v_src.shape[__pyx_v_i]) == 1) != 0);
       if (__pyx_t_2) {
 
-        /* "View.MemoryView":1294
+        /* "View.MemoryView":1296
  *         if src.shape[i] != dst.shape[i]:
  *             if src.shape[i] == 1:
  *                 broadcasting = True             # <<<<<<<<<<<<<<
  *                 src.strides[i] = 0
  *             else:
  */
         __pyx_v_broadcasting = 1;
 
-        /* "View.MemoryView":1295
+        /* "View.MemoryView":1297
  *             if src.shape[i] == 1:
  *                 broadcasting = True
  *                 src.strides[i] = 0             # <<<<<<<<<<<<<<
  *             else:
  *                 _err_extents(i, dst.shape[i], src.shape[i])
  */
         (__pyx_v_src.strides[__pyx_v_i]) = 0;
 
-        /* "View.MemoryView":1293
+        /* "View.MemoryView":1295
  *     for i in range(ndim):
  *         if src.shape[i] != dst.shape[i]:
  *             if src.shape[i] == 1:             # <<<<<<<<<<<<<<
  *                 broadcasting = True
  *                 src.strides[i] = 0
  */
         goto __pyx_L7;
       }
 
-      /* "View.MemoryView":1297
+      /* "View.MemoryView":1299
  *                 src.strides[i] = 0
  *             else:
  *                 _err_extents(i, dst.shape[i], src.shape[i])             # <<<<<<<<<<<<<<
  * 
  *         if src.suboffsets[i] >= 0:
  */
       /*else*/ {
-        __pyx_t_6 = __pyx_memoryview_err_extents(__pyx_v_i, (__pyx_v_dst.shape[__pyx_v_i]), (__pyx_v_src.shape[__pyx_v_i])); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 1297, __pyx_L1_error)
+        __pyx_t_6 = __pyx_memoryview_err_extents(__pyx_v_i, (__pyx_v_dst.shape[__pyx_v_i]), (__pyx_v_src.shape[__pyx_v_i])); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 1299, __pyx_L1_error)
       }
       __pyx_L7:;
 
-      /* "View.MemoryView":1292
+      /* "View.MemoryView":1294
  * 
  *     for i in range(ndim):
  *         if src.shape[i] != dst.shape[i]:             # <<<<<<<<<<<<<<
  *             if src.shape[i] == 1:
  *                 broadcasting = True
  */
     }
 
-    /* "View.MemoryView":1299
+    /* "View.MemoryView":1301
  *                 _err_extents(i, dst.shape[i], src.shape[i])
  * 
  *         if src.suboffsets[i] >= 0:             # <<<<<<<<<<<<<<
  *             _err_dim(ValueError, "Dimension %d is not direct", i)
  * 
  */
     __pyx_t_2 = (((__pyx_v_src.suboffsets[__pyx_v_i]) >= 0) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1300
+      /* "View.MemoryView":1302
  * 
  *         if src.suboffsets[i] >= 0:
  *             _err_dim(ValueError, "Dimension %d is not direct", i)             # <<<<<<<<<<<<<<
  * 
  *     if slices_overlap(&src, &dst, ndim, itemsize):
  */
-      __pyx_t_6 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Dimension %d is not direct"), __pyx_v_i); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 1300, __pyx_L1_error)
+      __pyx_t_6 = __pyx_memoryview_err_dim(__pyx_builtin_ValueError, ((char *)"Dimension %d is not direct"), __pyx_v_i); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(2, 1302, __pyx_L1_error)
 
-      /* "View.MemoryView":1299
+      /* "View.MemoryView":1301
  *                 _err_extents(i, dst.shape[i], src.shape[i])
  * 
  *         if src.suboffsets[i] >= 0:             # <<<<<<<<<<<<<<
  *             _err_dim(ValueError, "Dimension %d is not direct", i)
  * 
  */
     }
   }
 
-  /* "View.MemoryView":1302
+  /* "View.MemoryView":1304
  *             _err_dim(ValueError, "Dimension %d is not direct", i)
  * 
  *     if slices_overlap(&src, &dst, ndim, itemsize):             # <<<<<<<<<<<<<<
  * 
  *         if not slice_is_contig(src, order, ndim):
  */
   __pyx_t_2 = (__pyx_slices_overlap((&__pyx_v_src), (&__pyx_v_dst), __pyx_v_ndim, __pyx_v_itemsize) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1304
+    /* "View.MemoryView":1306
  *     if slices_overlap(&src, &dst, ndim, itemsize):
  * 
  *         if not slice_is_contig(src, order, ndim):             # <<<<<<<<<<<<<<
  *             order = get_best_order(&dst, ndim)
  * 
  */
     __pyx_t_2 = ((!(__pyx_memviewslice_is_contig(__pyx_v_src, __pyx_v_order, __pyx_v_ndim) != 0)) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1305
+      /* "View.MemoryView":1307
  * 
  *         if not slice_is_contig(src, order, ndim):
  *             order = get_best_order(&dst, ndim)             # <<<<<<<<<<<<<<
  * 
  *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)
  */
       __pyx_v_order = __pyx_get_best_slice_order((&__pyx_v_dst), __pyx_v_ndim);
 
-      /* "View.MemoryView":1304
+      /* "View.MemoryView":1306
  *     if slices_overlap(&src, &dst, ndim, itemsize):
  * 
  *         if not slice_is_contig(src, order, ndim):             # <<<<<<<<<<<<<<
  *             order = get_best_order(&dst, ndim)
  * 
  */
     }
 
-    /* "View.MemoryView":1307
+    /* "View.MemoryView":1309
  *             order = get_best_order(&dst, ndim)
  * 
  *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)             # <<<<<<<<<<<<<<
  *         src = tmp
  * 
  */
-    __pyx_t_7 = __pyx_memoryview_copy_data_to_temp((&__pyx_v_src), (&__pyx_v_tmp), __pyx_v_order, __pyx_v_ndim); if (unlikely(__pyx_t_7 == ((void *)NULL))) __PYX_ERR(2, 1307, __pyx_L1_error)
+    __pyx_t_7 = __pyx_memoryview_copy_data_to_temp((&__pyx_v_src), (&__pyx_v_tmp), __pyx_v_order, __pyx_v_ndim); if (unlikely(__pyx_t_7 == ((void *)NULL))) __PYX_ERR(2, 1309, __pyx_L1_error)
     __pyx_v_tmpdata = __pyx_t_7;
 
-    /* "View.MemoryView":1308
+    /* "View.MemoryView":1310
  * 
  *         tmpdata = copy_data_to_temp(&src, &tmp, order, ndim)
  *         src = tmp             # <<<<<<<<<<<<<<
  * 
  *     if not broadcasting:
  */
     __pyx_v_src = __pyx_v_tmp;
 
-    /* "View.MemoryView":1302
+    /* "View.MemoryView":1304
  *             _err_dim(ValueError, "Dimension %d is not direct", i)
  * 
  *     if slices_overlap(&src, &dst, ndim, itemsize):             # <<<<<<<<<<<<<<
  * 
  *         if not slice_is_contig(src, order, ndim):
  */
   }
 
-  /* "View.MemoryView":1310
+  /* "View.MemoryView":1312
  *         src = tmp
  * 
  *     if not broadcasting:             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_2 = ((!(__pyx_v_broadcasting != 0)) != 0);
   if (__pyx_t_2) {
 
-    /* "View.MemoryView":1313
+    /* "View.MemoryView":1315
  * 
  * 
  *         if slice_is_contig(src, 'C', ndim):             # <<<<<<<<<<<<<<
  *             direct_copy = slice_is_contig(dst, 'C', ndim)
  *         elif slice_is_contig(src, 'F', ndim):
  */
     __pyx_t_2 = (__pyx_memviewslice_is_contig(__pyx_v_src, 'C', __pyx_v_ndim) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1314
+      /* "View.MemoryView":1316
  * 
  *         if slice_is_contig(src, 'C', ndim):
  *             direct_copy = slice_is_contig(dst, 'C', ndim)             # <<<<<<<<<<<<<<
  *         elif slice_is_contig(src, 'F', ndim):
  *             direct_copy = slice_is_contig(dst, 'F', ndim)
  */
       __pyx_v_direct_copy = __pyx_memviewslice_is_contig(__pyx_v_dst, 'C', __pyx_v_ndim);
 
-      /* "View.MemoryView":1313
+      /* "View.MemoryView":1315
  * 
  * 
  *         if slice_is_contig(src, 'C', ndim):             # <<<<<<<<<<<<<<
  *             direct_copy = slice_is_contig(dst, 'C', ndim)
  *         elif slice_is_contig(src, 'F', ndim):
  */
       goto __pyx_L12;
     }
 
-    /* "View.MemoryView":1315
+    /* "View.MemoryView":1317
  *         if slice_is_contig(src, 'C', ndim):
  *             direct_copy = slice_is_contig(dst, 'C', ndim)
  *         elif slice_is_contig(src, 'F', ndim):             # <<<<<<<<<<<<<<
  *             direct_copy = slice_is_contig(dst, 'F', ndim)
  * 
  */
     __pyx_t_2 = (__pyx_memviewslice_is_contig(__pyx_v_src, 'F', __pyx_v_ndim) != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1316
+      /* "View.MemoryView":1318
  *             direct_copy = slice_is_contig(dst, 'C', ndim)
  *         elif slice_is_contig(src, 'F', ndim):
  *             direct_copy = slice_is_contig(dst, 'F', ndim)             # <<<<<<<<<<<<<<
  * 
  *         if direct_copy:
  */
       __pyx_v_direct_copy = __pyx_memviewslice_is_contig(__pyx_v_dst, 'F', __pyx_v_ndim);
 
-      /* "View.MemoryView":1315
+      /* "View.MemoryView":1317
  *         if slice_is_contig(src, 'C', ndim):
  *             direct_copy = slice_is_contig(dst, 'C', ndim)
  *         elif slice_is_contig(src, 'F', ndim):             # <<<<<<<<<<<<<<
  *             direct_copy = slice_is_contig(dst, 'F', ndim)
  * 
  */
     }
     __pyx_L12:;
 
-    /* "View.MemoryView":1318
+    /* "View.MemoryView":1320
  *             direct_copy = slice_is_contig(dst, 'F', ndim)
  * 
  *         if direct_copy:             # <<<<<<<<<<<<<<
  * 
  *             refcount_copying(&dst, dtype_is_object, ndim, False)
  */
     __pyx_t_2 = (__pyx_v_direct_copy != 0);
     if (__pyx_t_2) {
 
-      /* "View.MemoryView":1320
+      /* "View.MemoryView":1322
  *         if direct_copy:
  * 
  *             refcount_copying(&dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
  *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
  *             refcount_copying(&dst, dtype_is_object, ndim, True)
  */
       __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 0);
 
-      /* "View.MemoryView":1321
+      /* "View.MemoryView":1323
  * 
  *             refcount_copying(&dst, dtype_is_object, ndim, False)
  *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))             # <<<<<<<<<<<<<<
  *             refcount_copying(&dst, dtype_is_object, ndim, True)
  *             free(tmpdata)
  */
       (void)(memcpy(__pyx_v_dst.data, __pyx_v_src.data, __pyx_memoryview_slice_get_size((&__pyx_v_src), __pyx_v_ndim)));
 
-      /* "View.MemoryView":1322
+      /* "View.MemoryView":1324
  *             refcount_copying(&dst, dtype_is_object, ndim, False)
  *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
  *             refcount_copying(&dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
  *             free(tmpdata)
  *             return 0
  */
       __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 1);
 
-      /* "View.MemoryView":1323
+      /* "View.MemoryView":1325
  *             memcpy(dst.data, src.data, slice_get_size(&src, ndim))
  *             refcount_copying(&dst, dtype_is_object, ndim, True)
  *             free(tmpdata)             # <<<<<<<<<<<<<<
  *             return 0
  * 
  */
       free(__pyx_v_tmpdata);
 
-      /* "View.MemoryView":1324
+      /* "View.MemoryView":1326
  *             refcount_copying(&dst, dtype_is_object, ndim, True)
  *             free(tmpdata)
  *             return 0             # <<<<<<<<<<<<<<
  * 
  *     if order == 'F' == get_best_order(&dst, ndim):
  */
       __pyx_r = 0;
       goto __pyx_L0;
 
-      /* "View.MemoryView":1318
+      /* "View.MemoryView":1320
  *             direct_copy = slice_is_contig(dst, 'F', ndim)
  * 
  *         if direct_copy:             # <<<<<<<<<<<<<<
  * 
  *             refcount_copying(&dst, dtype_is_object, ndim, False)
  */
     }
 
-    /* "View.MemoryView":1310
+    /* "View.MemoryView":1312
  *         src = tmp
  * 
  *     if not broadcasting:             # <<<<<<<<<<<<<<
  * 
  * 
  */
   }
 
-  /* "View.MemoryView":1326
+  /* "View.MemoryView":1328
  *             return 0
  * 
  *     if order == 'F' == get_best_order(&dst, ndim):             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_t_2 = (__pyx_v_order == 'F');
   if (__pyx_t_2) {
     __pyx_t_2 = ('F' == __pyx_get_best_slice_order((&__pyx_v_dst), __pyx_v_ndim));
   }
   __pyx_t_8 = (__pyx_t_2 != 0);
   if (__pyx_t_8) {
 
-    /* "View.MemoryView":1329
+    /* "View.MemoryView":1331
  * 
  * 
  *         transpose_memslice(&src)             # <<<<<<<<<<<<<<
  *         transpose_memslice(&dst)
  * 
  */
-    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_src)); if (unlikely(__pyx_t_5 == ((int)0))) __PYX_ERR(2, 1329, __pyx_L1_error)
+    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_src)); if (unlikely(__pyx_t_5 == ((int)0))) __PYX_ERR(2, 1331, __pyx_L1_error)
 
-    /* "View.MemoryView":1330
+    /* "View.MemoryView":1332
  * 
  *         transpose_memslice(&src)
  *         transpose_memslice(&dst)             # <<<<<<<<<<<<<<
  * 
  *     refcount_copying(&dst, dtype_is_object, ndim, False)
  */
-    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_dst)); if (unlikely(__pyx_t_5 == ((int)0))) __PYX_ERR(2, 1330, __pyx_L1_error)
+    __pyx_t_5 = __pyx_memslice_transpose((&__pyx_v_dst)); if (unlikely(__pyx_t_5 == ((int)0))) __PYX_ERR(2, 1332, __pyx_L1_error)
 
-    /* "View.MemoryView":1326
+    /* "View.MemoryView":1328
  *             return 0
  * 
  *     if order == 'F' == get_best_order(&dst, ndim):             # <<<<<<<<<<<<<<
  * 
  * 
  */
   }
 
-  /* "View.MemoryView":1332
+  /* "View.MemoryView":1334
  *         transpose_memslice(&dst)
  * 
  *     refcount_copying(&dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
  *     copy_strided_to_strided(&src, &dst, ndim, itemsize)
  *     refcount_copying(&dst, dtype_is_object, ndim, True)
  */
   __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 0);
 
-  /* "View.MemoryView":1333
+  /* "View.MemoryView":1335
  * 
  *     refcount_copying(&dst, dtype_is_object, ndim, False)
  *     copy_strided_to_strided(&src, &dst, ndim, itemsize)             # <<<<<<<<<<<<<<
  *     refcount_copying(&dst, dtype_is_object, ndim, True)
  * 
  */
   copy_strided_to_strided((&__pyx_v_src), (&__pyx_v_dst), __pyx_v_ndim, __pyx_v_itemsize);
 
-  /* "View.MemoryView":1334
+  /* "View.MemoryView":1336
  *     refcount_copying(&dst, dtype_is_object, ndim, False)
  *     copy_strided_to_strided(&src, &dst, ndim, itemsize)
  *     refcount_copying(&dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
  * 
  *     free(tmpdata)
  */
   __pyx_memoryview_refcount_copying((&__pyx_v_dst), __pyx_v_dtype_is_object, __pyx_v_ndim, 1);
 
-  /* "View.MemoryView":1336
+  /* "View.MemoryView":1338
  *     refcount_copying(&dst, dtype_is_object, ndim, True)
  * 
  *     free(tmpdata)             # <<<<<<<<<<<<<<
  *     return 0
  * 
  */
   free(__pyx_v_tmpdata);
 
-  /* "View.MemoryView":1337
+  /* "View.MemoryView":1339
  * 
  *     free(tmpdata)
  *     return 0             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_broadcast_leading')
  */
   __pyx_r = 0;
   goto __pyx_L0;
 
-  /* "View.MemoryView":1268
+  /* "View.MemoryView":1270
  * 
  * @cname('__pyx_memoryview_copy_contents')
  * cdef int memoryview_copy_contents(__Pyx_memviewslice src,             # <<<<<<<<<<<<<<
  *                                   __Pyx_memviewslice dst,
  *                                   int src_ndim, int dst_ndim,
  */
 
@@ -20299,217 +20388,217 @@
     #endif
   }
   __pyx_r = -1;
   __pyx_L0:;
   return __pyx_r;
 }
 
-/* "View.MemoryView":1340
+/* "View.MemoryView":1342
  * 
  * @cname('__pyx_memoryview_broadcast_leading')
  * cdef void broadcast_leading(__Pyx_memviewslice *mslice,             # <<<<<<<<<<<<<<
  *                             int ndim,
  *                             int ndim_other) nogil:
  */
 
 static void __pyx_memoryview_broadcast_leading(__Pyx_memviewslice *__pyx_v_mslice, int __pyx_v_ndim, int __pyx_v_ndim_other) {
   int __pyx_v_i;
   int __pyx_v_offset;
   int __pyx_t_1;
   int __pyx_t_2;
   int __pyx_t_3;
 
-  /* "View.MemoryView":1344
+  /* "View.MemoryView":1346
  *                             int ndim_other) nogil:
  *     cdef int i
  *     cdef int offset = ndim_other - ndim             # <<<<<<<<<<<<<<
  * 
  *     for i in range(ndim - 1, -1, -1):
  */
   __pyx_v_offset = (__pyx_v_ndim_other - __pyx_v_ndim);
 
-  /* "View.MemoryView":1346
+  /* "View.MemoryView":1348
  *     cdef int offset = ndim_other - ndim
  * 
  *     for i in range(ndim - 1, -1, -1):             # <<<<<<<<<<<<<<
  *         mslice.shape[i + offset] = mslice.shape[i]
  *         mslice.strides[i + offset] = mslice.strides[i]
  */
   for (__pyx_t_1 = (__pyx_v_ndim - 1); __pyx_t_1 > -1; __pyx_t_1-=1) {
     __pyx_v_i = __pyx_t_1;
 
-    /* "View.MemoryView":1347
+    /* "View.MemoryView":1349
  * 
  *     for i in range(ndim - 1, -1, -1):
  *         mslice.shape[i + offset] = mslice.shape[i]             # <<<<<<<<<<<<<<
  *         mslice.strides[i + offset] = mslice.strides[i]
  *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
  */
     (__pyx_v_mslice->shape[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->shape[__pyx_v_i]);
 
-    /* "View.MemoryView":1348
+    /* "View.MemoryView":1350
  *     for i in range(ndim - 1, -1, -1):
  *         mslice.shape[i + offset] = mslice.shape[i]
  *         mslice.strides[i + offset] = mslice.strides[i]             # <<<<<<<<<<<<<<
  *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
  * 
  */
     (__pyx_v_mslice->strides[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->strides[__pyx_v_i]);
 
-    /* "View.MemoryView":1349
+    /* "View.MemoryView":1351
  *         mslice.shape[i + offset] = mslice.shape[i]
  *         mslice.strides[i + offset] = mslice.strides[i]
  *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]             # <<<<<<<<<<<<<<
  * 
  *     for i in range(offset):
  */
     (__pyx_v_mslice->suboffsets[(__pyx_v_i + __pyx_v_offset)]) = (__pyx_v_mslice->suboffsets[__pyx_v_i]);
   }
 
-  /* "View.MemoryView":1351
+  /* "View.MemoryView":1353
  *         mslice.suboffsets[i + offset] = mslice.suboffsets[i]
  * 
  *     for i in range(offset):             # <<<<<<<<<<<<<<
  *         mslice.shape[i] = 1
  *         mslice.strides[i] = mslice.strides[0]
  */
   __pyx_t_1 = __pyx_v_offset;
   __pyx_t_2 = __pyx_t_1;
   for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
     __pyx_v_i = __pyx_t_3;
 
-    /* "View.MemoryView":1352
+    /* "View.MemoryView":1354
  * 
  *     for i in range(offset):
  *         mslice.shape[i] = 1             # <<<<<<<<<<<<<<
  *         mslice.strides[i] = mslice.strides[0]
  *         mslice.suboffsets[i] = -1
  */
     (__pyx_v_mslice->shape[__pyx_v_i]) = 1;
 
-    /* "View.MemoryView":1353
+    /* "View.MemoryView":1355
  *     for i in range(offset):
  *         mslice.shape[i] = 1
  *         mslice.strides[i] = mslice.strides[0]             # <<<<<<<<<<<<<<
  *         mslice.suboffsets[i] = -1
  * 
  */
     (__pyx_v_mslice->strides[__pyx_v_i]) = (__pyx_v_mslice->strides[0]);
 
-    /* "View.MemoryView":1354
+    /* "View.MemoryView":1356
  *         mslice.shape[i] = 1
  *         mslice.strides[i] = mslice.strides[0]
  *         mslice.suboffsets[i] = -1             # <<<<<<<<<<<<<<
  * 
  * 
  */
     (__pyx_v_mslice->suboffsets[__pyx_v_i]) = -1L;
   }
 
-  /* "View.MemoryView":1340
+  /* "View.MemoryView":1342
  * 
  * @cname('__pyx_memoryview_broadcast_leading')
  * cdef void broadcast_leading(__Pyx_memviewslice *mslice,             # <<<<<<<<<<<<<<
  *                             int ndim,
  *                             int ndim_other) nogil:
  */
 
   /* function exit code */
 }
 
-/* "View.MemoryView":1362
+/* "View.MemoryView":1364
  * 
  * @cname('__pyx_memoryview_refcount_copying')
  * cdef void refcount_copying(__Pyx_memviewslice *dst, bint dtype_is_object,             # <<<<<<<<<<<<<<
  *                            int ndim, bint inc) nogil:
  * 
  */
 
 static void __pyx_memoryview_refcount_copying(__Pyx_memviewslice *__pyx_v_dst, int __pyx_v_dtype_is_object, int __pyx_v_ndim, int __pyx_v_inc) {
   int __pyx_t_1;
 
-  /* "View.MemoryView":1366
+  /* "View.MemoryView":1368
  * 
  * 
  *     if dtype_is_object:             # <<<<<<<<<<<<<<
  *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,
  *                                            dst.strides, ndim, inc)
  */
   __pyx_t_1 = (__pyx_v_dtype_is_object != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1367
+    /* "View.MemoryView":1369
  * 
  *     if dtype_is_object:
  *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,             # <<<<<<<<<<<<<<
  *                                            dst.strides, ndim, inc)
  * 
  */
     __pyx_memoryview_refcount_objects_in_slice_with_gil(__pyx_v_dst->data, __pyx_v_dst->shape, __pyx_v_dst->strides, __pyx_v_ndim, __pyx_v_inc);
 
-    /* "View.MemoryView":1366
+    /* "View.MemoryView":1368
  * 
  * 
  *     if dtype_is_object:             # <<<<<<<<<<<<<<
  *         refcount_objects_in_slice_with_gil(dst.data, dst.shape,
  *                                            dst.strides, ndim, inc)
  */
   }
 
-  /* "View.MemoryView":1362
+  /* "View.MemoryView":1364
  * 
  * @cname('__pyx_memoryview_refcount_copying')
  * cdef void refcount_copying(__Pyx_memviewslice *dst, bint dtype_is_object,             # <<<<<<<<<<<<<<
  *                            int ndim, bint inc) nogil:
  * 
  */
 
   /* function exit code */
 }
 
-/* "View.MemoryView":1371
+/* "View.MemoryView":1373
  * 
  * @cname('__pyx_memoryview_refcount_objects_in_slice_with_gil')
  * cdef void refcount_objects_in_slice_with_gil(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                                              Py_ssize_t *strides, int ndim,
  *                                              bint inc) with gil:
  */
 
 static void __pyx_memoryview_refcount_objects_in_slice_with_gil(char *__pyx_v_data, Py_ssize_t *__pyx_v_shape, Py_ssize_t *__pyx_v_strides, int __pyx_v_ndim, int __pyx_v_inc) {
   __Pyx_RefNannyDeclarations
   #ifdef WITH_THREAD
   PyGILState_STATE __pyx_gilstate_save = __Pyx_PyGILState_Ensure();
   #endif
   __Pyx_RefNannySetupContext("refcount_objects_in_slice_with_gil", 0);
 
-  /* "View.MemoryView":1374
+  /* "View.MemoryView":1376
  *                                              Py_ssize_t *strides, int ndim,
  *                                              bint inc) with gil:
  *     refcount_objects_in_slice(data, shape, strides, ndim, inc)             # <<<<<<<<<<<<<<
  * 
  * @cname('__pyx_memoryview_refcount_objects_in_slice')
  */
   __pyx_memoryview_refcount_objects_in_slice(__pyx_v_data, __pyx_v_shape, __pyx_v_strides, __pyx_v_ndim, __pyx_v_inc);
 
-  /* "View.MemoryView":1371
+  /* "View.MemoryView":1373
  * 
  * @cname('__pyx_memoryview_refcount_objects_in_slice_with_gil')
  * cdef void refcount_objects_in_slice_with_gil(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                                              Py_ssize_t *strides, int ndim,
  *                                              bint inc) with gil:
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
   #ifdef WITH_THREAD
   __Pyx_PyGILState_Release(__pyx_gilstate_save);
   #endif
 }
 
-/* "View.MemoryView":1377
+/* "View.MemoryView":1379
  * 
  * @cname('__pyx_memoryview_refcount_objects_in_slice')
  * cdef void refcount_objects_in_slice(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                                     Py_ssize_t *strides, int ndim, bint inc):
  *     cdef Py_ssize_t i
  */
 
@@ -20518,178 +20607,178 @@
   __Pyx_RefNannyDeclarations
   Py_ssize_t __pyx_t_1;
   Py_ssize_t __pyx_t_2;
   Py_ssize_t __pyx_t_3;
   int __pyx_t_4;
   __Pyx_RefNannySetupContext("refcount_objects_in_slice", 0);
 
-  /* "View.MemoryView":1381
+  /* "View.MemoryView":1383
  *     cdef Py_ssize_t i
  * 
  *     for i in range(shape[0]):             # <<<<<<<<<<<<<<
  *         if ndim == 1:
  *             if inc:
  */
   __pyx_t_1 = (__pyx_v_shape[0]);
   __pyx_t_2 = __pyx_t_1;
   for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
     __pyx_v_i = __pyx_t_3;
 
-    /* "View.MemoryView":1382
+    /* "View.MemoryView":1384
  * 
  *     for i in range(shape[0]):
  *         if ndim == 1:             # <<<<<<<<<<<<<<
  *             if inc:
  *                 Py_INCREF((<PyObject **> data)[0])
  */
     __pyx_t_4 = ((__pyx_v_ndim == 1) != 0);
     if (__pyx_t_4) {
 
-      /* "View.MemoryView":1383
+      /* "View.MemoryView":1385
  *     for i in range(shape[0]):
  *         if ndim == 1:
  *             if inc:             # <<<<<<<<<<<<<<
  *                 Py_INCREF((<PyObject **> data)[0])
  *             else:
  */
       __pyx_t_4 = (__pyx_v_inc != 0);
       if (__pyx_t_4) {
 
-        /* "View.MemoryView":1384
+        /* "View.MemoryView":1386
  *         if ndim == 1:
  *             if inc:
  *                 Py_INCREF((<PyObject **> data)[0])             # <<<<<<<<<<<<<<
  *             else:
  *                 Py_DECREF((<PyObject **> data)[0])
  */
         Py_INCREF((((PyObject **)__pyx_v_data)[0]));
 
-        /* "View.MemoryView":1383
+        /* "View.MemoryView":1385
  *     for i in range(shape[0]):
  *         if ndim == 1:
  *             if inc:             # <<<<<<<<<<<<<<
  *                 Py_INCREF((<PyObject **> data)[0])
  *             else:
  */
         goto __pyx_L6;
       }
 
-      /* "View.MemoryView":1386
+      /* "View.MemoryView":1388
  *                 Py_INCREF((<PyObject **> data)[0])
  *             else:
  *                 Py_DECREF((<PyObject **> data)[0])             # <<<<<<<<<<<<<<
  *         else:
  *             refcount_objects_in_slice(data, shape + 1, strides + 1,
  */
       /*else*/ {
         Py_DECREF((((PyObject **)__pyx_v_data)[0]));
       }
       __pyx_L6:;
 
-      /* "View.MemoryView":1382
+      /* "View.MemoryView":1384
  * 
  *     for i in range(shape[0]):
  *         if ndim == 1:             # <<<<<<<<<<<<<<
  *             if inc:
  *                 Py_INCREF((<PyObject **> data)[0])
  */
       goto __pyx_L5;
     }
 
-    /* "View.MemoryView":1388
+    /* "View.MemoryView":1390
  *                 Py_DECREF((<PyObject **> data)[0])
  *         else:
  *             refcount_objects_in_slice(data, shape + 1, strides + 1,             # <<<<<<<<<<<<<<
  *                                       ndim - 1, inc)
  * 
  */
     /*else*/ {
 
-      /* "View.MemoryView":1389
+      /* "View.MemoryView":1391
  *         else:
  *             refcount_objects_in_slice(data, shape + 1, strides + 1,
  *                                       ndim - 1, inc)             # <<<<<<<<<<<<<<
  * 
  *         data += strides[0]
  */
       __pyx_memoryview_refcount_objects_in_slice(__pyx_v_data, (__pyx_v_shape + 1), (__pyx_v_strides + 1), (__pyx_v_ndim - 1), __pyx_v_inc);
     }
     __pyx_L5:;
 
-    /* "View.MemoryView":1391
+    /* "View.MemoryView":1393
  *                                       ndim - 1, inc)
  * 
  *         data += strides[0]             # <<<<<<<<<<<<<<
  * 
  * 
  */
     __pyx_v_data = (__pyx_v_data + (__pyx_v_strides[0]));
   }
 
-  /* "View.MemoryView":1377
+  /* "View.MemoryView":1379
  * 
  * @cname('__pyx_memoryview_refcount_objects_in_slice')
  * cdef void refcount_objects_in_slice(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                                     Py_ssize_t *strides, int ndim, bint inc):
  *     cdef Py_ssize_t i
  */
 
   /* function exit code */
   __Pyx_RefNannyFinishContext();
 }
 
-/* "View.MemoryView":1397
+/* "View.MemoryView":1399
  * 
  * @cname('__pyx_memoryview_slice_assign_scalar')
  * cdef void slice_assign_scalar(__Pyx_memviewslice *dst, int ndim,             # <<<<<<<<<<<<<<
  *                               size_t itemsize, void *item,
  *                               bint dtype_is_object) nogil:
  */
 
 static void __pyx_memoryview_slice_assign_scalar(__Pyx_memviewslice *__pyx_v_dst, int __pyx_v_ndim, size_t __pyx_v_itemsize, void *__pyx_v_item, int __pyx_v_dtype_is_object) {
 
-  /* "View.MemoryView":1400
+  /* "View.MemoryView":1402
  *                               size_t itemsize, void *item,
  *                               bint dtype_is_object) nogil:
  *     refcount_copying(dst, dtype_is_object, ndim, False)             # <<<<<<<<<<<<<<
  *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,
  *                          itemsize, item)
  */
   __pyx_memoryview_refcount_copying(__pyx_v_dst, __pyx_v_dtype_is_object, __pyx_v_ndim, 0);
 
-  /* "View.MemoryView":1401
+  /* "View.MemoryView":1403
  *                               bint dtype_is_object) nogil:
  *     refcount_copying(dst, dtype_is_object, ndim, False)
  *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,             # <<<<<<<<<<<<<<
  *                          itemsize, item)
  *     refcount_copying(dst, dtype_is_object, ndim, True)
  */
   __pyx_memoryview__slice_assign_scalar(__pyx_v_dst->data, __pyx_v_dst->shape, __pyx_v_dst->strides, __pyx_v_ndim, __pyx_v_itemsize, __pyx_v_item);
 
-  /* "View.MemoryView":1403
+  /* "View.MemoryView":1405
  *     _slice_assign_scalar(dst.data, dst.shape, dst.strides, ndim,
  *                          itemsize, item)
  *     refcount_copying(dst, dtype_is_object, ndim, True)             # <<<<<<<<<<<<<<
  * 
  * 
  */
   __pyx_memoryview_refcount_copying(__pyx_v_dst, __pyx_v_dtype_is_object, __pyx_v_ndim, 1);
 
-  /* "View.MemoryView":1397
+  /* "View.MemoryView":1399
  * 
  * @cname('__pyx_memoryview_slice_assign_scalar')
  * cdef void slice_assign_scalar(__Pyx_memviewslice *dst, int ndim,             # <<<<<<<<<<<<<<
  *                               size_t itemsize, void *item,
  *                               bint dtype_is_object) nogil:
  */
 
   /* function exit code */
 }
 
-/* "View.MemoryView":1407
+/* "View.MemoryView":1409
  * 
  * @cname('__pyx_memoryview__slice_assign_scalar')
  * cdef void _slice_assign_scalar(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                               Py_ssize_t *strides, int ndim,
  *                               size_t itemsize, void *item) nogil:
  */
 
@@ -20698,118 +20787,118 @@
   Py_ssize_t __pyx_v_stride;
   Py_ssize_t __pyx_v_extent;
   int __pyx_t_1;
   Py_ssize_t __pyx_t_2;
   Py_ssize_t __pyx_t_3;
   Py_ssize_t __pyx_t_4;
 
-  /* "View.MemoryView":1411
+  /* "View.MemoryView":1413
  *                               size_t itemsize, void *item) nogil:
  *     cdef Py_ssize_t i
  *     cdef Py_ssize_t stride = strides[0]             # <<<<<<<<<<<<<<
  *     cdef Py_ssize_t extent = shape[0]
  * 
  */
   __pyx_v_stride = (__pyx_v_strides[0]);
 
-  /* "View.MemoryView":1412
+  /* "View.MemoryView":1414
  *     cdef Py_ssize_t i
  *     cdef Py_ssize_t stride = strides[0]
  *     cdef Py_ssize_t extent = shape[0]             # <<<<<<<<<<<<<<
  * 
  *     if ndim == 1:
  */
   __pyx_v_extent = (__pyx_v_shape[0]);
 
-  /* "View.MemoryView":1414
+  /* "View.MemoryView":1416
  *     cdef Py_ssize_t extent = shape[0]
  * 
  *     if ndim == 1:             # <<<<<<<<<<<<<<
  *         for i in range(extent):
  *             memcpy(data, item, itemsize)
  */
   __pyx_t_1 = ((__pyx_v_ndim == 1) != 0);
   if (__pyx_t_1) {
 
-    /* "View.MemoryView":1415
+    /* "View.MemoryView":1417
  * 
  *     if ndim == 1:
  *         for i in range(extent):             # <<<<<<<<<<<<<<
  *             memcpy(data, item, itemsize)
  *             data += stride
  */
     __pyx_t_2 = __pyx_v_extent;
     __pyx_t_3 = __pyx_t_2;
     for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
       __pyx_v_i = __pyx_t_4;
 
-      /* "View.MemoryView":1416
+      /* "View.MemoryView":1418
  *     if ndim == 1:
  *         for i in range(extent):
  *             memcpy(data, item, itemsize)             # <<<<<<<<<<<<<<
  *             data += stride
  *     else:
  */
       (void)(memcpy(__pyx_v_data, __pyx_v_item, __pyx_v_itemsize));
 
-      /* "View.MemoryView":1417
+      /* "View.MemoryView":1419
  *         for i in range(extent):
  *             memcpy(data, item, itemsize)
  *             data += stride             # <<<<<<<<<<<<<<
  *     else:
  *         for i in range(extent):
  */
       __pyx_v_data = (__pyx_v_data + __pyx_v_stride);
     }
 
-    /* "View.MemoryView":1414
+    /* "View.MemoryView":1416
  *     cdef Py_ssize_t extent = shape[0]
  * 
  *     if ndim == 1:             # <<<<<<<<<<<<<<
  *         for i in range(extent):
  *             memcpy(data, item, itemsize)
  */
     goto __pyx_L3;
   }
 
-  /* "View.MemoryView":1419
+  /* "View.MemoryView":1421
  *             data += stride
  *     else:
  *         for i in range(extent):             # <<<<<<<<<<<<<<
  *             _slice_assign_scalar(data, shape + 1, strides + 1,
  *                                 ndim - 1, itemsize, item)
  */
   /*else*/ {
     __pyx_t_2 = __pyx_v_extent;
     __pyx_t_3 = __pyx_t_2;
     for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
       __pyx_v_i = __pyx_t_4;
 
-      /* "View.MemoryView":1420
+      /* "View.MemoryView":1422
  *     else:
  *         for i in range(extent):
  *             _slice_assign_scalar(data, shape + 1, strides + 1,             # <<<<<<<<<<<<<<
  *                                 ndim - 1, itemsize, item)
  *             data += stride
  */
       __pyx_memoryview__slice_assign_scalar(__pyx_v_data, (__pyx_v_shape + 1), (__pyx_v_strides + 1), (__pyx_v_ndim - 1), __pyx_v_itemsize, __pyx_v_item);
 
-      /* "View.MemoryView":1422
+      /* "View.MemoryView":1424
  *             _slice_assign_scalar(data, shape + 1, strides + 1,
  *                                 ndim - 1, itemsize, item)
  *             data += stride             # <<<<<<<<<<<<<<
  * 
  * 
  */
       __pyx_v_data = (__pyx_v_data + __pyx_v_stride);
     }
   }
   __pyx_L3:;
 
-  /* "View.MemoryView":1407
+  /* "View.MemoryView":1409
  * 
  * @cname('__pyx_memoryview__slice_assign_scalar')
  * cdef void _slice_assign_scalar(char *data, Py_ssize_t *shape,             # <<<<<<<<<<<<<<
  *                               Py_ssize_t *strides, int ndim,
  *                               size_t itemsize, void *item) nogil:
  */
 
@@ -20899,151 +20988,155 @@
 }
 
 static PyObject *__pyx_pf_15View_dot_MemoryView___pyx_unpickle_Enum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
   PyObject *__pyx_v___pyx_PickleError = 0;
   PyObject *__pyx_v___pyx_result = 0;
   PyObject *__pyx_r = NULL;
   __Pyx_RefNannyDeclarations
-  int __pyx_t_1;
-  PyObject *__pyx_t_2 = NULL;
-  PyObject *__pyx_t_3 = NULL;
+  PyObject *__pyx_t_1 = NULL;
+  int __pyx_t_2;
+  int __pyx_t_3;
   PyObject *__pyx_t_4 = NULL;
   PyObject *__pyx_t_5 = NULL;
-  int __pyx_t_6;
+  PyObject *__pyx_t_6 = NULL;
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__pyx_unpickle_Enum", 0);
 
   /* "(tree fragment)":4
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
- *     if __pyx_checksum != 0xb068931:             # <<<<<<<<<<<<<<
+ *     if __pyx_checksum not in (0xb068931, 0x82a3537, 0x6ae9995):             # <<<<<<<<<<<<<<
  *         from pickle import PickleError as __pyx_PickleError
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  */
-  __pyx_t_1 = ((__pyx_v___pyx_checksum != 0xb068931) != 0);
-  if (__pyx_t_1) {
+  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 4, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_1);
+  __pyx_t_2 = (__Pyx_PySequence_ContainsTF(__pyx_t_1, __pyx_tuple__24, Py_NE)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(2, 4, __pyx_L1_error)
+  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+  __pyx_t_3 = (__pyx_t_2 != 0);
+  if (__pyx_t_3) {
 
     /* "(tree fragment)":5
  *     cdef object __pyx_result
- *     if __pyx_checksum != 0xb068931:
+ *     if __pyx_checksum not in (0xb068931, 0x82a3537, 0x6ae9995):
  *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  *     __pyx_result = Enum.__new__(__pyx_type)
  */
-    __pyx_t_2 = PyList_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 5, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_2);
+    __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 5, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_1);
     __Pyx_INCREF(__pyx_n_s_PickleError);
     __Pyx_GIVEREF(__pyx_n_s_PickleError);
-    PyList_SET_ITEM(__pyx_t_2, 0, __pyx_n_s_PickleError);
-    __pyx_t_3 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 5, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_3);
-    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 5, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_2);
-    __Pyx_INCREF(__pyx_t_2);
-    __pyx_v___pyx_PickleError = __pyx_t_2;
-    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+    PyList_SET_ITEM(__pyx_t_1, 0, __pyx_n_s_PickleError);
+    __pyx_t_4 = __Pyx_Import(__pyx_n_s_pickle, __pyx_t_1, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 5, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_4);
+    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_4, __pyx_n_s_PickleError); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 5, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_1);
+    __Pyx_INCREF(__pyx_t_1);
+    __pyx_v___pyx_PickleError = __pyx_t_1;
+    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
 
     /* "(tree fragment)":6
- *     if __pyx_checksum != 0xb068931:
+ *     if __pyx_checksum not in (0xb068931, 0x82a3537, 0x6ae9995):
  *         from pickle import PickleError as __pyx_PickleError
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)             # <<<<<<<<<<<<<<
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)             # <<<<<<<<<<<<<<
  *     __pyx_result = Enum.__new__(__pyx_type)
  *     if __pyx_state is not None:
  */
-    __pyx_t_2 = __Pyx_PyInt_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 6, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_2);
-    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_Incompatible_checksums_s_vs_0xb0, __pyx_t_2); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 6, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_4);
-    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
+    __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 6, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_1);
+    __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_Incompatible_checksums_0x_x_vs_0, __pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(2, 6, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_5);
+    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
     __Pyx_INCREF(__pyx_v___pyx_PickleError);
-    __pyx_t_2 = __pyx_v___pyx_PickleError; __pyx_t_5 = NULL;
-    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
-      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_2);
-      if (likely(__pyx_t_5)) {
-        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
-        __Pyx_INCREF(__pyx_t_5);
+    __pyx_t_1 = __pyx_v___pyx_PickleError; __pyx_t_6 = NULL;
+    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_1))) {
+      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
+      if (likely(__pyx_t_6)) {
+        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
+        __Pyx_INCREF(__pyx_t_6);
         __Pyx_INCREF(function);
-        __Pyx_DECREF_SET(__pyx_t_2, function);
+        __Pyx_DECREF_SET(__pyx_t_1, function);
       }
     }
-    __pyx_t_3 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_5, __pyx_t_4) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_4);
-    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
+    __pyx_t_4 = (__pyx_t_6) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_6, __pyx_t_5) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_5);
+    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
+    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
+    if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 6, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_4);
+    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
     __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
-    if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 6, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_3);
-    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
     __PYX_ERR(2, 6, __pyx_L1_error)
 
     /* "(tree fragment)":4
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
- *     if __pyx_checksum != 0xb068931:             # <<<<<<<<<<<<<<
+ *     if __pyx_checksum not in (0xb068931, 0x82a3537, 0x6ae9995):             # <<<<<<<<<<<<<<
  *         from pickle import PickleError as __pyx_PickleError
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  */
   }
 
   /* "(tree fragment)":7
  *         from pickle import PickleError as __pyx_PickleError
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  *     __pyx_result = Enum.__new__(__pyx_type)             # <<<<<<<<<<<<<<
  *     if __pyx_state is not None:
  *         __pyx_unpickle_Enum__set_state(<Enum> __pyx_result, __pyx_state)
  */
-  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_MemviewEnum_type), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 7, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_t_2);
-  __pyx_t_4 = NULL;
-  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_2))) {
-    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_2);
-    if (likely(__pyx_t_4)) {
-      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
-      __Pyx_INCREF(__pyx_t_4);
+  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_MemviewEnum_type), __pyx_n_s_new); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 7, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_1);
+  __pyx_t_5 = NULL;
+  if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
+    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
+    if (likely(__pyx_t_5)) {
+      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
+      __Pyx_INCREF(__pyx_t_5);
       __Pyx_INCREF(function);
-      __Pyx_DECREF_SET(__pyx_t_2, function);
+      __Pyx_DECREF_SET(__pyx_t_1, function);
     }
   }
-  __pyx_t_3 = (__pyx_t_4) ? __Pyx_PyObject_Call2Args(__pyx_t_2, __pyx_t_4, __pyx_v___pyx_type) : __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_v___pyx_type);
-  __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
-  if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 7, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_t_3);
-  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
-  __pyx_v___pyx_result = __pyx_t_3;
-  __pyx_t_3 = 0;
+  __pyx_t_4 = (__pyx_t_5) ? __Pyx_PyObject_Call2Args(__pyx_t_1, __pyx_t_5, __pyx_v___pyx_type) : __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_v___pyx_type);
+  __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
+  if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 7, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_t_4);
+  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
+  __pyx_v___pyx_result = __pyx_t_4;
+  __pyx_t_4 = 0;
 
   /* "(tree fragment)":8
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  *     __pyx_result = Enum.__new__(__pyx_type)
  *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
  *         __pyx_unpickle_Enum__set_state(<Enum> __pyx_result, __pyx_state)
  *     return __pyx_result
  */
-  __pyx_t_1 = (__pyx_v___pyx_state != Py_None);
-  __pyx_t_6 = (__pyx_t_1 != 0);
-  if (__pyx_t_6) {
+  __pyx_t_3 = (__pyx_v___pyx_state != Py_None);
+  __pyx_t_2 = (__pyx_t_3 != 0);
+  if (__pyx_t_2) {
 
     /* "(tree fragment)":9
  *     __pyx_result = Enum.__new__(__pyx_type)
  *     if __pyx_state is not None:
  *         __pyx_unpickle_Enum__set_state(<Enum> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
  *     return __pyx_result
  * cdef __pyx_unpickle_Enum__set_state(Enum __pyx_result, tuple __pyx_state):
  */
-    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(2, 9, __pyx_L1_error)
-    __pyx_t_3 = __pyx_unpickle_Enum__set_state(((struct __pyx_MemviewEnum_obj *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_3)) __PYX_ERR(2, 9, __pyx_L1_error)
-    __Pyx_GOTREF(__pyx_t_3);
-    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
+    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None)||((void)PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_v___pyx_state)->tp_name), 0))) __PYX_ERR(2, 9, __pyx_L1_error)
+    __pyx_t_4 = __pyx_unpickle_Enum__set_state(((struct __pyx_MemviewEnum_obj *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_4)) __PYX_ERR(2, 9, __pyx_L1_error)
+    __Pyx_GOTREF(__pyx_t_4);
+    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
 
     /* "(tree fragment)":8
- *         raise __pyx_PickleError("Incompatible checksums (%s vs 0xb068931 = (name))" % __pyx_checksum)
+ *         raise __pyx_PickleError("Incompatible checksums (0x%x vs (0xb068931, 0x82a3537, 0x6ae9995) = (name))" % __pyx_checksum)
  *     __pyx_result = Enum.__new__(__pyx_type)
  *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
  *         __pyx_unpickle_Enum__set_state(<Enum> __pyx_result, __pyx_state)
  *     return __pyx_result
  */
   }
 
@@ -21063,18 +21156,18 @@
  * def __pyx_unpickle_Enum(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
 
   /* function exit code */
   __pyx_L1_error:;
-  __Pyx_XDECREF(__pyx_t_2);
-  __Pyx_XDECREF(__pyx_t_3);
+  __Pyx_XDECREF(__pyx_t_1);
   __Pyx_XDECREF(__pyx_t_4);
   __Pyx_XDECREF(__pyx_t_5);
+  __Pyx_XDECREF(__pyx_t_6);
   __Pyx_AddTraceback("View.MemoryView.__pyx_unpickle_Enum", __pyx_clineno, __pyx_lineno, __pyx_filename);
   __pyx_r = NULL;
   __pyx_L0:;
   __Pyx_XDECREF(__pyx_v___pyx_PickleError);
   __Pyx_XDECREF(__pyx_v___pyx_result);
   __Pyx_XGIVEREF(__pyx_r);
   __Pyx_RefNannyFinishContext();
@@ -21991,15 +22084,15 @@
   {&__pyx_kp_s_Can_only_create_a_buffer_that_is, __pyx_k_Can_only_create_a_buffer_that_is, sizeof(__pyx_k_Can_only_create_a_buffer_that_is), 0, 0, 1, 0},
   {&__pyx_kp_s_Cannot_assign_to_read_only_memor, __pyx_k_Cannot_assign_to_read_only_memor, sizeof(__pyx_k_Cannot_assign_to_read_only_memor), 0, 0, 1, 0},
   {&__pyx_kp_s_Cannot_create_writable_memory_vi, __pyx_k_Cannot_create_writable_memory_vi, sizeof(__pyx_k_Cannot_create_writable_memory_vi), 0, 0, 1, 0},
   {&__pyx_kp_s_Cannot_index_with_type_s, __pyx_k_Cannot_index_with_type_s, sizeof(__pyx_k_Cannot_index_with_type_s), 0, 0, 1, 0},
   {&__pyx_n_s_Ellipsis, __pyx_k_Ellipsis, sizeof(__pyx_k_Ellipsis), 0, 0, 1, 1},
   {&__pyx_kp_s_Empty_shape_tuple_for_cython_arr, __pyx_k_Empty_shape_tuple_for_cython_arr, sizeof(__pyx_k_Empty_shape_tuple_for_cython_arr), 0, 0, 1, 0},
   {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
-  {&__pyx_kp_s_Incompatible_checksums_s_vs_0xb0, __pyx_k_Incompatible_checksums_s_vs_0xb0, sizeof(__pyx_k_Incompatible_checksums_s_vs_0xb0), 0, 0, 1, 0},
+  {&__pyx_kp_s_Incompatible_checksums_0x_x_vs_0, __pyx_k_Incompatible_checksums_0x_x_vs_0, sizeof(__pyx_k_Incompatible_checksums_0x_x_vs_0), 0, 0, 1, 0},
   {&__pyx_n_s_IndexError, __pyx_k_IndexError, sizeof(__pyx_k_IndexError), 0, 0, 1, 1},
   {&__pyx_kp_s_Indirect_dimensions_not_supporte, __pyx_k_Indirect_dimensions_not_supporte, sizeof(__pyx_k_Indirect_dimensions_not_supporte), 0, 0, 1, 0},
   {&__pyx_n_s_InnerFunctionError, __pyx_k_InnerFunctionError, sizeof(__pyx_k_InnerFunctionError), 0, 0, 1, 1},
   {&__pyx_kp_s_Invalid_mode_expected_c_or_fortr, __pyx_k_Invalid_mode_expected_c_or_fortr, sizeof(__pyx_k_Invalid_mode_expected_c_or_fortr), 0, 0, 1, 0},
   {&__pyx_kp_s_Invalid_shape_in_axis_d_d, __pyx_k_Invalid_shape_in_axis_d_d, sizeof(__pyx_k_Invalid_shape_in_axis_d_d), 0, 0, 1, 0},
   {&__pyx_n_s_MemoryError, __pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 0, 1, 1},
   {&__pyx_kp_s_MemoryView_of_r_at_0x_x, __pyx_k_MemoryView_of_r_at_0x_x, sizeof(__pyx_k_MemoryView_of_r_at_0x_x), 0, 0, 1, 0},
@@ -22181,20 +22274,20 @@
   {&__pyx_n_s_vector_seqs, __pyx_k_vector_seqs, sizeof(__pyx_k_vector_seqs), 0, 0, 1, 1},
   {0, 0, 0, 0, 0, 0, 0}
 };
 static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(void) {
   __pyx_builtin_IndexError = __Pyx_GetBuiltinName(__pyx_n_s_IndexError); if (!__pyx_builtin_IndexError) __PYX_ERR(0, 220, __pyx_L1_error)
   __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 224, __pyx_L1_error)
   __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 226, __pyx_L1_error)
-  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(1, 945, __pyx_L1_error)
-  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(2, 148, __pyx_L1_error)
-  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(2, 151, __pyx_L1_error)
+  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(1, 944, __pyx_L1_error)
+  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(2, 149, __pyx_L1_error)
+  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(2, 152, __pyx_L1_error)
   __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(2, 2, __pyx_L1_error)
-  __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(2, 404, __pyx_L1_error)
-  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(2, 613, __pyx_L1_error)
+  __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(2, 406, __pyx_L1_error)
+  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(2, 615, __pyx_L1_error)
   return 0;
   __pyx_L1_error:;
   return -1;
 }
 
 static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(void) {
   __Pyx_RefNannyDeclarations
@@ -22243,88 +22336,88 @@
  * 
  *     for idx in range(lenpos):
  */
   __pyx_tuple__4 = PyTuple_Pack(2, __pyx_float_0_0, __pyx_int_0); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 281, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__4);
   __Pyx_GIVEREF(__pyx_tuple__4);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":945
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":944
  *         __pyx_import_array()
  *     except Exception:
  *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_umath() except -1:
  */
-  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(1, 945, __pyx_L1_error)
+  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple__5)) __PYX_ERR(1, 944, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__5);
   __Pyx_GIVEREF(__pyx_tuple__5);
 
-  /* "../../../../../../apps/anaconda3/envs/aesara-3.9/lib/python3.9/site-packages/numpy/__init__.pxd":951
+  /* "../../../../../../apps/anaconda3/envs/aesara-dev-311/lib/python3.11/site-packages/numpy/__init__.pxd":950
  *         _import_umath()
  *     except Exception:
  *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
  * 
  * cdef inline int import_ufunc() except -1:
  */
-  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(1, 951, __pyx_L1_error)
+  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_u_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(1, 950, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__6);
   __Pyx_GIVEREF(__pyx_tuple__6);
 
-  /* "View.MemoryView":133
+  /* "View.MemoryView":134
  * 
  *         if not self.ndim:
  *             raise ValueError("Empty shape tuple for cython.array")             # <<<<<<<<<<<<<<
  * 
  *         if itemsize <= 0:
  */
-  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_s_Empty_shape_tuple_for_cython_arr); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(2, 133, __pyx_L1_error)
+  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_s_Empty_shape_tuple_for_cython_arr); if (unlikely(!__pyx_tuple__7)) __PYX_ERR(2, 134, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__7);
   __Pyx_GIVEREF(__pyx_tuple__7);
 
-  /* "View.MemoryView":136
+  /* "View.MemoryView":137
  * 
  *         if itemsize <= 0:
  *             raise ValueError("itemsize <= 0 for cython.array")             # <<<<<<<<<<<<<<
  * 
  *         if not isinstance(format, bytes):
  */
-  __pyx_tuple__8 = PyTuple_Pack(1, __pyx_kp_s_itemsize_0_for_cython_array); if (unlikely(!__pyx_tuple__8)) __PYX_ERR(2, 136, __pyx_L1_error)
+  __pyx_tuple__8 = PyTuple_Pack(1, __pyx_kp_s_itemsize_0_for_cython_array); if (unlikely(!__pyx_tuple__8)) __PYX_ERR(2, 137, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__8);
   __Pyx_GIVEREF(__pyx_tuple__8);
 
-  /* "View.MemoryView":148
+  /* "View.MemoryView":149
  * 
  *         if not self._shape:
  *             raise MemoryError("unable to allocate shape and strides.")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_shape_and_str); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(2, 148, __pyx_L1_error)
+  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_shape_and_str); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(2, 149, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__9);
   __Pyx_GIVEREF(__pyx_tuple__9);
 
-  /* "View.MemoryView":176
+  /* "View.MemoryView":177
  *             self.data = <char *>malloc(self.len)
  *             if not self.data:
  *                 raise MemoryError("unable to allocate array data.")             # <<<<<<<<<<<<<<
  * 
  *             if self.dtype_is_object:
  */
-  __pyx_tuple__10 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_array_data); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(2, 176, __pyx_L1_error)
+  __pyx_tuple__10 = PyTuple_Pack(1, __pyx_kp_s_unable_to_allocate_array_data); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(2, 177, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__10);
   __Pyx_GIVEREF(__pyx_tuple__10);
 
-  /* "View.MemoryView":192
+  /* "View.MemoryView":193
  *             bufmode = PyBUF_F_CONTIGUOUS | PyBUF_ANY_CONTIGUOUS
  *         if not (flags & bufmode):
  *             raise ValueError("Can only create a buffer that is contiguous in memory.")             # <<<<<<<<<<<<<<
  *         info.buf = self.data
  *         info.len = self.len
  */
-  __pyx_tuple__11 = PyTuple_Pack(1, __pyx_kp_s_Can_only_create_a_buffer_that_is); if (unlikely(!__pyx_tuple__11)) __PYX_ERR(2, 192, __pyx_L1_error)
+  __pyx_tuple__11 = PyTuple_Pack(1, __pyx_kp_s_Can_only_create_a_buffer_that_is); if (unlikely(!__pyx_tuple__11)) __PYX_ERR(2, 193, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__11);
   __Pyx_GIVEREF(__pyx_tuple__11);
 
   /* "(tree fragment)":2
  * def __reduce_cython__(self):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")             # <<<<<<<<<<<<<<
  * def __setstate_cython__(self, __pyx_state):
@@ -22339,66 +22432,66 @@
  * def __setstate_cython__(self, __pyx_state):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")             # <<<<<<<<<<<<<<
  */
   __pyx_tuple__13 = PyTuple_Pack(1, __pyx_kp_s_no_default___reduce___due_to_non); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(2, 4, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__13);
   __Pyx_GIVEREF(__pyx_tuple__13);
 
-  /* "View.MemoryView":418
+  /* "View.MemoryView":420
  *     def __setitem__(memoryview self, object index, object value):
  *         if self.view.readonly:
  *             raise TypeError("Cannot assign to read-only memoryview")             # <<<<<<<<<<<<<<
  * 
  *         have_slices, index = _unellipsify(index, self.view.ndim)
  */
-  __pyx_tuple__14 = PyTuple_Pack(1, __pyx_kp_s_Cannot_assign_to_read_only_memor); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(2, 418, __pyx_L1_error)
+  __pyx_tuple__14 = PyTuple_Pack(1, __pyx_kp_s_Cannot_assign_to_read_only_memor); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(2, 420, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__14);
   __Pyx_GIVEREF(__pyx_tuple__14);
 
-  /* "View.MemoryView":495
+  /* "View.MemoryView":497
  *             result = struct.unpack(self.view.format, bytesitem)
  *         except struct.error:
  *             raise ValueError("Unable to convert item to object")             # <<<<<<<<<<<<<<
  *         else:
  *             if len(self.view.format) == 1:
  */
-  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_s_Unable_to_convert_item_to_object); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(2, 495, __pyx_L1_error)
+  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_s_Unable_to_convert_item_to_object); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(2, 497, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__15);
   __Pyx_GIVEREF(__pyx_tuple__15);
 
-  /* "View.MemoryView":520
+  /* "View.MemoryView":522
  *     def __getbuffer__(self, Py_buffer *info, int flags):
  *         if flags & PyBUF_WRITABLE and self.view.readonly:
  *             raise ValueError("Cannot create writable memory view from read-only memoryview")             # <<<<<<<<<<<<<<
  * 
  *         if flags & PyBUF_ND:
  */
-  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_s_Cannot_create_writable_memory_vi); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(2, 520, __pyx_L1_error)
+  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_s_Cannot_create_writable_memory_vi); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(2, 522, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__16);
   __Pyx_GIVEREF(__pyx_tuple__16);
 
-  /* "View.MemoryView":570
+  /* "View.MemoryView":572
  *         if self.view.strides == NULL:
  * 
  *             raise ValueError("Buffer view does not expose strides")             # <<<<<<<<<<<<<<
  * 
  *         return tuple([stride for stride in self.view.strides[:self.view.ndim]])
  */
-  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_s_Buffer_view_does_not_expose_stri); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(2, 570, __pyx_L1_error)
+  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_s_Buffer_view_does_not_expose_stri); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(2, 572, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__17);
   __Pyx_GIVEREF(__pyx_tuple__17);
 
-  /* "View.MemoryView":577
+  /* "View.MemoryView":579
  *     def suboffsets(self):
  *         if self.view.suboffsets == NULL:
  *             return (-1,) * self.view.ndim             # <<<<<<<<<<<<<<
  * 
  *         return tuple([suboffset for suboffset in self.view.suboffsets[:self.view.ndim]])
  */
-  __pyx_tuple__18 = PyTuple_New(1); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(2, 577, __pyx_L1_error)
+  __pyx_tuple__18 = PyTuple_New(1); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(2, 579, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__18);
   __Pyx_INCREF(__pyx_int_neg_1);
   __Pyx_GIVEREF(__pyx_int_neg_1);
   PyTuple_SET_ITEM(__pyx_tuple__18, 0, __pyx_int_neg_1);
   __Pyx_GIVEREF(__pyx_tuple__18);
 
   /* "(tree fragment)":2
@@ -22416,22 +22509,22 @@
  * def __setstate_cython__(self, __pyx_state):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")             # <<<<<<<<<<<<<<
  */
   __pyx_tuple__20 = PyTuple_Pack(1, __pyx_kp_s_no_default___reduce___due_to_non); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(2, 4, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__20);
   __Pyx_GIVEREF(__pyx_tuple__20);
 
-  /* "View.MemoryView":703
+  /* "View.MemoryView":705
  *     for suboffset in suboffsets[:ndim]:
  *         if suboffset >= 0:
  *             raise ValueError("Indirect dimensions not supported")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_kp_s_Indirect_dimensions_not_supporte); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(2, 703, __pyx_L1_error)
+  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_kp_s_Indirect_dimensions_not_supporte); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(2, 705, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__21);
   __Pyx_GIVEREF(__pyx_tuple__21);
 
   /* "(tree fragment)":2
  * def __reduce_cython__(self):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")             # <<<<<<<<<<<<<<
  * def __setstate_cython__(self, __pyx_state):
@@ -22445,113 +22538,118 @@
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")
  * def __setstate_cython__(self, __pyx_state):
  *     raise TypeError("no default __reduce__ due to non-trivial __cinit__")             # <<<<<<<<<<<<<<
  */
   __pyx_tuple__23 = PyTuple_Pack(1, __pyx_kp_s_no_default___reduce___due_to_non); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(2, 4, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_tuple__23);
   __Pyx_GIVEREF(__pyx_tuple__23);
+  __pyx_tuple__24 = PyTuple_Pack(3, __pyx_int_184977713, __pyx_int_136983863, __pyx_int_112105877); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(2, 4, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__24);
+  __Pyx_GIVEREF(__pyx_tuple__24);
 
   /* "aesara/scan/scan_perform.pyx":64
  * 
  * 
  * def get_version():             # <<<<<<<<<<<<<<
  *     return 0.326
  * 
  */
-  __pyx_codeobj__24 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_scan_perform_pyx, __pyx_n_s_get_version, 64, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__24)) __PYX_ERR(0, 64, __pyx_L1_error)
+  __pyx_codeobj__25 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_scan_perform_pyx, __pyx_n_s_get_version, 64, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__25)) __PYX_ERR(0, 64, __pyx_L1_error)
 
   /* "aesara/scan/scan_perform.pyx":76
  * @cython.cdivision(True)
  * @cython.boundscheck(False)
  * def perform(             # <<<<<<<<<<<<<<
  *     const unsigned int n_shared_outs,
  *     const unsigned int n_mit_mot_outs,
  */
-  __pyx_tuple__25 = PyTuple_Pack(87, __pyx_n_s_n_shared_outs, __pyx_n_s_n_mit_mot_outs, __pyx_n_s_n_seqs, __pyx_n_s_n_mit_mot, __pyx_n_s_n_mit_sot, __pyx_n_s_n_sit_sot, __pyx_n_s_n_nit_sot, __pyx_n_s_as_while, __pyx_n_s_mintaps, __pyx_n_s_pos, __pyx_n_s_store_steps, __pyx_n_s_tap_array, __pyx_n_s_tap_array_len, __pyx_n_s_vector_seqs, __pyx_n_s_vector_outs, __pyx_n_s_mit_mot_out_slices, __pyx_n_s_mitmots_preallocated, __pyx_n_s_mit_mot_out_to_tap_idx, __pyx_n_s_outs_is_tensor, __pyx_n_s_inner_input_storage, __pyx_n_s_inner_output_storage, __pyx_n_s_destroy_map, __pyx_n_s_outer_inputs, __pyx_n_s_outer_outputs, __pyx_n_s_outer_output_dtypes, __pyx_n_s_outer_output_ndims, __pyx_n_s_fn, __pyx_n_s_t_fn, __pyx_n_s_t0_fn, __pyx_n_s_dt_fn, __pyx_n_s_n_steps, __pyx_n_s_n_outs, __pyx_n_s_seqs_arg_offset, __pyx_n_s_shared_arg_offset, __pyx_n_s_nit_sot_arg_offset, __pyx_n_s_offset_out, __pyx_n_s_lenpos, __pyx_n_s_l, __pyx_n_s_offset, __pyx_n_s_tap, __pyx_n_s_idx, __pyx_n_s_a_offset, __pyx_n_s_o_offset, __pyx_n_s_idx_2, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_k, __pyx_n_s_kdx, __pyx_n_s_tdx, __pyx_n_s_pdx, __pyx_n_s_jout, __pyx_n_s_begin, __pyx_n_s_end, __pyx_n_s_cond, __pyx_n_s_len_output_storage, __pyx_n_s_mitmot_inp_offset, __pyx_n_s_mitmot_out_idx, __pyx_n_s_inp_idx, __pyx_n_s_inner_inp_idx, __pyx_n_s_store_steps_j, __pyx_n_s_store_steps_idx, __pyx_n_s_mintaps_idx, __pyx_n_s_sh0, __pyx_n_s_pos_j, __pyx_n_s_pos_idx, __pyx_n_s_outer_outputs_idx, __pyx_n_s_outer_outputs_idx_0, __pyx_n_s_outer_inputs_offset_idx, __pyx_n_s_other_args, __pyx_n_s_nb_mitmot_in, __pyx_n_s_old_mitmot_input_storage, __pyx_n_s_old_mitmot_input_data, __pyx_n_s_old_output_storage, __pyx_n_s_old_output_data, __pyx_n_s_var, __pyx_n_s_exc, __pyx_n_s_outer_outputs_j_0, __pyx_n_s_old_var, __pyx_n_s_new_var, __pyx_n_s_outer_outputs_j, __pyx_n_s_old_data, __pyx_n_s_inner_output_storage_jout_0, __pyx_n_s_shape, __pyx_n_s_dtype, __pyx_n_s_new_outer_outputs_j_0, __pyx_n_s_tmp, __pyx_n_s_s); if (unlikely(!__pyx_tuple__25)) __PYX_ERR(0, 76, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__25);
-  __Pyx_GIVEREF(__pyx_tuple__25);
-  __pyx_codeobj__26 = (PyObject*)__Pyx_PyCode_New(27, 0, 87, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__25, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_scan_perform_pyx, __pyx_n_s_perform, 76, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__26)) __PYX_ERR(0, 76, __pyx_L1_error)
+  __pyx_tuple__26 = PyTuple_Pack(87, __pyx_n_s_n_shared_outs, __pyx_n_s_n_mit_mot_outs, __pyx_n_s_n_seqs, __pyx_n_s_n_mit_mot, __pyx_n_s_n_mit_sot, __pyx_n_s_n_sit_sot, __pyx_n_s_n_nit_sot, __pyx_n_s_as_while, __pyx_n_s_mintaps, __pyx_n_s_pos, __pyx_n_s_store_steps, __pyx_n_s_tap_array, __pyx_n_s_tap_array_len, __pyx_n_s_vector_seqs, __pyx_n_s_vector_outs, __pyx_n_s_mit_mot_out_slices, __pyx_n_s_mitmots_preallocated, __pyx_n_s_mit_mot_out_to_tap_idx, __pyx_n_s_outs_is_tensor, __pyx_n_s_inner_input_storage, __pyx_n_s_inner_output_storage, __pyx_n_s_destroy_map, __pyx_n_s_outer_inputs, __pyx_n_s_outer_outputs, __pyx_n_s_outer_output_dtypes, __pyx_n_s_outer_output_ndims, __pyx_n_s_fn, __pyx_n_s_t_fn, __pyx_n_s_t0_fn, __pyx_n_s_dt_fn, __pyx_n_s_n_steps, __pyx_n_s_n_outs, __pyx_n_s_seqs_arg_offset, __pyx_n_s_shared_arg_offset, __pyx_n_s_nit_sot_arg_offset, __pyx_n_s_offset_out, __pyx_n_s_lenpos, __pyx_n_s_l, __pyx_n_s_offset, __pyx_n_s_tap, __pyx_n_s_idx, __pyx_n_s_a_offset, __pyx_n_s_o_offset, __pyx_n_s_idx_2, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_k, __pyx_n_s_kdx, __pyx_n_s_tdx, __pyx_n_s_pdx, __pyx_n_s_jout, __pyx_n_s_begin, __pyx_n_s_end, __pyx_n_s_cond, __pyx_n_s_len_output_storage, __pyx_n_s_mitmot_inp_offset, __pyx_n_s_mitmot_out_idx, __pyx_n_s_inp_idx, __pyx_n_s_inner_inp_idx, __pyx_n_s_store_steps_j, __pyx_n_s_store_steps_idx, __pyx_n_s_mintaps_idx, __pyx_n_s_sh0, __pyx_n_s_pos_j, __pyx_n_s_pos_idx, __pyx_n_s_outer_outputs_idx, __pyx_n_s_outer_outputs_idx_0, __pyx_n_s_outer_inputs_offset_idx, __pyx_n_s_other_args, __pyx_n_s_nb_mitmot_in, __pyx_n_s_old_mitmot_input_storage, __pyx_n_s_old_mitmot_input_data, __pyx_n_s_old_output_storage, __pyx_n_s_old_output_data, __pyx_n_s_var, __pyx_n_s_exc, __pyx_n_s_outer_outputs_j_0, __pyx_n_s_old_var, __pyx_n_s_new_var, __pyx_n_s_outer_outputs_j, __pyx_n_s_old_data, __pyx_n_s_inner_output_storage_jout_0, __pyx_n_s_shape, __pyx_n_s_dtype, __pyx_n_s_new_outer_outputs_j_0, __pyx_n_s_tmp, __pyx_n_s_s); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 76, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__26);
+  __Pyx_GIVEREF(__pyx_tuple__26);
+  __pyx_codeobj__27 = (PyObject*)__Pyx_PyCode_New(27, 0, 87, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__26, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_scan_perform_pyx, __pyx_n_s_perform, 76, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__27)) __PYX_ERR(0, 76, __pyx_L1_error)
 
-  /* "View.MemoryView":286
+  /* "View.MemoryView":287
  *         return self.name
  * 
  * cdef generic = Enum("<strided and direct or indirect>")             # <<<<<<<<<<<<<<
  * cdef strided = Enum("<strided and direct>") # default
  * cdef indirect = Enum("<strided and indirect>")
  */
-  __pyx_tuple__27 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct_or_indirect); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(2, 286, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__27);
-  __Pyx_GIVEREF(__pyx_tuple__27);
+  __pyx_tuple__28 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct_or_indirect); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(2, 287, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__28);
+  __Pyx_GIVEREF(__pyx_tuple__28);
 
-  /* "View.MemoryView":287
+  /* "View.MemoryView":288
  * 
  * cdef generic = Enum("<strided and direct or indirect>")
  * cdef strided = Enum("<strided and direct>") # default             # <<<<<<<<<<<<<<
  * cdef indirect = Enum("<strided and indirect>")
  * 
  */
-  __pyx_tuple__28 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(2, 287, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__28);
-  __Pyx_GIVEREF(__pyx_tuple__28);
+  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_kp_s_strided_and_direct); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(2, 288, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__29);
+  __Pyx_GIVEREF(__pyx_tuple__29);
 
-  /* "View.MemoryView":288
+  /* "View.MemoryView":289
  * cdef generic = Enum("<strided and direct or indirect>")
  * cdef strided = Enum("<strided and direct>") # default
  * cdef indirect = Enum("<strided and indirect>")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_tuple__29 = PyTuple_Pack(1, __pyx_kp_s_strided_and_indirect); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(2, 288, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__29);
-  __Pyx_GIVEREF(__pyx_tuple__29);
+  __pyx_tuple__30 = PyTuple_Pack(1, __pyx_kp_s_strided_and_indirect); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(2, 289, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__30);
+  __Pyx_GIVEREF(__pyx_tuple__30);
 
-  /* "View.MemoryView":291
+  /* "View.MemoryView":292
  * 
  * 
  * cdef contiguous = Enum("<contiguous and direct>")             # <<<<<<<<<<<<<<
  * cdef indirect_contiguous = Enum("<contiguous and indirect>")
  * 
  */
-  __pyx_tuple__30 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_direct); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(2, 291, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__30);
-  __Pyx_GIVEREF(__pyx_tuple__30);
+  __pyx_tuple__31 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_direct); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(2, 292, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__31);
+  __Pyx_GIVEREF(__pyx_tuple__31);
 
-  /* "View.MemoryView":292
+  /* "View.MemoryView":293
  * 
  * cdef contiguous = Enum("<contiguous and direct>")
  * cdef indirect_contiguous = Enum("<contiguous and indirect>")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_tuple__31 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_indirect); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(2, 292, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__31);
-  __Pyx_GIVEREF(__pyx_tuple__31);
+  __pyx_tuple__32 = PyTuple_Pack(1, __pyx_kp_s_contiguous_and_indirect); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(2, 293, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__32);
+  __Pyx_GIVEREF(__pyx_tuple__32);
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_Enum(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
  */
-  __pyx_tuple__32 = PyTuple_Pack(5, __pyx_n_s_pyx_type, __pyx_n_s_pyx_checksum, __pyx_n_s_pyx_state, __pyx_n_s_pyx_PickleError, __pyx_n_s_pyx_result); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(2, 1, __pyx_L1_error)
-  __Pyx_GOTREF(__pyx_tuple__32);
-  __Pyx_GIVEREF(__pyx_tuple__32);
-  __pyx_codeobj__33 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__32, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle_Enum, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__33)) __PYX_ERR(2, 1, __pyx_L1_error)
+  __pyx_tuple__33 = PyTuple_Pack(5, __pyx_n_s_pyx_type, __pyx_n_s_pyx_checksum, __pyx_n_s_pyx_state, __pyx_n_s_pyx_PickleError, __pyx_n_s_pyx_result); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(2, 1, __pyx_L1_error)
+  __Pyx_GOTREF(__pyx_tuple__33);
+  __Pyx_GIVEREF(__pyx_tuple__33);
+  __pyx_codeobj__34 = (PyObject*)__Pyx_PyCode_New(3, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__33, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_stringsource, __pyx_n_s_pyx_unpickle_Enum, 1, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__34)) __PYX_ERR(2, 1, __pyx_L1_error)
   __Pyx_RefNannyFinishContext();
   return 0;
   __pyx_L1_error:;
   __Pyx_RefNannyFinishContext();
   return -1;
 }
 
 static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void) {
-  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
+  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_float_0_0 = PyFloat_FromDouble(0.0); if (unlikely(!__pyx_float_0_0)) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_float_0_326 = PyFloat_FromDouble(0.326); if (unlikely(!__pyx_float_0_326)) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
+  __pyx_int_112105877 = PyInt_FromLong(112105877L); if (unlikely(!__pyx_int_112105877)) __PYX_ERR(0, 1, __pyx_L1_error)
+  __pyx_int_136983863 = PyInt_FromLong(136983863L); if (unlikely(!__pyx_int_136983863)) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_int_184977713 = PyInt_FromLong(184977713L); if (unlikely(!__pyx_int_184977713)) __PYX_ERR(0, 1, __pyx_L1_error)
   __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(0, 1, __pyx_L1_error)
   return 0;
   __pyx_L1_error:;
   return -1;
 }
 
@@ -22597,62 +22695,62 @@
   int __pyx_lineno = 0;
   const char *__pyx_filename = NULL;
   int __pyx_clineno = 0;
   __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
   /*--- Type init code ---*/
   __pyx_vtabptr_array = &__pyx_vtable_array;
   __pyx_vtable_array.get_memview = (PyObject *(*)(struct __pyx_array_obj *))__pyx_array_get_memview;
-  if (PyType_Ready(&__pyx_type___pyx_array) < 0) __PYX_ERR(2, 105, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type___pyx_array) < 0) __PYX_ERR(2, 106, __pyx_L1_error)
   #if PY_VERSION_HEX < 0x030800B1
   __pyx_type___pyx_array.tp_print = 0;
   #endif
-  if (__Pyx_SetVtable(__pyx_type___pyx_array.tp_dict, __pyx_vtabptr_array) < 0) __PYX_ERR(2, 105, __pyx_L1_error)
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_array) < 0) __PYX_ERR(2, 105, __pyx_L1_error)
+  if (__Pyx_SetVtable(__pyx_type___pyx_array.tp_dict, __pyx_vtabptr_array) < 0) __PYX_ERR(2, 106, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_array) < 0) __PYX_ERR(2, 106, __pyx_L1_error)
   __pyx_array_type = &__pyx_type___pyx_array;
-  if (PyType_Ready(&__pyx_type___pyx_MemviewEnum) < 0) __PYX_ERR(2, 279, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type___pyx_MemviewEnum) < 0) __PYX_ERR(2, 280, __pyx_L1_error)
   #if PY_VERSION_HEX < 0x030800B1
   __pyx_type___pyx_MemviewEnum.tp_print = 0;
   #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type___pyx_MemviewEnum.tp_dictoffset && __pyx_type___pyx_MemviewEnum.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type___pyx_MemviewEnum.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_MemviewEnum) < 0) __PYX_ERR(2, 279, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_MemviewEnum) < 0) __PYX_ERR(2, 280, __pyx_L1_error)
   __pyx_MemviewEnum_type = &__pyx_type___pyx_MemviewEnum;
   __pyx_vtabptr_memoryview = &__pyx_vtable_memoryview;
   __pyx_vtable_memoryview.get_item_pointer = (char *(*)(struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_get_item_pointer;
   __pyx_vtable_memoryview.is_slice = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_is_slice;
   __pyx_vtable_memoryview.setitem_slice_assignment = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *, PyObject *))__pyx_memoryview_setitem_slice_assignment;
   __pyx_vtable_memoryview.setitem_slice_assign_scalar = (PyObject *(*)(struct __pyx_memoryview_obj *, struct __pyx_memoryview_obj *, PyObject *))__pyx_memoryview_setitem_slice_assign_scalar;
   __pyx_vtable_memoryview.setitem_indexed = (PyObject *(*)(struct __pyx_memoryview_obj *, PyObject *, PyObject *))__pyx_memoryview_setitem_indexed;
   __pyx_vtable_memoryview.convert_item_to_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *))__pyx_memoryview_convert_item_to_object;
   __pyx_vtable_memoryview.assign_item_from_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *, PyObject *))__pyx_memoryview_assign_item_from_object;
-  if (PyType_Ready(&__pyx_type___pyx_memoryview) < 0) __PYX_ERR(2, 330, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type___pyx_memoryview) < 0) __PYX_ERR(2, 331, __pyx_L1_error)
   #if PY_VERSION_HEX < 0x030800B1
   __pyx_type___pyx_memoryview.tp_print = 0;
   #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type___pyx_memoryview.tp_dictoffset && __pyx_type___pyx_memoryview.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type___pyx_memoryview.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
-  if (__Pyx_SetVtable(__pyx_type___pyx_memoryview.tp_dict, __pyx_vtabptr_memoryview) < 0) __PYX_ERR(2, 330, __pyx_L1_error)
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_memoryview) < 0) __PYX_ERR(2, 330, __pyx_L1_error)
+  if (__Pyx_SetVtable(__pyx_type___pyx_memoryview.tp_dict, __pyx_vtabptr_memoryview) < 0) __PYX_ERR(2, 331, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_memoryview) < 0) __PYX_ERR(2, 331, __pyx_L1_error)
   __pyx_memoryview_type = &__pyx_type___pyx_memoryview;
   __pyx_vtabptr__memoryviewslice = &__pyx_vtable__memoryviewslice;
   __pyx_vtable__memoryviewslice.__pyx_base = *__pyx_vtabptr_memoryview;
   __pyx_vtable__memoryviewslice.__pyx_base.convert_item_to_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *))__pyx_memoryviewslice_convert_item_to_object;
   __pyx_vtable__memoryviewslice.__pyx_base.assign_item_from_object = (PyObject *(*)(struct __pyx_memoryview_obj *, char *, PyObject *))__pyx_memoryviewslice_assign_item_from_object;
   __pyx_type___pyx_memoryviewslice.tp_base = __pyx_memoryview_type;
-  if (PyType_Ready(&__pyx_type___pyx_memoryviewslice) < 0) __PYX_ERR(2, 965, __pyx_L1_error)
+  if (PyType_Ready(&__pyx_type___pyx_memoryviewslice) < 0) __PYX_ERR(2, 967, __pyx_L1_error)
   #if PY_VERSION_HEX < 0x030800B1
   __pyx_type___pyx_memoryviewslice.tp_print = 0;
   #endif
   if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_type___pyx_memoryviewslice.tp_dictoffset && __pyx_type___pyx_memoryviewslice.tp_getattro == PyObject_GenericGetAttr)) {
     __pyx_type___pyx_memoryviewslice.tp_getattro = __Pyx_PyObject_GenericGetAttr;
   }
-  if (__Pyx_SetVtable(__pyx_type___pyx_memoryviewslice.tp_dict, __pyx_vtabptr__memoryviewslice) < 0) __PYX_ERR(2, 965, __pyx_L1_error)
-  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_memoryviewslice) < 0) __PYX_ERR(2, 965, __pyx_L1_error)
+  if (__Pyx_SetVtable(__pyx_type___pyx_memoryviewslice.tp_dict, __pyx_vtabptr__memoryviewslice) < 0) __PYX_ERR(2, 967, __pyx_L1_error)
+  if (__Pyx_setup_reduce((PyObject*)&__pyx_type___pyx_memoryviewslice) < 0) __PYX_ERR(2, 967, __pyx_L1_error)
   __pyx_memoryviewslice_type = &__pyx_type___pyx_memoryviewslice;
   __Pyx_RefNannyFinishContext();
   return 0;
   __pyx_L1_error:;
   __Pyx_RefNannyFinishContext();
   return -1;
 }
@@ -22672,46 +22770,46 @@
   sizeof(PyTypeObject),
   #else
   sizeof(PyHeapTypeObject),
   #endif
   __Pyx_ImportType_CheckSize_Warn);
    if (!__pyx_ptype_7cpython_4type_type) __PYX_ERR(3, 9, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
-  __pyx_t_1 = PyImport_ImportModule("numpy"); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 200, __pyx_L1_error)
+  __pyx_t_1 = PyImport_ImportModule("numpy"); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 199, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_1);
   __pyx_ptype_5numpy_dtype = __Pyx_ImportType(__pyx_t_1, "numpy", "dtype", sizeof(PyArray_Descr), __Pyx_ImportType_CheckSize_Ignore);
-   if (!__pyx_ptype_5numpy_dtype) __PYX_ERR(1, 200, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_dtype) __PYX_ERR(1, 199, __pyx_L1_error)
   __pyx_ptype_5numpy_flatiter = __Pyx_ImportType(__pyx_t_1, "numpy", "flatiter", sizeof(PyArrayIterObject), __Pyx_ImportType_CheckSize_Ignore);
-   if (!__pyx_ptype_5numpy_flatiter) __PYX_ERR(1, 223, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_flatiter) __PYX_ERR(1, 222, __pyx_L1_error)
   __pyx_ptype_5numpy_broadcast = __Pyx_ImportType(__pyx_t_1, "numpy", "broadcast", sizeof(PyArrayMultiIterObject), __Pyx_ImportType_CheckSize_Ignore);
-   if (!__pyx_ptype_5numpy_broadcast) __PYX_ERR(1, 227, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_broadcast) __PYX_ERR(1, 226, __pyx_L1_error)
   __pyx_ptype_5numpy_ndarray = __Pyx_ImportType(__pyx_t_1, "numpy", "ndarray", sizeof(PyArrayObject), __Pyx_ImportType_CheckSize_Ignore);
-   if (!__pyx_ptype_5numpy_ndarray) __PYX_ERR(1, 239, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_ndarray) __PYX_ERR(1, 238, __pyx_L1_error)
   __pyx_ptype_5numpy_generic = __Pyx_ImportType(__pyx_t_1, "numpy", "generic", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_generic) __PYX_ERR(1, 771, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_generic) __PYX_ERR(1, 770, __pyx_L1_error)
   __pyx_ptype_5numpy_number = __Pyx_ImportType(__pyx_t_1, "numpy", "number", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_number) __PYX_ERR(1, 773, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_number) __PYX_ERR(1, 772, __pyx_L1_error)
   __pyx_ptype_5numpy_integer = __Pyx_ImportType(__pyx_t_1, "numpy", "integer", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_integer) __PYX_ERR(1, 775, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_integer) __PYX_ERR(1, 774, __pyx_L1_error)
   __pyx_ptype_5numpy_signedinteger = __Pyx_ImportType(__pyx_t_1, "numpy", "signedinteger", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_signedinteger) __PYX_ERR(1, 777, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_signedinteger) __PYX_ERR(1, 776, __pyx_L1_error)
   __pyx_ptype_5numpy_unsignedinteger = __Pyx_ImportType(__pyx_t_1, "numpy", "unsignedinteger", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_unsignedinteger) __PYX_ERR(1, 779, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_unsignedinteger) __PYX_ERR(1, 778, __pyx_L1_error)
   __pyx_ptype_5numpy_inexact = __Pyx_ImportType(__pyx_t_1, "numpy", "inexact", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_inexact) __PYX_ERR(1, 781, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_inexact) __PYX_ERR(1, 780, __pyx_L1_error)
   __pyx_ptype_5numpy_floating = __Pyx_ImportType(__pyx_t_1, "numpy", "floating", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_floating) __PYX_ERR(1, 783, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_floating) __PYX_ERR(1, 782, __pyx_L1_error)
   __pyx_ptype_5numpy_complexfloating = __Pyx_ImportType(__pyx_t_1, "numpy", "complexfloating", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_complexfloating) __PYX_ERR(1, 785, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_complexfloating) __PYX_ERR(1, 784, __pyx_L1_error)
   __pyx_ptype_5numpy_flexible = __Pyx_ImportType(__pyx_t_1, "numpy", "flexible", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_flexible) __PYX_ERR(1, 787, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_flexible) __PYX_ERR(1, 786, __pyx_L1_error)
   __pyx_ptype_5numpy_character = __Pyx_ImportType(__pyx_t_1, "numpy", "character", sizeof(PyObject), __Pyx_ImportType_CheckSize_Warn);
-   if (!__pyx_ptype_5numpy_character) __PYX_ERR(1, 789, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_character) __PYX_ERR(1, 788, __pyx_L1_error)
   __pyx_ptype_5numpy_ufunc = __Pyx_ImportType(__pyx_t_1, "numpy", "ufunc", sizeof(PyUFuncObject), __Pyx_ImportType_CheckSize_Ignore);
-   if (!__pyx_ptype_5numpy_ufunc) __PYX_ERR(1, 827, __pyx_L1_error)
+   if (!__pyx_ptype_5numpy_ufunc) __PYX_ERR(1, 826, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
   __Pyx_RefNannyFinishContext();
   return 0;
   __pyx_L1_error:;
   __Pyx_XDECREF(__pyx_t_1);
   __Pyx_RefNannyFinishContext();
   return -1;
@@ -22898,15 +22996,15 @@
   #endif
   __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_d);
   __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_b);
   __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
   Py_INCREF(__pyx_cython_runtime);
-  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
+  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   /*--- Initialize various global constants etc. ---*/
   if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
   if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   #endif
   if (__pyx_module_is_main_aesara__scan__scan_perform) {
     if (PyObject_SetAttr(__pyx_m, __pyx_n_s_name_2, __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
@@ -23020,107 +23118,107 @@
  *  This code implements the operations that scan has to carry on when called
  */
   __pyx_t_2 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_2) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
 
-  /* "View.MemoryView":209
+  /* "View.MemoryView":210
  *         info.obj = self
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_array_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
  * 
  *     def __dealloc__(array self):
  */
-  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_array_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 209, __pyx_L1_error)
+  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_array_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 210, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  if (PyDict_SetItem((PyObject *)__pyx_array_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 209, __pyx_L1_error)
+  if (PyDict_SetItem((PyObject *)__pyx_array_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 210, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   PyType_Modified(__pyx_array_type);
 
-  /* "View.MemoryView":286
+  /* "View.MemoryView":287
  *         return self.name
  * 
  * cdef generic = Enum("<strided and direct or indirect>")             # <<<<<<<<<<<<<<
  * cdef strided = Enum("<strided and direct>") # default
  * cdef indirect = Enum("<strided and indirect>")
  */
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 286, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 287, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_XGOTREF(generic);
   __Pyx_DECREF_SET(generic, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":287
+  /* "View.MemoryView":288
  * 
  * cdef generic = Enum("<strided and direct or indirect>")
  * cdef strided = Enum("<strided and direct>") # default             # <<<<<<<<<<<<<<
  * cdef indirect = Enum("<strided and indirect>")
  * 
  */
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__28, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 287, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__29, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 288, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_XGOTREF(strided);
   __Pyx_DECREF_SET(strided, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":288
+  /* "View.MemoryView":289
  * cdef generic = Enum("<strided and direct or indirect>")
  * cdef strided = Enum("<strided and direct>") # default
  * cdef indirect = Enum("<strided and indirect>")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__29, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 288, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__30, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 289, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_XGOTREF(indirect);
   __Pyx_DECREF_SET(indirect, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":291
+  /* "View.MemoryView":292
  * 
  * 
  * cdef contiguous = Enum("<contiguous and direct>")             # <<<<<<<<<<<<<<
  * cdef indirect_contiguous = Enum("<contiguous and indirect>")
  * 
  */
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__30, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 291, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 292, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_XGOTREF(contiguous);
   __Pyx_DECREF_SET(contiguous, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":292
+  /* "View.MemoryView":293
  * 
  * cdef contiguous = Enum("<contiguous and direct>")
  * cdef indirect_contiguous = Enum("<contiguous and indirect>")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__31, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 292, __pyx_L1_error)
+  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)__pyx_MemviewEnum_type), __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 293, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
   __Pyx_XGOTREF(indirect_contiguous);
   __Pyx_DECREF_SET(indirect_contiguous, __pyx_t_2);
   __Pyx_GIVEREF(__pyx_t_2);
   __pyx_t_2 = 0;
 
-  /* "View.MemoryView":316
+  /* "View.MemoryView":317
  * 
  * DEF THREAD_LOCKS_PREALLOCATED = 8
  * cdef int __pyx_memoryview_thread_locks_used = 0             # <<<<<<<<<<<<<<
  * cdef PyThread_type_lock[THREAD_LOCKS_PREALLOCATED] __pyx_memoryview_thread_locks = [
  *     PyThread_allocate_lock(),
  */
   __pyx_memoryview_thread_locks_used = 0;
 
-  /* "View.MemoryView":317
+  /* "View.MemoryView":318
  * DEF THREAD_LOCKS_PREALLOCATED = 8
  * cdef int __pyx_memoryview_thread_locks_used = 0
  * cdef PyThread_type_lock[THREAD_LOCKS_PREALLOCATED] __pyx_memoryview_thread_locks = [             # <<<<<<<<<<<<<<
  *     PyThread_allocate_lock(),
  *     PyThread_allocate_lock(),
  */
   __pyx_t_4[0] = PyThread_allocate_lock();
@@ -23129,37 +23227,37 @@
   __pyx_t_4[3] = PyThread_allocate_lock();
   __pyx_t_4[4] = PyThread_allocate_lock();
   __pyx_t_4[5] = PyThread_allocate_lock();
   __pyx_t_4[6] = PyThread_allocate_lock();
   __pyx_t_4[7] = PyThread_allocate_lock();
   memcpy(&(__pyx_memoryview_thread_locks[0]), __pyx_t_4, sizeof(__pyx_memoryview_thread_locks[0]) * (8));
 
-  /* "View.MemoryView":549
+  /* "View.MemoryView":551
  *         info.obj = self
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 549, __pyx_L1_error)
+  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 551, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  if (PyDict_SetItem((PyObject *)__pyx_memoryview_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 549, __pyx_L1_error)
+  if (PyDict_SetItem((PyObject *)__pyx_memoryview_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 551, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   PyType_Modified(__pyx_memoryview_type);
 
-  /* "View.MemoryView":995
+  /* "View.MemoryView":997
  *         return self.from_object
  * 
  *     __pyx_getbuffer = capsule(<void *> &__pyx_memoryview_getbuffer, "getbuffer(obj, view, flags)")             # <<<<<<<<<<<<<<
  * 
  * 
  */
-  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 995, __pyx_L1_error)
+  __pyx_t_2 = __pyx_capsule_create(((void *)(&__pyx_memoryview_getbuffer)), ((char *)"getbuffer(obj, view, flags)")); if (unlikely(!__pyx_t_2)) __PYX_ERR(2, 997, __pyx_L1_error)
   __Pyx_GOTREF(__pyx_t_2);
-  if (PyDict_SetItem((PyObject *)__pyx_memoryviewslice_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 995, __pyx_L1_error)
+  if (PyDict_SetItem((PyObject *)__pyx_memoryviewslice_type->tp_dict, __pyx_n_s_pyx_getbuffer, __pyx_t_2) < 0) __PYX_ERR(2, 997, __pyx_L1_error)
   __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
   PyType_Modified(__pyx_memoryviewslice_type);
 
   /* "(tree fragment)":1
  * def __pyx_unpickle_Enum(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
  *     cdef object __pyx_PickleError
  *     cdef object __pyx_result
@@ -23574,15 +23672,15 @@
 #if CYTHON_COMPILING_IN_CPYTHON
 static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
 #if CYTHON_FAST_PYCALL
     if (PyFunction_Check(func)) {
         return __Pyx_PyFunction_FastCall(func, NULL, 0);
     }
 #endif
-#ifdef __Pyx_CyFunction_USED
+#if defined(__Pyx_CyFunction_USED) && defined(NDEBUG)
     if (likely(PyCFunction_Check(func) || __Pyx_CyFunction_Check(func)))
 #else
     if (likely(PyCFunction_Check(func)))
 #endif
     {
         if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
             return __Pyx_PyObject_CallMethO(func, NULL);
@@ -23990,15 +24088,15 @@
         uval = NULL;
         if (uoffset > 0) {
             prepend_sign = !!prepend_sign;
             if (uoffset > prepend_sign) {
                 padding = PyUnicode_FromOrdinal(padding_char);
                 if (likely(padding) && uoffset > prepend_sign + 1) {
                     PyObject *tmp;
-                    PyObject *repeat = PyInt_FromSize_t(uoffset - prepend_sign);
+                    PyObject *repeat = PyInt_FromSsize_t(uoffset - prepend_sign);
                     if (unlikely(!repeat)) goto done_or_error;
                     tmp = PyNumber_Multiply(padding, repeat);
                     Py_DECREF(repeat);
                     Py_DECREF(padding);
                     padding = tmp;
                 }
                 if (unlikely(!padding)) goto done_or_error;
@@ -24885,15 +24983,15 @@
 }
 #ifndef Py_NO_RETURN
 #define Py_NO_RETURN
 #endif
 static void __pyx_fatalerror(const char *fmt, ...) Py_NO_RETURN {
     va_list vargs;
     char msg[200];
-#ifdef HAVE_STDARG_PROTOTYPES
+#if PY_VERSION_HEX >= 0x030A0000 || defined(HAVE_STDARG_PROTOTYPES)
     va_start(vargs, fmt);
 #else
     va_start(vargs);
 #endif
     vsnprintf(msg, 200, fmt, vargs);
     va_end(vargs);
     Py_FatalError(msg);
@@ -24981,15 +25079,15 @@
         ps2 = PyBytes_AS_STRING(s2);
         if (ps1[0] != ps2[0]) {
             return (equals == Py_NE);
         } else if (length == 1) {
             return (equals == Py_EQ);
         } else {
             int result;
-#if CYTHON_USE_UNICODE_INTERNALS
+#if CYTHON_USE_UNICODE_INTERNALS && (PY_VERSION_HEX < 0x030B0000)
             Py_hash_t hash1, hash2;
             hash1 = ((PyBytesObject*)s1)->ob_shash;
             hash2 = ((PyBytesObject*)s2)->ob_shash;
             if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                 return (equals == Py_NE);
             }
 #endif
@@ -25134,15 +25232,15 @@
 #endif
     return PyObject_GetAttr(o, n);
 }
 
 /* ObjectGetItem */
 #if CYTHON_USE_TYPE_SLOTS
 static PyObject *__Pyx_PyObject_GetIndex(PyObject *obj, PyObject* index) {
-    PyObject *runerr;
+    PyObject *runerr = NULL;
     Py_ssize_t key_value;
     PySequenceMethods *m = Py_TYPE(obj)->tp_as_sequence;
     if (unlikely(!(m && m->sq_item))) {
         PyErr_Format(PyExc_TypeError, "'%.200s' object is not subscriptable", Py_TYPE(obj)->tp_name);
         return NULL;
     }
     key_value = __Pyx_PyIndex_AsSsize_t(index);
@@ -25683,25 +25781,43 @@
   }
   Py_XDECREF(name_attr);
   return ret;
 }
 static int __Pyx_setup_reduce(PyObject* type_obj) {
     int ret = 0;
     PyObject *object_reduce = NULL;
+    PyObject *object_getstate = NULL;
     PyObject *object_reduce_ex = NULL;
     PyObject *reduce = NULL;
     PyObject *reduce_ex = NULL;
     PyObject *reduce_cython = NULL;
     PyObject *setstate = NULL;
     PyObject *setstate_cython = NULL;
+    PyObject *getstate = NULL;
 #if CYTHON_USE_PYTYPE_LOOKUP
-    if (_PyType_Lookup((PyTypeObject*)type_obj, __pyx_n_s_getstate)) goto __PYX_GOOD;
+    getstate = _PyType_Lookup((PyTypeObject*)type_obj, __pyx_n_s_getstate);
 #else
-    if (PyObject_HasAttr(type_obj, __pyx_n_s_getstate)) goto __PYX_GOOD;
+    getstate = __Pyx_PyObject_GetAttrStrNoError(type_obj, __pyx_n_s_getstate);
+    if (!getstate && PyErr_Occurred()) {
+        goto __PYX_BAD;
+    }
 #endif
+    if (getstate) {
+#if CYTHON_USE_PYTYPE_LOOKUP
+        object_getstate = _PyType_Lookup(&PyBaseObject_Type, __pyx_n_s_getstate);
+#else
+        object_getstate = __Pyx_PyObject_GetAttrStrNoError((PyObject*)&PyBaseObject_Type, __pyx_n_s_getstate);
+        if (!object_getstate && PyErr_Occurred()) {
+            goto __PYX_BAD;
+        }
+#endif
+        if (object_getstate != getstate) {
+            goto __PYX_GOOD;
+        }
+    }
 #if CYTHON_USE_PYTYPE_LOOKUP
     object_reduce_ex = _PyType_Lookup(&PyBaseObject_Type, __pyx_n_s_reduce_ex); if (!object_reduce_ex) goto __PYX_BAD;
 #else
     object_reduce_ex = __Pyx_PyObject_GetAttrStr((PyObject*)&PyBaseObject_Type, __pyx_n_s_reduce_ex); if (!object_reduce_ex) goto __PYX_BAD;
 #endif
     reduce_ex = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_n_s_reduce_ex); if (unlikely(!reduce_ex)) goto __PYX_BAD;
     if (reduce_ex == object_reduce_ex) {
@@ -25738,14 +25854,16 @@
     if (!PyErr_Occurred())
         PyErr_Format(PyExc_RuntimeError, "Unable to initialize pickling for %s", ((PyTypeObject*)type_obj)->tp_name);
     ret = -1;
 __PYX_GOOD:
 #if !CYTHON_USE_PYTYPE_LOOKUP
     Py_XDECREF(object_reduce);
     Py_XDECREF(object_reduce_ex);
+    Py_XDECREF(object_getstate);
+    Py_XDECREF(getstate);
 #endif
     Py_XDECREF(reduce);
     Py_XDECREF(reduce_ex);
     Py_XDECREF(reduce_cython);
     Py_XDECREF(setstate);
     Py_XDECREF(setstate_cython);
     return ret;
@@ -25810,15 +25928,15 @@
     Py_XDECREF(result);
     return NULL;
 }
 #endif
 
 /* CLineInTraceback */
 #ifndef CYTHON_CLINE_IN_TRACEBACK
-static int __Pyx_CLineForTraceback(CYTHON_NCP_UNUSED PyThreadState *tstate, int c_line) {
+static int __Pyx_CLineForTraceback(CYTHON_UNUSED PyThreadState *tstate, int c_line) {
     PyObject *use_cline;
     PyObject *ptype, *pvalue, *ptraceback;
 #if CYTHON_COMPILING_IN_CPYTHON
     PyObject **cython_runtime_dict;
 #endif
     if (unlikely(!__pyx_cython_runtime)) {
         return c_line;
@@ -25934,14 +26052,20 @@
     Py_INCREF(code_object);
 }
 
 /* AddTraceback */
 #include "compile.h"
 #include "frameobject.h"
 #include "traceback.h"
+#if PY_VERSION_HEX >= 0x030b00a6
+  #ifndef Py_BUILD_CORE
+    #define Py_BUILD_CORE 1
+  #endif
+  #include "internal/pycore_frame.h"
+#endif
 static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
             const char *funcname, int c_line,
             int py_line, const char *filename) {
     PyCodeObject *py_code = NULL;
     PyObject *py_funcname = NULL;
     #if PY_MAJOR_VERSION < 3
     PyObject *py_srcfile = NULL;
@@ -25997,22 +26121,32 @@
     return NULL;
 }
 static void __Pyx_AddTraceback(const char *funcname, int c_line,
                                int py_line, const char *filename) {
     PyCodeObject *py_code = 0;
     PyFrameObject *py_frame = 0;
     PyThreadState *tstate = __Pyx_PyThreadState_Current;
+    PyObject *ptype, *pvalue, *ptraceback;
     if (c_line) {
         c_line = __Pyx_CLineForTraceback(tstate, c_line);
     }
     py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
     if (!py_code) {
+        __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
         py_code = __Pyx_CreateCodeObjectForTraceback(
             funcname, c_line, py_line, filename);
-        if (!py_code) goto bad;
+        if (!py_code) {
+            /* If the code object creation fails, then we should clear the
+               fetched exception references and propagate the new exception */
+            Py_XDECREF(ptype);
+            Py_XDECREF(pvalue);
+            Py_XDECREF(ptraceback);
+            goto bad;
+        }
+        __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
         __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
     }
     py_frame = PyFrame_New(
         tstate,            /*PyThreadState *tstate,*/
         py_code,           /*PyCodeObject *code,*/
         __pyx_d,    /*PyObject *globals,*/
         0                  /*PyObject *locals*/
@@ -27092,15 +27226,15 @@
                         z = __Pyx_c_prod_float(a, a);
                         return __Pyx_c_prod_float(z, z);
                 }
             }
             if (a.imag == 0) {
                 if (a.real == 0) {
                     return a;
-                } else if (b.imag == 0) {
+                } else if ((b.imag == 0) && (a.real >= 0)) {
                     z.real = powf(a.real, b.real);
                     z.imag = 0;
                     return z;
                 } else if (a.real > 0) {
                     r = a.real;
                     theta = 0;
                 } else {
@@ -27246,15 +27380,15 @@
                         z = __Pyx_c_prod_double(a, a);
                         return __Pyx_c_prod_double(z, z);
                 }
             }
             if (a.imag == 0) {
                 if (a.real == 0) {
                     return a;
-                } else if (b.imag == 0) {
+                } else if ((b.imag == 0) && (a.real >= 0)) {
                     z.real = pow(a.real, b.real);
                     z.imag = 0;
                     return z;
                 } else if (a.real > 0) {
                     r = a.real;
                     theta = 0;
                 } else {
@@ -28276,19 +28410,41 @@
     PyErr_SetString(PyExc_OverflowError,
         "can't convert negative value to char");
     return (char) -1;
 }
 
 /* CheckBinaryVersion */
   static int __Pyx_check_binary_version(void) {
-    char ctversion[4], rtversion[4];
-    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
-    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
-    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
+    char ctversion[5];
+    int same=1, i, found_dot;
+    const char* rt_from_call = Py_GetVersion();
+    PyOS_snprintf(ctversion, 5, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
+    found_dot = 0;
+    for (i = 0; i < 4; i++) {
+        if (!ctversion[i]) {
+            same = (rt_from_call[i] < '0' || rt_from_call[i] > '9');
+            break;
+        }
+        if (rt_from_call[i] != ctversion[i]) {
+            same = 0;
+            break;
+        }
+    }
+    if (!same) {
+        char rtversion[5] = {'\0'};
         char message[200];
+        for (i=0; i<4; ++i) {
+            if (rt_from_call[i] == '.') {
+                if (found_dot) break;
+                found_dot = 1;
+            } else if (rt_from_call[i] < '0' || rt_from_call[i] > '9') {
+                break;
+            }
+            rtversion[i] = rt_from_call[i];
+        }
         PyOS_snprintf(message, sizeof(message),
                       "compiletime version %s of module '%.100s' "
                       "does not match runtime version %s",
                       ctversion, __Pyx_MODULE_NAME, rtversion);
         return PyErr_WarnEx(NULL, message, 1);
     }
     return 0;
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/checkpoints.py` & `aesara_nightly-2.9.0.post2/aesara/scan/checkpoints.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/op.py` & `aesara_nightly-2.9.0.post2/aesara/scan/op.py`

 * *Files 0% similar despite different names*

```diff
@@ -567,21 +567,20 @@
             "inner_out_from_inner_inp": {},
             "outer_out_from_inner_inp": {},
             "outer_inp_from_inner_out": {},
             "inner_inp_from_inner_out": {},
             "outer_out_from_inner_out": {},
         }
 
-        for (oinp, iinp, iout, oout) in zip(
+        for oinp, iinp, iout, oout in zip(
             outer_input_indices,
             inner_input_indices,
             inner_output_indices,
             outer_output_indices,
         ):
-
             if oout != -1:
                 mappings["outer_inp_from_outer_out"][oout] = oinp
                 mappings["inner_inp_from_outer_out"][oout] = iinp
                 mappings["inner_out_from_outer_out"][oout] = iout
 
             if oinp != -1:
                 mappings["inner_inp_from_outer_inp"][oinp] = iinp
@@ -611,20 +610,18 @@
         # inputs and output and ensure that they have the same dtype
         nb_recurr_outputs = (
             self.info.n_mit_mot + self.info.n_mit_sot + self.info.n_sit_sot
         )
         var_mappings = self.get_oinp_iinp_iout_oout_mappings()
 
         for outer_oidx in range(nb_recurr_outputs):
-
             inner_iidxs = var_mappings["inner_inp_from_outer_out"][outer_oidx]
             inner_oidxs = var_mappings["inner_out_from_outer_out"][outer_oidx]
 
-            for (inner_iidx, inner_oidx) in product(inner_iidxs, inner_oidxs):
-
+            for inner_iidx, inner_oidx in product(inner_iidxs, inner_oidxs):
                 type_input = self.inner_inputs[inner_iidx].type
                 type_output = self.inner_outputs[inner_oidx].type
                 if (
                     # TODO: Use the `Type` interface for this
                     type_input.dtype != type_output.dtype
                     or type_input.broadcastable != type_output.broadcastable
                 ):
@@ -746,15 +743,17 @@
             speed up allocation of the subsequent iterations. All those temporary
             allocations are freed at the end of all iterations; this is what the
             flag `aesara.config.allow_gc` means.
         strict
             If ``True``, all the shared variables used in the inner-graph must be provided.
 
         """
-        self.fgraph, shared_inputs, _, _ = construct_nominal_fgraph(inputs, outputs)
+        self.fgraph, shared_inputs = construct_nominal_fgraph(inputs, outputs)
+
+        assert not self.fgraph.update_mapping
 
         # The shared variables should have been removed, so, if there are
         # any, it's because the user didn't specify an input.
         if shared_inputs:
             raise MissingInputError(f"Scan is missing inputs: {shared_inputs}")
 
         self.info = info
@@ -1193,18 +1192,16 @@
         for inner_nonseq, _outer_nonseq in zip(
             self.inner_non_seqs(self.inner_inputs), self.outer_non_seqs(inputs)
         ):
             outer_nonseq = copy_var_format(_outer_nonseq, as_var=inner_nonseq)
             new_inputs.append(outer_nonseq)
             if not outer_nonseq.type.in_same_class(inner_nonseq.type):
                 raise ValueError(
-                    (
-                        f"Argument {outer_nonseq} given to the scan node is not"
-                        f" compatible with its corresponding loop function variable {inner_nonseq}"
-                    )
+                    f"Argument {outer_nonseq} given to the scan node is not"
+                    f" compatible with its corresponding loop function variable {inner_nonseq}"
                 )
 
         for outer_nitsot in self.outer_nitsot(inputs):
             # For every nit_sot input we get as input a int/uint that
             # depicts the size in memory for that sequence. This feature is
             # used by truncated BPTT and by scan space optimization
             if (
@@ -1336,15 +1333,14 @@
         # remove those outputs here just to compensate for an overly rigid
         # `Function` pipeline.
         update_mapping = {}
 
         preallocated_mitmot_outs = []
 
         if config.scan__allow_output_prealloc:
-
             # Go through the mitmots. Whenever a mitmot has a tap both as an
             # input and an output, wrap the input such that the corresponding
             # output variable becomes an update to be performed on it, possibly
             # inplace at the end of the functions's execution.
             wrapped_inputs = [In(x, borrow=False) for x in fgraph.inputs[: info.n_seqs]]
 
             input_idx = info.n_seqs
@@ -1582,15 +1578,14 @@
             #     thunk_capsule = c_thunk.cthunk
             #     # We need to perform the following after calling
             #     # the thunk function:
             #     # for o in node.outputs:
             #     #     compute_map[o][0] = True
 
             def p(node, inputs, outputs):
-
                 t0_call = time.perf_counter()
 
                 try:
                     t_fn, n_steps = scan_perform_ext.perform(
                         self.info.n_shared_outs,
                         self.info.n_mit_mot_outs,
                         self.info.n_seqs,
@@ -1887,15 +1882,14 @@
             # 4.5. Keep a reference to the variables (ndarrays,
             # etc) currently in the output_storage to be able to compare them
             # with the actual outputs of the inner function after its
             # execution. Also keep pointers to their data to be able to detect
             # cases where outputs reused the allocated object but alter the
             # memory region they refer to.
             for idx in range(len(inner_output_storage)):
-
                 var = inner_output_storage[idx].storage[0]
                 old_inner_output_storage[idx] = var
 
                 if var is None:
                     old_inner_output_data[idx] = None
                 elif isinstance(self.fn.maker.fgraph.outputs[idx], TensorVariable):
                     old_inner_output_data[idx] = var.data
@@ -1959,15 +1953,14 @@
 
             # 5.3 Copy over the values for mit_mot outputs
             mitmot_inp_grp_offset = 0
             mitmot_out_idx = 0
             for mitmot_grp_idx, taps in enumerate(info.mit_mot_in_slices):
                 for out_slice in info.mit_mot_out_slices[mitmot_grp_idx]:
                     if self.mitmots_preallocated[mitmot_out_idx]:
-
                         mitmot_inp_idx = mitmot_inp_grp_offset + taps.index(out_slice)
                         inner_inp_idx = info.n_seqs + mitmot_inp_idx
 
                         # Verify whether the input points to the same data as
                         # it did before the execution of the inner function.
                         old_var = old_mitmot_input_storage[mitmot_inp_idx]
                         new_var = inner_input_storage[inner_inp_idx].storage[0]
@@ -1999,15 +1992,14 @@
 
             # 5.4 Copy over the values for mit_sot/sit_sot outputs
             begin = info.n_mit_mot
             end = self.n_outs
             offset_out -= info.n_mit_mot
 
             for j in range(begin, end):
-
                 # Copy the output value to `outs`, if necessary
                 if store_steps[j] == 1 or self.vector_outs[j]:
                     output_storage[j][0][pos[j]] = inner_output_storage[
                         offset_out + j
                     ].storage[0]
                 else:
                     # Check whether the initialization of the output storage
@@ -2048,15 +2040,14 @@
                             )
                             raise ne from e
 
             # 5.5 Copy over the values for nit_sot outputs
             begin = end
             end += info.n_nit_sot
             for j in range(begin, end):
-
                 if i == 0:
                     jout = j + offset_out
                     shape = (store_steps[j],) + inner_output_storage[jout].storage[
                         0
                     ].shape
                     dtype = inner_output_storage[jout].storage[0].dtype
                     if (
@@ -2112,15 +2103,14 @@
             i = i + 1
 
         # 6. Check if you need to re-order output buffers
         begin = info.n_mit_mot
         end = self.n_outs + info.n_nit_sot
         for idx in range(begin, end):
             if store_steps[idx] < i - self.mintaps[idx] and pos[idx] < store_steps[idx]:
-
                 pdx = pos[idx]
                 if pdx >= store_steps[idx] // 2:
                     # It seems inefficient to copy the bigger part of the
                     # array over, and back, but it is the only way that
                     # there is no overlap in the areas of out[idx][0] that
                     # are read and written.
                     # This way, there will be no information overwritten
@@ -2324,15 +2314,14 @@
                 if x is None:
                     scan_outs.append(None)
                 else:
                     scan_outs.append((Shape_i(0)(o),) + x[1:])
         return scan_outs
 
     def connection_pattern(self, node):
-
         # We cache the result of this function because, with a previous
         # implementation that repeatedly called grad, there were cases
         # where calls to aesara.grad() took as much as 4h for functions
         # containing many nested scans.
         if hasattr(node.tag, "connection_pattern"):
             return node.tag.connection_pattern
 
@@ -2354,15 +2343,14 @@
             inner_oidxs = var_mappings["inner_out_from_outer_out"][outer_oidx]
 
             for outer_iidx in range(len(node.inputs)):
                 inner_iidxs = var_mappings["inner_inp_from_outer_inp"][outer_iidx]
 
                 for inner_oidx in inner_oidxs:
                     for inner_iidx in inner_iidxs:
-
                         if inner_connect_pattern[inner_iidx][inner_oidx]:
                             connection_pattern[outer_iidx][outer_oidx] = True
                             break
 
                     if connection_pattern[outer_iidx][outer_oidx]:
                         break
 
@@ -2371,15 +2359,14 @@
         # input to `z_t` then `x` is an input to `z_t`.
 
         n_outs = len(node.outputs)
 
         for steps in range(n_outs):
             for iidx in range(n_outs):
                 for jidx in range(n_outs):
-
                     # Get the idx of the outer input corresponding to that
                     # outer output
                     j_inp_idx = var_mappings["outer_inp_from_outer_out"][jidx]
 
                     if j_inp_idx != -1:
                         if connection_pattern[j_inp_idx][iidx] is True:
                             for k in range(len(connection_pattern)):
@@ -2523,15 +2510,14 @@
 
         var_mappings = self.get_oinp_iinp_iout_oout_mappings()
         dC_dinps_t = [None for inp in diff_inputs]
         disconnected_dC_dinps_t = [True for inp in diff_inputs]
         dC_dXts = []
         Xts = []
         for idx, Xt in enumerate(diff_outputs):
-
             # We are looking for x[t-1] for a given x[t]
             if idx >= info.n_mit_mot_outs:
                 Xt_placeholder = safe_new(Xt)
                 Xts.append(Xt_placeholder)
 
             # Different processing based on whether Xt is a nitsot output
             # or not. NOTE : This cannot be done by using
@@ -2603,15 +2589,14 @@
                 for Xt, Xt_placeholder in zip(diff_outputs[info.n_mit_mot_outs :], Xts):
                     tmp = forced_replace(dC_dinps_t[dx], Xt, Xt_placeholder)
                     dC_dinps_t[dx] = tmp
 
         # construct dX_dtm1
         dC_dXtm1s = []
         for pos, x in enumerate(dC_dinps_t[info.n_seqs :]):
-
             # Get the index of the first inner input corresponding to the
             # pos-ieth inner input state
             idxs = var_mappings["inner_out_from_inner_inp"][info.n_seqs + pos]
 
             # Check if the pos-th input is associated with one of the
             # recurrent states
             x_is_state = pos < sum(
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/rewriting.py` & `aesara_nightly-2.9.0.post2/aesara/scan/rewriting.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """This module provides optimizations for the `Scan` `Op`."""
 
 import copy
 import dataclasses
 from itertools import chain
 from sys import maxsize
-from typing import Dict, List, Optional, Tuple, cast
+from typing import TYPE_CHECKING, Dict, List, Optional, Tuple, cast
 
 import numpy as np
 
 import aesara
 from aesara import scalar as aes
 from aesara import tensor as at
 from aesara.compile import optdb
@@ -32,38 +32,41 @@
 from aesara.graph.rewriting.db import EquilibriumDB, SequenceDB
 from aesara.graph.type import HasShape
 from aesara.graph.utils import InconsistencyError
 from aesara.scan.op import Scan, ScanInfo
 from aesara.scan.utils import (
     ScanArgs,
     compress_outs,
-    expand_empty,
     reconstruct_graph,
     safe_new,
     scan_can_remove_outs,
 )
 from aesara.tensor.basic import Alloc, AllocEmpty, get_scalar_constant_value
 from aesara.tensor.elemwise import DimShuffle, Elemwise
 from aesara.tensor.exceptions import NotScalarConstantError
 from aesara.tensor.math import Dot, dot, maximum, minimum
 from aesara.tensor.rewriting.basic import constant_folding, local_useless_switch
 from aesara.tensor.rewriting.elemwise import local_upcast_elemwise_constant_inputs
 from aesara.tensor.rewriting.math import local_abs_merge, local_mul_switch_sink
-from aesara.tensor.shape import shape
+from aesara.tensor.shape import shape, shape_tuple
 from aesara.tensor.subtensor import (
     IncSubtensor,
     Subtensor,
     get_canonical_form_slice,
     get_idx_list,
     get_slice_elements,
+    indices_from_subtensor,
     set_subtensor,
 )
 from aesara.tensor.var import TensorConstant, get_unique_value
 
 
+if TYPE_CHECKING:
+    from aesara.tensor.var import TensorVariable
+
 list_opt_slice = [
     local_abs_merge,
     local_mul_switch_sink,
     local_upcast_elemwise_constant_inputs,
     local_useless_switch,
     constant_folding,
 ]
@@ -460,15 +463,14 @@
                 or (x.owner in to_remove_set)
                 or isinstance(x, Constant)
                 or (x in inner_seqs_set)
                 for x in nd.inputs
             )
             and isinstance(nd.op, Elemwise)
         ):
-
             outside_ins = []
             depends_on_seqs = False
 
             for x in nd.inputs:
                 if x in inner_non_seqs_set:
                     _idx = inner_non_seqs_map[x]
                     new_input = outer_non_seqs[_idx]
@@ -508,15 +510,14 @@
                 replace_with_out.append(nw_outer_node.outputs[idx])
 
         elif (
             nd not in to_remove_set
             and isinstance(nd.op, DimShuffle)
             and (nd.inputs[0] in inner_seqs_set or nd.inputs[0].owner in to_remove_set)
         ):
-
             to_remove_set.add(nd)
             x = nd.inputs[0]
             if x in inner_seqs_set:
                 outside_ins = outer_seqs[inner_seqs_map[x]]
             elif x in to_replace_set:
                 outside_ins = replace_with_out[to_replace_map[x]]
             new_ord = (0,)
@@ -558,15 +559,14 @@
             out in to_keep_set
             and out.owner not in existent_nodes_set
             and
             # If types are different, conversion Op will be inserted,
             # and it may trigger an infinite loop.
             out.type.is_super(replace_with_in[idx].type)
         ):
-
             clean_to_replace.append(out)
             clean_replace_with_in.append(replace_with_in[idx])
             clean_replace_with_out.append(replace_with_out[idx])
 
     if len(clean_to_replace) > 0:
         # We can finally put an end to all this madness
         givens = {}
@@ -677,24 +677,22 @@
 
 def push_out_inner_vars(
     fgraph: FunctionGraph,
     inner_vars: List[Variable],
     old_scan_node: Apply,
     old_scan_args: ScanArgs,
 ) -> Tuple[List[Variable], ScanArgs, Dict[Variable, Variable]]:
-
     tmp_outer_vars: List[Optional[Variable]] = []
     new_scan_node = old_scan_node
     new_scan_args = old_scan_args
     replacements: Dict[Variable, Variable] = {}
 
     # For the inner_vars that already exist in the outer graph,
     # simply obtain a reference to them
     for idx in range(len(inner_vars)):
-
         var = inner_vars[idx]
 
         new_outer_var: Optional[Variable] = None
 
         if var in old_scan_args.inner_in_seqs:
             idx_seq = old_scan_args.inner_in_seqs.index(var)
             new_outer_var = old_scan_args.outer_in_seqs[idx_seq]
@@ -716,15 +714,14 @@
     # them as new nitsot outputs to the scan node.
     idx_add_as_nitsots = [i for i, v in enumerate(tmp_outer_vars) if v is None]
     add_as_nitsots = [inner_vars[idx] for idx in idx_add_as_nitsots]
 
     new_outs: List[Variable] = []
 
     if len(add_as_nitsots) > 0:
-
         new_scan_node, replacements = add_nitsot_outputs(
             fgraph, old_scan_node, old_scan_args, add_as_nitsots
         )
 
         assert isinstance(new_scan_node.op, Scan)
 
         new_scan_args = ScanArgs(
@@ -751,15 +748,14 @@
 
 def add_nitsot_outputs(
     fgraph: FunctionGraph,
     old_scan_node: Apply,
     old_scan_args: ScanArgs,
     new_outputs_inner,
 ) -> Tuple[Apply, Dict[Variable, Variable]]:
-
     assert isinstance(old_scan_node.op, Scan)
 
     nb_new_outs = len(new_outputs_inner)
 
     # Create the initial values for the new nitsot outputs
     # (the initial value is the nb of steps to store. For a nistot,
     # it should be the number of steps performed by scan)
@@ -844,20 +840,18 @@
     for nd in local_fgraph_topo:
         if (
             isinstance(nd.op, Elemwise)
             and isinstance(nd.op.scalar_op, aes.Add)
             and nd.out in args.inner_out_sit_sot
             and inner_sitsot_only_last_step_used(fgraph, nd.out, args)
         ):
-
             # Ensure that one of the input to the add is the output of
             # the add from a previous iteration of the inner function
             sitsot_idx = args.inner_out_sit_sot.index(nd.out)
             if args.inner_in_sit_sot[sitsot_idx] in nd.inputs:
-
                 # Ensure that the other input to the add is a dot product
                 # between 2 matrices which will become a tensor3 and a
                 # matrix if pushed outside of the scan. Also make sure
                 # that the output of the Dot is ONLY used by the 'add'
                 # otherwise doing a Dot in the outer graph will only
                 # duplicate computation.
 
@@ -873,15 +867,14 @@
                     and isinstance(dot_input.owner.op, Dot)
                     and len(clients[dot_input]) == 1
                     and dot_input.owner.inputs[0].ndim == 2
                     and dot_input.owner.inputs[1].ndim == 2
                     and get_outer_ndim(dot_input.owner.inputs[0], args) == 3
                     and get_outer_ndim(dot_input.owner.inputs[1], args) == 3
                 ):
-
                     # The optimization can be be applied in this case.
 
                     # Move out of scan the two inputs to the Dot and
                     # perform a dot outside of scan on these two inputs
                     inner_dot_inputs = nd.inputs[dot_in_idx].owner.inputs
                     (
                         outer_dot_inputs,
@@ -1022,17 +1015,15 @@
             )
             return cast(Apply[Scan], new_outs[0].owner)
         except InconsistencyError:
             # Failed moving output to be computed inplace
             return None
 
     def apply(self, fgraph):
-
         for scan_idx, original_node in enumerate(reversed(fgraph.toposort())):
-
             if not isinstance(original_node.op, Scan):
                 continue
 
             # First attempt to make the Scan compute inplace every recurrent
             # output that seems like it could be computed inplace. If that
             # fails, go through these outputs individually, trying each of
             # them.
@@ -1111,14 +1102,80 @@
 def sanitize(x):
     if x is None:
         return None
     else:
         return at.as_tensor_variable(x)
 
 
+def reshape_output_storage(
+    out_storage: "TensorVariable",
+    steps_needed: "TensorVariable",
+    tap_spread: int,
+) -> "TensorVariable":
+    """Resize the first dimension of ``storage`` in ``set_subtensor(storage[:tap_spread], initial_tap_vals)``.
+
+    This is used by `save_mem_new_scan` to reduce the amount of storage
+    (pre)allocated for `Scan` output arrays (i.e. ``storage`` is assumed to be
+    an `AllocEmpty` output).
+
+    Parameters
+    ----------
+    out_storage
+        This corresponds to a graph with the form
+        ``set_subtensor(storage[:tap_spread], initial_tap_vals)``.
+    tap_spread
+        The spread of the relevant tap.  This will generally be the length of
+        ``initial_tap_vals``, but sometimes not (e.g. because the initial
+        values broadcast across the indices/slice).
+
+    Returns
+    -------
+    Return a graph like
+    ``set_subtensor(new_storage[:tap_spread], initial_tap_vals)``,
+    where ``new_storage`` is an `AllocEmpty` with a first
+    dimension having length ``maximum(steps_needed_var, tap_spread)``.
+
+    """
+    out_storage_node = out_storage.owner
+    if (
+        out_storage_node
+        and isinstance(out_storage_node.op, IncSubtensor)
+        and out_storage_node.op.set_instead_of_inc
+        and len(out_storage_node.op.idx_list) == 1
+        and isinstance(out_storage_node.op.idx_list[0], slice)
+    ):
+        # The "fill" value of the `IncSubtensor` across the
+        # slice.  This should generally consist of the initial
+        # values.
+        initial_tap_vals = out_storage_node.inputs[1]
+
+        storage_slice = indices_from_subtensor(
+            out_storage_node.inputs[2:], out_storage_node.op.idx_list
+        )
+        inner_storage_var = out_storage_node.inputs[0]
+
+        # Why this size exactly?  (N.B. This is what the original Theano logic ultimately did.)
+        max_storage_size = at.switch(
+            at.lt(steps_needed, tap_spread), steps_needed + 2 * tap_spread, steps_needed
+        )
+        new_inner_storage_var = at.empty(
+            (
+                max_storage_size,
+                *shape_tuple(inner_storage_var)[1:],
+            ),
+            dtype=initial_tap_vals.dtype,
+        )
+        res = at.set_subtensor(new_inner_storage_var[storage_slice], initial_tap_vals)
+    else:
+        max_storage_size = maximum(steps_needed, tap_spread)
+        res = out_storage[:max_storage_size]
+
+    return cast("TensorVariable", res)
+
+
 @node_rewriter([Scan])
 def save_mem_new_scan(fgraph, node):
     r"""Graph optimizer that reduces scan memory consumption.
 
     This optimizations attempts to determine if a `Scan` node, during its execution,
     for any of its outputs, can get away with allocating a memory buffer that is
     large enough to contain some of the computed timesteps of that output but not
@@ -1214,15 +1271,14 @@
     flag_store = False
 
     # 2.2 Loop over the clients
     for i, out in enumerate(node.outputs[:c_outs]):
         # look at all its clients
         slices[i] = []
         for cl, _ in fgraph.clients[out]:
-
             # 2.1 outputs of the function
             # => output needs all its intermediate values
             if isinstance(cl, str):
                 # if the node is actually an output, then
                 # we need to store the entire thing
                 global_nsteps = None
                 slices[i] = None
@@ -1407,118 +1463,78 @@
         # 3.2 check orphane outputs to see if we can eliminate any
         required, not_required = scan_can_remove_outs(node.op, orphane_outs)
         # 3.3. compose replace pairs for those nodes that need not
         # to store everything in memory ( or ar orphane and required
         # by the inner function .. )
         replaced_outs = []
         offset = 1 + op_info.n_seqs + op_info.n_mit_mot
-        for idx, _val in enumerate(store_steps[op_info.n_mit_mot :]):
+        for idx, steps_needed in enumerate(store_steps[op_info.n_mit_mot :]):
             i = idx + op_info.n_mit_mot
-            if not (isinstance(_val, int) and _val <= 0 and i not in required):
+            if not (
+                isinstance(steps_needed, int)
+                and steps_needed <= 0
+                and i not in required
+            ):
+                if i in required:
+                    steps_needed = 1
 
-                if idx + op_info.n_mit_mot in required:
-                    val = 1
-                else:
-                    val = _val
                 # If the memory for this output has been pre-allocated
                 # before going into the scan op (by an alloc node)
                 if idx < op_info.n_mit_sot + op_info.n_sit_sot:
                     # In case the input is still an alloc node, we
                     # actually have two options:
                     #   a) the input is a set_subtensor, in that case we
                     #      can replace the initial tensor by a slice,
                     #   b) it is not, and we simply take a slice of it.
-                    # TODO: commit change below with Razvan
-                    if (
-                        nw_inputs[offset + idx].owner
-                        and isinstance(nw_inputs[offset + idx].owner.op, IncSubtensor)
-                        and isinstance(
-                            nw_inputs[offset + idx].owner.op.idx_list[0], slice
-                        )
-                    ):
-
-                        assert isinstance(
-                            nw_inputs[offset + idx].owner.op, IncSubtensor
-                        )
-                        _nw_input = nw_inputs[offset + idx].owner.inputs[1]
-                        cval = at.as_tensor_variable(val)
-                        initl = at.as_tensor_variable(init_l[i])
-                        tmp_idx = at.switch(cval < initl, cval + initl, cval - initl)
-                        nw_input = expand_empty(_nw_input, tmp_idx)
-                    else:
-                        tmp = at.as_tensor_variable(val)
-                        initl = at.as_tensor_variable(init_l[i])
-                        tmp = maximum(tmp, initl)
-                        nw_input = nw_inputs[offset + idx][:tmp]
+                    out_storage = nw_inputs[offset + idx]
+                    tap_spread = init_l[i]
+                    nw_input = reshape_output_storage(
+                        out_storage, steps_needed, tap_spread
+                    )
 
                     nw_inputs[offset + idx] = nw_input
-                    replaced_outs.append(op_info.n_mit_mot + idx)
-                    odx = op_info.n_mit_mot + idx
+                    replaced_outs.append(i)
                     old_outputs += [
                         (
-                            odx,
-                            [
-                                x[0].outputs[0]
-                                for x in fgraph.clients[node.outputs[odx]]
-                            ],
+                            i,
+                            [x[0].outputs[0] for x in fgraph.clients[node.outputs[i]]],
                         )
                     ]
                 # If there is no memory pre-allocated for this output
                 elif idx < op_info.n_mit_sot + op_info.n_sit_sot + op_info.n_nit_sot:
-
                     pos = (
                         op_info.n_mit_mot
                         + idx
                         + op_info.n_seqs
                         + 1
                         + op_info.n_shared_outs
                     )
                     if nw_inputs[pos] == node.inputs[0]:
-                        nw_inputs[pos] = val
-                    odx = op_info.n_mit_mot + idx
-                    replaced_outs.append(odx)
+                        nw_inputs[pos] = steps_needed
+                    replaced_outs.append(i)
                     old_outputs += [
                         (
-                            odx,
-                            [
-                                x[0].outputs[0]
-                                for x in fgraph.clients[node.outputs[odx]]
-                            ],
+                            i,
+                            [x[0].outputs[0] for x in fgraph.clients[node.outputs[i]]],
                         )
                     ]
         # 3.4. Recompute inputs for everything else based on the new
         # number of steps
         if global_nsteps is not None:
-            for idx, val in enumerate(store_steps[op_info.n_mit_mot :]):
-                if val == 0:
-                    # val == 0 means that we want to keep all intermediate
+            for idx, steps_needed in enumerate(store_steps[op_info.n_mit_mot :]):
+                if steps_needed == 0:
+                    # steps_needed == 0 means that we want to keep all intermediate
                     # results for that state, including the initial values.
                     if idx < op_info.n_mit_sot + op_info.n_sit_sot:
                         in_idx = offset + idx
-                        # Number of steps in the initial state
-                        initl = init_l[op_info.n_mit_mot + idx]
-
-                        # If the initial buffer has the form
-                        # inc_subtensor(zeros(...)[...], _nw_input)
-                        # we want to make the zeros tensor as small as
-                        # possible (nw_steps + initl), and call
-                        # inc_subtensor on that instead.
-                        # Otherwise, simply take 0:(nw_steps+initl).
-                        if (
-                            nw_inputs[in_idx].owner
-                            and isinstance(nw_inputs[in_idx].owner.op, IncSubtensor)
-                            and isinstance(
-                                nw_inputs[in_idx].owner.op.idx_list[0], slice
-                            )
-                        ):
-                            _nw_input = nw_inputs[in_idx].owner.inputs[1]
-                            nw_input = expand_empty(_nw_input, nw_steps)
-                            nw_inputs[in_idx] = nw_input
-                        else:
-                            nw_input = nw_inputs[in_idx][: (initl + nw_steps)]
+                        out_storage = nw_inputs[in_idx]
+                        tap_spread = init_l[op_info.n_mit_mot + idx]
+                        nw_input = reshape_output_storage(
+                            out_storage, steps_needed, tap_spread
+                        )
 
                     elif (
                         idx < op_info.n_mit_sot + op_info.n_sit_sot + op_info.n_nit_sot
                     ):
                         in_idx = offset + idx + op_info.n_shared_outs
                         if nw_inputs[in_idx] == node.inputs[0]:
                             nw_inputs[in_idx] = nw_steps
@@ -1674,15 +1690,14 @@
 
     """
 
     def add_requirements(self, fgraph):
         fgraph.attach_feature(ReplaceValidate())
 
     def merge(self, nodes):
-
         if nodes[0].op.info.as_while:
             as_while = True
             condition = nodes[0].op.inner_outputs[-1]
         else:
             as_while = False
 
         # We keep the inner_ins and inner_outs of each original node separated.
@@ -2134,15 +2149,14 @@
     ):
         for s_outer_imm, s_inner_omm, s_outer_omm, sosl in seen:
             if (
                 osl == sosl
                 and equal_computations(inner_omm, s_inner_omm, left, right)
                 and outer_imm == s_outer_imm
             ):
-
                 new_outer_out_mit_mot.append(s_outer_omm)
                 break
         else:
             seen.append((outer_imm, inner_omm, outer_omm, osl))
             new_outer_out_mit_mot.append(outer_omm)
     na.outer_out_mit_mot = new_outer_out_mit_mot
     if remove:
@@ -2168,37 +2182,34 @@
     # and assumes dimshuffle are applied to vectors before calling dot
     op = node.op
     sitsot_ins = op.inner_sitsot(op.inner_inputs)
     sitsot_outs = op.inner_sitsot_outs(op.inner_outputs)
     outer_sitsot = op.outer_sitsot_outs(node.outputs)
     seqs = op.inner_seqs(op.inner_inputs)
     for inp, out, outer_out in zip(sitsot_ins, sitsot_outs, outer_sitsot):
-
         if (
             out.owner
             and isinstance(out.owner.op, Elemwise)
             and isinstance(out.owner.op.scalar_op, aes.Add)
             and inp in out.owner.inputs
             and len(fgraph.clients[outer_out]) == 1
             and not isinstance(fgraph.clients[outer_out][0][0], str)
             and isinstance(fgraph.clients[outer_out][0][0].op, Subtensor)
             and fgraph.clients[outer_out][0][0].op.idx_list == (-1,)
         ):
-
             x = out.owner.inputs[0]
             if x == inp:
                 x = out.owner.inputs[1]
             # We need to check if x is the result of an outer product
             if (
                 x.owner
                 and isinstance(x.owner.op, Dot)
                 and x.owner.inputs[0].ndim == 2
                 and x.owner.inputs[1].ndim == 2
             ):
-
                 # We need to check if any of the inputs are a sequence
                 inp1 = x.owner.inputs[0]
                 inp2 = x.owner.inputs[1]
 
                 if inp1 in seqs or inp2 in seqs:
                     new_scan_out = inp1
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/scan_perform.pyx` & `aesara_nightly-2.9.0.post2/aesara/scan/scan_perform.pyx`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/scan_perform_ext.py` & `aesara_nightly-2.9.0.post2/aesara/scan/scan_perform_ext.py`

 * *Files 0% similar despite different names*

```diff
@@ -45,15 +45,14 @@
 
 try:
     try_import()
     need_reload = True
     if version != getattr(scan_perform, "_version", None):
         raise ImportError("Scan code version mismatch")
 except ImportError:
-
     dirname = "scan_perform"
     loc = os.path.join(config.compiledir, dirname)
 
     os.makedirs(loc, exist_ok=True)
 
     with lock_ctx(loc):
         # Maybe someone else already finished compiling it while we were
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/utils.py` & `aesara_nightly-2.9.0.post2/aesara/scan/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -706,15 +706,15 @@
         assert q == len(inner_outputs)
 
     @staticmethod
     def from_node(node, clone=False) -> "ScanArgs":
         from aesara.scan.op import Scan
 
         if not isinstance(node.op, Scan):
-            raise TypeError("{} is not a Scan node".format(node))
+            raise TypeError(f"{node} is not a Scan node")
         return ScanArgs(
             node.inputs,
             node.outputs,
             node.op.inner_inputs,
             node.op.inner_outputs,
             node.op.info,
             clone=clone,
@@ -881,17 +881,17 @@
         field_names = filter(field_filter, self.field_names)
 
         for field_name in field_names:
             lst = getattr(self, field_name)
 
             field_prefix = field_name[:8]
             if field_prefix.endswith("in"):
-                agg_field_name = "{}puts".format(field_prefix)
+                agg_field_name = f"{field_prefix}puts"
             else:
-                agg_field_name = "{}tputs".format(field_prefix)
+                agg_field_name = f"{field_prefix}tputs"
 
             agg_list = getattr(self, agg_field_name)
 
             if field_name in self.nested_list_fields:
                 for n, sub_lst in enumerate(lst):
                     idx = safe_index(sub_lst, i)
                     if idx is not None:
@@ -904,15 +904,14 @@
                     return FieldInfo(field_name, agg_field_name, idx, None, agg_idx)
 
         return None
 
     def _remove_from_fields(
         self, i: Variable, field_filter: Callable[[str], bool] = default_filter
     ) -> Optional[FieldInfo]:
-
         field_info = self.find_among_fields(i, field_filter=field_filter)
 
         if field_info is None:
             return None
 
         if field_info.inner_index is not None:
             getattr(self, field_info.name)[field_info.index].remove(i)
@@ -930,26 +929,25 @@
             seen.add(i)
 
         var_mappings = self.var_mappings
 
         field_info = self.find_among_fields(i)
 
         if field_info is None:
-            raise ValueError("{} not found among fields.".format(i))
+            raise ValueError(f"{i} not found among fields.")
 
         # Find the `var_mappings` key suffix that matches the field/set of
         # arguments containing our source node
         if field_info.name[:8].endswith("_in"):
-            map_key_suffix = "{}p".format(field_info.name[:8])
+            map_key_suffix = f"{field_info.name[:8]}p"
         else:
             map_key_suffix = field_info.name[:9]
 
         dependent_nodes = set()
         for k, v in var_mappings.items():
-
             if not k.endswith(map_key_suffix):
                 continue
 
             dependent_idx = v[field_info.agg_index]
             dependent_idx = (
                 dependent_idx if isinstance(dependent_idx, list) else [dependent_idx]
             )
@@ -959,17 +957,17 @@
             # "outer_inputs", "inner_inputs", "inner_outputs", or
             # "outer_outputs").
             # To do this, we need to parse the "shared" prefix of the
             # current `var_mappings` key and append the missing parts so that
             # it either forms `"*_inputs"` or `"*_outputs"`.
             to_agg_field_prefix = k[:9]
             if to_agg_field_prefix.endswith("p"):
-                to_agg_field_name = "{}uts".format(to_agg_field_prefix)
+                to_agg_field_name = f"{to_agg_field_prefix}uts"
             else:
-                to_agg_field_name = "{}puts".format(to_agg_field_prefix)
+                to_agg_field_name = f"{to_agg_field_prefix}puts"
 
             to_agg_field = getattr(self, to_agg_field_name)
 
             for d_id in dependent_idx:
                 if d_id < 0:
                     continue
 
@@ -994,15 +992,14 @@
             seen |= sub_dependent_nodes
 
         return dependent_nodes
 
     def remove_from_fields(
         self, i: Variable, rm_dependents: bool = True
     ) -> List[Tuple[Variable, Optional[FieldInfo]]]:
-
         if rm_dependents:
             vars_to_remove = self.get_dependent_nodes(i) | {i}
         else:
             vars_to_remove = {i}
 
         rm_info: List[Tuple[Variable, Optional[FieldInfo]]] = []
         for v in vars_to_remove:
@@ -1043,37 +1040,37 @@
                 in ("mit_mot_out_slices", "mit_mot_in_slices", "mit_sot_in_slices")
             ):
                 getattr(res, attr).extend(getattr(other, attr))
         return res
 
     def __str__(self):
         inner_arg_strs = [
-            "\t{}={}".format(p, getattr(self, p))
+            f"\t{p}={getattr(self, p)}"
             for p in self.field_names
             if p.startswith("outer_in") or p == "n_steps"
         ]
         inner_arg_strs += [
-            "\t{}={}".format(p, getattr(self, p))
+            f"\t{p}={getattr(self, p)}"
             for p in self.field_names
             if p.startswith("inner_in")
         ]
         inner_arg_strs += [
-            "\tmit_mot_in_slices={}".format(self.mit_mot_in_slices),
-            "\tmit_sot_in_slices={}".format(self.mit_sot_in_slices),
+            f"\tmit_mot_in_slices={self.mit_mot_in_slices}",
+            f"\tmit_sot_in_slices={self.mit_sot_in_slices}",
         ]
         inner_arg_strs += [
-            "\t{}={}".format(p, getattr(self, p))
+            f"\t{p}={getattr(self, p)}"
             for p in self.field_names
             if p.startswith("inner_out")
         ]
         inner_arg_strs += [
-            "\tmit_mot_out_slices={}".format(self.mit_mot_out_slices),
+            f"\tmit_mot_out_slices={self.mit_mot_out_slices}",
         ]
         inner_arg_strs += [
-            "\t{}={}".format(p, getattr(self, p))
+            f"\t{p}={getattr(self, p)}"
             for p in self.field_names
             if p.startswith("outer_out")
         ]
         res = "ScanArgs(\n{})".format(",\n".join(inner_arg_strs))
         return res
 
     def __repr__(self):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/scan/views.py` & `aesara_nightly-2.9.0.post2/aesara/scan/views.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/basic.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -36,16 +36,16 @@
 from aesara.tensor.math import (
     rad2deg,
     round_half_to_even,
     sgn,
     sigmoid,
     sin,
     sinh,
-    sqr,
     sqrt,
+    square,
     tan,
     tanh,
     trunc,
 )
 from aesara.tensor.shape import shape, specify_broadcastable
 from aesara.tensor.type import TensorType
 from aesara.tensor.type import continuous_dtypes as tensor_continuous_dtypes
@@ -589,15 +589,14 @@
             out[0][0] = _asarray(out[0][0], dtype="int32")
         # backport
         out[1][0] = _asarray(csm.indices, dtype="int32")
         out[2][0] = _asarray(csm.indptr, dtype="int32")
         out[3][0] = _asarray(csm.shape, dtype="int32")
 
     def grad(self, inputs, g):
-
         # g[1:] is all integers, so their Jacobian in this op
         # is 0. We thus don't need to worry about what their values
         # are.
 
         # if g[0] is disconnected, then this op doesn't contribute
         # any gradient anywhere. but we know that at least one of
         # g[1:] is connected, or this grad method wouldn't have been
@@ -1133,15 +1132,14 @@
         ]
 
 
 get_item_list = GetItemList()
 
 
 class GetItemListGrad(Op):
-
     __props__ = ()
 
     def infer_shape(self, fgraph, node, shapes):
         return [(shapes[0])]
 
     def make_node(self, x, index, gz):
         x = as_sparse_variable(x)
@@ -1225,15 +1223,14 @@
         ]
 
 
 get_item_2lists = GetItem2Lists()
 
 
 class GetItem2ListsGrad(Op):
-
     __props__ = ()
 
     def infer_shape(self, fgraph, node, shapes):
         return [(shapes[0])]
 
     def make_node(self, x, ind1, ind2, gz):
         x = as_sparse_variable(x)
@@ -1431,15 +1428,14 @@
         x = as_sparse_variable(x)
         assert x.format in ("csr", "csc")
         assert len(index) == 2
 
         input_op = [x]
 
         for ind in index:
-
             if isinstance(ind, slice):
                 raise Exception("GetItemScalar called with a slice as index!")
 
             # in case of indexing using int instead of aesara variable
             elif isinstance(ind, int):
                 ind = at.constant(ind)
                 input_op += [ind]
@@ -2514,22 +2510,20 @@
     y = as_sparse_or_tensor_variable(y)
 
     x_is_sparse_variable = _is_sparse_variable(x)
     y_is_sparse_variable = _is_sparse_variable(y)
 
     assert x_is_sparse_variable or y_is_sparse_variable
     if x_is_sparse_variable and y_is_sparse_variable:
-
         # mul_s_s is not implemented if the types differ
         if y.dtype == "float64" and x.dtype == "float32":
             x = x.astype("float64")
 
         return mul_s_s(x, y)
     elif x_is_sparse_variable and not y_is_sparse_variable:
-
         # mul is unimplemented if the dtypes differ
         if y.dtype == "float64" and x.dtype == "float32":
             x = x.astype("float64")
 
         return mul_s_d(x, y)
     elif y_is_sparse_variable and not x_is_sparse_variable:
         return mul_s_d(y, x)
@@ -2649,15 +2643,14 @@
     At least one of `x` and `y` must be a sparse matrix.
 
     DS swap input as a dense matrix cannot be a left operand.
 
     """
 
     def helper(x, y):
-
         scipy_ver = [int(n) for n in scipy.__version__.split(".")[:2]]
 
         assert scipy_ver >= [0, 13]
 
         if hasattr(x, "getnnz"):
             x = as_sparse_variable(x)
         if hasattr(y, "getnnz"):
@@ -3251,16 +3244,16 @@
 def trunc(x):
     """
     Elemwise truncation.
 
     """
 
 
-@structured_monoid(sqr)  # type: ignore[no-redef]
-def sqr(x):
+@structured_monoid(square)  # type: ignore[no-redef]
+def square(x):
     """
     Elemwise `x` * `x`.
 
     """
 
 
 @structured_monoid(sqrt)  # type: ignore[no-redef]
@@ -3286,15 +3279,14 @@
     return _conj(_x)
 
 
 conj = conjugate
 
 
 class TrueDot(Op):
-
     # TODO
     # Simplify code by splitting into DotSS and DotSD.
 
     __props__ = ()
     # The grad_preserves_dense attribute doesn't change the
     # execution behavior.  To let the optimizer merge nodes with
     # different values of this attribute we shouldn't compare it
@@ -3429,15 +3421,14 @@
         return transpose(TrueDot(grad_preserves_dense)(y.T, x.T))
 
 
 class StructuredDot(Op):
     __props__ = ()
 
     def make_node(self, a, b):
-
         a = as_sparse_variable(a)
         assert a.format in ("csr", "csc", "bsr")
 
         if not _is_sparse_variable(a):
             raise TypeError(
                 "First argument must be of type SparseVariable " "or SparseConstant"
             )
@@ -3603,15 +3594,14 @@
                 g_a_data[i_idx] = dot_val
         out[0] = g_a_data
 
     def c_code_cache_version(self):
         return (1,)
 
     def c_code(self, node, name, inputs, outputs, sub):
-
         (_indices, _indptr, _d, _g) = inputs
         (_zout,) = outputs
         if node.inputs[2].type.dtype in ("complex64", "complex128"):
             raise NotImplementedError("Complex types are not supported for b")
         if node.inputs[3].type.dtype in ("complex64", "complex128"):
             raise NotImplementedError("Complex types are not supported for " "g_ab")
 
@@ -3739,15 +3729,14 @@
                 g_a_data[j_idx] = dot_val
         out[0] = g_a_data
 
     def c_code_cache_version(self):
         return (1,)
 
     def c_code(self, node, name, inputs, outputs, sub):
-
         (_indices, _indptr, _d, _g) = inputs
         (_zout,) = outputs
         if node.inputs[2].type.dtype in ("complex64", "complex128"):
             raise NotImplementedError("Complex types are not supported for b")
         if node.inputs[3].type.dtype in ("complex64", "complex128"):
             raise NotImplementedError("Complex types are not supported for " "g_ab")
 
@@ -3833,15 +3822,14 @@
 
 
 sdg_csr = StructuredDotGradCSR()
 
 
 def structured_dot_grad(sparse_A, dense_B, ga):
     if sparse_A.type.format in ("csc", "csr"):
-
         if sparse_A.type.format == "csc":
             sdgcsx = sdg_csc
             CSx = CSC
         else:
             sdgcsx = sdg_csr
             CSx = CSR
 
@@ -4242,15 +4230,14 @@
 
     def R_op(self, inputs, eval_points):
         if None in eval_points[:2]:
             return [None]
         return self.make_node(eval_points[0], eval_points[1], *inputs[2:]).outputs
 
     def connection_pattern(self, node):
-
         rval = [[True], [True], [False]]
         return rval
 
     def grad(self, inputs, grads):
         (g_output,) = grads
         x, y = inputs[:2]
         idx_list = inputs[2:]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/rewriting.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/rewriting.py`

 * *Files 0% similar despite different names*

```diff
@@ -957,15 +957,14 @@
     return False
 
 
 register_specialize(local_usmm_csx, "cxx_only")
 
 
 class CSMGradC(_NoPythonCOp):
-
     __props__ = ()
 
     def make_node(self, a_val, a_ind, a_ptr, a_dim, b_val, b_ind, b_ptr, b_dim):
         return Apply(
             self,
             [a_val, a_ind, a_ptr, a_dim, b_val, b_ind, b_ptr, b_dim],
             [b_val.type()],
@@ -1145,15 +1144,14 @@
             self, [a_data, a_indices, a_indptr, b], [tensor(b.dtype, shape=(None,))]
         )
 
     def c_code_cache_version(self):
         return (3,)
 
     def c_code(self, node, name, inputs, outputs, sub):
-
         (
             _data,
             _indices,
             _indptr,
             _b,
         ) = inputs
         (_zout,) = outputs
@@ -1283,15 +1281,14 @@
             self, [a_data, a_indices, a_indptr, b], [tensor(b.dtype, shape=(None,))]
         )
 
     def c_code_cache_version(self):
         return (3,)
 
     def c_code(self, node, name, inputs, outputs, sub):
-
         (
             _data,
             _indices,
             _indptr,
             _b,
         ) = inputs
         (_zout,) = outputs
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/sp.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/sandbox/sp.py`

 * *Files 1% similar despite different names*

```diff
@@ -147,36 +147,32 @@
         # spmat). However, this messes up the ordering of the column
         # values (order in which you write the values determines how
         # the vectorized data will get used later one)
 
         for fmapi in range(inshp[0]):  # loop over input features
             # loop over number of kernels (nkern=1 for weight sharing)
             for n in range(nkern):
-
                 # FOR EACH OUTPUT PIXEL...
                 # loop over output image height
                 for oy in np.arange(lbound[0], ubound[0], dy):
                     # loop over output image width
                     for ox in np.arange(lbound[1], ubound[1], dx):
-
                         # kern[l] is filter value to apply at (oj,oi)
                         # for (iy,ix)
                         l = 0  # noqa: E741
 
                         # ... ITERATE OVER INPUT UNITS IN RECEPTIVE FIELD
                         for ky in oy + np.arange(kshp[0]):
                             for kx in ox + np.arange(kshp[1]):
-
                                 # verify if we are still within image
                                 # boundaries. Equivalent to
                                 # zero-padding of the input image
                                 if all((ky, kx) >= topleft) and all(
                                     (ky, kx) < botright
                                 ):
-
                                     # convert to "valid" input space
                                     # coords used to determine column
                                     # index to write to in sparse mat
                                     iy, ix = np.array((ky, kx)) - topleft
                                     # determine raster-index of input pixel...
 
                                     # taking into account multiple
@@ -208,15 +204,15 @@
                                     # in sparse matrix.  The written
                                     # value is only useful for the
                                     # sparse case. It will determine
                                     # the way kernel taps are mapped
                                     # onto the sparse columns (idea of
                                     # kernel map)
                                     # n*... only for sparse
-                                    spmat[row + n * outsize, col] = tapi + 1
+                                    spmat[int(row + n * outsize), int(col)] = tapi + 1
 
                                     # total number of active taps
                                     # (used for kmap)
                                     ntaps += 1
 
                                 # absolute tap index (total number of taps)
                                 tapi += 1
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/sandbox/sp2.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/sandbox/sp2.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/sharedvar.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/sharedvar.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/type.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/type.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
-from typing import Iterable, Optional, Union
+from typing import Iterable, Literal, Optional, Union
 
 import numpy as np
 import scipy.sparse
-from typing_extensions import Literal
 
 import aesara
 from aesara import scalar as aes
 from aesara.graph.basic import Variable
 from aesara.graph.type import HasDataType
 from aesara.tensor.type import DenseTensorType, TensorType
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/sparse/utils.py` & `aesara_nightly-2.9.0.post2/aesara/sparse/utils.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Symbolic tensor types and constructor functions."""
 
 from functools import singledispatch
-from typing import TYPE_CHECKING, Any, Callable, NoReturn, Optional, Sequence, Union
+from typing import TYPE_CHECKING, List, Optional, Sequence, Tuple, Union
 
 from aesara.graph.basic import Constant, Variable
 from aesara.graph.op import Op
 
 
 if TYPE_CHECKING:
-    from numpy.typing import ArrayLike, NDArray
+    from numpy.typing import ArrayLike
 
 
 TensorLike = Union[Variable, Sequence[Variable], "ArrayLike"]
 
 
 def as_tensor_variable(
     x: TensorLike, name: Optional[str] = None, ndim: Optional[int] = None, **kwargs
@@ -145,7 +145,31 @@
 from aesara.tensor.subtensor import *  # noqa
 from aesara.tensor.type import *  # noqa
 from aesara.tensor.type_other import *  # noqa
 from aesara.tensor.var import TensorConstant, TensorVariable  # noqa
 
 
 __all__ = ["random"]  # noqa: F405
+
+# isort: off
+from aesara.tensor.math import DEPRECATED_NAMES as MATH_DEPRECATED_NAMES
+
+# isort: on
+
+
+DEPRECATED_NAMES: List[Tuple[str, str, object]] = MATH_DEPRECATED_NAMES
+
+
+def __getattr__(name):
+    """Intercept module-level attribute access of deprecated symbols.
+
+    Adapted from https://stackoverflow.com/a/55139609/3006474.
+
+    """
+    from warnings import warn
+
+    for old_name, msg, old_object in DEPRECATED_NAMES:
+        if name == old_name:
+            warn(msg, DeprecationWarning, stacklevel=2)
+            return old_object
+
+    raise AttributeError(f"module {__name__} has no attribute {name}")
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/basic.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -65,14 +65,16 @@
     uint_dtypes,
     values_eq_approx_always_true,
 )
 from aesara.tensor.var import TensorConstant, TensorVariable, get_unique_value
 
 
 if TYPE_CHECKING:
+    from numpy.typing import NDArray
+
     from aesara.tensor import TensorLike
 
 
 def __oplist_tag(thing, tag):
     tags = getattr(thing, "__oplist_tags", [])
     tags.append(tag)
     thing.__oplist_tags = tags
@@ -129,15 +131,14 @@
     else:
         return x
 
 
 @_as_tensor_variable.register(list)
 @_as_tensor_variable.register(tuple)
 def _as_tensor_Sequence(x, name, ndim, dtype=None, **kwargs):
-
     if len(x) == 0:
         return constant(x, name=name, ndim=ndim, dtype=dtype)
 
     # If a sequence has `Variable`s in it, then we want
     # to customize the conversion to a tensor type.
     def extract_constants(i):
         if isinstance(i, Variable):
@@ -248,24 +249,27 @@
     aes.GT,
     aes.LE,
     aes.GE,
     aes.Sub,
     aes.Add,
     aes.Mod,
     aes.Mul,
-    aes.IntDiv,
-    aes.TrueDiv,
+    aes.FloorDivide,
+    aes.TrueDivide,
     aes.ScalarMinimum,
     aes.ScalarMaximum,
 )
 
 
 def get_scalar_constant_value(
-    orig_v, elemwise=True, only_process_constants=False, max_recur=10
-):
+    orig_v,
+    elemwise: bool = True,
+    only_process_constants: bool = False,
+    max_recur: int = 10,
+) -> "NDArray":
     """Return the constant scalar(0-D) value underlying variable `v`.
 
     If `v` is the output of dimshuffles, fills, allocs, etc,
     cast, OutputGuard, DeepCopyOp, ScalarFromTensor, ScalarOp, Elemwise
     and some pattern with Subtensor, this function digs through them.
 
     If `v` is not some view of constant scalar data, then raise a
@@ -469,15 +473,14 @@
                     # MakeVector normally accept only scalar as input.
                     # We put this check in case there is change in the future
                     builtins.all(
                         var.ndim == 0 for var in v.owner.inputs[0].owner.inputs
                     )
                     and len(v.owner.op.idx_list) == 1
                 ):
-
                     idx = v.owner.op.idx_list[0]
                     if isinstance(idx, Type):
                         idx = get_scalar_constant_value(
                             v.owner.inputs[1], max_recur=max_recur
                         )
                     # Python 2.4 does not support indexing with numpy.integer
                     # So we cast it.
@@ -530,15 +533,14 @@
                     if isinstance(grandparent, Constant):
                         return np.asarray(np.shape(grandparent.data)[idx])
 
         raise NotScalarConstantError()
 
 
 class TensorFromScalar(COp):
-
     __props__ = ()
 
     def make_node(self, s):
         if not isinstance(s.type, aes.ScalarType):
             raise TypeError("Input must be a `ScalarType` `Type`")
 
         return Apply(self, [s], [tensor(dtype=s.type.dtype, shape=())])
@@ -587,15 +589,14 @@
         return (1,)
 
 
 tensor_from_scalar = TensorFromScalar()
 
 
 class ScalarFromTensor(COp):
-
     __props__ = ()
 
     def __call__(self, *args, **kwargs) -> ScalarVariable:
         return type_cast(ScalarVariable, super().__call__(*args, **kwargs))
 
     def make_node(self, t):
         if not isinstance(t.type, TensorType) or t.type.ndim > 0:
@@ -752,22 +753,24 @@
 
 
 fill = second
 pprint.assign(fill, printing.FunctionPrinter(["fill"]))
 
 
 def ones_like(model, dtype=None, opt=False):
-    """equivalent of numpy.ones_like
+    """Equivalent of `numpy.ones_like`.
+
     Parameters
     ----------
-    model : tensor
-    dtype : data-type, optional
-    opt : If True, we will return a constant instead of a graph when possible.
-          Useful for Aesara optimization, not for user building a graph as this
-          have the consequence that model isn't always in the graph.
+    model
+    dtype
+    opt
+        If ``True``, we will return a constant instead of a graph when possible.
+        Useful for Aesara optimization, not for user building a graph as this
+        have the consequence that model isn't always in the graph.
 
     Returns
     -------
     tensor
         tensor the shape of model containing ones of the type of dtype.
     """
     _model = as_tensor_variable(model)
@@ -778,22 +781,24 @@
     # TODO: Remove this weird option
     if opt and ret.type == _model.type:
         return ret
     return fill(_model, ret)
 
 
 def zeros_like(model, dtype=None, opt=False):
-    """equivalent of numpy.zeros_like
+    """Equivalent of `numpy.zeros_like`.
+
     Parameters
     ----------
-    model : tensor
-    dtype : data-type, optional
-    opt : If True, we will return a constant instead of a graph when possible.
-          Useful for Aesara optimization, not for user building a graph as this
-          have the consequence that model isn't always in the graph.
+    model
+    dtype
+    opt
+        If ``True``, we will return a constant instead of a graph when possible.
+        Useful for Aesara optimization, not for user building a graph as this
+        have the consequence that model isn't always in the graph.
 
     Returns
     -------
     tensor
         tensor the shape of model containing zeros of the type of dtype.
     """
 
@@ -972,15 +977,14 @@
 
     """
     _a = as_tensor_variable(a)
     return _a.flatten()[flatnonzero(_a)]
 
 
 class Tri(Op):
-
     __props__ = ("dtype",)
 
     def __init__(self, dtype=None):
         if dtype is None:
             dtype = config.floatX
         self.dtype = dtype
 
@@ -1248,15 +1252,14 @@
     """
     if a.ndim != 2:
         raise ValueError("The input array must be two dimensional.")
     return triu_indices(a.shape[0], k=k, m=a.shape[1])
 
 
 class Eye(Op):
-
     __props__ = ("dtype",)
 
     def __init__(self, dtype=None):
         if dtype is None:
             dtype = config.floatX
         self.dtype = dtype
 
@@ -1484,15 +1487,14 @@
     def c_code_cache_version(self):
         return (2,)
 
     def infer_shape(self, fgraph, node, input_shapes):
         return [node.inputs[1:]]
 
     def connection_pattern(self, node):
-
         rval = [[True]]
 
         for ipt in node.inputs[1:]:
             rval.append([False])
 
         return rval
 
@@ -2175,17 +2177,15 @@
 
     def __str__(self):
         if self.view == -1:
             return self.__class__.__name__
         else:
             return "{}{{{}}}".format(
                 self.__class__.__name__,
-                ", ".join(
-                    "{}={!r}".format(p, getattr(self, p)) for p in self.__props__
-                ),
+                ", ".join(f"{p}={getattr(self, p)!r}" for p in self.__props__),
             )
 
     def __setstate__(self, d):
         self.__dict__.update(d)
         if not hasattr(self, "view"):
             self.view = -1
 
@@ -2940,15 +2940,14 @@
         (out,) = out_
         start = start.item()
         stop = stop.item()
         step = step.item()
         out[0] = np.arange(start, stop, step, dtype=self.dtype)
 
     def connection_pattern(self, node):
-
         return [[True], [False], [True]]
 
     def L_op(self, inputs, outputs, grads):
         start, stop, step = inputs
         (gz,) = grads
         # `start` and `step` affect the output values
         # but the outputs are integers so there's
@@ -3070,15 +3069,14 @@
 
     """
 
     def __init__(self, sparse=False):
         self.sparse = sparse
 
     def __getitem__(self, *args):
-
         if isinstance(args[0], slice):
             sl = args[0]
             return arange(sl.start or 0, sl.stop, sl.step or 1)
 
         ndim = len(args[0])
         for sl in args[0]:
             if isinstance(sl.step, builtins.complex):
@@ -3777,15 +3775,14 @@
     __props__ = ("mode",)
 
     def __init__(self, mode):
         assert mode in ("raise", "wrap", "clip")
         self.mode = mode
 
     def infer_shape(self, fgraph, node, shapes):
-
         a_shape, choices_shape = shapes
         out_shape = aesara.tensor.extra_ops.broadcast_shape(
             a_shape, choices_shape[1:], arrays_are_shapes=True
         )
 
         return [out_shape]
 
@@ -3810,15 +3807,15 @@
         (out_shape,) = self.infer_shape(
             None, None, [shape_tuple(a), shape_tuple(choice)]
         )
 
         static_out_shape = ()
         for s in out_shape:
             try:
-                s_val = aesara.get_scalar_constant_value(s)
+                s_val = get_scalar_constant_value(s)
             except (NotScalarConstantError, AttributeError):
                 s_val = None
 
             if s_val == 1:
                 static_out_shape += (1,)
             else:
                 static_out_shape += (None,)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/blas.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/blas.py`

 * *Files 0% similar despite different names*

```diff
@@ -939,15 +939,15 @@
 
         if len(inputs) != 5:
             raise TypeError(
                 f"Wrong number of inputs for {self} (expected 5, got {len(inputs)})"
             )
         z, a, x, y, b = inputs
 
-        zr, xr, yr = [set(view_roots(i)) for i in (z, x, y)]
+        zr, xr, yr = (set(view_roots(i)) for i in (z, x, y))
 
         # We want the gemm to be inplace. When this op is inplace, it
         # declare to be inplace only on z. So to make it safe, we
         # raise an error if z can be a view on x or y.
 
         # I don't know if Aesara currently can support that case. As
         # this case don't happen in our code, I won't spent time
@@ -1460,15 +1460,14 @@
             # print 'TRYING', (s_i, M_i, s_j, M_j)
 
             gemm_of_sM_list, old_dot22 = _beta_L_plus_alpha_M(
                 fgraph, s_i, M_i, s_j, M_j
             )
             # print 'GOT IT', gemm_of_sM_list
             if gemm_of_sM_list:
-
                 assert len(gemm_of_sM_list) == 1
                 add_inputs = [
                     item_to_var(input) for k, input in enumerate(lst) if k not in (i, j)
                 ]
                 add_inputs.extend(gemm_of_sM_list)
                 if len(add_inputs) > 1:
                     rval = [add(*add_inputs)]
@@ -1961,15 +1960,14 @@
     compute scalar*dot(x,y).
 
     """
 
     check_input = False
 
     def make_node(self, x, y, a):
-
         if any(not isinstance(i.type, DenseTensorType) for i in (x, y, a)):
             raise NotImplementedError("Only dense tensor types are supported")
 
         if a.ndim != 0:
             raise TypeError(Gemm.E_scalar, a)
         if x.ndim != 2:
             raise TypeError(Gemm.E_rank, x)
@@ -2359,16 +2357,15 @@
                         "{strides}[{i}] > 0 && {strides}[{i}] % type_size == 0".format(
                             strides=strides, i=i
                         )
                         for i in range(1, ndim)
                     ),
                     "(%s)"
                     % " || ".join(
-                        "{strides}[{i}] == type_size".format(strides=strides, i=i)
-                        for i in range(1, ndim)
+                        f"{strides}[{i}] == type_size" for i in range(1, ndim)
                     ),
                 ]
             )
 
         x_ndim, y_ndim, z_ndim = (
             node.inputs[0].ndim,
             node.inputs[1].ndim,
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/blas_c.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/blas_c.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/blas_headers.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/blas_headers.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/blas_scipy.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/blas_scipy.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/c_code/alt_blas_common.h` & `aesara_nightly-2.9.0.post2/aesara/tensor/c_code/alt_blas_common.h`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/c_code/alt_blas_template.c` & `aesara_nightly-2.9.0.post2/aesara/tensor/c_code/alt_blas_template.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/c_code/dimshuffle.c` & `aesara_nightly-2.9.0.post2/aesara/tensor/c_code/dimshuffle.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/elemwise.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/elemwise.py`

 * *Files 1% similar despite different names*

```diff
@@ -250,15 +250,14 @@
 
     def R_op(self, inputs, eval_points):
         if None in eval_points:
             return [None]
         return self(*eval_points, return_list=True)
 
     def grad(self, inp, grads):
-
         (x,) = inp
         (gz,) = grads
         gz = as_tensor_variable(gz)
         grad_order = ["x"] * x.type.ndim
         for i, v in enumerate(self.new_order):
             if v != "x":
                 grad_order[v] = i
@@ -321,17 +320,17 @@
     Notes
     -----
     -``Elemwise(add)``: represents ``+`` on tensors ``x + y``
     -``Elemwise(add, {0 : 0})``: represents the ``+=`` operation ``x += y``
     -``Elemwise(add, {0 : 1})``: represents ``+=`` on the second argument ``y += x``
     -``Elemwise(mul)(np.random.random((10, 5)), np.random.random((1, 5)))``:
     the second input is completed along the first dimension to match the first input
-    -``Elemwise(true_div)(np.random.random(10, 5), np.random.random(10, 1))``: same but along the
+    -``Elemwise(true_divide)(np.random.random(10, 5), np.random.random(10, 1))``: same but along the
     second dimension
-    -``Elemwise(int_div)(np.random.random((1, 5)), np.random.random((10, 1)))``:
+    -``Elemwise(floor_div)(np.random.random((1, 5)), np.random.random((10, 1)))``:
     the output has size ``(10, 5)``.
     -``Elemwise(log)(np.random.random((3, 4, 5)))``
 
     """
 
     __props__ = ("scalar_op", "inplace_pattern")
 
@@ -531,15 +530,14 @@
                         rop_out = rop_out + bgrads[jdx] * eval_point
 
             rval[idx] = rop_out
 
         return rval
 
     def connection_pattern(self, node):
-
         if hasattr(self.scalar_op, "connection_pattern"):
             return self.scalar_op.connection_pattern(node)
 
         return [[True for output in node.outputs] for ipt in node.inputs]
 
     def L_op(self, inputs, outs, ograds):
         from aesara.tensor.math import sum as at_sum
@@ -677,15 +675,14 @@
 
         if (
             len(node.inputs) < 32
             and (self.nfunc is None or self.scalar_op.nin != len(node.inputs))
             and self.ufunc is None
             and impl == "py"
         ):
-
             ufunc = np.frompyfunc(
                 self.scalar_op.impl, len(node.inputs), self.scalar_op.nout
             )
             if self.scalar_op.nin > 0:
                 # We can reuse it for many nodes
                 self.ufunc = ufunc
             else:
@@ -819,15 +816,14 @@
             # numpy.real return a view!
             elif not variable.flags.owndata:
                 storage[0] = variable.copy()
             else:
                 storage[0] = variable
 
     def infer_shape(self, fgraph, node, i_shapes) -> List[Tuple[TensorVariable, ...]]:
-
         if len(node.outputs) > 1:
             from aesara.tensor.exceptions import ShapeError
 
             raise ShapeError(
                 "Multiple outputs are not supported by the default `Elemwise.infer_shape`"
             )
 
@@ -1011,15 +1007,15 @@
                 all_code = [("", "")] * (nnested - 1) + [("", code)] + [""]
             else:
                 all_code = [code]
             if len(all_code) == 1:
                 # No loops
                 task_decl = "".join(
                     [
-                        "{}& {}_i = *{}_iter;\n".format(dtype, name, name)
+                        f"{dtype}& {name}_i = *{name}_iter;\n"
                         for name, dtype in zip(
                             inames + list(real_onames), idtypes + list(real_odtypes)
                         )
                     ]
                 )
 
                 preloops = {}
@@ -1338,15 +1334,14 @@
             self._ufunc = np.frompyfunc(
                 self.scalar_op.impl, 2, 1, identity=self.scalar_op.identity
             )
 
         return self._ufunc
 
     def _output_dtype(self, idtype):
-
         if not self.upcast_discrete_output:
             return idtype
 
         dtype = self.dtype
 
         if dtype == "OLD":
             return dict(
@@ -1521,15 +1516,14 @@
         (ishape,) = shapes
         axis = self.axis
         if axis is None:
             return ((),)
         return ([ishape[i] for i in range(node.inputs[0].type.ndim) if i not in axis],)
 
     def _c_all(self, node, name, inames, onames, sub):
-
         input = node.inputs[0]
         output = node.outputs[0]
 
         iname = inames[0]
         oname = onames[0]
 
         idtype = input.type.dtype_specs()[1]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/elemwise_cgen.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/elemwise_cgen.py`

 * *Files 0% similar despite different names*

```diff
@@ -94,26 +94,26 @@
             continue
 
         # Find first dimension size that is != 1
         jl, xl = to_compare[-1]
         non1size_dim_check = f"""
             npy_intp non1size_dim{xl};
             non1size_dim{xl} = """
-        for (j, x) in to_compare[:-1]:
+        for j, x in to_compare[:-1]:
             non1size_dim_check += f"(%(lv{j})s_n{x} != 1) ? %(lv{j})s_n{x} : "
         non1size_dim_check += f"%(lv{jl})s_n{xl};"
         check += non1size_dim_check
 
         # Check the nonsize1 dims match
         # TODO: This is a bit inefficient because we are comparing one dimension against itself
         check += f"""
             if (non1size_dim{xl} != 1)
             {{
         """
-        for (j, x) in to_compare:
+        for j, x in to_compare:
             check += f"""
                 if ((%(lv{j})s_n{x} != non1size_dim{x}) && (%(lv{j})s_n{x} != 1))
                 {{
                     PyErr_Format(PyExc_ValueError, "Input dimension mismatch. One other input has shape[%%i] = %%lld, but input[%%i].shape[%%i] = %%lld.",
                        {x},
                        (long long int) non1size_dim{x},
                        {j},
@@ -158,15 +158,15 @@
             idx, candidate = nonx_candidates[0]
             var = sub[f"lv{int(idx)}"]
             dims_c_code += f"{array_name}[{i}] = {var}_n{candidate};\n"
             continue
 
         # In this case any non-size 1 variable will define the right size
         dims_c_code += f"{array_name}[{i}] = "
-        for (idx, candidate) in nonx_candidates[:-1]:
+        for idx, candidate in nonx_candidates[:-1]:
             var = sub[f"lv{int(idx)}"]
             dims_c_code += f"({var}_n{candidate} != 1)? {var}_n{candidate}: "
         idx, candidate = nonx_candidates[-1]
         var = sub[f"lv{idx}"]
         dims_c_code += f"{var}_n{candidate};\n"
     return dims_c_code
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/extra_ops.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/extra_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -689,15 +689,14 @@
     def perform(self, node, inputs, output_storage):
         x = inputs[0]
         repeats = inputs[1]
         z = output_storage[0]
         z[0] = np.repeat(x, repeats=repeats, axis=self.axis)
 
     def connection_pattern(self, node):
-
         return [[True], [False]]
 
     def grad(self, inputs, gout):
         (x, repeats) = inputs
         (gz,) = gout
         if repeats.ndim == 0:
             if self.axis is None:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/fft.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/fft.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 from aesara.tensor.basic import as_tensor_variable
 from aesara.tensor.math import sqrt
 from aesara.tensor.subtensor import set_subtensor
 from aesara.tensor.type import TensorType, integer_dtypes
 
 
 class RFFTOp(Op):
-
     __props__ = ()
 
     def output_type(self, inp):
         # add extra dim for real/imag
         return TensorType(inp.dtype, shape=(None,) * (inp.type.ndim + 1))
 
     def make_node(self, a, s=None):
@@ -67,15 +66,14 @@
         return [[True], [False]]
 
 
 rfft_op = RFFTOp()
 
 
 class IRFFTOp(Op):
-
     __props__ = ()
 
     def output_type(self, inp):
         # remove extra dim for real/imag
         return TensorType(inp.dtype, shape=(None,) * (inp.type.ndim - 1))
 
     def make_node(self, a, s=None):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/fourier.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/fourier.py`

 * *Files 2% similar despite different names*

```diff
@@ -157,17 +157,15 @@
 
         # Instead we resort to that to account for truncation:
         flip_shape = list(np.arange(0, a.ndim)[::-1])
         res = res.dimshuffle(flip_shape)
         res = switch(
             lt(n, shape(a)[axis]),
             set_subtensor(
-                res[
-                    n::,
-                ],
+                res[n::,],
                 0,
                 False,
                 False,
             ),
             res,
         )
         res = res.dimshuffle(flip_shape)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/inplace.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/inplace.py`

 * *Files 2% similar despite different names*

```diff
@@ -311,15 +311,15 @@
 @scalar_elemwise
 def iv_inplace(v, x):
     """Modified Bessel function of the first kind of order v (real)."""
 
 
 @scalar_elemwise
 def sigmoid_inplace(x):
-    """Logistic sigmoid function (1 / (1 + exp(x)), also known as expit or inverse logit"""
+    """Logistic sigmoid function (1 / (1 + exp(-x)), also known as expit or inverse logit"""
 
 
 @scalar_elemwise
 def softplus_inplace(x):
     """Compute log(1 + exp(x)), also known as softplus or log1pexp"""
 
 
@@ -364,20 +364,20 @@
 
 @scalar_elemwise
 def mul_inplace(a, b):
     """elementwise multiplication (inplace on `a`)"""
 
 
 @scalar_elemwise
-def true_div_inplace(a, b):
+def true_divide_inplace(a, b):
     """elementwise division (inplace on `a`)"""
 
 
 @scalar_elemwise
-def int_div_inplace(a, b):
+def floor_divide_inplace(a, b):
     """elementwise division (inplace on `a`)"""
 
 
 @scalar_elemwise
 def mod_inplace(a, b):
     """elementwise modulo (inplace on `a`)"""
 
@@ -388,20 +388,25 @@
 
 
 @scalar_elemwise
 def conj_inplace(a):
     """elementwise conjugate (inplace on `a`)"""
 
 
+@scalar_elemwise
+def hyp2f1_inplace(a, b, c, z):
+    """gaussian hypergeometric function"""
+
+
 pprint.assign(add_inplace, printing.OperatorPrinter("+=", -2, "either"))
 pprint.assign(mul_inplace, printing.OperatorPrinter("*=", -1, "either"))
 pprint.assign(sub_inplace, printing.OperatorPrinter("-=", -2, "left"))
 pprint.assign(neg_inplace, printing.OperatorPrinter("-=", 0, "either"))
-pprint.assign(true_div_inplace, printing.OperatorPrinter("/=", -1, "left"))
-pprint.assign(int_div_inplace, printing.OperatorPrinter("//=", -1, "left"))
+pprint.assign(true_divide_inplace, printing.OperatorPrinter("/=", -1, "left"))
+pprint.assign(floor_divide_inplace, printing.OperatorPrinter("//=", -1, "left"))
 pprint.assign(pow_inplace, printing.OperatorPrinter("**=", 1, "right"))
 
 
 def transpose_inplace(x, **kwargs):
     "Perform a transpose on a tensor without copying the underlying storage"
     dims = list(range(x.ndim - 1, -1, -1))
     return DimShuffle(x.broadcastable, dims)(x)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/io.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/io.py`

 * *Files 0% similar despite different names*

```diff
@@ -136,15 +136,14 @@
             [
                 Variable(Generic(), None),
                 tensor(self.dtype, shape=self.static_shape),
             ],
         )
 
     def perform(self, node, inp, out):
-
         data = np.zeros(self.shape, dtype=self.dtype)
         request = comm.Irecv(data, self.source, self.tag)
 
         out[0][0] = request
         out[1][0] = data
 
     def __str__(self):
@@ -180,15 +179,14 @@
         return Apply(
             self,
             [request, data],
             [tensor(data.dtype, shape=data.type.shape)],
         )
 
     def perform(self, node, inp, out):
-
         request = inp[0]
         data = inp[1]
 
         request.wait()
 
         out[0][0] = data
 
@@ -221,15 +219,14 @@
 
     def make_node(self, data):
         return Apply(self, [data], [Variable(Generic(), None), data.type()])
 
     view_map = {1: [0]}
 
     def perform(self, node, inp, out):
-
         data = inp[0]
 
         request = comm.Isend(data, self.dest, self.tag)
 
         out[0][0] = request
         out[1][0] = data
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/math.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/math.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import builtins
 import warnings
-from typing import TYPE_CHECKING, Optional
+from typing import TYPE_CHECKING, List, Literal, Optional, Tuple
 
 import numpy as np
 
 from aesara import config, printing
 from aesara import scalar as aes
 from aesara.gradient import DisconnectedType
 from aesara.graph.basic import Apply, Variable
@@ -18,18 +18,20 @@
 from aesara.tensor.basic import (
     alloc,
     arange,
     as_tensor_variable,
     cast,
     concatenate,
     constant,
+    get_scalar_constant_value,
     stack,
     switch,
 )
 from aesara.tensor.elemwise import CAReduce, DimShuffle, Elemwise, scalar_elemwise
+from aesara.tensor.exceptions import NotScalarConstantError
 from aesara.tensor.shape import shape, specify_broadcastable
 from aesara.tensor.type import (
     DenseTensorType,
     TensorType,
     complex_dtypes,
     continuous_dtypes,
     discrete_dtypes,
@@ -42,14 +44,16 @@
 from aesara.tensor.utils import as_list
 from aesara.tensor.var import TensorConstant
 
 
 if TYPE_CHECKING:
     from numpy.typing import ArrayLike, DTypeLike
 
+    from aesara.tensor.var import TensorVariable
+
 # We capture the builtins that we are going to replace to follow the numpy API
 _abs = builtins.abs
 
 
 if int(config.tensor__cmp_sloppy) > 1:
     # This config variable is a quick-and-dirty way to get low-precision
     # comparisons.  For a more precise setting of these tolerances set
@@ -1150,22 +1154,18 @@
 
 @scalar_elemwise
 def round_half_away_from_zero(a):
     """round_half_away_from_zero(a)"""
 
 
 @scalar_elemwise
-def sqr(a):
+def square(a):
     """square of a"""
 
 
-# alias to sqr, included to maintain similarity with numpy interface
-square = sqr
-
-
 def cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None):
     """Calculate the covariance matrix.
 
     Covariance indicates the level to which two variables vary together.
     If we examine N-dimensional samples, :math:`m = [x_1, x_2, ... x_N]^T`,
     then the covariance matrix element :math:`C_{ij}` is the covariance of
     :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance
@@ -1383,14 +1383,24 @@
 
 @scalar_elemwise
 def gammal(k, x):
     """Lower incomplete gamma function."""
 
 
 @scalar_elemwise
+def hyp2f1(a, b, c, z):
+    """Gaussian hypergeometric function."""
+
+
+@scalar_elemwise
+def hyp2f1_der(a, b, c, z):
+    """Derivatives for Gaussian hypergeometric function."""
+
+
+@scalar_elemwise
 def j0(x):
     """Bessel function of the first kind of order 0."""
 
 
 @scalar_elemwise
 def j1(x):
     """Bessel function of the first kind of order 1."""
@@ -1414,15 +1424,15 @@
 @scalar_elemwise
 def iv(v, x):
     """Modified Bessel function of the first kind of order v (real)."""
 
 
 @scalar_elemwise
 def sigmoid(x):
-    """Logistic sigmoid function (1 / (1 + exp(x)), also known as expit or inverse logit"""
+    """Logistic sigmoid function (1 / (1 + exp(-x)), also known as expit or inverse logit"""
 
 
 expit = sigmoid
 
 
 @scalar_elemwise
 def softplus(x):
@@ -1508,15 +1518,14 @@
         else:
             axis = self.axis[0]
         # numpy.asarray is needed as otherwise we can end up with a
         # numpy scalar.
         output[0] = np.asarray(np.mean(input, dtype="float64", axis=axis))
 
     def c_code(self, node, name, inames, onames, sub):
-
         ret = super().c_code(node, name, inames, onames, sub)
 
         if self.axis is not None:
             return ret
 
         # TODO: c_code perform support only axis is None
         return (
@@ -1594,15 +1603,15 @@
             sum_dtype = "float32"
 
     s = sum(input, axis=axis, dtype=sum_dtype, keepdims=keepdims, acc_dtype=acc_dtype)
     shp = shape(input)
 
     # Cast shp into a float type
     # TODO Once we have a consistent casting policy, we could simply
-    # use true_div.
+    # use true_divide.
     if s.dtype in ("float16", "float32", "complex64"):
         shp = cast(shp, "float32")
     else:
         shp = cast(shp, "float64")
 
     if axis is None:
         axis = list(range(input.ndim))
@@ -1611,15 +1620,15 @@
     elif isinstance(axis, np.ndarray) and axis.ndim == 0:
         axis = [int(axis)]
     else:
         axis = [int(a) for a in axis]
 
     # This sequential division will possibly be optimized by Aesara:
     for i in axis:
-        s = true_div(s, shp[i])
+        s = true_divide(s, shp[i])
 
     # This can happen when axis is an empty list/tuple
     if s.dtype != shp.dtype and s.dtype in discrete_dtypes:
         s = cast(s, shp.dtype)
 
     if dtype == "float16" or (dtype is None and input.dtype == "float16"):
         s = cast(s, "float16")
@@ -1675,34 +1684,34 @@
 
     # compute the axis-wise mean
     mean_input = mean(input, axis, keepdims=True)
 
     # center the input
     centered_input = input - mean_input
 
-    # return the mean sqr
+    # return the mean square
     two = constant(2, dtype=centered_input.dtype)
     if ddof == 0:
         v = mean((centered_input**two), axis, keepdims=keepdims)
     else:
         shp = shape(input) - ddof
         v = sum((centered_input**two), axis=axis, keepdims=keepdims)
         for i in axis:
-            v = true_div(v, shp[i])
+            v = true_divide(v, shp[i])
 
     # use 'corrected_two_pass' algorithm
     if corrected:
         if ddof == 0:
             error = mean(centered_input, axis, keepdims=keepdims) ** 2
         else:
             shp = shape(input) - ddof
             shp_inp = shape(input)
             error = sum(centered_input, axis=axis, keepdims=keepdims) ** 2
             for i in axis:
-                error = true_div(error, shp[i] * shp_inp[i])
+                error = true_divide(error, shp[i] * shp_inp[i])
         v = v - error
 
     v.name = "var"
     return v
 
 
 def std(input, axis=None, ddof=0, keepdims=False, corrected=False):
@@ -1757,16 +1766,16 @@
 @scalar_elemwise(symbolname="scalar_minimum")
 def minimum(x, y):
     """elemwise minimum. See min for the minimum in one tensor"""
     # see decorator for function body
 
 
 def divmod(x, y):
-    """elementvise divmod, using floor_div and mod_check"""
-    return floor_div(x, y), mod_check(x, y)
+    """Element-wise `divmod`, using `floor_divide` and `mod_check`."""
+    return floor_divide(x, y), mod_check(x, y)
 
 
 @scalar_elemwise
 def add(a, *other_terms):
     """elementwise addition"""
     # see decorator for function body
 
@@ -1780,29 +1789,25 @@
 @scalar_elemwise
 def mul(a, *other_terms):
     """elementwise multiplication"""
     # see decorator for function body
 
 
 @scalar_elemwise
-def true_div(a, b):
+def true_divide(a, b):
     """elementwise [true] division (inverse of multiplication)"""
     # see decorator for function body
 
 
 @scalar_elemwise
-def int_div(a, b):
+def floor_divide(a, b):
     """elementwise [floor] division (inverse of multiplication)"""
     # see decorator for function body
 
 
-# floor_div and int_div are the same thing
-floor_div = int_div
-
-
 def ceil_intdiv(a, b):
     """Safely compute ``ceil(float_division(a, b))``.
 
     Works for all dtypes, but mostly useful when `a` and `b` are ints.
 
     """
     # If a and b are int with not many significant bits, we could
@@ -1810,15 +1815,15 @@
     # is faster or not. But this is not safe for int64, because the cast will
     # lose precision. For example:
     #     cast(cast(a, scalar.upcast(a.type.dtype, 'float32')) / b,
     #          aes.upcast(a.type.dtype, b.type.dtype))
 
     # We cast for the case when a and b are uint*; otherwise, neq will
     # force their upcast to int.
-    div = int_div(a, b)
+    div = floor_divide(a, b)
     ret = cast(neq(a % b, 0), div.dtype) + div
     assert ret.dtype == aes.upcast(
         div.owner.inputs[0].type.dtype, div.owner.inputs[1].type.dtype
     )
     return ret
 
 
@@ -1862,16 +1867,16 @@
     # for grep: clamp, bound
 
 
 pprint.assign(add, printing.OperatorPrinter("+", -2, "either"))
 pprint.assign(mul, printing.OperatorPrinter("*", -1, "either"))
 pprint.assign(sub, printing.OperatorPrinter("-", -2, "left"))
 pprint.assign(neg, printing.OperatorPrinter("-", 0, "either"))
-pprint.assign(true_div, printing.OperatorPrinter("/", -1, "left"))
-pprint.assign(int_div, printing.OperatorPrinter("//", -1, "left"))
+pprint.assign(true_divide, printing.OperatorPrinter("/", -1, "left"))
+pprint.assign(floor_divide, printing.OperatorPrinter("//", -1, "left"))
 pprint.assign(pow, printing.OperatorPrinter("**", 1, "right"))
 
 
 class Dot(Op):
     """
     Computes the dot product of two variables. For two matrices, this is
     equivalent to matrix multiplication. For two vectors, this is the inner
@@ -1907,15 +1912,15 @@
         if inputs[1].ndim not in (1, 2):
             raise TypeError(
                 "Input 1 (0-indexed) must have ndim of "
                 f"1 or 2, {int(inputs[1].ndim)} given. Consider calling "
                 "aesara.tensor.dot instead."
             )
 
-        sx, sy = [input.type.shape for input in inputs]
+        sx, sy = (input.type.shape for input in inputs)
         if len(sy) == 2:
             sz = sx[:-1] + sy[-1:]
         elif len(sy) == 1:
             sz = sx[:-1]
 
         i_dtypes = [input.type.dtype for input in inputs]
         outputs = [tensor(aes.upcast(*i_dtypes), shape=sz)]
@@ -1927,15 +1932,14 @@
 
         # the asarray is here because dot between two vectors
         # gives a numpy float object but we need to return a 0d
         # ndarray
         z[0] = np.asarray(np.dot(x, y))
 
     def grad(self, inp, grads):
-
         x, y = inp
         (gz,) = grads
         xdim, ydim, gdim = x.type.ndim, y.type.ndim, gz.type.ndim
 
         # grad is scalar, so x is vector and y is vector
         if gdim == 0:
             xgrad = gz * y
@@ -2618,15 +2622,14 @@
         # NaNs to be eliminated in the `at.switch` if we do have zeros.
         grad_case_without_zeros = gz * prod_out / prod_in
 
         if self.no_zeros_in_input:
             # this handles inputs with zeros, but only certain input shapes
             return [grad_case_without_zeros]
         else:
-
             where_zeros = eq(prod_in, 0.0)
             sum_where_zeros = sum(where_zeros, axis=self.axis)
             groups_with_single_zero = eq(sum_where_zeros, 1).dimshuffle(new_dims)
             # tensor with 0 everywhere except for those places where
             # a 0 part of a group with a single zero was to be found
             where_single_zero = groups_with_single_zero * where_zeros
             # further optimization to avoid computing ProdWithoutZeros
@@ -2911,15 +2914,14 @@
             if validate and x1_shape[-1] != x2_shape[-2]:
                 raise ValueError(
                     "number of columns of input 1 must be equal "
                     "the length of the 2nd-last dimension of input 2"
                 )
             return x2_shape[:-2] + x1_shape[-2:-1] + x2_shape[-1:]
         else:
-
             if validate:
                 from aesara.tensor.random.basic import broadcast_shapes
 
                 bshape = broadcast_shapes(x1_shape[:-2], x2_shape[:-2])
                 if x1_shape[-1] != x2_shape[-2]:
                     raise ValueError(
                         "length of the last dimension of input 1 must be equal "
@@ -2996,14 +2998,116 @@
     - Multiplication by scalars is not allowed, use `mul` instead.
     - Stacks of matrices are broadcast together as if the matrices were elements,
         respecting the signature ``(n, k), (k, m) -> (n, m)``:
     """
     return MatMul(dtype=dtype)(x1, x2)
 
 
+class Convolve(Op):
+    __props__ = ("mode",)
+
+    def __init__(self, mode="full"):
+        self.mode = mode
+
+    @classmethod
+    def _get_output_shape(cls, a, v, shapes, mode, validate=False):
+        a_shape, v_shape = shapes
+        from aesara.tensor.math import maximum, minimum
+
+        if a.ndim == 1 and v.ndim == 1:
+            m, n = a_shape[0], v_shape[0]
+            if n is None or m is None:
+                return (None,)
+            if mode == "full":
+                return (m + n - 1,)
+            elif mode == "same":
+                return (maximum(m, n),)
+            elif mode == "valid":
+                return (maximum(m, n) - minimum(m, n) + 1,)
+            if validate:
+                raise ValueError("Invalid mode - must be full, valid or same")
+            return ()
+        else:
+            if validate:
+                raise ValueError("`a` and `v` must be 1-dim.")
+            return ()
+
+    def make_node(self, a, v):
+        a = as_tensor_variable(a)
+        v = as_tensor_variable(v)
+
+        if a.ndim != 1 or v.ndim != 1:
+            raise ValueError("inputs to `convolve` must be 1-dim.")
+
+        out_shape = self._get_output_shape(
+            a, v, (a.type.shape, v.type.shape), self.mode, validate=True
+        )
+
+        static_out_shape = ()
+        for s in out_shape:
+            try:
+                s_val = get_scalar_constant_value(s)
+            except (NotScalarConstantError, AttributeError):
+                s_val = None
+
+            if s_val:
+                static_out_shape += (s_val,)
+            else:
+                static_out_shape += (None,)
+
+        out = TensorType(
+            aes.upcast(a.type.dtype, v.type.dtype), shape=static_out_shape
+        )()
+        return Apply(self, [a, v], [out])
+
+    def perform(self, node, inputs, outputs):
+        a, v = inputs
+        outputs[0][0] = np.convolve(a, v, mode=self.mode)
+
+    def infer_shape(self, fgraph, node, shapes):
+        a, v = node.inputs
+        return [self._get_output_shape(a, v, shapes, self.mode)]
+
+
+def convolve(
+    a: "ArrayLike", v: "ArrayLike", mode: Literal["full", "same", "valid"] = "full"
+) -> "TensorVariable":
+    """Compute the discrete, linear convolution of two one-dimensional sequences.
+
+    Parameters
+    ----------
+    a, v
+        Input arrays, both should be one dimensional.
+    mode
+       'full':
+            By default, mode is 'full'. This returns the convolution
+            at each point of overlap.
+
+        'same':
+            Mode 'same'. Boundary effects are still visible.
+
+        'valid':
+            The convolution product is only given for points
+            where the signals overlap completely.
+            Values outside the signal boundary have no effect.
+
+    Returns
+    -------
+    out
+        Discrete, linear convolution of a and v.
+
+    Raises
+    ------
+    ValueError
+        If the a and v are not one-dimensional.
+
+    """
+    return Convolve(mode=mode)(a, v)
+
+
 __all__ = [
     "max_and_argmax",
     "max",
     "matmul",
     "argmax",
     "min",
     "argmin",
@@ -3041,15 +3145,14 @@
     "ceil",
     "floor",
     "trunc",
     "iround",
     "round",
     "round_half_to_even",
     "round_half_away_from_zero",
-    "sqr",
     "square",
     "cov",
     "sqrt",
     "deg2rad",
     "rad2deg",
     "cos",
     "arccos",
@@ -3107,36 +3210,54 @@
     "std",
     "maximum",
     "minimum",
     "divmod",
     "add",
     "sub",
     "mul",
-    "true_div",
-    "int_div",
-    "floor_div",
+    "true_divide",
+    "floor_divide",
     "ceil_intdiv",
     "mod",
     "pow",
     "clip",
     "dot",
     "dense_dot",
     "tensordot",
     "outer",
     "any",
     "all",
     "ptp",
     "power",
     "logaddexp",
     "logsumexp",
+    "hyp2f1",
+    "hyp2f1_der",
+    "convolve",
 ]
 
-DEPRECATED_NAMES = [
+DEPRECATED_NAMES: List[Tuple[str, str, object]] = [
     ("abs_", "`abs_` is deprecated; use `abs` instead.", abs),
     ("inv", "`inv` is deprecated; use `reciprocal` instead.", reciprocal),
+    (
+        "true_div",
+        "`true_div` is deprecated; use `true_divide` or `divide` instead.",
+        true_divide,
+    ),
+    ("int_div", "`int_div` is deprecated; use `floor_divide` instead.", floor_divide),
+    (
+        "floor_div",
+        "`floor_div` is deprecated; use `floor_divide` instead.",
+        floor_divide,
+    ),
+    (
+        "sqr",
+        "`sqr` is deprecated; use `square` instead.",
+        square,
+    ),
 ]
 
 
 def __getattr__(name):
     """Intercept module-level attribute access of deprecated symbols.
 
     Adapted from https://stackoverflow.com/a/55139609/3006474.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nlinalg.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nlinalg.py`

 * *Files 0% similar despite different names*

```diff
@@ -246,15 +246,15 @@
         w = vector(dtype=x.dtype)
         v = matrix(dtype=x.dtype)
         return Apply(self, [x], [w, v])
 
     def perform(self, node, inputs, outputs):
         (x,) = inputs
         (w, v) = outputs
-        w[0], v[0] = [z.astype(x.dtype) for z in self._numop(x)]
+        w[0], v[0] = (z.astype(x.dtype) for z in self._numop(x))
 
     def infer_shape(self, fgraph, node, shapes):
         n = shapes[0][0]
         return [(n,), (n, n)]
 
 
 eig = Eig()
@@ -579,15 +579,14 @@
     U, V,  D : matrices
 
     """
     return SVD(full_matrices, compute_uv)(a)
 
 
 class Lstsq(Op):
-
     __props__ = ()
 
     def make_node(self, x, y, rcond):
         x = as_tensor_variable(x)
         y = as_tensor_variable(y)
         rcond = as_tensor_variable(rcond)
         return Apply(
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/__init__.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/__init__.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/abstract_conv.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/abstract_conv.py`

 * *Files 0% similar despite different names*

```diff
@@ -2141,15 +2141,14 @@
         border_mode="valid",
         subsample=None,
         filter_flip=True,
         filter_dilation=None,
         num_groups=1,
         unshared=False,
     ):
-
         self.convdim = convdim
         if convdim not in (2, 3):
             raise ValueError("convolution dimension {} is not supported", convdim)
 
         if subsample is None:
             subsample = (1,) * convdim
         if filter_dilation is None:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/basic.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -36,15 +36,15 @@
     mul,
     neg,
     or_,
     sigmoid,
     softplus,
 )
 from aesara.tensor.math import sum as at_sum
-from aesara.tensor.math import tanh, tensordot, true_div
+from aesara.tensor.math import tanh, tensordot, true_divide
 from aesara.tensor.nnet.blocksparse import sparse_block_dot
 from aesara.tensor.rewriting.basic import (
     register_canonicalize,
     register_specialize,
     register_stabilize,
 )
 from aesara.tensor.rewriting.math import local_mul_canonizer
@@ -569,15 +569,14 @@
         x_shp, b_shp, idx_shp = shapes
         nll_shp = (x_shp[0],)
         sm_shp = x_shp
         am_shp = idx_shp
         return [nll_shp, sm_shp, am_shp]
 
     def connection_pattern(self, node):
-
         return [
             [True, True, True],  # x
             [True, True, True],  # b
             [False, False, True],
         ]  # y_idx
 
     def grad(self, inp, grads):
@@ -917,15 +916,14 @@
 
 def crossentropy_softmax_max_and_argmax_1hot(x, y_idx, **kwargs):
     b = at.zeros_like(x[0, :])
     return crossentropy_softmax_max_and_argmax_1hot_with_bias(x, b, y_idx, **kwargs)
 
 
 class CrossentropyCategorical1HotGrad(Op):
-
     __props__ = ()
 
     def make_node(self, g_y, coding_dist, true_one_of_n):
         return Apply(self, [g_y, coding_dist, true_one_of_n], [coding_dist.type()])
 
     def perform(self, node, inp, out):
         g_y, coding_dist, true_one_of_n = inp
@@ -1338,15 +1336,15 @@
 
         # If there's a 'minus' sign before the whole expression, put it in
         # out_grad and iterate
         if incr.owner and incr.owner.op == neg:
             out_grad = -out_grad
             incr = incr.owner.inputs[0]
 
-        if incr.owner and incr.owner.op == true_div:
+        if incr.owner and incr.owner.op == true_divide:
             num, denom = incr.owner.inputs
 
             # set out_grad according to the numerator, it may be divided later
             # num should be a vector or a scalar
             if num.ndim == 1 or all(num.broadcastable):
                 out_grad *= -num
             else:
@@ -1402,15 +1400,15 @@
         # Check that rows is arange(labels.shape[0])
         if not _check_rows_is_arange_len_labels(fgraph, rows, labels):
             return
         # else, arguments of AdvancedIncSubtensor are OK,
         # it was really case 1.
 
     # Second case
-    elif d_sm.owner and d_sm.owner.op == true_div:
+    elif d_sm.owner and d_sm.owner.op == true_divide:
         # we're looking for
         # AdvIncSubtensor(zeros, grad_nll, arange(len(y)), y) / softmax
         try:
             num, denom = d_sm.owner.inputs
         except Exception:
             return
 
@@ -1651,15 +1649,14 @@
     elif true_dist.ndim == coding_dist.ndim - 1:
         return crossentropy_categorical_1hot(coding_dist, true_dist)
     else:
         raise TypeError("rank mismatch between coding and true distributions")
 
 
 class Prepend_scalar_constant_to_each_row(Op):
-
     __props__ = ()
 
     def __init__(self, val=0):
         if isinstance(val, float):
             val = aes.constant(val)
         self.val = val
 
@@ -1704,15 +1701,14 @@
     def grad(self, inp, grads):
         (mat,) = inp
         (goutput,) = grads
         return goutput[:, 1:]
 
 
 class Prepend_scalar_to_each_row(Op):
-
     __props__ = ()
 
     def make_node(self, val, mat):
         # check type of input
         x = at.as_tensor_variable(mat)
         if isinstance(val, float):
             val = aes.constant(val)
@@ -1948,28 +1944,26 @@
         ICASSP, 2001, <http://arxiv.org/abs/cs/0108006>`.
     """
 
     # First softmax that computes the probabilities of belonging to each class
     class_probs = softmax(dot(x, W1) + b1)
 
     if target is None:  # Computes the probabilities of all the outputs
-
         # Second softmax that computes the output probabilities
         activations = tensordot(x, W2, (1, 1)) + b2
         output_probs = softmax(activations.reshape((-1, n_outputs_per_class)))
         output_probs = output_probs.reshape((batch_size, n_classes, -1))
         output_probs = class_probs.dimshuffle(0, 1, "x") * output_probs
         output_probs = output_probs.reshape((batch_size, -1))
         # output_probs.shape[1] is n_classes * n_outputs_per_class, which might
         # be greater than n_outputs, so we ignore the potential irrelevant
         # outputs with the next line:
         output_probs = output_probs[:, :n_outputs]
 
     else:  # Computes the probabilities of the outputs specified by the targets
-
         target = target.flatten()
 
         # Classes to which belong each target
         target_classes = target // n_outputs_per_class
 
         # Outputs to which belong each target inside a class
         target_outputs_in_class = target % n_outputs_per_class
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/batchnorm.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/batchnorm.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import numpy as np
 
 import aesara
 from aesara.configdefaults import config
 from aesara.graph.basic import Apply
 from aesara.graph.op import Op
 from aesara.graph.rewriting.basic import copy_stack_trace, node_rewriter
-from aesara.scalar import Composite, add, as_common_dtype, mul, sub, true_div
+from aesara.scalar import Composite, add, as_common_dtype, mul, sub, true_divide
 from aesara.tensor import basic as at
 from aesara.tensor.basic import as_tensor_variable
 from aesara.tensor.elemwise import Elemwise
 from aesara.tensor.math import mean, prod, reciprocal, sqrt
 from aesara.tensor.math import sum as at_sum
 from aesara.tensor.rewriting.basic import register_specialize_device
 from aesara.tensor.shape import specify_broadcastable
@@ -23,15 +23,15 @@
     def __init__(self, dtype):
         self.dtype = dtype
         x = aesara.scalar.ScalarType(dtype=dtype).make_variable()
         mean = aesara.scalar.ScalarType(dtype=dtype).make_variable()
         std = aesara.scalar.ScalarType(dtype=dtype).make_variable()
         gamma = aesara.scalar.ScalarType(dtype=dtype).make_variable()
         beta = aesara.scalar.ScalarType(dtype=dtype).make_variable()
-        o = add(mul(true_div(sub(x, mean), std), gamma), beta)
+        o = add(mul(true_divide(sub(x, mean), std), gamma), beta)
         inputs = [x, mean, std, gamma, beta]
         outputs = [o]
         super().__init__(inputs, outputs)
 
     def grad(self, inps, grads):
         x, mean, std, gamma, beta = inps
         (top,) = grads
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/blocksparse.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/blocksparse.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/corr3d_gemm.c` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/corr3d_gemm.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/corr_gemm.c` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/corr_gemm.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/c_code/ctc_wrapper.c` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/c_code/ctc_wrapper.c`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/conv.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/conv.py`

 * *Files 0% similar despite different names*

```diff
@@ -517,15 +517,14 @@
 
         # downcast unroll_batch if not a divisor of batch size
         if (
             self.unroll_batch is not None
             and self.unroll_batch > 0
             and self.bsize % self.unroll_batch != 0
         ):
-
             if self.bsize <= self.unroll_batch:
                 self.unroll_batch = self.bsize
             else:
                 # find the maximum value under unroll_batch that would work
                 new = self.unroll_batch
                 assert new >= 1
                 while self.bsize % new != 0:
@@ -543,15 +542,14 @@
 
         # downcast unroll_kern if not a divisor of nb of kernel
         if (
             self.unroll_kern is not None
             and self.unroll_kern > 0
             and self.nkern % self.unroll_kern != 0
         ):
-
             if self.nkern <= self.unroll_kern:
                 self.unroll_kern = self.nkern
             else:
                 # find the maximum value under unroll_kern that would work
                 new = self.unroll_kern
                 assert new >= 1
                 while self.nkern % new != 0:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/conv3d2d.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/conv3d2d.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/corr.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/corr.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/corr3d.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/corr3d.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/ctc.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/ctc.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/neighbours.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/neighbours.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/rewriting.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/rewriting.py`

 * *Files 0% similar despite different names*

```diff
@@ -254,15 +254,14 @@
     copy_stack_trace(node.outputs[0], rval)
 
     return [rval]
 
 
 @node_rewriter([AbstractConv2d])
 def local_conv2d_cpu(fgraph, node):
-
     if not isinstance(node.op, AbstractConv2d) or node.inputs[0].dtype == "float16":
         return None
 
     img, kern = node.inputs
     if not isinstance(img.type, TensorType) or not isinstance(kern.type, TensorType):
         return None
     if node.op.border_mode not in ("full", "valid"):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/nnet/sigm.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/nnet/sigm.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/basic.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/basic.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 import abc
+from functools import partial
 from typing import List, Optional, Union
 
 import numpy as np
 import scipy.stats as stats
 
 import aesara
 from aesara.tensor.basic import as_tensor_variable
@@ -20,14 +21,21 @@
 except AttributeError:
     from numpy.lib.stride_tricks import _broadcast_shape
 
     def broadcast_shapes(*shapes):
         return _broadcast_shape(*[np.empty(x, dtype=[]) for x in shapes])
 
 
+def get_partial_wrapper(rv, name, *args, **kwargs):
+    func = partial(rv, *args, **kwargs)
+    func.__name__ = name
+    func.__module__ = rv.__module__
+    return func
+
+
 class ScipyRandomVariable(RandomVariable):
     r"""A class for straightforward `RandomVariable`\s that use SciPy-based samplers.
 
     By "straightforward" we mean `RandomVariable`\s for which the output shape
     is entirely determined by broadcasting the distribution parameters
     (e.g. basic scalar distributions).
 
@@ -221,92 +229,185 @@
         """
         return super().__call__(alpha, beta, size=size, **kwargs)
 
 
 beta = BetaRV()
 
 
-class NormalRV(RandomVariable):
-    r"""A normal continuous random variable.
+class RayleighRV(RandomVariable):
+    r"""A rayleigh continuous random variable.
 
-    The probability density function for `normal` in terms of its location parameter (mean)
-    :math:`\mu` and scale parameter (standard deviation) :math:`\sigma` is:
+    The probability density function for `rayleigh` is:
 
     .. math::
 
-        f(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
+        P(x;scale) = \\frac{x}{scale^2}e^{\\frac{-x^2}{2 \\cdotp scale^2}}
 
-    for :math:`\sigma > 0`.
 
     """
-    name = "normal"
+    name = "rayleigh"
     ndim_supp = 0
-    ndims_params = [0, 0]
+    ndims_params = [0]
     dtype = "floatX"
-    _print_name = ("N", "\\operatorname{N}")
+    _print_name = ("Rayleigh", "\\operatorname{Rayleigh}")
 
-    def __call__(self, loc=0.0, scale=1.0, size=None, **kwargs):
-        r"""Draw samples from a normal distribution.
+    def __call__(self, scale=1.0, size=None, **kwargs):
+        r"""Draw samples from a rayleigh distribution.
 
         Signature
         ---------
 
-        `(), () -> ()`
+        `() -> ()`
 
         Parameters
         ----------
-        loc
-            Mean :math:`\mu` of the normal distribution.
         scale
-            Standard deviation :math:`\sigma` of the normal distribution. Must be positive.
+            Scale, also equals the mode. Must be non-negative. Default is 1
         size
             Sample shape. If the given size is, e.g. `(m, n, k)` then `m * n * k`
             independent, identically distributed random variables are
             returned. Default is `None` in which case a single random variable
             is returned.
 
         """
-        return super().__call__(loc, scale, size=size, **kwargs)
+        return super().__call__(scale, size=size, **kwargs)
 
 
-normal = NormalRV()
+rayleigh = RayleighRV()
+
+
+class PowerRV(RandomVariable):
+    r"""A power continuous random variable.
+
+    The probability density function for `power` is:
+
+    .. math::
+
+        P(x; a) = ax^{a-1}, 0 \\le x \\le 1, a>0.
+
+    """
+    name = "power"
+    ndim_supp = 0
+    ndims_params = [0]
+    dtype = "floatX"
+    _print_name = ("Power", "\\operatorname{Power}")
+
+    def __call__(self, a, size=None, **kwargs):
+        r"""Draw samples from a rayleigh distribution.
+
+        Signature
+        ---------
+
+        `() -> ()`
+
+        Parameters
+        ----------
+        a
+            Parameter of the distribution. Must be non-negative.
+        size
+            Sample shape. If the given size is, e.g. `(m, n, k)` then `m * n * k`
+            independent, identically distributed random variables are
+            returned. Default is `None` in which case a single random variable
+            is returned.
+
+        """
+        return super().__call__(a, size=size, **kwargs)
+
+
+power = PowerRV()
+
 
+class ZipfRV(RandomVariable):
+    r"""A zipf discrete random variable.
 
-class StandardNormalRV(NormalRV):
-    r"""A standard normal continuous random variable.
+    The probability density function for `zipf` is:
 
-    The probability density function for `standard_normal` is:
+    .. math::
+
+        p(x) = \\frac{x^{-a}}{\\zeta(a)},
+
+    where :math:`\\zeta` is the Riemann Zeta function.
+
+    """
+    name = "zipf"
+    ndim_supp = 0
+    ndims_params = [0]
+    dtype = "int64"
+    _print_name = ("Zipf", "\\operatorname{Zipf}")
+
+    def __call__(self, a, size=None, **kwargs):
+        r"""Draw samples from a rayleigh distribution.
+
+        Signature
+        ---------
+
+        `() -> ()`
+
+        Parameters
+        ----------
+        a
+            Distribution parameter. Must be greater than 1.
+        size
+            Sample shape. If the given size is, e.g. `(m, n, k)` then `m * n * k`
+            independent, identically distributed random variables are
+            returned. Default is `None` in which case a single random variable
+            is returned.
+
+        """
+        return super().__call__(a, size=size, **kwargs)
+
+
+zipf = ZipfRV()
+
+
+class NormalRV(RandomVariable):
+    r"""A normal continuous random variable.
+
+    The probability density function for `normal` in terms of its location parameter (mean)
+    :math:`\mu` and scale parameter (standard deviation) :math:`\sigma` is:
 
     .. math::
 
-        f(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}}
+        f(x; \mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
+
+    for :math:`\sigma > 0`.
 
     """
+    name = "normal"
+    ndim_supp = 0
+    ndims_params = [0, 0]
+    dtype = "floatX"
+    _print_name = ("N", "\\operatorname{N}")
 
-    def __call__(self, size=None, **kwargs):
-        """Draw samples from a standard normal distribution.
+    def __call__(self, loc=0.0, scale=1.0, size=None, **kwargs):
+        r"""Draw samples from a normal distribution.
 
         Signature
         ---------
 
-        `nil -> ()`
+        `(), () -> ()`
 
         Parameters
         ----------
+        loc
+            Mean :math:`\mu` of the normal distribution.
+        scale
+            Standard deviation :math:`\sigma` of the normal distribution. Must be positive.
         size
             Sample shape. If the given size is, e.g. `(m, n, k)` then `m * n * k`
             independent, identically distributed random variables are
             returned. Default is `None` in which case a single random variable
             is returned.
 
         """
-        return super().__call__(loc=0.0, scale=1.0, size=size, **kwargs)
+        return super().__call__(loc, scale, size=size, **kwargs)
 
 
-standard_normal = StandardNormalRV()
+normal = NormalRV()
+standard_normal = get_partial_wrapper(normal, "standard_normal", loc=0.0, scale=1.0)
 
 
 class HalfNormalRV(ScipyRandomVariable):
     r"""A half-normal continuous random variable.
 
     The probability density function for `halfnormal` in terms of its location parameter
     :math:`\mu` and scale parameter :math:`\sigma` is:
@@ -465,14 +566,15 @@
 
     @classmethod
     def rng_fn_scipy(cls, rng, shape, scale, size):
         return stats.gamma.rvs(shape, scale=scale, size=size, random_state=rng)
 
 
 gamma = GammaRV()
+standard_gamma = get_partial_wrapper(gamma, "standard_gamma", rate=1.0)
 
 
 class ChiSquareRV(RandomVariable):
     r"""A chi square continuous random variable.
 
     The probability density function for `chisquare` in terms of the number of degrees of
     freedom :math:`k` is:
@@ -672,14 +774,17 @@
             is returned.
 
         """
         return super().__call__(scale, size=size, **kwargs)
 
 
 exponential = ExponentialRV()
+standard_exponential = get_partial_wrapper(
+    exponential, "standard_exponential", scale=1.0
+)
 
 
 class WeibullRV(RandomVariable):
     r"""A weibull continuous random variable.
 
     The probability density function for `weibull` in terms of its shape parameter :math:`k` is :
 
@@ -884,15 +989,14 @@
             mean = np.array([0.0], dtype=dtype)
         if cov is None:
             cov = np.array([[1.0]], dtype=dtype)
         return super().__call__(mean, cov, size=size, **kwargs)
 
     @classmethod
     def rng_fn(cls, rng, mean, cov, size):
-
         if mean.ndim > 1 or cov.ndim > 2:
             # Neither SciPy nor NumPy implement parameter broadcasting for
             # multivariate normals (or any other multivariate distributions),
             # so we need to implement that here
 
             size = tuple(size or ())
             if size:
@@ -1159,14 +1263,15 @@
 
     @classmethod
     def rng_fn_scipy(cls, rng, loc, scale, size):
         return stats.cauchy.rvs(loc=loc, scale=scale, random_state=rng, size=size)
 
 
 cauchy = CauchyRV()
+standard_cauchy = get_partial_wrapper(cauchy, "standard_cauchy", loc=0.0, scale=1.0)
 
 
 class HalfCauchyRV(ScipyRandomVariable):
     r"""A half-Cauchy continuous random variable.
 
     The probability density function for `halfcauchy` in terms of its location
     parameter :math:`x_0` and scale parameter :math:`\gamma` is:
@@ -1418,14 +1523,15 @@
 
     @classmethod
     def rng_fn_scipy(cls, rng, df, loc, scale, size):
         return stats.t.rvs(df, loc=loc, scale=scale, size=size, random_state=rng)
 
 
 t = StudentTRV()
+standard_t = get_partial_wrapper(t, "standard_t", loc=0.0, scale=1.0)
 
 
 class BernoulliRV(ScipyRandomVariable):
     r"""A Bernoulli discrete random variable.
 
     The probability mass function for `bernoulli` in terms of the probability
     of success :math:`p` of a single trial is:
@@ -2049,15 +2155,14 @@
     _print_name = ("permutation", "\\operatorname{permutation}")
 
     @classmethod
     def rng_fn(cls, rng, x, size):
         return rng.permutation(x if x.ndim > 0 else x.item())
 
     def _infer_shape(self, size, dist_params, param_shapes=None):
-
         param_shapes = param_shapes or [p.shape for p in dist_params]
 
         (x,) = dist_params
         (x_shape,) = param_shapes
 
         if x.ndim == 0:
             return (x,)
@@ -2121,13 +2226,20 @@
     "gamma",
     "lognormal",
     "halfnormal",
     "normal",
     "beta",
     "triangular",
     "uniform",
+    "standard_cauchy",
+    "standard_exponential",
+    "standard_gamma",
     "standard_normal",
+    "standard_t",
     "negative_binomial",
     "gengamma",
     "t",
     "random",
+    "rayleigh",
+    "power",
+    "zipf",
 ]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/op.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/op.py`

 * *Files 0% similar despite different names*

```diff
@@ -72,18 +72,16 @@
     if param_shapes is not None:
         ref_param = param_shapes[rep_param_idx]
         return (ref_param[-ndim_supp],)
     else:
         ref_param = dist_params[rep_param_idx]
         if ref_param.ndim < ndim_supp:
             raise ValueError(
-                (
-                    "Reference parameter does not match the "
-                    f"expected dimensions; {ref_param} has less than {ndim_supp} dim(s)."
-                )
+                "Reference parameter does not match the "
+                f"expected dimensions; {ref_param} has less than {ndim_supp} dim(s)."
             )
         return ref_param.shape[-ndim_supp:]
 
 
 class RandomVariable(Op):
     """An `Op` that produces a sample from a random variable.
 
@@ -162,15 +160,15 @@
         return default_supp_shape_from_params(self.ndim_supp, dist_params, **kwargs)
 
     def rng_fn(self, rng, *args, **kwargs) -> Union[int, float, np.ndarray]:
         """Sample a numeric random variate."""
         return getattr(rng, self.name)(*args, **kwargs)
 
     def __str__(self):
-        props_str = ", ".join((f"{getattr(self, prop)}" for prop in self.__props__[1:]))
+        props_str = ", ".join(f"{getattr(self, prop)}" for prop in self.__props__[1:])
         return f"{self.name}_rv{{{props_str}}}"
 
     def _infer_shape(
         self,
         size: TensorVariable,
         dist_params: Sequence[TensorVariable],
         param_shapes: Optional[Sequence[Tuple[Variable, ...]]] = None,
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/basic.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/rewriting/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -180,15 +180,14 @@
     ds_reps_new_dims = dim_orders[:reps_ind_split_idx]
     ds_ind_new_dims = dim_orders[reps_ind_split_idx:]
     ds_in_ind_space = ds_ind_new_dims and all(
         d >= reps_ind_split_idx for n, d in ds_ind_new_dims
     )
 
     if ds_in_ind_space or (not ds_ind_new_dims and not ds_reps_new_dims):
-
         # Update the `size` array to reflect the `DimShuffle`d dimensions,
         # since the trailing dimensions in `size` represent the independent
         # variates dimensions (for univariate distributions, at least)
         has_size = get_vector_length(size) > 0
         new_size = (
             [constant(1, dtype="int64") if o == "x" else size[o] for o in ds_new_order]
             if has_size
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/rewriting/jax.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/rewriting/jax.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/type.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/type.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/utils.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 from collections.abc import Sequence
-from functools import wraps
+from functools import partial, wraps
 from itertools import zip_longest
 from types import ModuleType
-from typing import TYPE_CHECKING, Optional, Union
+from typing import Callable, Literal, Optional, Union
 
 import numpy as np
-from typing_extensions import Literal
 
 from aesara.compile.sharedvalue import shared
 from aesara.graph.basic import Constant, Variable
 from aesara.tensor import get_vector_length
 from aesara.tensor.basic import as_tensor_variable, cast, constant
 from aesara.tensor.extra_ops import broadcast_to
 from aesara.tensor.math import maximum
 from aesara.tensor.shape import specify_shape
 from aesara.tensor.type import int_dtypes
 from aesara.tensor.var import TensorVariable
 
 
-if TYPE_CHECKING:
-    from aesara.tensor.random.op import RandomVariable
-
-
 def params_broadcast_shapes(param_shapes, ndims_params, use_aesara=True):
     """Broadcast parameters that have different dimensions.
 
     Parameters
     ==========
     param_shapes : list of ndarray or Variable
         The shapes of each parameters to broadcast.
@@ -184,40 +179,40 @@
             self.namespaces = [namespace]
 
         self.default_instance_seed = seed
         self.state_updates = []
         self.gen_seedgen = np.random.SeedSequence(seed)
 
         if isinstance(rng_ctor, type) and issubclass(rng_ctor, np.random.RandomState):
-
             # The legacy state does not accept `SeedSequence`s directly
             def rng_ctor(seed):
                 return np.random.RandomState(np.random.MT19937(seed))
 
         self.rng_ctor = rng_ctor
 
     def __getattr__(self, obj):
-
         ns_obj = next(
             (getattr(ns, obj) for ns in self.namespaces if hasattr(ns, obj)), None
         )
 
         if ns_obj is None:
-            raise AttributeError("No attribute {}.".format(obj))
+            raise AttributeError(f"No attribute {obj}.")
 
         from aesara.tensor.random.op import RandomVariable
 
-        if isinstance(ns_obj, RandomVariable):
+        if isinstance(ns_obj, RandomVariable) or (
+            isinstance(ns_obj, partial) and isinstance(ns_obj.func, RandomVariable)
+        ):
 
             @wraps(ns_obj)
             def meta_obj(*args, **kwargs):
                 return self.gen(ns_obj, *args, **kwargs)
 
         else:
-            raise AttributeError("No attribute {}.".format(obj))
+            raise AttributeError(f"No attribute {obj}.")
 
         setattr(self, obj, meta_obj)
         return getattr(self, obj)
 
     def updates(self):
         return list(self.state_updates)
 
@@ -241,21 +236,21 @@
 
         self.gen_seedgen = np.random.SeedSequence(seed)
         old_r_seeds = self.gen_seedgen.spawn(len(self.state_updates))
 
         for (old_r, new_r), old_r_seed in zip(self.state_updates, old_r_seeds):
             old_r.set_value(self.rng_ctor(old_r_seed), borrow=True)
 
-    def gen(self, op: "RandomVariable", *args, **kwargs) -> TensorVariable:
+    def gen(self, op: Callable, *args, **kwargs) -> TensorVariable:
         r"""Generate a draw from `op` seeded from this `RandomStream`.
 
         Parameters
         ----------
         op
-            A `RandomVariable` instance
+            A callable that creates a `RandomVariable`/sampler graph.
         args
             Positional arguments passed to `op`.
         kwargs
             Keyword arguments passed to `op`.
 
         Returns
         -------
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/random/var.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/random/var.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,25 +1,38 @@
 import copy
+from typing import TypeVar
 
 import numpy as np
 
 from aesara.compile.sharedvalue import SharedVariable, shared_constructor
-from aesara.tensor.random.type import random_generator_type, random_state_type
+from aesara.tensor.random.type import (
+    RandomGeneratorType,
+    RandomStateType,
+    RandomType,
+    random_generator_type,
+    random_state_type,
+)
 
 
-class RandomStateSharedVariable(SharedVariable):
-    def __str__(self):
-        return self.name or "RandomStateSharedVariable({})".format(repr(self.container))
+RNGTypeType = TypeVar("RNGTypeType", bound=RandomType)
+
 
+class RandomTypeSharedVariable(SharedVariable[RNGTypeType]):
+    """A `Variable` type representing shared RNG states."""
 
-class RandomGeneratorSharedVariable(SharedVariable):
     def __str__(self):
-        return self.name or "RandomGeneratorSharedVariable({})".format(
-            repr(self.container)
-        )
+        return self.name or f"{self.__class__.__name__}({repr(self.container)})"
+
+
+class RandomStateSharedVariable(RandomTypeSharedVariable[RandomStateType]):
+    pass
+
+
+class RandomGeneratorSharedVariable(RandomTypeSharedVariable[RandomGeneratorType]):
+    pass
 
 
 @shared_constructor.register(np.random.RandomState)
 @shared_constructor.register(np.random.Generator)
 def randomgen_constructor(
     value, name=None, strict=False, allow_downcast=None, borrow=False
 ):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/basic.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/basic.py`

 * *Files 0% similar despite different names*

```diff
@@ -322,15 +322,15 @@
                 ref_var_idx = idx
                 break
 
     if not hasattr(fgraph, "shape_feature"):
         return False
 
     input_shapes = [
-        tuple(fgraph.shape_feature.get_shape(i, j) for j in range(i.type.ndim))
+        tuple(fgraph.shape_feature.get_shape(fgraph, i, j) for j in range(i.type.ndim))
         for i in node.inputs
     ]
     bcasted_shape = broadcast_shape(
         *input_shapes,
         arrays_are_shapes=True,
     )
 
@@ -634,15 +634,14 @@
         elif node.op.scalar_op == aes.add and len(node.inputs) == 1:
             # No need to copy over any stack trace
             return [node.inputs[0]]
         elif node.op.scalar_op == aes.identity and len(node.inputs) == 1:
             return [node.inputs[0]]
 
         elif isinstance(node.op.scalar_op, aes.AND) and len(node.inputs) == 2:
-
             if isinstance(node.inputs[0], TensorConstant):
                 const_val = extract_constant(
                     node.inputs[0], only_process_constants=True
                 )
                 if not isinstance(const_val, Variable):
                     if const_val == 0:
                         return [zeros_like(node.inputs[1], dtype=dtype, opt=True)]
@@ -660,15 +659,14 @@
                         return [zeros_like(node.inputs[0], dtype=dtype, opt=True)]
                     elif node.outputs[0].dtype == "bool":
                         # If the output is not Boolean, it is the bitwise AND,
                         # and this rewrite would be wrong
                         return [node.inputs[0].astype(node.outputs[0].dtype)]
 
         elif isinstance(node.op.scalar_op, aes.OR) and len(node.inputs) == 2:
-
             if isinstance(node.inputs[0], TensorConstant):
                 const_val = extract_constant(
                     node.inputs[0], only_process_constants=True
                 )
                 if not isinstance(const_val, Variable):
                     if const_val == 0:
                         return [node.inputs[1].astype(node.outputs[0].dtype)]
@@ -1018,15 +1016,15 @@
 
         if correct_out.dtype != node.outputs[0].dtype:
             out = cast(correct_out, node.outputs[0].dtype)
         else:
             out = correct_out
 
         input_shapes = [
-            tuple(shape_feature.get_shape(inp, i) for i in range(inp.type.ndim))
+            tuple(shape_feature.get_shape(fgraph, inp, i) for i in range(inp.type.ndim))
             for inp in node.inputs
         ]
 
         out_shape = broadcast_shape(*input_shapes, arrays_are_shapes=True)
 
         out = alloc(out, *out_shape)
 
@@ -1121,15 +1119,14 @@
             copy_stack_trace(out, out2)
 
             return [out2]
 
 
 @node_rewriter(None)
 def constant_folding(fgraph, node):
-
     if not node.op.do_constant_folding(fgraph, node):
         return False
 
     if not all(isinstance(inp, Constant) for inp in node.inputs):
         return False
 
     storage_map = {i: [i.data] for i in node.inputs}
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/elemwise.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/elemwise.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 import sys
 import time
 from collections import defaultdict
 from typing import Optional
 from warnings import warn
 
-import aesara
 import aesara.scalar.basic as aes
 from aesara import compile
 from aesara.compile.mode import get_target_language
 from aesara.configdefaults import config
 from aesara.graph.basic import Apply, Constant, io_toposort
 from aesara.graph.features import ReplaceValidate
 from aesara.graph.op import compute_test_value, get_test_value
@@ -114,21 +113,17 @@
         chk = fgraph.checkpoint()
 
         if fgraph.update_mapping:
             update_outs = [fgraph.outputs[i] for i in fgraph.update_mapping]
         else:
             update_outs = []
 
-        protected_inputs = [
-            f.protected
-            for f in fgraph._features
-            if isinstance(f, aesara.compile.function.types.Supervisor)
-        ]
-        protected_inputs = sum(protected_inputs, [])  # flatten the list
-        protected_inputs.extend(fgraph.outputs)
+        protected_inputs = getattr(fgraph, "_supervisor_protected", set())
+        protected_inputs.update(fgraph.outputs)
+
         for node in list(io_toposort(fgraph.inputs, fgraph.outputs)):
             op = node.op
             if not isinstance(op, self.op):
                 continue
             # If big graph and the outputs are scalar, do not make it
             # inplace.
             if (
@@ -180,24 +175,22 @@
                 ]
 
             verbose = False
 
             raised_warning = not verbose
 
             for candidate_output in candidate_outputs:
-
                 # If the output of the node can be established as an update
                 # output of the fgraph, visit the candidate_inputs in an order
                 # that will improve the chances of making the node operate
                 # inplace on the input it's meant to update
                 candidate_out_var = node.outputs[candidate_output]
                 sorted_candidate_inputs = candidate_inputs
 
                 if candidate_out_var in update_outs:
-
                     # The candidate output is an update. Sort the
                     # variables in candidate_inputs in the following order:
                     # - Vars corresponding to the actual updated input
                     #   (best case scenario is for the node that procudes
                     #   an update to operate inplace on the variable to
                     #   update)
                     # - Vars computed inplace on the updates input (second
@@ -221,20 +214,18 @@
                         if inp in updated_inputs:
                             # the candidate input is the actual updated input
                             updated_vars.append(inp_idx)
                         elif (
                             hasattr(fgraph, "destroy_handler")
                             and inp.owner
                             and any(
-                                fgraph.destroy_handler.root_destroyer.get(up_inp, None)
-                                is inp.owner
+                                fgraph.root_destroyer.get(up_inp, None) is inp.owner
                                 for up_inp in updated_inputs
                             )
                         ):
-
                             # the candidate input is a variable computed
                             # inplace on the updated input via a sequence of
                             # one or more inplace operations
                             vars_from_inplace.append(inp_idx)
                         else:
                             other_vars.append(inp_idx)
 
@@ -688,20 +679,18 @@
                         ["x" for x in i.owner.inputs],
                         ["z" for z in i.owner.outputs],
                         {"fail": "%(fail)s"},
                     )
 
                 except (NotImplementedError, MethodNotDefined):
                     warn(
-                        (
-                            "Rewrite warning: "
-                            f"The Op {i.owner.op.scalar_op} does not provide a C implementation."
-                            " As well as being potentially slow, this also disables "
-                            "loop fusion."
-                        )
+                        "Rewrite warning: "
+                        f"The Op {i.owner.op.scalar_op} does not provide a C implementation."
+                        " As well as being potentially slow, this also disables "
+                        "loop fusion."
                     )
                     scalar_node = None
 
             # Compute the number of inputs in case we fuse this input.
             # We subtract 1 because we replace the existing input with the new
             # inputs from `tmp_input`.
             new_nb_input_ = new_nb_input + len(tmp_input) - 1
@@ -758,20 +747,18 @@
                 ["x" for x in s_g],
                 ["z" for x in s_new_out],
                 {"fail": "%(fail)s"},
             )
         except (NotImplementedError, MethodNotDefined):
             name = str(s_new_out[0].owner.op)
             warn(
-                (
-                    "Rewrite warning: "
-                    f"The Op {name} does not provide a C implementation."
-                    " As well as being potentially slow, this also disables "
-                    "loop fusion."
-                )
+                "Rewrite warning: "
+                f"The Op {name} does not provide a C implementation."
+                " As well as being potentially slow, this also disables "
+                "loop fusion."
             )
             return False
 
         # create the composite op.
         composite_op = aes.Composite(s_inputs, s_new_out)
 
         # create the new node.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/extra_ops.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/extra_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -163,15 +163,14 @@
     return [new_x]
 
 
 @register_useless
 @register_canonicalize
 @node_rewriter([BroadcastTo])
 def local_remove_scalar_BroadcastTo(fgraph, node):
-
     bcast_shape = node.inputs[1:]
 
     if not bcast_shape:
         bcasted_var = node.inputs[0]
         # If this isn't true, the graph is invalid
         assert bcasted_var.ndim == 0
         return [bcasted_var]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/jax.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/jax.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/math.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/math.py`

 * *Files 2% similar despite different names*

```diff
@@ -52,29 +52,38 @@
     add,
     dot,
     eq,
     erf,
     erfc,
     exp,
     expm1,
+    floor_divide,
     ge,
-    int_div,
     isinf,
     le,
     log,
     log1mexp,
     log1p,
     makeKeepDims,
 )
 from aesara.tensor.math import max as at_max
 from aesara.tensor.math import maximum, mul, neg
 from aesara.tensor.math import pow as at_pow
-from aesara.tensor.math import prod, reciprocal, sgn, sigmoid, softplus, sqr, sqrt, sub
+from aesara.tensor.math import (
+    prod,
+    reciprocal,
+    sgn,
+    sigmoid,
+    softplus,
+    sqrt,
+    square,
+    sub,
+)
 from aesara.tensor.math import sum as at_sum
-from aesara.tensor.math import true_div
+from aesara.tensor.math import true_divide
 from aesara.tensor.rewriting.basic import (
     broadcast_like,
     encompasses_broadcastable,
     local_fill_sink,
     register_canonicalize,
     register_specialize,
     register_specialize_device,
@@ -308,14 +317,51 @@
     # Case for expm1(softplus(x)) aka expm1(log1pexp) -> exp(x)
     if isinstance(prev_op, aes_math.Softplus) and isinstance(node_op, aes.Expm1):
         x = x.owner.inputs[0]
         return [exp(x)]
 
 
 @register_specialize
+@node_rewriter([log])
+def log_diff_exp(fgraph, node):
+    r"""Rewrite that changes ``log(exp(a) - exp(b))`` to ``a + log1mexp(b - a)``."""
+
+    x = node.inputs[0]
+
+    if not x.owner or not isinstance(x.owner.op, Elemwise):
+        return
+
+    prev_op = x.owner.op.scalar_op
+    node_op = node.op.scalar_op
+
+    if not (isinstance(prev_op, aes.Sub) and isinstance(node_op, aes.Log)):
+        return
+
+    a, b = x.owner.inputs
+    a_owner = a.owner
+    b_owner = b.owner
+
+    if not (a_owner and isinstance(a_owner.op, Elemwise)) or not (
+        b_owner and isinstance(a_owner.op, Elemwise)
+    ):
+        return
+
+    a_scalar_op, b_scalar_op = a_owner.op.scalar_op, b_owner.op.scalar_op
+
+    if isinstance(a_scalar_op, aes.Exp) and isinstance(b_scalar_op, aes.Exp):
+        a = a_owner.inputs[0]
+        b = b_owner.inputs[0]
+        new_out = add(a, log1mexp(sub(b, a)))
+        old_out = node.outputs[0]
+        if new_out.dtype != old_out.dtype:
+            new_out = cast(new_out, old_out.dtype)
+        return [new_out]
+
+
+@register_specialize
 @node_rewriter([Elemwise])
 def local_exp_log_nan_switch(fgraph, node):
     # Rewrites of the kind exp(log...(x)) that require a `nan` switch
     x = node.inputs[0]
 
     if not isinstance(node.op, Elemwise):
         return
@@ -370,16 +416,16 @@
 
 @register_canonicalize
 @register_specialize
 @node_rewriter([Sum])
 def local_sumsqr2dot(fgraph, node):
     """
     This rewrite detects
-    ``at.sqr(W.dimshuffle("x", 0, 1) * G.dimshuffle(0, "x", 1) ).sum(axis=(1, 2))``
-    and converts it to ``at.dot(at.sqr(G), at.sqr(W).sum(axis=0))``.
+    ``at.square(W.dimshuffle("x", 0, 1) * G.dimshuffle(0, "x", 1) ).sum(axis=(1, 2))``
+    and converts it to ``at.dot(at.square(G), at.square(W).sum(axis=0))``.
     """
     if (
         isinstance(node.op, Sum)
         and isinstance(node.op.scalar_op, aes.Add)
         and node.op.axis == (1, 2)
     ):
         in1 = node.inputs[0]
@@ -404,15 +450,15 @@
                     and in_mul1.owner.op.new_order == ("x", 0, 1)
                     and isinstance(in_mul2.owner.op, DimShuffle)
                     and in_mul2.owner.op.new_order == (0, "x", 1)
                 ):
                     W = in_mul1.owner.inputs[0]
                     G = in_mul2.owner.inputs[0]
 
-                    new_out = dot(sqr(G), sqr(W).sum(axis=0))
+                    new_out = dot(square(G), square(W).sum(axis=0))
                     if new_out.dtype != out.dtype:
                         new_out = cast(new_out, dtype=out.dtype)
                     return [new_out]
 
 
 @register_stabilize
 @register_specialize
@@ -535,15 +581,15 @@
                     return fct
             except NotScalarConstantError:
                 pass
     return False
 
 
 @register_canonicalize
-@node_rewriter([true_div, int_div])
+@node_rewriter([true_divide, floor_divide])
 def local_div_switch_sink(fgraph, node):
     """
     This rewrite makes the following changes in the graph:
 
         at.div(at.switch(cond, 0, iff), A) -> at.switch(cond, 0, at.div(iff, A))
         at.div(at.switch(cond, ift, 0), A) -> at.switch(cond, at.div(ift, A), 0)
 
@@ -551,15 +597,15 @@
 
     This is useful because ``A`` may not be numerically stable and give
     ``nan`` or ``inf`` values for cases where the switch returns 0.
 
     See `local_mul_switch_sink` for more details.
 
     """
-    if node.op != true_div and node.op != int_div:
+    if node.op != true_divide and node.op != floor_divide:
         return False
     op = node.op
     if node.inputs[0].owner and node.inputs[0].owner.op == switch:
         switch_node = node.inputs[0].owner
         try:
             if (
                 get_scalar_constant_value(
@@ -627,15 +673,15 @@
     ----------
     main
         A suitable `Op` class that is commutative, associative and
         takes one to an arbitrary number of inputs, e.g. add or
         mul
     inverse
         An `Op` class such that ``inverse(main(x, y), y) == x``
-        (e.g. `sub` or `true_div`).
+        (e.g. `sub` or `true_divide`).
     reciprocal
         A function such that ``main(x, reciprocal(y)) == inverse(x, y)``
         (e.g. `neg` or `reciprocal`).
     calculate
         Function that takes a list of `numpy.ndarray` instances
         for the numerator, another list for the denumerator,
         and calculates ``inverse(main(\*num), main(\*denum))``. It
@@ -646,15 +692,15 @@
 
     Examples
     --------
     >>> import aesara.tensor as at
     >>> from aesara.tensor.rewriting.math import AlgebraicCanonizer
     >>> add_canonizer = AlgebraicCanonizer(add, sub, neg, \\
     ...                                    lambda n, d: sum(n) - sum(d))
-    >>> mul_canonizer = AlgebraicCanonizer(mul, true_div, inv, \\
+    >>> mul_canonizer = AlgebraicCanonizer(mul, true_divide, inv, \\
     ...                                    lambda n, d: prod(n) / prod(d))
 
     Examples of rewrites `mul_canonizer` can perform:
 
         | x / x -> 1
         | (x * y) / x -> y
         | x / y / x -> 1 / y
@@ -1071,15 +1117,15 @@
             return []
         else:
             return [v]
     return v
 
 
 local_mul_canonizer = AlgebraicCanonizer(
-    mul, true_div, reciprocal, mul_calculate, False
+    mul, true_divide, reciprocal, mul_calculate, False
 )
 register_canonicalize(local_mul_canonizer, name="local_mul_canonizer")
 
 
 @register_canonicalize
 @node_rewriter([neg])
 def local_neg_to_mul(fgraph, node):
@@ -1134,15 +1180,14 @@
                 # Copy over stacktrace from previous output to new mul op,
                 # for same reason as above.
                 copy_stack_trace(node.outputs, new_op_output)
 
             # If `node.op` is a `Prod`, then the scalars need to be raised to
             # the power of the number of elements in the input to the `Prod`
             if isinstance(node.op, Prod) and new_op_input_nb_elements != 1:
-
                 scalars = [s**new_op_input_nb_elements for s in scalars]
 
             # Scale the output of the op by the scalars and return as
             # replacement for the original output
             mul_inputs = scalars
             if new_op_input_nb_elements != 1:
                 mul_inputs.append(new_op_output)
@@ -1426,15 +1471,15 @@
     # denominator would still be needed before the summation or production.
 
     if isinstance(node.op, (Sum, Prod)):
         axis = node.op.axis
         if axis is None:
             axis = list(range(node.inputs[0].ndim))
         node_input = node.inputs[0]
-        if node_input.owner and node_input.owner.op == true_div:
+        if node_input.owner and node_input.owner.op == true_divide:
             numerator, denominator = node_input.owner.inputs
 
             if denominator.owner and isinstance(denominator.owner.op, DimShuffle):
                 dimshuffle_input = denominator.owner.inputs[0]
                 dimshuffle_order = denominator.owner.op.new_order
 
                 compatible_dims = []
@@ -1472,21 +1517,21 @@
                         optimized_dimshuffle = DimShuffle(
                             dimshuffle_input.type.broadcastable,
                             optimized_dimshuffle_order,
                         )(dimshuffle_input)
 
                     if isinstance(node.op, Sum):
                         op_on_compatible_dims = at_sum(numerator, axis=compatible_dims)
-                        rval = true_div(op_on_compatible_dims, optimized_dimshuffle)
+                        rval = true_divide(op_on_compatible_dims, optimized_dimshuffle)
                         if len(reordered_incompatible_dims) > 0:
                             rval = at_sum(rval, axis=reordered_incompatible_dims)
                     elif isinstance(node.op, Prod):
                         op_on_compatible_dims = prod(numerator, axis=compatible_dims)
                         dtype = numerator.dtype
-                        rval = true_div(
+                        rval = true_divide(
                             op_on_compatible_dims,
                             (
                                 optimized_dimshuffle
                                 ** prod(
                                     [
                                         numerator.shape[ax].astype(dtype)
                                         for ax in compatible_dims
@@ -1530,15 +1575,14 @@
         op_type = Sum if isinstance(node.op, Sum) else Prod
         (node_inps,) = node.inputs
         out_dtype = node.op.dtype
         # This is done to make sure the rewrite doesn't affect other
         # computations.
         if len(fgraph.clients[node_inps]) == 1:
             if node_inps.owner and (isinstance(node_inps.owner.op, node.op.__class__)):
-
                 # check to see either the inner or outer prod is doing a
                 # product over all axis, in which case we can remove it
                 if node_inps.owner.op.axis is None or node.op.axis is None:
                     return [op_type(None, dtype=out_dtype)(node_inps.owner.inputs[0])]
 
                 # figure out which axes were in the original sum
                 newaxis = list(tuple(node_inps.owner.op.axis))
@@ -1770,26 +1814,26 @@
     """
     - (-a / b) -> a / b
 
     Also performs - (c / b) -> ((-c) / b) when c is a scalar constant.
 
     """
     if node.op == neg:
-        if node.inputs[0].owner and node.inputs[0].owner.op == true_div:
+        if node.inputs[0].owner and node.inputs[0].owner.op == true_divide:
             frac = node.inputs[0]
             num, denom = frac.owner.inputs
             if num.owner and num.owner.op == neg:
                 if len(fgraph.clients[frac]) == 1:
                     # No other clients of the original division
                     new_num = num.owner.inputs[0]
-                    return [true_div(new_num, denom)]
+                    return [true_divide(new_num, denom)]
             elif all(num.broadcastable) and isinstance(num, Constant):
                 if len(fgraph.clients[frac]) == 1:
                     new_num = -num.data
-                    return [true_div(new_num, denom)]
+                    return [true_divide(new_num, denom)]
 
 
 @register_canonicalize
 @register_specialize
 @node_rewriter([sub])
 def local_sub_neg_to_add(fgraph, node):
     """
@@ -1815,15 +1859,14 @@
 
     """
     # This rewrite is only registered during specialization, because the
     # `local_neg_to_mul` rewrite modifies the relevant pattern during canonicalization
 
     # Rewrite is only applicable when there are two inputs to add
     if node.op == add and len(node.inputs) == 2:
-
         # Look for pattern with either input order
         for first, second in (node.inputs, reversed(node.inputs)):
             if second.owner:
                 if second.owner.op == neg:
                     pre_neg = second.owner.inputs[0]
                     new_out = sub(first, pre_neg)
                     return [new_out]
@@ -1855,17 +1898,17 @@
             if value == 0:
                 # print '... returning zeros'
                 return fill_chain(_asarray(0, dtype=otype.dtype), node.inputs)
 
 
 # TODO: Add this to the canonicalization to reduce redundancy.
 @register_specialize
-@node_rewriter([true_div])
+@node_rewriter([true_divide])
 def local_div_to_reciprocal(fgraph, node):
-    if node.op == true_div and np.all(get_constant(node.inputs[0]) == 1.0):
+    if node.op == true_divide and np.all(get_constant(node.inputs[0]) == 1.0):
         out = node.outputs[0]
         new_out = reciprocal(local_mul_canonizer.merge_num_denum(node.inputs[1:], []))
         # The ones could have forced upcasting
         if new_out.dtype != out.dtype:
             new_out = cast(new_out, dtype=out.dtype)
         # The ones could have forced a specific length
         if not out.type.is_super(new_out.type):
@@ -1897,40 +1940,40 @@
         return False
 
 
 @register_specialize
 @node_rewriter([mul])
 def local_mul_to_sqr(fgraph, node):
     """
-    x*x -> sqr(x)
+    x*x -> square(x)
     """
     if node.op == mul:
         if len(node.inputs) == 2:
             if node.inputs[0] is node.inputs[1]:
-                return [sqr(node.inputs[0])]
+                return [square(node.inputs[0])]
 
 
 @register_canonicalize
-@node_rewriter([int_div])
+@node_rewriter([floor_divide])
 def local_intdiv_by_one(fgraph, node):
     """x // 1 -> x"""
-    if node.op in [int_div]:
+    if node.op in [floor_divide]:
         if isinstance(node.inputs[1], TensorConstant) and np.all(
             node.inputs[1].value == 1
         ):
             return [node.inputs[0].astype(node.outputs[0].dtype)]
 
 
 @register_canonicalize
 @register_specialize
-@node_rewriter([int_div, true_div])
+@node_rewriter([floor_divide, true_divide])
 def local_zero_div(fgraph, node):
     """0 / x -> 0"""
     if isinstance(node.op, Elemwise) and isinstance(
-        node.op.scalar_op, (aes.IntDiv, aes.TrueDiv)
+        node.op.scalar_op, (aes.FloorDivide, aes.TrueDivide)
     ):
         if get_constant(node.inputs[0]) == 0:
             ret = broadcast_like(0, node.outputs[0], fgraph)
             ret.tag.values_eq_approx = values_eq_approx_remove_nan
             return [ret]
 
 
@@ -1947,27 +1990,27 @@
         y = get_constant(ysym)
         if (y is not None) and encompasses_broadcastable(
             xsym.type.broadcastable, ysym.type.broadcastable
         ):
             rval = None
 
             if np.all(y == 2):
-                rval = [sqr(xsym)]
+                rval = [square(xsym)]
             if np.all(y == 1):
                 rval = [xsym]
             if np.all(y == 0):
                 rval = [fill(xsym, np.asarray(1, dtype=odtype))]
             if np.all(y == 0.5):
                 rval = [sqrt(xsym)]
             if np.all(y == -0.5):
                 rval = [reciprocal(sqrt(xsym))]
             if np.all(y == -1):
                 rval = [reciprocal(xsym)]
             if np.all(y == -2):
-                rval = [reciprocal(sqr(xsym))]
+                rval = [reciprocal(square(xsym))]
             if rval:
                 rval[0] = cast(rval[0], odtype)
                 assert rval[0].type == node.outputs[0].type, (rval, node.outputs)
                 return rval
     else:
         return False
 
@@ -2005,16 +2048,16 @@
             rval = None
             # 512 is too small for the cpu and too big for some gpu!
             if abs(y) == int(abs(y)) and abs(y) <= 512:
                 pow2 = [xsym]
                 pow2_scal = [aes.get_scalar_type(xsym.dtype)()]
                 y_to_do = abs(y)
                 for i in range(int(np.log2(y_to_do))):
-                    pow2.append(sqr(pow2[i]))
-                    pow2_scal.append(aes.sqr(pow2_scal[i]))
+                    pow2.append(square(pow2[i]))
+                    pow2_scal.append(aes.square(pow2_scal[i]))
                 rval1 = None
                 rval1_scal = None
                 while y_to_do > 0:
                     log_to_do = int(np.log2(y_to_do))
                     if rval1:
                         rval1 *= pow2[log_to_do]
                         rval1_scal *= pow2_scal[log_to_do]
@@ -2205,21 +2248,21 @@
     This is needed for check_for_x_over_absX to apply in more case.
 
     """
     if node.op == at_abs and node.inputs[0].owner:
         assert node.nin == 1
         if node.inputs[0].owner.op == mul:
             return [mul(*[at_abs(i) for i in node.inputs[0].owner.inputs])]
-        if node.inputs[0].owner.op == true_div:
+        if node.inputs[0].owner.op == true_divide:
             i = node.inputs[0].owner.inputs
-            return [true_div(at_abs(i[0]), at_abs(i[1]))]
+            return [true_divide(at_abs(i[0]), at_abs(i[1]))]
 
 
 @register_specialize
-@node_rewriter([mul, true_div])
+@node_rewriter([mul, true_divide])
 def local_abs_merge(fgraph, node):
     """
     Merge abs generated by local_abs_lift when the canonizer don't
     need it anymore
 
     """
     if node.op == mul and sum(i.owner.op == at_abs for i in node.inputs if i.owner) > 1:
@@ -2235,20 +2278,22 @@
                 if not (const >= 0).all():
                     return False
                 inputs.append(i)
             else:
                 return False
         return [at_abs(mul(*inputs))]
     if (
-        node.op == true_div
+        node.op == true_divide
         and sum(i.owner.op == at_abs for i in node.inputs if i.owner) == 2
     ):
         return [
             at_abs(
-                true_div(node.inputs[0].owner.inputs[0], node.inputs[1].owner.inputs[0])
+                true_divide(
+                    node.inputs[0].owner.inputs[0], node.inputs[1].owner.inputs[0]
+                )
             )
         ]
 
 
 @register_stabilize
 @register_specialize
 @node_rewriter([log])
@@ -2483,28 +2528,28 @@
             num,
             denum,
         )
 
 
 @register_canonicalize
 @register_stabilize
-@node_rewriter([mul, true_div, reciprocal])
+@node_rewriter([mul, true_divide, reciprocal])
 def local_greedy_distributor(fgraph, node):
     """Reduce the number of multiplications and/or divisions.
 
     This rewrite tries to apply distributivity of multiplication
     to addition in order to reduce the number of multiplications
     and/or divisions that must be done. The algorithm weighs division
     more than multiplication to account for the former's slightly
     greater computational cost.
 
     The following expressions are simplified:
     1. ``((a/x + b/y) * x * y) -> a*y + b*x``
     2. ``((a/x + b) * x) -> a + b*x``
-    3. There are other forms too where node is a true_div.
+    3. There are other forms too where node is a true_divide.
 
     The following expressions are not simplified:
     4. ``((a + b) * x) /> a*x + b*x``
 
     This rewrite aims to reduce computational cost. It may also
     increase numerical stability, e.g. when ``x`` and/or ``y`` tend to ``0`` in
     Example 1.
@@ -2675,15 +2720,15 @@
     ret = switch(x < threshold, node.outputs[0], stab_value)
     ret.tag.values_eq_approx = values_eq_approx_remove_inf
     return [ret]
 
 
 @register_stabilize
 @register_specialize
-@node_rewriter([true_div])
+@node_rewriter([true_divide])
 def local_grad_log_erfc_neg(fgraph, node):
     """Stability rewrite for the grad of ``log(erfc(x))``.
 
     Notes
     -----
         ([y*]exp(-(x**2)))/erfc(x)  # The y* is optional
         ([y*]exp(x**2))/erfc(-x) => [y*](when x > threshold,
@@ -2696,15 +2741,15 @@
     is the second.
 
     TODO: at the test point 10 in float32, there is instability in the original
     value. The original gives -30.0, the stab -20.1 and in float64 -18.1.
     Make it so that the test does not generate an error in that case!
 
     """
-    if node.op != true_div:
+    if node.op != true_divide:
         return False
     if not node.inputs[1].owner or node.inputs[1].owner.op != erfc:
         return False
 
     erfc_in = node.inputs[1]
     erfc_x = erfc_in.owner.inputs[0]
 
@@ -2736,15 +2781,18 @@
             del y[idx]
 
     if not exp_in.owner.inputs[0].owner:
         return False
 
     if exp_in.owner.inputs[0].owner.op == neg:
         neg_in = exp_in.owner.inputs[0]
-        if not neg_in.owner.inputs[0].owner or neg_in.owner.inputs[0].owner.op != sqr:
+        if (
+            not neg_in.owner.inputs[0].owner
+            or neg_in.owner.inputs[0].owner.op != square
+        ):
             return False
         sqr_in = neg_in.owner.inputs[0]
         x = sqr_in.owner.inputs[0]
     elif exp_in.owner.inputs[0].owner.op == mul:
         # We should compare that -(erfc_x**2) is equivalent to mul_neg.
         # There is currently no easy way to do this in the general case,
         # so we implement some common case for now.
@@ -2783,15 +2831,15 @@
             )
         except NotScalarConstantError:
             return False
 
         if len(mul_neg.owner.inputs) == 2:
             if (
                 not mul_neg.owner.inputs[1].owner
-                or mul_neg.owner.inputs[1].owner.op != sqr
+                or mul_neg.owner.inputs[1].owner.op != square
             ):
                 return False
             sqr_in = mul_neg.owner.inputs[1]
             x = sqr_in.owner.inputs[0]
         elif len(mul_neg.owner.inputs) == 3:
             if mul_neg.owner.inputs[1] is not mul_neg.owner.inputs[2]:
                 return False
@@ -2832,15 +2880,15 @@
         # TODO FIXME: We shouldn't need to use tags for this.
         return False
 
     if erfc_x is not x:
         return None
 
     # we move the y outside the div.
-    true_div_no_mul = true_div(exp_in, erfc_in)
+    true_div_no_mul = true_divide(exp_in, erfc_in)
     true_div_no_mul.owner.tag.local_grad_log_erfc_neg = True
 
     # aaron value
     stab_value = (
         x
         * at_pow(1 - 1 / (2 * (x**2)) + 3 / (4 * (x**4)) - 15 / (8 * (x**6)), -1)
         * cast(sqrt(np.pi), dtype=x.dtype)
@@ -3120,26 +3168,25 @@
                     # Return the multiplication of all other inputs.
                     return mul(*(var_node.inputs[0:idx] + var_node.inputs[idx + 1 :]))
     # No match.
     return None
 
 
 @register_stabilize
-@node_rewriter([true_div])
+@node_rewriter([true_divide])
 def local_exp_over_1_plus_exp(fgraph, node):
     """
 
     exp(x)/(1+exp(x)) -> sigm(x)
     c/(1+exp(x)) -> c*sigm(-x)
 
     """
     # This rewrite should be done for numerical stability
     # so we don't care to check client counts
-    if node.op == true_div:
-
+    if node.op == true_divide:
         # find all the exp() terms in the numerator
         num, denom = node.inputs
         num_exp_x, num_rest, num_neg = partition_num_or_denom(num, is_exp)
         denom_1pexp, denom_rest, denom_neg = partition_num_or_denom(denom, is_1pexp)
 
         sigmoids = []
         for t in denom_1pexp:
@@ -3507,15 +3554,15 @@
 
 @register_stabilize
 @node_rewriter([reciprocal])
 def local_reciprocal_1_plus_exp(fgraph, node):
     """``reciprocal(1+exp(x)) -> sigm(-x)``
 
     TODO: This is redundant; we can just decided on *one* canonical form
-    for division (e.g. either `true_div` or `reciprocal`) and have this
+    for division (e.g. either `true_divide` or `reciprocal`) and have this
     taken care of with existing rewrites.
     """
     # This Rewrite should be done for numerical stability
     # so we don't care to check client counts
     if node.op == reciprocal:
         reciprocal_arg = node.inputs[0]
         if reciprocal_arg.owner and reciprocal_arg.owner.op == add:
@@ -3559,29 +3606,29 @@
 )
 register_stabilize(log1pmexp_to_log1mexp, name="log1pmexp_to_log1mexp")
 
 
 # log(sigmoid(x) / (1 - sigmoid(x))) -> x
 # i.e logit(sigmoid(x)) -> x
 local_logit_sigmoid = PatternNodeRewriter(
-    (log, (true_div, (sigmoid, "x"), (sub, 1, (sigmoid, "x")))),
+    (log, (true_divide, (sigmoid, "x"), (sub, 1, (sigmoid, "x")))),
     "x",
     tracks=[sigmoid],
     get_nodes=get_clients_at_depth2,
     allow_multiple_clients=True,
     name="local_logit_sigmoid",
 )
 register_canonicalize(local_logit_sigmoid)
 register_specialize(local_logit_sigmoid)
 
 
 # sigmoid(log(x / (1-x)) -> x
 # i.e., sigmoid(logit(x)) -> x
 local_sigmoid_logit = PatternNodeRewriter(
-    (sigmoid, (log, (true_div, "x", (sub, 1, "x")))),
+    (sigmoid, (log, (true_divide, "x", (sub, 1, "x")))),
     "x",
     allow_multiple_clients=True,
     name="local_sigmoid_logit",
 )
 register_canonicalize(local_sigmoid_logit)
 register_specialize(local_sigmoid_logit)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/shape.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/shape.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,19 @@
 import traceback
-from io import StringIO
-from typing import Optional
+from typing import (
+    TYPE_CHECKING,
+    Callable,
+    Dict,
+    List,
+    Optional,
+    Sequence,
+    Set,
+    Tuple,
+    Union,
+)
 from typing import cast as type_cast
 from warnings import warn
 
 import numpy as np
 
 import aesara
 from aesara.configdefaults import config
@@ -13,15 +22,15 @@
 from aesara.graph.fg import FunctionGraph
 from aesara.graph.rewriting.basic import (
     GraphRewriter,
     check_chain,
     copy_stack_trace,
     node_rewriter,
 )
-from aesara.graph.utils import InconsistencyError, get_variable_trace_string
+from aesara.graph.utils import InconsistencyError
 from aesara.tensor.basic import (
     MakeVector,
     as_tensor_variable,
     cast,
     constant,
     extract_constant,
     get_scalar_constant_value,
@@ -43,18 +52,31 @@
     SpecifyShape,
     Unbroadcast,
     shape_i,
     specify_shape,
     unbroadcast,
 )
 from aesara.tensor.subtensor import Subtensor, get_idx_list
-from aesara.tensor.type import TensorType, discrete_dtypes, integer_dtypes
+from aesara.tensor.type import HasShape, TensorType, discrete_dtypes, integer_dtypes
 from aesara.tensor.type_other import NoneConst
 
 
+if TYPE_CHECKING:
+    from numpy.typing import ArrayLike
+
+    from aesara.graph.basic import Apply
+    from aesara.graph.tensor.var import TensorVariable
+
+    InputShapesType = List[Optional[Tuple[Variable, ...]]]
+    OutputShapesType = List[Optional[Tuple[Variable, ...]]]
+    ShapeInferFunctionType = Callable[
+        [FunctionGraph, "Apply", InputShapesType], OutputShapesType
+    ]
+
+
 class ShapeFeature(Feature):
     r"""A `Feature` that tracks shape information in a graph.
 
     This `Feature` aids in the replacement of all `Shape`\s and `Subtensor`\s of `Shape`\s with
     `Shape_i` and `MakeVector` `Op`\s.
 
     This `Feature` and its associated rewrites have several goals:
@@ -69,89 +91,51 @@
     something just to know how big it will be.  Firstly, it is a waste
     of time to compute such outputs.  But it is important to get rid
     of these outputs as early as possible in the compilation process
     because the extra computations make it appear as if many internal
     graph nodes have multiple clients.  Many rewrites refuse to
     work on nodes with multiple clients.
 
-    Lifting is done by using an `<Op>.infer_shape` function if one is
-    present, or else using a conservative default.  An Op that
-    supports shape-lifting should define a infer_shape(self, fgraph, node,
-    input_shapes) function.  The argument input_shapes is a tuple of
-    tuples... there is an interior tuple for each input to the node.
-    The tuple has as many elements as dimensions.  The element in
-    position i of tuple j represents the i'th shape component of the
-    j'th input.  The function should return a tuple of tuples.  One
-    output tuple for each node.output.  Again, the i'th element of the
-    j'th output tuple represents the output[j].shape[i] of the
-    function.  If an output is not a TensorType, then None should be
-    returned instead of a tuple for that output.
-
-    For example the infer_shape for a matrix-matrix product would accept
-    input_shapes=((x0,x1), (y0,y1)) and return ((x0, y1),).
-
-    Inferring the shape of internal nodes in the graph is important
-    for doing size-driven rewrites.  If we know how big various
-    intermediate results will be, we can estimate the cost of many Ops
-    accurately, and generate c-code that is specific [e.g. unrolled]
-    to particular sizes.
-
-    In cases where you cannot figure out the shape, raise a ShapeError.
-
-    Notes
-    -----
-    Right now there is only the ConvOp that could really take
-    advantage of this shape inference, but it is worth it even
-    just for the ConvOp.  All that's necessary to do shape
-    inference is 1) to mark shared inputs as having a particular
-    shape, either via a .tag or some similar hacking; and 2) to
-    add an optional In() argument to promise that inputs will
-    have a certain shape (or even to have certain shapes in
-    certain dimensions).
-
-    We can't automatically infer the shape of shared variables as they can
-    change of shape during the execution by default.
+    Lifting is done by using an :meth:`Op.infer_shape` method if one is
+    present, or else using a conservative default..
 
-    To use this shape information in rewrites, use the
-    ``shape_of`` dictionary.
+    Inferring the shape of internal nodes in the graph is important for doing
+    size-driven rewrites.  If we know how big various intermediate results will
+    be, we can estimate the cost of many `Op`\s accurately, and generate code
+    that is specific (e.g. unrolled) to particular sizes.
 
-    For example:
+    In cases where `ShapeFeature` cannot figure out the shape, it raises a
+    `ShapeError`.
 
-    .. code-block:: python
+    .. note::
 
-        try:
-            shape_of = fgraph.shape_feature.shape_of
-        except AttributeError:
-            # This can happen when the mode doesn't include the ShapeFeature.
-            return
+        We can't automatically infer the shape of shared variables as they can
+        change of shape during the execution by default.
 
-        shape_of_output_zero = shape_of[node.output[0]]
-
-    The ``shape_of_output_zero`` symbol will contain a tuple, whose
-    elements are either integers or symbolic integers.
-
-    TODO: check to see if the symbols are necessarily
-    non-constant... or are integer literals sometimes Aesara
-    constants?? That would be confusing.
+    To use the shape information gathered by a `FunctionGraph`-attached
+    `ShapeFeature` in rewrites, use the :meth:`ShapeFeature.get_shape` method.
 
     """
+    lscalar_one = constant(1, dtype="int64", ndim=0)
 
-    def get_node_infer_shape(self, node):
+    def get_node_infer_shape(
+        self, fgraph: FunctionGraph, node: "Apply"
+    ) -> "OutputShapesType":
         try:
-            shape_infer = node.op.infer_shape
+            shape_infer: "ShapeInferFunctionType" = node.op.infer_shape
         except AttributeError:
             shape_infer = self.default_infer_shape
 
         try:
             o_shapes = shape_infer(
-                self.fgraph, node, [self.shape_of[r] for r in node.inputs]
+                fgraph, node, [self.shape_of[r] for r in node.inputs]
             )
         except ShapeError:
             o_shapes = self.default_infer_shape(
-                self.fgraph, node, [self.shape_of[r] for r in node.inputs]
+                fgraph, node, [self.shape_of[r] for r in node.inputs]
             )
         except NotImplementedError as e:
             raise NotImplementedError(
                 "Code called by infer_shape failed raising a "
                 "NotImplementedError. Raising NotImplementedError to "
                 "indicate that a shape cannot be computed is no longer "
                 "supported, and one should now use ShapeError "
@@ -164,85 +148,112 @@
                 f"{type(e)}\nException message: {str(e)}\nTraceback: {traceback.format_exc()}"
             )
             if config.on_shape_error == "raise":
                 raise Exception(msg).with_traceback(e.__traceback__)
             else:
                 warn(msg)
             o_shapes = self.default_infer_shape(
-                self.fgraph, node, [self.shape_of[r] for r in node.inputs]
+                fgraph, node, [self.shape_of[r] for r in node.inputs]
             )
 
         return o_shapes
 
-    def get_shape(self, var, idx):
-        """Rewrites can call this to get a `Shape_i`.
+    def get_shape(self, fgraph: FunctionGraph, var: Variable, idx: int) -> Variable:
+        """Get the shape of `var` at index `idx`.
 
-        It is better to call this then use directly ``shape_of[var][idx]``
-        as this method should update `shape_of` if needed.
+        It is better to call this than use ``ShapeFeature.shape_of[var][idx]``,
+        since this method will update `ShapeFeature.shape_of` when needed.
 
         TODO: Up to now, we don't update it in all cases. Update in all cases.
+
         """
-        r = self.shape_of[var][idx]
+        var_shape = self.shape_of[var]
+        assert var_shape is not None
+
+        var_idx_shape = var_shape[idx]
+
         if (
-            r.owner
-            and isinstance(r.owner.op, Shape_i)
-            and r.owner.inputs[0] not in self.fgraph.variables
+            var_idx_shape.owner
+            and isinstance(var_idx_shape.owner.op, Shape_i)
+            and var_idx_shape.owner.inputs[0] not in fgraph.variables
         ):
             assert var.owner
             node = var.owner
-            # recur on inputs
+
+            # Recurse on inputs
+            # TODO FIXME: Remove the recursion here.
             for i in node.inputs:
-                if getattr(i.type, "ndim", None) > 0:
-                    self.get_shape(i, 0)
-            o_shapes = self.get_node_infer_shape(node)
+                if isinstance(i.type, HasShape):
+                    self.get_shape(fgraph, i, 0)
+
+            o_shapes = self.get_node_infer_shape(fgraph, node)
             assert len(o_shapes) == len(node.outputs)
 
             # Only change the variables and dimensions that would introduce
             # extra computation
             for new_shps, out in zip(o_shapes, node.outputs):
-                if not hasattr(out.type, "ndim"):
+                if not isinstance(out.type, HasShape):
                     continue
 
-                merged_shps = list(self.shape_of[out])
+                out_shape = self.shape_of[out]
+                assert out_shape is not None
+
+                merged_shps = list(out_shape)
+
                 changed = False
                 for i in range(out.type.ndim):
                     n_r = merged_shps[i]
                     if (
                         n_r.owner
                         and isinstance(n_r.owner.op, Shape_i)
-                        and n_r.owner.inputs[0] not in self.fgraph.variables
+                        and n_r.owner.inputs[0] not in fgraph.variables
                     ):
                         changed = True
+
+                        assert new_shps is not None
+
                         merged_shps[i] = new_shps[i]
+
                 if changed:
                     self.set_shape(out, merged_shps, override=True)
-            r = self.shape_of[var][idx]
-        return r
 
-    def shape_ir(self, i, r):
-        """Return symbolic r.shape[i] for tensor variable r, int i."""
-        if hasattr(r.type, "shape") and r.type.shape[i] is not None:
-            return constant(r.type.shape[i], dtype="int64")
+            var_shape = self.shape_of[var]
+            assert var_shape is not None
+
+            var_idx_shape = var_shape[idx]
+
+        return var_idx_shape
+
+    def shape_ir(self, i: int, r: Variable) -> Variable:
+        r"""Return symbolic `r.shape[i]`."""
+        if isinstance(r.type, HasShape) and r.type.shape[i] is not None:
+            return constant(r.type.shape[i], dtype="int64", ndim=0)
         else:
             # Do not call make_node for test_value
             s = Shape_i(i)(r)
+
+            assert isinstance(s, Variable)
+
             try:
-                s = get_scalar_constant_value(s)
+                s = constant(get_scalar_constant_value(s), dtype="int64", ndim=0)
             except NotScalarConstantError:
                 pass
+
             return s
 
-    def shape_tuple(self, r):
+    def shape_tuple(self, r: Variable) -> Optional[Tuple[Variable, ...]]:
         """Return a tuple of symbolic shape vars for tensor variable r."""
-        if not hasattr(r.type, "ndim"):
+        if not isinstance(r.type, HasShape):
             # This happen for NoneConst.
             return None
         return tuple(self.shape_ir(i, r) for i in range(r.type.ndim))
 
-    def default_infer_shape(self, fgraph, node, i_shapes):
+    def default_infer_shape(
+        self, fgraph: FunctionGraph, node: "Apply", i_shapes: "InputShapesType"
+    ) -> "OutputShapesType":
         """Return a list of shape tuple or None for the outputs of node.
 
         This function is used for Ops that don't implement infer_shape.
         Ops that do implement infer_shape should use the i_shapes parameter,
         but this default implementation ignores it.
 
         """
@@ -250,139 +261,129 @@
         for r in node.outputs:
             try:
                 rval.append(self.shape_tuple(r))
             except AttributeError:
                 rval.append(None)
         return rval
 
-    def unpack(self, s_i, var):
-        """Return a symbolic integer scalar for the shape element s_i.
+    def to_symbolic_int(
+        self, s_i: Union[int, float, np.integer, "ArrayLike", Variable]
+    ) -> Variable:
+        """Return a symbolic integer scalar for the shape element `s_i`.
 
-        The s_i argument was produced by the infer_shape() of an Op subclass.
+        TODO: Re-evaluate the need for this, since it's effectively eager
+        canonicalization.
 
-        var: the variable that correspond to s_i. This is just for
-        error reporting.
+        Parameters
+        ----------
+        s_i
+            The `s_i` argument is assumed to be produced by an :meth:`Op.infer_shape`.
 
         """
-        assert s_i is not None
-
         if s_i == 1:
             return self.lscalar_one
-        if isinstance(s_i, float) and int(s_i) == s_i:
-            s_i = int(s_i)
-        if isinstance(s_i, (np.integer, int)) or (
+
+        if isinstance(s_i, (float, int, np.integer)) or (
             isinstance(s_i, np.ndarray) and s_i.ndim == 0
         ):
-            # this shape is a constant
-            if s_i < 0:
-                msg = "There is a negative shape in the graph!"
-                msg += get_variable_trace_string(var)
-                # The rest of the pipeline don't handle correctly this
-                # case.  So we have 2 choices, stop compilation or
-                # consider the shape as unknown.  As we have more
-                # chance to give the stack trace here then later, I
-                # choose that options as it would give better error
-                # message.
-                raise AssertionError(msg)
-            return constant(s_i, dtype="int64")
-        if isinstance(s_i, (tuple, list)):
-            # this dimension is the same as many of the inputs
-            # which tells us that if one of the inputs is known,
-            # the others all become known.
-            # TODO: should be implemented in Elemwise, and Dot
-            #
-            # worst case, we loop over shape_of and replace things
-            raise NotImplementedError(s_i)
+            assert int(s_i) == s_i and s_i >= 0
+            return constant(s_i, dtype="int64", ndim=0)
+
+        assert isinstance(s_i, Variable)
 
-        # s_i is x.shape[i] for some x, we change it to shape_of[x][i]
+        # TODO FIXME: This is eager canonicalization; we should let the
+        # relevant canonicalization passes do their job and not perform the
+        # same logic manually.
         if (
             s_i.owner
             and isinstance(s_i.owner.op, Subtensor)
             and s_i.owner.inputs[0].owner
             and isinstance(s_i.owner.inputs[0].owner.op, Shape)
         ):
+            # s_i is x.shape[i] for some x, we change it to shape_of[x][i]
             assert s_i.type.ndim == 0
             assert len(s_i.owner.op.idx_list) == 1
 
             # The current Subtensor always put constant index in the graph.
             # This was not True in the past. So call the Subtensor function
             # that will return the right index.
             idx = get_idx_list(s_i.owner.inputs, s_i.owner.op.idx_list)
             assert len(idx) == 1
             idx = idx[0]
             try:
                 i = get_scalar_constant_value(idx)
             except NotScalarConstantError:
-                pass
+                return s_i
             else:
                 # Executed only if no exception was raised
                 x = s_i.owner.inputs[0].owner.inputs[0]
                 # x should already have been imported, and should be in shape_of.
-                s_i = self.shape_of[x][i]
-
-        if s_i.type.dtype in integer_dtypes:
-            if getattr(s_i.type, "ndim", 0):
-                raise TypeError("Shape element must be scalar", s_i)
-            return s_i
-        else:
-            raise TypeError(
-                "Unsupported shape element", s_i, type(s_i), getattr(s_i, "type", None)
-            )
-
-    def set_shape(self, r, s, override=False):
+                s_x = self.shape_of[x]
+                assert s_x is not None
+                s_i = s_x[i]
+
+        if s_i.type.dtype not in integer_dtypes or getattr(s_i.type, "ndim", 0) != 0:
+            raise TypeError(f"Shape element {str(s_i)} must be an integer scalar")
+
+        return s_i
+
+    def set_shape(
+        self, r: Variable, s: Optional[Sequence[Variable]], override: bool = False
+    ) -> None:
         """Assign the shape `s` to previously un-shaped variable `r`.
 
         Parameters
         ----------
-        r : a variable
-        s : None or a tuple of symbolic integers
-        override : If False, it mean r is a new object in the fgraph.
-            If True, it mean r is already in the fgraph and we want to
-            override its shape.
+        r
+        s
+        override
+            If ``False``, it means `r` is a new, unseen term.
+            If ``True``, it means `r` is assumed to have already been seen and
+            we want to override its shape.
 
         """
         if not override:
             assert r not in self.shape_of, "r already in shape_of"
         if s is None:
             self.shape_of[r] = s
         else:
             if not isinstance(s, (tuple, list)):
                 raise TypeError("shapes must be tuple/list", (r, s))
 
             if r.type.ndim != len(s):
-                sio = StringIO()
-                aesara.printing.debugprint(r, file=sio, print_type=True)
                 raise AssertionError(
-                    f"Something inferred a shape with {len(s)} dimensions "
-                    f"for a variable with {int(r.type.ndim)} dimensions"
-                    f" for the variable:\n{sio.getvalue()}"
+                    f"A shape with {len(s)} dimensions was inferred for {r}: "
+                    f"a variable with {int(r.type.ndim)} dimensions."
                 )
 
-            shape_vars = []
+            shape_vars: Tuple[Variable, ...] = ()
             for i in range(r.type.ndim):
-                if hasattr(r.type, "shape") and r.type.shape[i] is not None:
-                    shape_vars.append(constant(r.type.shape[i], dtype="int64"))
+                if isinstance(r.type, HasShape) and r.type.shape[i] is not None:
+                    shape_vars += (constant(r.type.shape[i], dtype="int64", ndim=0),)
                 else:
-                    shape_vars.append(self.unpack(s[i], r))
+                    shape_vars += (self.to_symbolic_int(s[i]),)
+
             assert all(
-                not hasattr(r.type, "shape")
+                not isinstance(r.type, HasShape)
                 or r.type.shape[i] != 1
                 or self.lscalar_one.equals(shape_vars[i])
                 or self.lscalar_one.equals(extract_constant(shape_vars[i]))
                 for i in range(r.type.ndim)
             )
+
             self.shape_of[r] = tuple(shape_vars)
+
             for sv in shape_vars:
                 self.shape_of_reverse_index.setdefault(sv, set()).add(r)
 
-    def update_shape(self, r, other_r):
-        """Replace shape of r by shape of other_r.
+    def update_shape(self, r: Variable, other_r: Variable) -> None:
+        """Replace shape of `r` by shape of `other_r`.
 
-        If, on some dimensions, the shape of other_r is not informative,
-        keep the shape of r on those dimensions.
+        If, on some dimensions, the shape of `other_r` is not informative, keep
+        the shape of `r` on those dimensions.
 
         """
         # other_r should already have a shape
         assert other_r in self.shape_of, ("other_r not in shape_of", other_r)
         other_shape = self.shape_of[other_r]
 
         # If other_shape has no information, call is pointless.
@@ -391,168 +392,169 @@
 
         if r in self.shape_of:
             r_shape = self.shape_of[r]
         else:
             # If no info is known on r's shape, use other_shape
             self.set_shape(r, other_shape)
             return
+
         if (
             other_r.owner
             and r.owner
             and other_r.owner.inputs == r.owner.inputs
             and other_r.owner.op == r.owner.op
         ):
             # We are doing a merge, so the two shape graphs will be the
             # same.  This is only done so that we call `ancestors` less
             # frequently.
             return
 
         # Merge other_shape with r_shape, giving the priority to other_shape
-        merged_shape = []
+        merged_shape: Tuple[Variable, ...] = ()
         for i, ps in enumerate(other_shape):
-            if r_shape is None and other_shape:
-                merged_shape.append(other_shape[i])
-            elif (
-                ps.owner
+            if r_shape is None:
+                merged_shape += (ps,)
+                continue
+
+            rs = r_shape[i]
+            if (
+                # TODO FIXME: This is another instance of eager
+                # canonicalization that we need to address.
+                ps.owner is not None
                 and isinstance(getattr(ps.owner, "op", None), Shape_i)
                 and ps.owner.op.i == i
                 and ps.owner.inputs[0] in (r, other_r)
             ):
                 # If other_shape[i] is uninformative, use r_shape[i].
                 # For now, we consider 2 cases of uninformative other_shape[i]:
                 #  - Shape_i(i)(other_r);
                 #  - Shape_i(i)(r).
-                merged_shape.append(r_shape[i])
-            elif isinstance(r_shape[i], (Constant, int)):
-                # We do this to call less often ancestors and make
-                # sure we have the simplest shape possible.
-                merged_shape.append(r_shape[i])
-            elif isinstance(other_shape[i], (Constant, int)):
-                # We do this to call less often ancestors and make
-                # sure we have the simplest shape possible.
-                merged_shape.append(other_shape[i])
-            elif other_shape[i] == r_shape[i]:
-                # This mean the shape is equivalent
-                # We do not want to do the ancestor check in those cases
-                merged_shape.append(r_shape[i])
-            elif r_shape[i] in ancestors([other_shape[i]]):
+                merged_shape += (rs,)
+            elif isinstance(rs, Constant):
+                # We always prefer constants
+                merged_shape += (rs,)
+            elif isinstance(ps, Constant):
+                merged_shape += (ps,)
+            elif ps == rs:
+                # The shapes are equivalent.  We do not want to do the ancestor
+                # check in those cases
+                merged_shape += (rs,)
+            elif (
+                # TODO FIXME: This could be unnecessarily costly.
+                rs
+                in ancestors([ps])
+            ):
                 # Another case where we want to use r_shape[i] is when
                 # other_shape[i] actually depends on r_shape[i]. In that case,
                 # we do not want to substitute an expression with another that
                 # is strictly more complex. Such a substitution could also lead
                 # to cycles: if (in the future) r_shape[i] gets replaced by an
                 # expression of other_shape[i], other_shape[i] may end up
                 # depending on itself.
-                merged_shape.append(r_shape[i])
+                merged_shape += (rs,)
             else:
-                merged_shape.append(other_shape[i])
+                merged_shape += (ps,)
+
         assert all(
             (
-                not hasattr(r.type, "shape")
+                not isinstance(r.type, HasShape)
                 or r.type.shape[i] != 1
                 and other_r.type.shape[i] != 1
             )
             or self.lscalar_one.equals(merged_shape[i])
             or self.lscalar_one.equals(
                 extract_constant(merged_shape[i], only_process_constants=True)
             )
             for i in range(r.type.ndim)
         )
-        self.shape_of[r] = tuple(merged_shape)
-        for sv in self.shape_of[r]:
+
+        self.shape_of[r] = merged_shape
+        for sv in merged_shape:
             self.shape_of_reverse_index.setdefault(sv, set()).add(r)
 
-    def set_shape_i(self, r, i, s_i):
+    def set_shape_i(self, r: Variable, i: int, s_i: Variable) -> None:
         """Replace element i of shape_of[r] by s_i"""
-        assert r in self.shape_of
+
         prev_shape = self.shape_of[r]
+        assert prev_shape is not None
+
         # prev_shape is a tuple, so we cannot change it inplace,
         # so we build another one.
-        new_shape = []
+        new_shape: Tuple[Variable, ...] = ()
         for j, s_j in enumerate(prev_shape):
             if j == i:
-                new_shape.append(self.unpack(s_i, r))
+                new_shape += (self.to_symbolic_int(s_i),)
             else:
-                new_shape.append(s_j)
+                new_shape += (s_j,)
+
         assert all(
-            not hasattr(r.type, "shape")
+            not isinstance(r.type, HasShape)
             or r.type.shape[idx] != 1
             or self.lscalar_one.equals(new_shape[idx])
             or self.lscalar_one.equals(extract_constant(new_shape[idx]))
             for idx in range(r.type.ndim)
         )
-        self.shape_of[r] = tuple(new_shape)
-        for sv in self.shape_of[r]:
+
+        self.shape_of[r] = new_shape
+
+        for sv in new_shape:
             self.shape_of_reverse_index.setdefault(sv, set()).add(r)
 
-    def init_r(self, r):
+    def init_r(self, r: Variable) -> None:
         """Register r's shape in the shape_of dictionary."""
         if r not in self.shape_of:
             self.set_shape(r, self.shape_tuple(r))
 
-    def make_vector_shape(self, r):
-        return as_tensor_variable(self.shape_of[r], ndim=1, dtype="int64")
+    def make_vector_shape(self, r: Variable) -> "TensorVariable":
+        r_shape = self.shape_of[r]
+        assert r_shape is not None
+        return as_tensor_variable(r_shape, ndim=1, dtype="int64")
 
     def on_attach(self, fgraph):
-
         if hasattr(fgraph, "shape_feature"):
             raise AlreadyThere("This FunctionGraph already has a ShapeFeature")
 
-        if hasattr(self, "fgraph") and self.fgraph != fgraph:
-            raise Exception("This ShapeFeature is already attached to a graph")
-
-        self.fgraph = fgraph
-
         fgraph.shape_feature = self
-        # Must be local to the object as otherwise we reuse the same
-        # variable for multiple fgraph!
-        self.lscalar_one = constant(1, dtype="int64")
+
         assert self.lscalar_one.type.dtype == "int64"
 
-        self.fgraph = fgraph
-        # Variable -> tuple(scalars) or None  (All tensor vars map to tuple)
-        self.shape_of = {}
-        # Variable ->
-        self.scheduled = {}
-        # shape var -> graph v
-        self.shape_of_reverse_index = {}
+        self.shape_of: Dict[Variable, Optional[Tuple[Variable, ...]]] = {}
+        self.scheduled: Dict["Apply", Variable] = {}
+        self.shape_of_reverse_index: Dict[Variable, Set[Variable]] = {}
 
         for node in fgraph.toposort():
             self.on_import(fgraph, node, reason="on_attach")
 
     def on_detach(self, fgraph):
-        self.shape_of = {}
-        self.scheduled = {}
-        self.shape_of_reverse_index = {}
-        self.fgraph = None
+        self.shape_of.clear()
+        self.scheduled.clear()
+        self.shape_of_reverse_index.clear()
         del fgraph.shape_feature
 
     def on_import(self, fgraph, node, reason):
         if node.outputs[0] in self.shape_of:
             # this is a revert, not really an import
             for r in node.outputs + node.inputs:
                 assert r in self.shape_of
             return
 
         for i, r in enumerate(node.inputs):
             # make sure we have shapes for the inputs
             self.init_r(r)
 
-        o_shapes = self.get_node_infer_shape(node)
+        o_shapes = self.get_node_infer_shape(fgraph, node)
 
         # this is packed information
         # an element of o_shapes is either None or a tuple
         #   elements of the tuple can be either strings, or ints
         if len(o_shapes) != len(node.outputs):
             raise Exception(
-                (
-                    f'The infer_shape method for the Op "{node.op}" returned a list '
-                    f"with the wrong number of element: len(o_shapes) = {len(o_shapes)} "
-                    f" != len(node.outputs) = {len(node.outputs)}"
-                )
+                f'The infer_shape method for the Op "{node.op}" returned a list '
+                f"with the wrong number of element: len(o_shapes) = {len(o_shapes)} "
+                f" != len(node.outputs) = {len(node.outputs)}"
             )
 
         # Ensure shapes are in 'int64'. This is to make sure the assert
         # found in the `local_useless_subtensor` rewrite does not fail.
         for sh_idx, sh in enumerate(o_shapes):
             if sh is None:
                 continue
@@ -569,15 +571,15 @@
                 # but this works with `local_useless_subtensor`, so for now we
                 # keep it this way. See #266 for a better long-term fix.
                 if getattr(d, "dtype", "int64") != "int64":
                     assert d.dtype in discrete_dtypes, (node, d.dtype)
                     assert str(d.dtype) != "uint64", node
                     new_shape += sh[len(new_shape) : i + 1]
                     if isinstance(d, Constant):
-                        casted_d = constant(d.data, dtype="int64")
+                        casted_d = constant(d.data, dtype="int64", ndim=0)
                     else:
                         casted_d = cast(d, "int64")
                     new_shape[i] = casted_d
             if new_shape:
                 # We replace the shape with wrong dtype by the one with
                 # 'int64'.
                 new_shape += sh[len(new_shape) :]
@@ -602,15 +604,15 @@
         # 1) we are trying to get rid of r, or
         # 2) we are putting things back after a failed transaction.
 
         # In case 1, if r has a shape_i client, we will want to
         # replace the shape_i of r with the shape of new_r.  Say that
         # r is *scheduled*.
         # At that point, node is no longer a client of r, but of new_r
-        for (shpnode, idx) in fgraph.clients[r] + [(node, i)]:
+        for shpnode, idx in fgraph.clients[r] + [(node, i)]:
             if isinstance(getattr(shpnode, "op", None), Shape_i):
                 idx = shpnode.op.i
                 repl = self.shape_of[new_r][idx]
                 if repl.owner is shpnode:
                     # This mean the replacement shape object is
                     # exactly the same as the current shape object. So
                     # no need for replacement.
@@ -680,18 +682,18 @@
         sx = self.shape_of[x]
         sy = self.shape_of[y]
 
         if sx is None or sy is None:
             return False
 
         if dim_x is not None:
-            sx = [sx[dim_x]]
+            sx = (sx[dim_x],)
 
         if dim_y is not None:
-            sy = [sy[dim_y]]
+            sy = (sy[dim_y],)
 
         if len(sx) != len(sy):
             return False
 
         # Canonicalize the graphs so that comparisons are reasonable
         # TODO FIXME: This should *not* need to be performed manually here.
         # Instead, the shape information in `self.shape_of` should be operated
@@ -707,18 +709,18 @@
 
         canon_shapes_fg = type_cast(
             FunctionGraph,
             rewrite_graph(shapes_fg, custom_rewrite=topo_constant_folding),
         )
         canon_shapes = canon_shapes_fg.outputs
 
-        sx = canon_shapes[: len(sx)]
-        sy = canon_shapes[len(sx) :]
+        sx_ = canon_shapes[: len(sx)]
+        sy_ = canon_shapes[len(sx) :]
 
-        for dx, dy in zip(sx, sy):
+        for dx, dy in zip(sx_, sy_):
             if not equal_computations([dx], [dy]):
                 return False
 
         return True
 
     def clone(self):
         return type(self)()
@@ -880,15 +882,15 @@
             if cst_outshp_i == -1:
                 shape_match[dim] = True
                 nb_m1 += 1
                 continue
 
             # Match shape_of[input][dim] or its constant equivalent
             if shape_feature:
-                inpshp_i = shape_feature.get_shape(inp, dim)
+                inpshp_i = shape_feature.get_shape(fgraph, inp, dim)
                 if inpshp_i == outshp_i or (
                     extract_constant(inpshp_i, only_process_constants=1)
                     == extract_constant(outshp_i, only_process_constants=1)
                 ):
                     shape_match[dim] = True
                     continue
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/special.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/special.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from aesara import scalar as aes
 from aesara.graph.rewriting.basic import copy_stack_trace, node_rewriter
 from aesara.tensor.elemwise import DimShuffle, Elemwise
 from aesara.tensor.math import Sum, exp
 from aesara.tensor.math import sum as at_sum
-from aesara.tensor.math import true_div
+from aesara.tensor.math import true_divide
 from aesara.tensor.rewriting.basic import register_specialize
 from aesara.tensor.rewriting.math import local_mul_canonizer
 from aesara.tensor.special import LogSoftmax, Softmax, SoftmaxGrad
 from aesara.tensor.subtensor import AdvancedIncSubtensor
 from aesara.tensor.type import values_eq_approx_remove_inf, values_eq_approx_remove_nan
 
 
@@ -46,23 +46,23 @@
 
     Note: only grad is affected
     """
     if (
         isinstance(node.op, SoftmaxGrad)
         and len(node.inputs) == 2
         and node.inputs[0].owner is not None
-        and node.inputs[0].owner.op == true_div
+        and node.inputs[0].owner.op == true_divide
         and len(node.inputs[0].owner.inputs) >= 2
         and node.inputs[0].owner.inputs[1].owner is not None
         and isinstance(node.inputs[0].owner.inputs[1].owner.op, Softmax)
         and node.inputs[1] == node.inputs[0].owner.inputs[1]
         and not (
             # skip if it will be optimized by
             # local_advanced_indexing_crossentropy_onehot_grad
-            node.inputs[0].owner.op == true_div
+            node.inputs[0].owner.op == true_divide
             and node.inputs[0].owner.inputs[0].owner is not None
             and isinstance(
                 node.inputs[0].owner.inputs[0].owner.op, AdvancedIncSubtensor
             )
             # the rewrite only applies to legacy SoftmaxGrad
             and node.op == SoftmaxGrad(axis=-1)
             and node.inputs[0].owner.inputs[1].ndim == 2
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/subtensor.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/subtensor.py`

 * *Files 0% similar despite different names*

```diff
@@ -439,15 +439,15 @@
             old_axes = u.owner.op.axes
             new_axes = []
 
             # loop through indices being subtensor-ed
             # i indexes broadcastable pattern before subtensor
             # j indexes broadcastable pattern after subtensor
             j = 0
-            for (i, x) in enumerate(node.op.idx_list):
+            for i, x in enumerate(node.op.idx_list):
                 # if it is not a slice, it will reduce the dimension, should
                 # not appear in the broascastable dimensions
                 if isinstance(x, slice):
                     if i in old_axes:
                         new_axes.append(j)
                     j += 1
             # now keep the broadcastable pattern of all
@@ -815,15 +815,14 @@
         and e.stop is None
         and (
             e.step is None
             or extract_constant(e.step, only_process_constants=True) == -1
         )
         for e in idx_cst
     ):
-
         # `IncSubtensor` broadcasts `x` on `y` based on run-time shapes, so we
         # must check that they are the same
         if not fgraph.shape_feature.same_shape(x, y):
             return
 
         # There are no reversals, so we don't need a replacement.
         if all(e.step is None for e in node.op.idx_list):
@@ -1372,15 +1371,14 @@
 
         try:
             replace_y = get_scalar_constant_value(y, elemwise=False)
         except NotScalarConstantError:
             return
 
         if replace_x == replace_y:
-
             # No need to copy over the stacktrace,
             # because x should already have a stacktrace
             return [x]
         else:
             return False
 
 
@@ -1730,15 +1728,14 @@
         if all(
             idxs_nonaxis_subtensor1 == idxs_nonaxis_subtensor2
             for i, (idxs_nonaxis_subtensor1, idxs_nonaxis_subtensor2) in enumerate(
                 zip(idxs_subtensor1, idxs_subtensor2)
             )
             if i != axis
         ):
-
             base_tensor = subtensor1.owner.inputs[0]
             new_idxs = list(idxs_subtensor1)
             new_idxs[axis] = slice(start_subtensor1, stop_subtensor2, step_subtensor1)
             merged_subtensors = base_tensor[new_idxs]
 
             new_joined_tensors = [
                 *tensors[:subtensor1_idx],
@@ -1772,15 +1769,14 @@
         y = None
 
     idx_list = getattr(node.op, "idx_list", None)
     new_indices = list(indices_from_subtensor(indices, idx_list))
     has_new_index = False
 
     for i, index in enumerate(new_indices):
-
         if not isinstance(index, Constant):
             continue
 
         index_val = index.data
 
         if index_val is None or isinstance(index_val, slice):
             # TODO: If slice index dtypes matter, we can consider converting
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/rewriting/uncanonicalize.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/rewriting/uncanonicalize.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/shape.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/shape.py`

 * *Files 0% similar despite different names*

```diff
@@ -644,18 +644,16 @@
         return Apply(self, [x, shp], [tensor(x.type.dtype, shape=out_shape)])
 
     def perform(self, node, inp, out_, params):
         x, shp = inp
         (out,) = out_
         if len(shp) != self.ndim:
             raise ValueError(
-                (
-                    "Shape argument to Reshape has incorrect"
-                    f" length: {len(shp)}, should be {self.ndim}"
-                )
+                "Shape argument to Reshape has incorrect"
+                f" length: {len(shp)}, should be {self.ndim}"
             )
         out[0] = np.reshape(x, shp)
 
     def connection_pattern(self, node):
         return [[True], [False]]
 
     def grad(self, inp, grads):
@@ -715,15 +713,14 @@
             elif crit > 1:
                 raise ValueError(
                     "shape argument to Reshape.perform"
                     " must have at most one entry equal to -1"
                 )
             return [requ]
         else:
-
             requ = [requ[i] for i in range(self.ndim)]
             # since new_dims can have negative value (-1), the
             # multiplication of all values should be negated
             # to give a positive value.
             # To avoid optimization complexity, we avoid checking
             # for the case when there are two or more '-1' values.
             if self.ndim:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/sharedvar.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/sharedvar.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/signal/conv.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/signal/conv.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/signal/pool.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/signal/pool.py`

 * *Files 0% similar despite different names*

```diff
@@ -596,15 +596,15 @@
 
         # iterate over non-pooling dimensions
         for k in np.ndindex(*x.shape[:-nd]):
             zzk = zz[k]
             yk = y[k]
             # iterate over pooling regions
             for r in np.ndindex(*pool_out_shp):
-                zzk[r] = func(yk[[region_slices[i][r[i]] for i in range(nd)]])
+                zzk[r] = func(yk[tuple(region_slices[i][r[i]] for i in range(nd))])
 
     def infer_shape(self, fgraph, node, in_shapes):
         ws, stride, pad = [node.inputs[1], node.inputs[2], node.inputs[3]]
         shp = self.out_shape(
             in_shapes[0], ws, self.ignore_border, stride, pad, self.ndim
         )
         return [shp]
@@ -1574,15 +1574,15 @@
                     region_slice[i] = region_slices[i][r[i]]
                     region_size *= region_sizes[i][r[i]]
                 if sum_mode:
                     val = gzk[r]
                 else:
                     # divide by region size
                     val = gzk[r] / region_size
-                gxk[region_slice] += val
+                gxk[tuple(region_slice)] += val
 
         # unpad the image
         gx = gx[
             (slice(None),) * (len(x.shape) - nd)
             + tuple(slice(pad[i], img_shp[i] - pad[i]) for i in range(nd))
         ]
         gx_stg[0] = gx
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/slinalg.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/slinalg.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 import logging
 import warnings
-from typing import TYPE_CHECKING, Union
+from typing import TYPE_CHECKING, Literal, Union
 
 import numpy as np
 import scipy.linalg
-from typing_extensions import Literal
 
 import aesara.tensor
 from aesara.graph.basic import Apply
 from aesara.graph.op import Op
 from aesara.tensor import as_tensor_variable
 from aesara.tensor import basic as at
 from aesara.tensor import math as atm
@@ -125,15 +124,14 @@
             return [grad]
 
 
 cholesky = Cholesky()
 
 
 class CholeskySolve(Op):
-
     __props__ = ("lower", "check_finite")
 
     def __init__(
         self,
         lower=True,
         check_finite=True,
     ):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/sort.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/sort.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/special.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/special.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 import numpy as np
 import scipy
 
 from aesara.graph.basic import Apply
 from aesara.link.c.op import COp
 from aesara.tensor.basic import as_tensor_variable
-from aesara.tensor.math import neg, sum
+from aesara.tensor.math import gamma, neg, sum
 
 
 class SoftmaxGrad(COp):
     """
     Gradient wrt x of the Softmax Op.
 
     """
@@ -764,11 +764,23 @@
         warnings.warn(
             "Softmax no longer converts a vector to a row matrix.",
             UserWarning,
         )
     return LogSoftmax(axis=axis)(c)
 
 
+def poch(z, m):
+    """Compute the Pochhammer/rising factorial."""
+    return gamma(z + m) / gamma(z)
+
+
+def factorial(n):
+    """Compute the factorial."""
+    return gamma(n + 1)
+
+
 __all__ = [
     "softmax",
     "log_softmax",
+    "poch",
+    "factorial",
 ]
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/subtensor.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/subtensor.py`

 * *Files 1% similar despite different names*

```diff
@@ -809,15 +809,14 @@
             # We have an optimization that will convert this to a
             # set subtensor here at:
             # aesara/tensor/opt.py:local_incsubtensor_of_zeros_to_setsubtensor()
             first = IncSubtensor(self.idx_list)(x.zeros_like(), gz, *rest)
         return [first] + [DisconnectedType()()] * len(rest)
 
     def connection_pattern(self, node):
-
         rval = [[True]]
 
         for ipt in node.inputs[1:]:
             rval.append([False])
 
         return rval
 
@@ -1587,15 +1586,14 @@
             if not self.set_instead_of_inc:
                 x.__setitem__(cdata, sub_x + y)
             else:
                 x.__setitem__(cdata, y)
         out[0] = x
 
     def c_code(self, node, name, inputs, outputs, sub):
-
         # This method delegates much of the work to helper
         # methods. This method implements the main logic
         # but subclasses may override the helper methods
         # to change the particulars.
 
         self.do_type_checking(node)
 
@@ -1832,15 +1830,14 @@
         if eval_points[0] is None or eval_points[1] is None:
             return [None]
         # Again we ignore eval points for indices because incsubtensor is
         # not differentiable wrt to those
         return self(eval_points[0], eval_points[1], *inputs[2:], return_list=True)
 
     def connection_pattern(self, node):
-
         rval = [[True], [True]]
 
         for ipt in node.inputs[2:]:
             rval.append([False])
 
         return rval
 
@@ -2467,15 +2464,14 @@
 
     def R_op(self, inputs, eval_points):
         if None in eval_points[:2]:
             return [None]
         return self.make_node(eval_points[0], eval_points[1], *inputs[2:]).outputs
 
     def connection_pattern(self, node):
-
         rval = [[True], [True], [False]]
         return rval
 
     def grad(self, inputs, grads):
         (g_output,) = grads
         x, y, idx_list = inputs
         if x.dtype in discrete_dtypes:
@@ -2686,15 +2682,14 @@
                     dtype=x.type.dtype,
                     shape=tuple(1 if s == 1 else None for s in x.type.shape),
                 )
             ],
         )
 
     def perform(self, node, inputs, out_):
-
         x, y, *indices = inputs
 
         check_advanced_indexing_dimensions(x, indices)
 
         (out,) = out_
         if not self.inplace:
             out[0] = x.copy()
@@ -2708,15 +2703,14 @@
         else:
             np.add.at(out[0], tuple(indices), y)
 
     def infer_shape(self, fgraph, node, ishapes):
         return [ishapes[0]]
 
     def connection_pattern(self, node):
-
         rval = [[True], [True]]
 
         for ipt in node.inputs[2:]:
             rval.append([False])
 
         return rval
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/type.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/type.py`

 * *Files 0% similar despite different names*

```diff
@@ -375,15 +375,19 @@
     @property
     def broadcastable(self):
         """A boolean tuple indicating which dimensions have a shape equal to one."""
         return tuple(s == 1 for s in self.shape)
 
     @property
     def ndim(self):
-        """The number of dimensions."""
+        """The number of dimensions that a `Variable``'s values
+        will have at evaluation time. This must be known when we are building
+        the expression graphs.
+
+        """
         return len(self.shape)
 
     def __str__(self):
         if self.name:
             return self.name
         else:
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/type_other.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/type_other.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,14 @@
     x = aesara.tensor.as_tensor_variable(x, ndim=0)
     if x.type.dtype not in integer_dtypes:
         raise TypeError("index must be integers")
     return x
 
 
 class MakeSlice(Op):
-
     __props__ = ()
 
     def make_node(self, slc, stop=None, step=None):
         # We need to accept and handle in make_node inputs the node
         # inputs to allow redoing a new op elsewhere in the graph by
         # optimization.
         if isinstance(slc, slice):
@@ -110,15 +109,14 @@
 
 
 SliceType.constant_type = SliceConstant
 
 
 @_as_symbolic.register(slice)
 def as_symbolic_slice(x, **kwargs):
-
     if any(isinstance(i, Variable) for i in (x.start, x.stop, x.step)):
         return make_slice(x)
 
     return SliceConstant(slicetype, x)
 
 
 class NoneTypeT(Generic):
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/utils.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/utils.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/var.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/var.py`

 * *Files 2% similar despite different names*

```diff
@@ -166,24 +166,24 @@
         except (NotImplementedError, TypeError):
             return NotImplemented
 
     def __divmod__(self, other):
         return at.math.divmod(self, other)
 
     def __truediv__(self, other):
-        return at.math.true_div(self, other)
+        return at.math.true_divide(self, other)
 
     def __floordiv__(self, other):
-        return at.math.floor_div(self, other)
+        return at.math.floor_divide(self, other)
 
     def __rtruediv__(self, other):
-        return at.math.true_div(other, self)
+        return at.math.true_divide(other, self)
 
     def __rfloordiv__(self, other):
-        return at.math.floor_div(other, self)
+        return at.math.floor_divide(other, self)
 
     # Do not use these; in-place `Op`s should be inserted by optimizations
     # only!
     # def __iadd__(self, other):
     #    return _add_inplace(self, other)
     # def __isub__(self, other):
     #    return _sub_inplace(self, other)
@@ -285,14 +285,20 @@
     #     raise Exception("Aesara Variables can't work with len(Aesara "
     #                     "Variable) due to Python restriction. You can use "
     #                     "AesaraVariable.shape[0] instead.")
 
     def reshape(self, shape, ndim=None):
         """Return a reshaped view/copy of this variable.
 
+        Returns a view of this ``Variable`` that has been reshaped as in
+        `numpy.reshape`.  If the shape is a `Variable` argument, then you might
+        need to use the optional `ndim` parameter to declare how many elements
+        the shape has, and therefore how many dimensions the reshaped ``Variable``
+        will have.
+
         Parameters
         ----------
         shape
             Something that can be converted to a symbolic vector of integers.
         ndim
             The length of the shape. Passing None here means for
             Aesara to try and guess the length of `shape`.
@@ -313,14 +319,30 @@
         return at.reshape(self, shape, ndim=ndim)
 
     def dimshuffle(self, *pattern):
         """
         Reorder the dimensions of this variable, optionally inserting
         broadcasted dimensions.
 
+        Returns a view of this variable with permuted dimensions.  Typically the
+        pattern will include the integers ``0, 1, ... ndim-1``, and any number of
+        ``'x'`` characters in dimensions where this variable should be broadcasted.
+
+        A few examples of patterns and their effect:
+
+            * ``('x',)``: make a 0d (scalar) into a 1d vector
+            * ``(0, 1)``: identity for 2d vectors
+            * ``(1, 0)``: inverts the first and second dimensions
+            * ``('x', 0)``: make a row out of a 1d vector (N to 1xN)
+            * ``(0, 'x')``: make a column out of a 1d vector (N to Nx1)
+            * ``(2, 0, 1)``: AxBxC to CxAxB
+            * ``(0, 'x', 1)``: AxB to Ax1xB
+            * ``(1, 'x', 0)``: AxB to Bx1xA
+            * ``(1,)``: This removes the dimension at index 0. It must be a broadcastable dimension.
+
         Parameters
         ----------
         pattern
             List/tuple of int mixed with 'x' for broadcastable dimensions.
 
         Examples
         --------
@@ -343,17 +365,24 @@
         """
         if (len(pattern) == 1) and (isinstance(pattern[0], (list, tuple))):
             pattern = pattern[0]
         op = at.elemwise.DimShuffle(list(self.type.broadcastable), pattern)
         return op(self)
 
     def flatten(self, ndim=1):
+        """
+        Returns a view of this variable with `ndim` dimensions, whose shape for the first
+        ``ndim-1`` dimensions will be the same as ``self``, and shape in the
+        remaining dimension will be expanded to fit in all the data from ``self``.
+
+        """
         return at.basic.flatten(self, ndim)
 
     def ravel(self):
+        """See `flatten`."""
         return at.basic.flatten(self)
 
     def diagonal(self, offset=0, axis1=0, axis2=1):
         return at.basic.diagonal(self, offset, axis1, axis2)
 
     def transfer(self, target):
         """Transfer this this array's data to another device.
@@ -948,15 +977,14 @@
 
     @property
     def sum(self):
         """Compute sum of non NaN / Inf values in the array."""
         try:
             return self._sum
         except AttributeError:
-
             # Prevent warnings when there are `inf`s and `-inf`s present
             with warnings.catch_warnings():
                 warnings.simplefilter("ignore", category=RuntimeWarning)
                 self._sum = self.no_nan.sum()
 
             # The following 2 lines are needed as in Python 3.3 with NumPy
             # 1.7.1, numpy.ndarray and numpy.memmap aren't hashable.
@@ -1041,15 +1069,15 @@
         if len(val) > 20:
             val = val[:10] + ".." + val[-10:]
 
         if self.name is not None:
             name = self.name
         else:
             name = "TensorConstant"
-        return "%s{%s}" % (name, val)
+        return f"{name}{{{val}}}"
 
     def signature(self):
         return TensorConstantSignature((self.type, self.data))
 
     def equals(self, other):
         # Override Constant.equals to allow to compare with
         # numpy.ndarray, and python type.
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/tensor/xlogx.py` & `aesara_nightly-2.9.0.post2/aesara/tensor/xlogx.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/typed_list/basic.py` & `aesara_nightly-2.9.0.post2/aesara/typed_list/basic.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/aesara/typed_list/rewriting.py` & `aesara_nightly-2.9.0.post2/aesara/typed_list/rewriting.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 
 @node_rewriter([Append, Extend, Insert, Reverse, Remove], inplace=True)
 def typed_list_inplace_rewrite(fgraph, node):
     if (
         isinstance(node.op, (Append, Extend, Insert, Reverse, Remove))
         and not node.op.inplace
     ):
-
         new_op = node.op.__class__(inplace=True)
         new_node = new_op(*node.inputs)
         return [new_node]
     return False
 
 
 optdb.register(
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/typed_list/type.py` & `aesara_nightly-2.9.0.post2/aesara/typed_list/type.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,14 @@
     depth
         Optional parameters, any value above 0 will create a nested list of
         this depth. (0-based)
 
     """
 
     def __init__(self, ttype, depth=0):
-
         if depth < 0:
             raise ValueError("Please specify a depth superior or" "equal to 0")
         if not isinstance(ttype, Type):
             raise TypeError("Expected an Aesara Type")
 
         if depth == 0:
             self.ttype = ttype
@@ -125,15 +124,14 @@
             + """
         %(name)s = (PyListObject*) (py_%(name)s);
         """
             % dict(name=name, fail=sub["fail"])
         )
 
     def c_sync(self, name, sub):
-
         return """
         Py_XDECREF(py_%(name)s);
         py_%(name)s = (PyObject*)(%(name)s);
         Py_INCREF(py_%(name)s);
         """ % dict(
             name=name
         )
@@ -142,7 +140,8 @@
         return ""
 
     def c_code_cache_version(self):
         return (2,)
 
     dtype = property(lambda self: self.ttype)
     ndim = property(lambda self: self.ttype.ndim + 1)
+    shape = property(lambda self: (None,) + self.ttype.shape)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/updates.py` & `aesara_nightly-2.9.0.post2/aesara/updates.py`

 * *Files 0% similar despite different names*

```diff
@@ -42,15 +42,14 @@
             if not isinstance(key, SharedVariable):
                 raise TypeError(
                     "OrderedUpdates keys must inherit from SharedVariable", key
                 )
 
     def __setitem__(self, key, value):
         if isinstance(key, SharedVariable):
-
             # TODO: consider doing error-checking on value.
             # insist that it is an Aesara variable? Have the right type?
             # This could have weird consequences - for example a
 
             return super().__setitem__(key, value)
         else:
             raise TypeError("OrderedUpdates keys must inherit from SharedVariable", key)
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/utils.py` & `aesara_nightly-2.9.0.post2/aesara/utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -160,15 +160,14 @@
         def function_wrapper(*args, **kwargs):
             nonlocal message
 
             current_call_source = "|".join(
                 traceback.format_stack(inspect.currentframe())
             )
             if current_call_source not in function_wrapper.last_call_source:
-
                 if not message:
                     message = f"Function {func.__name__} is deprecated."
 
                 warnings.warn(
                     message,
                     category=DeprecationWarning,
                     stacklevel=2,
```

### Comparing `aesara-nightly-2.8.9.post118/aesara/version.py` & `aesara_nightly-2.9.0.post2/aesara/version.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/.static/version_switch.js` & `aesara_nightly-2.9.0.post2/doc/.static/version_switch.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/.templates/layout.html` & `aesara_nightly-2.9.0.post2/doc/.templates/layout.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/acknowledgement.rst` & `aesara_nightly-2.9.0.post2/doc/acknowledgement.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/bcast.png` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/bcast.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/bcast.svg` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/bcast.svg`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/conf.py` & `aesara_nightly-2.9.0.post2/doc/conf.py`

 * *Files 6% similar despite different names*

```diff
@@ -29,23 +29,26 @@
 # General configuration
 # ---------------------
 
 # Add any Sphinx extension module names here, as strings. They can be
 # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
 extensions = [
     "sphinx.ext.autodoc",
+    "sphinx.ext.autosummary",
     "sphinx.ext.todo",
     "sphinx.ext.doctest",
     "sphinx.ext.napoleon",
     "sphinx.ext.linkcode",
+    "sphinx_design",
 ]
 
 todo_include_todos = True
 napoleon_google_docstring = False
 napoleon_include_special_with_doc = False
+autosummary_generate = True
 
 # We do it like this to support multiple sphinx version without having warning.
 # Our buildbot consider warning as error.
 try:
     from sphinx.ext import imgmath
 
     extensions.append("sphinx.ext.imgmath")
@@ -117,27 +120,23 @@
 
 # The style sheet to use for HTML and HTML Help pages. A file of that name
 # must exist either in Sphinx' static/ path, or in one of the custom paths
 # given in html_static_path.
 # html_style = 'default.css'
 # html_theme = 'sphinxdoc'
 
-# html4_writer added to Fix colon & whitespace misalignment
-# https://github.com/readthedocs/sphinx_rtd_theme/issues/766#issuecomment-513852197
-html4_writer = True
-
 # Read the docs style:
-if os.environ.get("READTHEDOCS") != "True":
-    try:
-        import sphinx_rtd_theme
-    except ImportError:
-        pass  # assume we have sphinx >= 1.3
-    else:
-        html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]
-    html_theme = "sphinx_rtd_theme"
+html_theme = "sphinx_book_theme"
+html_theme_options = {
+    "repository_url": "https://github.com/aesara-devs/aesara",
+    "use_repository_button": True,
+    "use_download_button": False,
+}
+html_title = ""
+html_logo = "images/aesara_logo_200.png"
 
 
 def setup(app):
     app.add_css_file("fix_rtd.css")
 
 
 # The name for this set of Sphinx documents.  If None, it defaults to
@@ -155,15 +154,15 @@
 # docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
 # pixels large.
 # html_favicon = None
 
 # Add any paths that contain custom static files (such as style sheets) here,
 # relative to this directory. They are copied after the builtin static files,
 # so a file named "default.css" will overwrite the builtin "default.css".
-html_static_path = [".static", "images", "library/d3viz/examples"]
+html_static_path = [".static", "images", "troubleshoot/d3viz/examples"]
 
 # If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
 # using the given strftime format.
 html_last_updated_fmt = "%b %d, %Y"
 
 # If true, SmartyPants will be used to convert quotes and dashes to
 # typographically correct entities.
```

### Comparing `aesara-nightly-2.8.9.post118/doc/core_development_guide.rst` & `aesara_nightly-2.9.0.post2/doc/core_development_guide.rst`

 * *Files 4% similar despite different names*

```diff
@@ -20,16 +20,14 @@
 * :ref:`graph_rewriting` -- Tutorial on how graph rewriting works in Aesara.
 
 * :ref:`pipeline` -- Describes the steps of compiling an Aesara Function.
 
 * :ref:`graphstructures` -- Describes the symbolic graphs generated by
   :mod:`aesara.scan`.
 
-* :ref:`unittest` -- Tutorial on how to use unittest in testing Aesara.
-
 * :ref:`sandbox_debugging_step_mode` -- How to step through the execution of
   an Aesara function and print the inputs and outputs of each op.
 
 * :ref:`sandbox_elemwise` -- Description of element wise operations.
 
 * :ref:`sandbox_randnb` -- Description of how Aesara deals with random
   numbers.
```

### Comparing `aesara-nightly-2.8.9.post118/doc/dev_start_guide.rst` & `aesara_nightly-2.9.0.post2/doc/dev_start_guide.rst`

 * *Files 4% similar despite different names*

```diff
@@ -12,16 +12,14 @@
 
 We recommend creating an issue to discuss proposed changes before making them.
 This is a good way to make sure that proposed changes will be accepted.
 
 Resources
 =========
 
-See :ref:`aesara-community` for a list of Aesara resources.
-
 The Theano Google group is also relevant to (early) Aesara versions:
 `theano-dev`_.
 
 .. _theano-dev: https://groups.google.com/group/theano-dev
 
 
 .. _quality_contributions:
@@ -72,17 +70,14 @@
 
 * To cross-reference other objects (e.g. reference other classes or methods) in
   the docstrings, use the
   `cross-referencing objects <http://www.sphinx-doc.org/en/stable/domains.html#cross-referencing-python-objects>`_
   syntax. ``:py`` can be omitted, see e.g. this
   `stackoverflow answer <http://stackoverflow.com/a/7754189>`_.
 
-* See :ref:`metadocumentation`, for some information on how to generate the
-  documentation.
-
 
 A Docstring Example
 ~~~~~~~~~~~~~~~~~~~
 Here is an example on how to add a docstring to a class.
 
 .. testcode:: python
 
@@ -148,22 +143,42 @@
     git remote add upstream git://github.com/aesara-devs/aesara.git
 
 .. note::
 
     You can choose a name other than "upstream" to reference the official Aesara
     repository.
 
+We also have to pull the necessary tags like so:
+
+.. code-block:: bash
+
+    git fetch -t --all
+
+.. note::
+
+    If an error along the lines of `errno=Operation timed out` occurs here, then you
+    may need to run 
+    
+    .. code-block:: bash
+        
+        git remote set-url upstream https://github.com/aesara-devs/aesara.git
+        git fetch -t --all
+
 Setting up the your local development environment
 -------------------------------------------------
 
 You will need to create a virtual environment and install the project requirements within it.
 
 The recommended approach is to install `conda <https://conda.io/projects/conda/en/latest/user-guide/install/index.html>`_ and
 create a virtual environment in the project directory:
 
+.. note::
+
+    For computers using an ARM processor, replace the `environment.yml` below with `environment-arm.yml`.
+
 .. code-block:: bash
 
     conda env create -n aesara-dev -f environment.yml
     conda activate aesara-dev
 
 Afterward, you can install the development dependencies:
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/apply.png` & `aesara_nightly-2.9.0.post2/doc/extend/op/apply.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/apply.svg` & `aesara_nightly-2.9.0.post2/doc/extend/op/apply.svg`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/apply2.svg` & `aesara_nightly-2.9.0.post2/doc/extend/op/apply2.svg`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/creating_a_c_op.rst` & `aesara_nightly-2.9.0.post2/doc/extend/backend/creating_a_c_op.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/creating_a_numba_jax_op.rst` & `aesara_nightly-2.9.0.post2/doc/extend/backend/creating_a_numba_jax_op.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/creating_an_op.rst` & `aesara_nightly-2.9.0.post2/doc/extend/op/creating_an_op.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 .. _creating_an_op:
 
 Creating a new :class:`Op`: Python implementation
 =================================================
 
 So suppose you have looked through the library documentation and you don't see
 a function that does what you want.
@@ -631,17 +630,16 @@
                 # Op that should be removed from the graph.
                 self.op_class,
             )
 
 Testing the gradient
 ^^^^^^^^^^^^^^^^^^^^
 
-The function :ref:`verify_grad <validating_grad>`
-verifies the gradient of an :class:`Op` or Aesara graph. It compares the
-analytic (symbolically computed) gradient and the numeric
+The function ``verify_grad`` verifies the gradient of an :class:`Op` or Aesara
+graph. It compares the analytic (symbolically computed) gradient and the numeric
 gradient (computed through the Finite Difference Method).
 
 If there is an error, the function raises an exception. If you want to
 see it fail, you can implement an incorrect gradient (for instance, by removing
 the multiplication by 2).
 
 .. testcode:: tests
@@ -730,17 +728,14 @@
 generator.
 
 For convenience, the classes :class:`InferShapeTester` and :class:`RopLop_checker`
 already do this for you. If you implement your own :meth:`setUp` method,
 don't forget to call the parent :meth:`setUp` method.
 
 
-:download:`Solution<extending_aesara_solution_1.py>`
-
-
 :func:`as_op`
 ---------------------
 
 :func:`as_op` is a Python decorator that converts a Python function into a
 basic Aesara :class:`Op` that will call the supplied function during execution.
 
 This isn't the recommended way to build an :class:`Op`, but allows for a quick
@@ -837,17 +832,14 @@
 variable that get replaced by an inplace version, it will keep that
 tag.
 
 
 Final Note
 ----------
 
-A more extensive discussion of this section's content may be found in
-the advanced tutorial :ref:`Extending Aesara<extending>`.
-
 The section :ref:`Other Ops <other_ops>` includes more instructions for
 the following specific cases:
 
  - :ref:`scalar_ops`
  - :ref:`sparse_ops`
  - :ref:`Random ops <random_ops>`
  - :ref:`openmp_ops`
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/ctype.rst` & `aesara_nightly-2.9.0.post2/doc/extend/backend/ctype.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/graph_rewriting.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/rewrites/graph_rewriting.rst`

 * *Files 2% similar despite different names*

```diff
@@ -16,16 +16,15 @@
 
 
 Graph and Node Rewriters
 ========================
 
 There are two types of basic rewriters: *graph* rewriters and *node* rewriters.
 
-A graph rewriter takes a :class:`FunctionGraph` object (see its
-:doc:`documentation </library/graph/fgraph>` for more details) and navigates through it
+A graph rewriter takes a :class:`FunctionGraph` object and navigates through it
 in a suitable way, replacing some :class:`Variable`\s by others in the process.
 A node rewriter, on the other hand, is defined as a function on a
 *single* :ref:`apply` node and must return either ``False`` (to mean that
 nothing is to be done) or a list of new :class:`Variable`\s that we would like to
 substitute for the node's current outputs.
 
 Some graph rewriters navigate the computation graph in a particular fashion
@@ -107,15 +106,15 @@
 
    class Simplify(GraphRewriter):
        def add_requirements(self, fgraph):
            fgraph.attach_feature(ReplaceValidate())
 
        def apply(self, fgraph):
            for node in fgraph.toposort():
-               if node.op == true_div:
+               if node.op == true_divide:
                    x, y = node.inputs
                    z = node.outputs[0]
                    if x.owner and x.owner.op == mul:
                        a, b = x.owner.inputs
                        if y == a:
                            fgraph.replace_validate(z, b)
                        elif y == b:
@@ -148,53 +147,53 @@
 we can now say that ``z == (a*b)/y``. If ``y==a`` then ``z==b`` and if
 ``y==b`` then ``z==a``. When either case happens then we can replace
 ``z`` by either ``a`` or ``b`` using :meth:`FunctionGraph.replace_validate`; otherwise, we do
 nothing.
 
 Now, we test the rewriter:
 
->>> from aesara.scalar import float64, add, mul, true_div
+>>> from aesara.scalar import float64, add, mul, true_divide
 >>> x = float64('x')
 >>> y = float64('y')
 >>> z = float64('z')
->>> a = add(z, mul(true_div(mul(y, x), y), true_div(z, x)))
+>>> a = add(z, mul(true_divide(mul(y, x), y), true_divide(z, x)))
 >>> e = aesara.graph.fg.FunctionGraph([x, y, z], [a])
 >>> e
-FunctionGraph(add(z, mul(true_div(mul(y, x), y), true_div(z, x))))
+FunctionGraph(add(z, mul(true_divide(mul(y, x), y), true_divide(z, x))))
 >>> simplify.rewrite(e)
 >>> e
-FunctionGraph(add(z, mul(x, true_div(z, x))))
+FunctionGraph(add(z, mul(x, true_divide(z, x))))
 
 You can check what happens if you put many
 instances of :math:`\frac{xy}{y}` in the graph. Note that it sometimes
 won't work for reasons that have nothing to do with the quality of the
 rewrite you wrote. For example, consider the following:
 
 >>> x = float64('x')
 >>> y = float64('y')
 >>> z = float64('z')
->>> a = true_div(mul(add(y, z), x), add(y, z))
+>>> a = true_divide(mul(add(y, z), x), add(y, z))
 >>> e = aesara.graph.fg.FunctionGraph([x, y, z], [a])
 >>> e
-FunctionGraph(true_div(mul(add(y, z), x), add(y, z)))
+FunctionGraph(true_divide(mul(add(y, z), x), add(y, z)))
 >>> simplify.rewrite(e)
 >>> e
-FunctionGraph(true_div(mul(add(y, z), x), add(y, z)))
+FunctionGraph(true_divide(mul(add(y, z), x), add(y, z)))
 
 Nothing happened here. The reason is: ``add(y, z) != add(y,
 z)``. That is the case for efficiency reasons. To fix this problem we
 first need to merge the parts of the graph that represent the same
 computation, using the :class:`MergeOptimizer` defined in
 :mod:`aesara.graph.rewriting.basic`.
 
 >>> from aesara.graph.rewriting.basic import MergeOptimizer
 >>> MergeOptimizer().rewrite(e)  # doctest: +ELLIPSIS
 (0, ..., None, None, {}, 1, 0)
 >>> e
-FunctionGraph(true_div(mul(*1 -> add(y, z), x), *1))
+FunctionGraph(true_divide(mul(*1 -> add(y, z), x), *1))
 >>> simplify.rewrite(e)
 >>> e
 FunctionGraph(x)
 
 Once the merge is done, both occurrences of ``add(y, z)`` are
 collapsed into a single one and is used as an input in two
 places. Note that ``add(x, y)`` and ``add(y, x)`` are still considered
@@ -220,28 +219,28 @@
 .. testcode::
 
    from aesara.graph.rewriting.basic import NodeRewriter
 
 
    class LocalSimplify(NodeRewriter):
        def transform(self, fgraph, node):
-           if node.op == true_div:
+           if node.op == true_divide:
                x, y = node.inputs
                if x.owner and x.owner.op == mul:
                    a, b = x.owner.inputs
                    if y == a:
                        return [b]
                    elif y == b:
                        return [a]
            return False
 
        def tracks(self):
            # This tells certain navigators to only apply this `NodeRewriter`
            # on these kinds of `Op`s
-           return [true_div]
+           return [true_divide]
 
    local_simplify = LocalSimplify()
 
 
 In this case, the transformation is defined in the
 :meth:`NodeRewriter.transform` method, which is given an explicit
 :class:`Apply` node on which to work.  The entire graph--as a ``fgraph``--is
@@ -257,23 +256,23 @@
 with a :class:`NodeProcessingGraphRewriter`.  A :class:`NodeProcessingGraphRewriter` is
 a graph rewriter that loops through all nodes in the graph (or a well-defined
 subset of them) and applies one or several node rewriters.
 
 >>> x = float64('x')
 >>> y = float64('y')
 >>> z = float64('z')
->>> a = add(z, mul(true_div(mul(y, x), y), true_div(z, x)))
+>>> a = add(z, mul(true_divide(mul(y, x), y), true_divide(z, x)))
 >>> e = aesara.graph.fg.FunctionGraph([x, y, z], [a])
 >>> e
-FunctionGraph(add(z, mul(true_div(mul(y, x), y), true_div(z, x))))
+FunctionGraph(add(z, mul(true_divide(mul(y, x), y), true_divide(z, x))))
 >>> simplify = aesara.graph.rewriting.basic.WalkingGraphRewriter(local_simplify)
 >>> simplify.rewrite(e)
 (<aesara.graph.rewriting.basic.WalkingGraphRewriter object at 0x...>, 1, 5, 3, ..., ..., ...)
 >>> e
-FunctionGraph(add(z, mul(x, true_div(z, x))))
+FunctionGraph(add(z, mul(x, true_divide(z, x))))
 
 :class:`SubstitutionNodeRewriter`, :class:`RemovalNodeRewriter`, :class:`PatternNodeRewriter`
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 
 Aesara defines some shortcuts to make :class:`NodeRewriter`\s:
 
 .. function:: SubstitutionNodeRewriter(op1, op2)
@@ -305,16 +304,16 @@
 
    # Removing `identity`
    remove_identity = RemovalNodeRewriter(identity)
 
    # The "simplify" operation we've been defining in the past few
    # sections. Note that we need two patterns to account for the
    # permutations of the arguments to `mul`.
-   local_simplify_1 = PatternNodeRewriter((true_div, (mul, 'x', 'y'), 'y'), 'x')
-   local_simplify_2 = PatternNodeRewriter((true_div, (mul, 'x', 'y'), 'x'), 'y')
+   local_simplify_1 = PatternNodeRewriter((true_divide, (mul, 'x', 'y'), 'y'), 'x')
+   local_simplify_2 = PatternNodeRewriter((true_divide, (mul, 'x', 'y'), 'x'), 'y')
 
 .. note::
 
    :class:`SubstitutionNodeRewriter`, :class:`RemovalNodeRewriter` and :class:`PatternNodeRewriter` produce node rewriters, which
    means that everything we said previously about node rewriters
    apply (e.g. they need to be wrapped in a :class:`NodeProcessingGraphRewriter`, etc.)
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/graphstructures.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graphstructures.rst`

 * *Files 2% similar despite different names*

```diff
@@ -208,15 +208,15 @@
 Aesara to perform rewrites and produce more efficient compiled code.
 
 Every symbolic :class:`Variable` in an Aesara graph has an associated
 :class:`Type` instance, and :class:`Type`\s also serve as a means of
 constructing :class:`Variable` instances.  In other words, :class:`Type`\s and
 :class:`Variable`\s go hand-in-hand.
 
-For example, :ref:`aesara.tensor.irow <libdoc_tensor_creation>` is an instance of a
+For example, :ref:`aesara.tensor.irow <reference_tensor_create>` is an instance of a
 :class:`Type` and it can be used to construct variables as follows:
 
 >>> from aesara.tensor import irow
 >>> irow()
 <TensorType(int32, (1, ?))>
 
 As the string print-out shows, `irow` specifies the following information about
@@ -321,15 +321,15 @@
 it is assumed that the gradient is not defined.
 
 Using the `chain rule <http://en.wikipedia.org/wiki/Chain_rule>`_,
 these gradients can be composed in order to obtain the expression of the
 gradient of the graph's output with respect to the graph's inputs.
 
 A following section of this tutorial will examine the topic of
-:ref:`differentiation<tutcomputinggrads>` in greater detail.
+:ref:`differentiation<reference_gradient_tutorial>` in greater detail.
 
 Rewrites
 ========
 
 When compiling an Aesara graph using :func:`aesara.function`, a graph is
 necessarily provided.  While this graph structure shows how to compute the
 output from the input, it also offers the possibility to improve the way this
@@ -358,17 +358,17 @@
 The output file is available at ./pics/symbolic_graph_no_rewrite.png
 >>> aesara.printing.pydotprint(f, outfile="./pics/symbolic_graph_rewite.png", var_with_name_simple=True)  # doctest: +SKIP
 The output file is available at ./pics/symbolic_graph_rewrite.png
 
 We used :func:`aesara.printing.pydotprint` to visualize the rewritten graph
 (right), which is much more compact than the un-rewritten graph (left).
 
-.. |g1| image:: ./pics/symbolic_graph_unopt.png
+.. |g1| image:: ./symbolic_graph_unopt.png
         :width: 500 px
-.. |g2| image:: ./pics/symbolic_graph_opt.png
+.. |g2| image:: ./symbolic_graph_opt.png
         :width: 500 px
 
 ================================ ====================== ================================
         Un-rewritten graph                                      Rewritten graph
 ================================ ====================== ================================
 |g1|                                                              |g2|
 ================================ ====================== ================================
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/inplace.rst` & `aesara_nightly-2.9.0.post2/doc/extend/op/inplace.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/op.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/op.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/other_ops.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/other_ops.rst`

 * *Files 4% similar despite different names*

```diff
@@ -208,23 +208,14 @@
 
 *       :class:`TensorType <tensor.type.TensorType>` : Aesara type that represents
         a multidimensional array containing elements that all have the same
         type. Variables of this Aesara type are represented in C as objects of
         class
         `PyArrayObject <http://docs.scipy.org/doc/numpy/reference/c-api.types-and-structures.html#PyArrayObject>`_.
 
-*       :ref:`TypedList <libdoc_typed_list>` : Aesara type that represents a
-        typed list (a list where every element in the list has the same Aesara
-        type). Variables of this Aesara type are represented in C as objects
-        of class `PyListObject <https://docs.python.org/2/c-api/list.html>`_.
-
-*       :ref:`ScalarType <libdoc_scalar>` : Aesara type that represents a C
-        primitive type. The C type associated with this Aesara type is the
-        represented C primitive itself.
-
 *       :ref:`SparseTensorType <sparse_ops>` : Aesara `Type` used to represent sparse
         tensors. There is no equivalent C type for this Aesara `Type` but you
         can split a sparse variable into its parts as TensorVariables. Those
         can then be used as inputs to an op with C code.
 
 *       :class:`Generic <aesara.link.c.type.Generic>` : Aesara type that
         represents a simple Python Object. Variables of this Aesara type are
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/pics/symbolic_graph_opt.png` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/symbolic_graph_opt.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/pics/symbolic_graph_unopt.png` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/symbolic_graph_unopt.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/pipeline.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/compilation/pipeline.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/scan.rst` & `aesara_nightly-2.9.0.post2/doc/reference/loops/scan_extend.rst`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 .. _scan_internals:
 
-Developer documentation for `Scan`
-++++++++++++++++++++++++++++++++++
+`Scan` internals
+================
 
 Context
-=======
+-------
 
 This document is meant to act as reference material for developers working
 on Aesara's loop mechanism. This mechanism is called `Scan` and its internals
 are highly complex, hence the need for a centralized repository of knowledge
 regarding its inner workings.
 
 The `aesara.scan` function is the public-facing interface for looping in
@@ -24,30 +24,30 @@
 working inside `Scan` itself, it will mostly discuss things from the point of view
 of the `Scan` `Op` class. Nonetheless, it will attempt to link those elements to
 their corresponding concepts in the `Scan` function as often as is reasonably
 practical.
 
 
 Pre-requisites
-==============
+--------------
 
 The following sections assumes the reader is familiar with the following :
 
 1. Aesara's :ref:`graph structure <graphstructures>` (`Apply` nodes, `Variable` nodes and `Op`\s)
 
-2. The interface and usage of Aesara's :ref:`scan <lib_scan>` function
+2. The interface and usage of Aesara's :ref:`scan <reference_scan>` function
 
 Additionally, the :ref:`scan_internals_rewrites` section below assumes
 knowledge of:
 
 3. Aesara's :ref:`graph rewriting <graph_rewriting>`
 
 
 Relevant code files
-===================
+-------------------
 
 The implementation of `Scan` is spread over several files in
 ``aesara/scan``.  The different files, and sections of the code they
 deal with, are :
 
 * ``basic.py`` implements the `scan` function. The `scan` function
   arranges the arguments of `scan` correctly, constructs the `Scan` `Op` and
@@ -64,15 +64,15 @@
   simpler and easier signatures to be used in specific cases.
 
 * ``opt.py`` contains the list of all Aesara graph rewrites for the
   `Scan` operator.
 
 
 Notation
-========
+--------
 
 `Scan` being a sizeable and complex module, it has its own naming convention for
 functions and variables which this section will attempt to introduce.
 
 A `Scan` `Op` contains an Aesara function representing the computation
 that is done in a single iteration of the loop represented by the `Scan` `Op` (in
 other words, the computation given by the function provided as value to
@@ -85,15 +85,15 @@
 `Op`* (or *`Scan` node* for short) are referred to as **outer inputs** and **outer
 outputs**, respectively, because these inputs and outputs are variables in the
 outer function graph. The inputs and outputs of `Scan`'s inner function are
 designated **inner inputs** and **inner outputs**, respectively.
 
 
 `Scan` variables
-================
+----------------
 
 The following are the different types of variables that `Scan` has the
 capacity to handle, along with their various caracteristics.
 
 **Sequence** : A sequence is an Aesara variable which `Scan` will iterate
 over and give sub-elements to its inner function as input. A sequence
 has no associated output. For a sequence variable ``X``, at timestep
@@ -154,76 +154,76 @@
 Multiply-recurrent multiple outputs (MITMOT)                 Initial values for the required timesteps where ``t<0``  Output value at previous required timesteps                   Output values for current and multiple future timesteps        Concatenation of the values of the output at all timestep  *No corresponding argument*
 ===========================================================  =======================================================  ============================================================  =============================================================  =========================================================  ======================================================
 
 
 .. _scan_internals_rewrites:
 
 Rewrites
-========
+--------
 
 `remove_constants_and_unused_inputs_scan`
------------------------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 This rewrite serves two purposes, The first is to remove a :class:`Scan`\ `Op`'s
 unused inputs. The second is to take a `Scan` `Op`'s constant inputs and remove
 them, instead injecting the constants directly into the graph or the `Scan`
 `Op`'s inner function. This will allow constant folding to happen inside the
 inner function.
 
 
 `PushOutNonSeqScan`
--------------------
+~~~~~~~~~~~~~~~~~~~
 
 This rewrite pushes sub-graphs that depends only on non-sequence inputs out of
 `Scan`'s inner function and into the outer function. Such computation ends up
 being done every iteration on the same values so moving it to the outer function
 to be executed only once, before the `Scan`\ `Op`, reduces the amount of
 computation that needs to be performed.
 
 
 `PushOutSeqScan`
-----------------
+~~~~~~~~~~~~~~~~
 
 This rewrite resembles `PushOutNonSeqScan` but it tries to push, out of
 the inner function, the computation that only relies on sequence and
 non-sequence inputs. The idea behind this rewrite is that, when it is
 possible to do so, it is generally more computationally efficient to perform
 a single operation on a large tensor rather then perform that same operation
 many times on many smaller tensors. In many cases, this rewrite can
 increase memory usage but, in some specific cases, it can also decrease it.
 
 
 `PushOutScanOutput`
--------------------
+~~~~~~~~~~~~~~~~~~~
 
 This rewrite attempts to push out some of the computation at the end
 of the inner function to the outer function, to be executed after the `Scan`
 node. Like `PushOutSeqScan`, this rewrite aims to replace many operations
 on small tensors by few operations on large tensors. It can also lead to
 increased memory usage.
 
 
 `PushOutDot1`
--------------
+~~~~~~~~~~~~~
 
 This is another rewrite that attempts to detect certain patterns of
 computation in a `Scan`\ `Op`'s inner function and move this computation to the
 outer graph.
 
 
 `ScanInplaceOptimizer`
-----------------------
+~~~~~~~~~~~~~~~~~~~~~~
 
 This rewrite attempts to make `Scan` compute its recurrent outputs inplace
 on the input tensors that contain their initial states. This rewrite can
 improve runtime performance as well as reduce memory usage.
 
 
 `ScanSaveMem`
--------------
+~~~~~~~~~~~~~
 
 This rewrite attempts to determine if a `Scan` node, during its execution,
 for any of its outputs, can get away with allocating a memory buffer that is
 large enough to contain some of the computed timesteps of that output but not
 all of them.
 
 By default, during the execution of a `Scan` node, memory buffers will be
@@ -236,49 +236,49 @@
 that output is ever used in the outer function, the `ScanSaveMem` rewrite
 could determine that there is no need to store all computed timesteps for
 that SITSOT output. Only the most recently computed timestep ever needs to
 be kept in memory.
 
 
 `ScanMerge`
------------
+~~~~~~~~~~~
 
 This rewrite attempts to fuse distinct `Scan` nodes into a single `Scan` node
 that performs all the computation. The main advantage of merging `Scan` nodes
 together comes from the possibility of both original `Scan`\ `Op`\s having some
 computation in common. In such a setting, this computation ends up being done
 twice. The fused `Scan`\s, however, would only need to do it once and could
 therefore be more computationally efficient. Also, since every `Scan` node
 involves a certain overhead, at runtime, reducing the number of `Scan` nodes in
 the graph can improve performance.
 
 
 `scan_merge_inouts`
--------------------
+~~~~~~~~~~~~~~~~~~~
 
 This rewrite attempts to merge a `Scan`\s identical outer inputs as well
 as merge its identical outer outputs (outputs that perform the same
 computation on the same inputs). This can reduce the amount of computation as
 well as result in a simpler graph for both the inner function and the outer
 function.
 
 
 Helper classes and functions
-============================
+----------------------------
 
 Because of the complexity involved in dealing with `Scan`, a large number of
 helper classes and functions have been developed over time to implement
 operations commonly needed when dealing with the `Scan`\ `Op`. The `Scan`\ `Op`
 itself defines a large number of them and others can be found in the file
 ``utils.py``. This sections aims to point out the most useful ones sorted
 by usage.
 
 
 Accessing/manipulating `Scan`'s inputs and outputs by type
-----------------------------------------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Declared in ``utils.py``, the class `ScanArgs` handles the
 parsing of the inputs and outputs (both inner and outer) to a format
 that is easier to analyze and manipulate. Without this class,
 analyzing `Scan`'s inputs and outputs can require convoluted logic
 which make for code that is hard to read and to maintain. Because of
 this, you should favor using `ScanArgs` when it is practical and
@@ -287,15 +287,15 @@
 The `Scan` `Op` extends `ScanPropertiesMixin`, which defines a few helper
 methods for this purpose, such as `inner_nitsot_outs` or `mitmot_out_taps`, but
 they are often poorly documented and easy to misuse. These should be used with
 great care.
 
 
 Navigating between outer inputs/outputs and inner inputs/outputs
-----------------------------------------------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Navigation between these four sets of variables can be done in two ways,
 depending on the type of navigation that is required.
 
 If the goal is to navigate between variables that are associated with the same
 states (e.g. going from an outer sequence input to the corresponding inner
 sequence input, going from an inner output associated with a recurrent state
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/type.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/type.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/unittest.rst` & `aesara_nightly-2.9.0.post2/doc/compile/io.rst`

 * *Files 25% similar despite different names*

```diff
@@ -1,289 +1,330 @@
-.. _unittest:
-
-============
-Unit Testing
-============
-
-.. warning::
-   This document is very outdated.
-
-Aesara relies heavily on unit testing. Its importance cannot be
-stressed enough!
-
-Unit Testing revolves around the following principles:
-
-* ensuring correctness: making sure that your :class:`Op`, :class:`Type` or
-  rewrites works in the way you intended it to work. It is important for
-  this testing to be as thorough as possible: test not only the obvious cases,
-  but more importantly the corner cases which are more likely to trigger bugs
-  down the line.
-
-* test all possible failure paths. This means testing that your code
-  fails in the appropriate manner, by raising the correct errors when
-  in certain situations.
-
-* sanity check: making sure that everything still runs after you've
-  done your modification. If your changes cause unit tests to start
-  failing, it could be that you've changed an API on which other users
-  rely on. It is therefore your responsibility to either a) provide
-  the fix or b) inform the author of your changes and coordinate with
-  that person to produce a fix. If this sounds like too much of a
-  burden... then good! APIs aren't meant to be changed on a whim!
-
-
-We use `pytest <https://docs.pytest.org>`_.  New tests should
-generally take the form of a test function, and each check within a test should
-involve an assertion of some kind.
 
 .. note::
 
-  Tests that check for a lack of failures (e.g. that ``Exception``\s aren't
-  raised) are generally *not* good tests.  Instead, assert something more
-  relevant and explicit about the expected outputs or side-effects of the code
-  being tested.
+    ***TODO*** Freshen up this old documentation
 
 
-How to Run Unit Tests
----------------------
+.. _function_inputs:
 
-Mostly ``pytest aesara/``
+===========================================
+:mod:`io` - defines aesara.function [TODO]
+===========================================
 
-Folder Layout
--------------
+.. module:: aesara.compile.io
+   :platform: Unix, Windows
+   :synopsis: defines In and Out
+.. moduleauthor:: LISA
 
-Files containing unit tests should be prefixed with the word "test".
 
-Ideally, every python module should have a unittest file associated
-with it, as shown below. Unit tests that test functionality of module
-``<module>.py`` should therefore be stored in
-``tests/<sub-package>/test_<module>.py``::
+Inputs
+======
 
-    Aesara/aesara/tensor/basic.py
-    Aesara/tests/tensor/test_basic.py
+The ``inputs`` argument to ``aesara.function`` is a list, containing the ``Variable`` instances for which values will be specified at the time of the function call.  But inputs can be more than just Variables.
+``In`` instances let us attach properties to ``Variables`` to tell function more about how to use them.
 
-    Aesara/aesara/tensor/elemwise.py
-    Aesara/tests/tensor/test_elemwise.py
 
+.. class:: In(object)
 
-How to Write a Unit Test
-========================
+   .. method:: __init__(variable, name=None, value=None, update=None, mutable=False, strict=False, autoname=True, implicit=None)
 
-Test Cases and Methods
-----------------------
+      ``variable``: a Variable instance. This will be assigned a value
+      before running the function, not computed from its owner.
 
-Unit tests should be grouped "logically" into test cases, which are
-meant to group all unit tests operating on the same element and/or
-concept.
+      ``name``: Any type. (If ``autoname_input==True``, defaults to
+      ``variable.name``). If ``name`` is a valid Python identifier, this input
+      can be set by ``kwarg``, and its value can be accessed by
+      ``self.<name>``. The default value is ``None``.
 
-Test cases should be functions or classes prefixed with the word "test".
+      ``value``: literal or ``Container``. The initial/default value for this
+        input. If update is`` None``, this input acts just like
+        an argument with a default value in Python. If update is not ``None``,
+        changes to this
+        value will "stick around", whether due to an update or a user's
+        explicit action.
 
-Test methods should be as specific as possible and cover a particular
-aspect of the problem. For example, when testing the :class:`Dot` :class:`Op`, one
-test method could check for validity, while another could verify that
-the proper errors are raised when inputs have invalid dimensions.
+      ``update``: Variable instance. This expression Variable will
+      replace ``value`` after each function call. The default value is
+      ``None``, indicating that no update is to be done.
 
-Test method names should be as explicit as possible, so that users can
-see at first glance, what functionality is being tested and what tests
-need to be added.
+      ``mutable``: Bool (requires value). If ``True``, permit the
+      compiled function to modify the Python object being used as the
+      default value. The default value is ``False``.
 
-Checking for correctness
-------------------------
+      ``strict``: Bool (default: ``False`` ). ``True`` means that the value
+      you pass for this input must have exactly the right type. Otherwise, it
+      may be cast automatically to the proper type.
 
-When checking for correctness of mathematical expressions, the user
-should preferably compare aesara's output to the equivalent NumPy
-implementation.
+      ``autoname``: Bool. If set to ``True``, if ``name`` is ``None`` and
+      the Variable has a name, it will be taken as the input's
+      name. If autoname is set to ``False``, the name is the exact
+      value passed as the name parameter (possibly ``None``).
 
-Example:
+      ``implicit``: Bool or ``None`` (default: ``None``)
+            ``True``: This input is implicit in the sense that the user is not allowed
+            to provide a value for it. Requires ``value`` to be set.
 
-.. code-block:: python
+            ``False``: The user can provide a value for this input. Be careful
+            when ``value`` is a container, because providing an input value will
+            overwrite the content of this container.
 
-    import numpy as np
-    import aesara.tensor as at
+            ``None``: Automatically choose between ``True`` or ``False`` depending on the
+            situation. It will be set to ``False`` in all cases except if
+            ``value`` is a container (so that there is less risk of accidentally
+            overwriting its content without being aware of it).
 
 
-    def test_dot_validity():
-        a = at.dmatrix('a')
-        b = at.dmatrix('b')
-        c = at.dot(a, b)
+Value: initial and default values
+---------------------------------
 
-        c_fn = aesara.function([a, b], [c])
+A non-None `value` argument makes an In() instance an optional parameter
+of the compiled function.  For example, in the following code we are
+defining an arity-2 function ``inc``.
 
-        avals = ...
-        bvals = ...
+>>> import aesara.tensor as at
+>>> from aesara import function
+>>> from aesara.compile.io import In
+>>> u, x, s = at.scalars('u', 'x', 's')
+>>> inc = function([u, In(x, value=3), In(s, update=(s+x*u), value=10.0)], [])
 
-        res = c_fn(avals, bvals)
-        exp_res = np.dot(self.avals, self.bvals)
-        assert np.array_equal(res, exp_res)
+Since we provided a ``value`` for ``s`` and ``x``, we can call it with just a value for ``u`` like this:
 
+>>> inc(5)         # update s with 10+3*5
+[]
+>>> print(inc[s])
+25.0
 
-Creating an :class:`Op` Unit Test
-=================================
+The effect of this call is to increment the storage associated to ``s`` in ``inc`` by 15.
 
-A few tools have been developed to help automate the development of
-unit tests for Aesara :class:`Op`\s.
+If we pass two arguments to ``inc``, then we override the value associated to
+``x``, but only for this one function call.
 
+>>> inc(3, 4)      # update s with 25 + 3*4
+[]
+>>> print(inc[s])
+37.0
+>>> print(inc[x])   # the override value of 4 was only temporary
+3.0
 
-.. _validating_grad:
+If we pass three arguments to ``inc``, then we override the value associated
+with ``x`` and ``u`` and ``s``.
+Since ``s``'s value is updated on every call, the old value of ``s`` will be ignored and then replaced.
 
-Validating the Gradient
------------------------
+>>> inc(3, 4, 7)      # update s with 7 + 3*4
+[]
+>>> print(inc[s])
+19.0
 
-The :func:`aesara.gradient.verify_grad` function can be used to validate that the :meth:`Op.grad`
-method of your :class:`Op` is properly implemented. :func:`verify_grad` is based
-on the Finite Difference Method where the derivative of function :math:`f`
-at point :math:`x` is approximated as:
+We can also assign to ``inc[s]`` directly:
 
-.. math::
+>>> inc[s] = 10
+>>> inc[s]
+array(10.0)
 
-   \frac{\partial{f}}{\partial{x}} = lim_{\Delta \rightarrow 0} \frac {f(x+\Delta) - f(x-\Delta)} {2\Delta}
+Input Argument Restrictions
+---------------------------
 
-:func:`verify_grad` performs the following steps:
+The following restrictions apply to the inputs to ``aesara.function``:
 
-* approximates the gradient numerically using the Finite Difference Method
+- Every input list element must be a valid ``In`` instance, or must be
+  upgradable to a valid ``In`` instance. See the shortcut rules below.
 
-* calculate the gradient using the symbolic expression provided in the
-  ``grad`` function
+- The same restrictions apply as in Python function definitions:
+  default arguments and keyword arguments must come at the end of
+  the list. Un-named mandatory arguments must come at the beginning of
+  the list.
 
-* compares the two values. The tests passes if they are equal to
-  within a certain tolerance.
+- Names have to be unique within an input list.  If multiple inputs
+  have the same name, then the function will raise an exception. [***Which
+  exception?**]
 
-Here is the prototype for the :func:`verify_grad` function.
+- Two ``In`` instances may not name the same Variable. I.e. you cannot
+  give the same parameter multiple times.
 
-.. code-block:: python
+If no name is specified explicitly for an In instance, then its name
+will be taken from the Variable's name. Note that this feature can cause
+harmless-looking input lists to not satisfy the two conditions above.
+In such cases, Inputs should be named explicitly to avoid problems
+such as duplicate names, and named arguments preceding unnamed ones.
+This automatic naming feature can be disabled by instantiating an In
+instance explicitly with the ``autoname`` flag set to False.
 
-    def verify_grad(fun, pt, n_tests=2, rng=None, eps=1.0e-7, abs_tol=0.0001, rel_tol=0.0001):
 
-:func:`verify_grad` raises an :class:`Exception` if the difference between the analytic gradient and
-numerical gradient (computed through the Finite Difference Method) of a random
-projection of the fun's output to a scalar exceeds both the given absolute and
-relative tolerances.
+Access to function values and containers
+----------------------------------------
 
-The parameters are as follows:
+For each input, ``aesara.function`` will create a ``Container`` if
+``value`` was not already a ``Container`` (or if ``implicit`` was ``False``). At the time of a function call,
+each of these containers must be filled with a value. Each input (but
+especially ones with a default value or an update expression) may have a
+value between calls. The function interface defines a way to get at
+both the current value associated with an input, as well as the container
+which will contain all future values:
 
-* ``fun``: a Python function that takes Aesara variables as inputs,
-  and returns an Aesara variable.
-  For instance, an :class:`Op` instance with a single output is such a function.
-  It can also be a Python function that calls an :class:`Op` with some of its
-  inputs being fixed to specific values, or that combine multiple :class:`Op`\s.
+  - The ``value`` property accesses the current values. It is both readable
+    and writable, but assignments (writes) may be implemented by an internal
+    copy and/or casts.
 
-* ``pt``: the list of `np.ndarrays` to use as input values
+  - The ``container`` property accesses the corresponding container.
+    This property accesses is a read-only dictionary-like interface. It is
+    useful for fetching the container associated with a particular input to
+    share containers between functions, or to have a sort of pointer to an
+    always up-to-date value.
 
-* ``n_tests``: number of times to run the test
+Both ``value`` and ``container`` properties provide dictionary-like access based on three types of keys:
 
-* ``rng``: random number generator used to generate a random vector `u`,
-  we check the gradient of ``sum(u*fn)`` at ``pt``
+- integer keys: you can look up a value/container by its position in the input list;
+- name keys: you can look up a value/container by its name;
+- Variable keys: you can look up a value/container by the Variable it corresponds to.
 
-* ``eps``: stepsize used in the Finite Difference Method
+In addition to these access mechanisms, there is an even more convenient
+method to access values by indexing a Function directly by typing
+``fn[<name>]``, as in the examples above.
 
-* ``abs_tol``: absolute tolerance used as threshold for gradient comparison
+To show some examples of these access methods...
 
-* ``rel_tol``: relative tolerance used as threshold for gradient comparison
 
-In the general case, you can define ``fun`` as you want, as long as it
-takes as inputs Aesara symbolic variables and returns a sinble Aesara
-symbolic variable:
+>>> from aesara import tensor as at, function
+>>> a, b, c = at.scalars('xys') # set the internal names of graph nodes
+>>> # Note that the name of c is 's', not 'c'!
+>>> fn = function([a, b, ((c, c+a+b), 10.0)], [])
 
-.. testcode::
+>>> # the value associated with c is accessible in 3 ways
+>>> fn['s'] is fn.value[c]
+True
+>>> fn['s'] is fn.container[c].value
+True
 
-    def test_verify_exprgrad():
-        def fun(x,y,z):
-            return (x + at.cos(y)) / (4 * z)**2
+>>> fn['s']
+array(10.0)
+>>> fn(1, 2)
+[]
+>>> fn['s']
+array(13.0)
+>>> fn['s'] = 99.0
+>>> fn(1, 0)
+[]
+>>> fn['s']
+array(100.0)
+>>> fn.value[c] = 99.0
+>>> fn(1,0)
+[]
+>>> fn['s']
+array(100.0)
+>>> fn['s'] == fn.value[c]
+True
+>>> fn['s'] == fn.container[c].value
+True
 
-        x_val = np.asarray([[1], [1.1], [1.2]])
-        y_val = np.asarray([0.1, 0.2])
-        z_val = np.asarray(2)
-        rng = np.random.default_rng(42)
 
-        aesara.gradient.verify_grad(fun, [x_val, y_val, z_val], rng=rng)
+Input Shortcuts
+---------------
 
-Here is an example showing how to use :func:`verify_grad` on an :class:`Op` instance:
+Every element of the inputs list will be upgraded to an In instance if necessary.
 
-.. testcode::
+- a Variable instance ``r`` will be upgraded like ``In(r)``
 
-    def test_flatten_outdimNone():
-        """
-        Testing gradient w.r.t. all inputs of an `Op` (in this example the `Op`
-        being used is `Flatten`, which takes a single input).
-        """
-        a_val = np.asarray([[0,1,2],[3,4,5]], dtype='float64')
-        rng = np.random.default_rng(42)
-        aesara.gradient.verify_grad(at.Flatten(), [a_val], rng=rng)
+- a tuple ``(name, r)`` will be ``In(r, name=name)``
 
-.. note::
+- a tuple ``(r, val)`` will be ``In(r, value=value, autoname=True)``
+
+- a tuple ``((r,up), val)`` will be ``In(r, value=value, update=up, autoname=True)``
+
+- a tuple ``(name, r, val)`` will be ``In(r, name=name, value=value)``
+
+- a tuple ``(name, (r,up), val)`` will be ``In(r, name=name, value=val, update=up, autoname=True)``
+
+Example:
 
-    Although :func:`verify_grad` is defined in :mod:`aesara.gradient`, unittests
-    should use the version of :func:`verify_grad` defined in :mod:`tests.unittest_tools`.
-    This is simply a wrapper function which takes care of seeding the random
-    number generator appropriately before calling :func:`aesara.gradient.verify_grad`
-
-:func:`makeTester` and :func:`makeBroadcastTester`
-==================================================
-
-Most :class:`Op` unittests perform the same function. All such tests must
-verify that the :class:`Op` generates the proper output, that the gradient is
-valid, that the :class:`Op` fails in known/expected ways. Because so much of
-this is common, two helper functions exists to make your lives easier:
-:func:`makeTester` and :func:`makeBroadcastTester` (defined in module
-:mod:`tests.tensor.utils`).
-
-Here is an example of ``makeTester`` generating testcases for the dot
-product :class:`Op`:
-
-.. testcode::
-
-    import numpy as np
-
-    from tests.tensor.utils import makeTester
-
-
-    rng = np.random.default_rng(23098)
-
-    TestDot = makeTester(
-        name="DotTester",
-        op=np.dot,
-        expected=lambda x, y: np.dot(x, y),
-        checks={},
-        good=dict(
-            correct1=(rng.random((5, 7)), rng.random((7, 5))),
-            correct2=(rng.random((5, 7)), rng.random((7, 9))),
-            correct3=(rng.random((5, 7)), rng.random((7,))),
-        ),
-        bad_build=dict(),
-        bad_runtime=dict(
-            bad1=(rng.random((5, 7)), rng.random((5, 7))),
-            bad2=(rng.random((5, 7)), rng.random((8, 3)))
-        ),
-        grad=dict(),
-    )
-
-In the above example, we provide a name and a reference to the :class:`Op` we
-want to test. We then provide in the ``expected`` field, a function
-which :func:`makeTester` can use to compute the correct values. The
-following five parameters are dictionaries which contain:
-
-* checks: dictionary of validation functions (dictionary key is a
-  description of what each function does). Each function accepts two
-  parameters and performs some sort of validation check on each
-  :class:`Op`-input/:class:`Op`-output value pairs.  If the function returns ``False``, an
-  ``Exception`` is raised containing the check's description.
-
-* good: contains valid input values, for which the output should match
-  the expected output. Unit tests will fail if this is not the case.
-
-* bad_build: invalid parameters which should generate an ``Exception``
-  when attempting to build the graph (call to :meth:`Op.make_node` should
-  fail).  Fails unless an ``Exception`` is raised.
-
-* bad_runtime: invalid parameters which should generate an ``Exception``
-  at runtime, when trying to compute the actual output values (call to
-  :meth:`Op.perform` should fail). Fails unless an ``Exception`` is raised.
-
-* grad: dictionary containing input values which will be used in the
-  call to :func:`verify_grad`
-
-
-:func:`makeBroadcastTester` is a wrapper function for :func:`makeTester`.  If an
-``inplace=True`` parameter is passed to it, it will take care of
-adding an entry to the ``checks`` dictionary. This check will ensure
-that inputs and outputs are equal, after the :class:`Op`'s perform function has
-been applied.
+>>> import aesara
+>>> from aesara import tensor as at
+>>> from aesara.compile.io import In
+>>> x = at.scalar()
+>>> y = at.scalar('y')
+>>> z = at.scalar('z')
+>>> w = at.scalar('w')
+
+>>> fn = aesara.function(inputs=[x, y, In(z, value=42), ((w, w+x), 0)],
+...                      outputs=x + y + z)
+>>> # the first two arguments are required and the last two are
+>>> # optional and initialized to 42 and 0, respectively.
+>>> # The last argument, w, is updated with w + x each time the
+>>> # function is called.
+
+>>> fn(1)               # illegal because there are two required arguments # doctest: +ELLIPSIS
+Traceback (most recent call last):
+  ...
+TypeError: Missing required input: y
+>>> fn(1, 2)            # legal, z is 42, w goes 0 -> 1 (because w <- w + x)
+array(45.0)
+>>> fn(1, y=2)        # legal, z is 42, w goes 1 -> 2
+array(45.0)
+>>> fn(x=1, y=2)    # illegal because x was not named # doctest: +ELLIPSIS
+Traceback (most recent call last):
+  ...
+TypeError: Unknown input or state: x. The function has 3 named inputs (y, z, w), and 1 unnamed input which thus cannot be accessed through keyword argument (use 'name=...' in a variable's constructor to give it a name).
+>>> fn(1, 2, 3)         # legal, z is 3, w goes 2 -> 3
+array(6.0)
+>>> fn(1, z=3, y=2) # legal, z is 3, w goes 3 -> 4
+array(6.0)
+>>> fn(1, 2, w=400)   # legal, z is 42 again, w goes 400 -> 401
+array(45.0)
+>>> fn(1, 2)            # legal, z is 42, w goes 401 -> 402
+array(45.0)
+
+In the example above, ``z`` has value 42 when no value is explicitly given.
+This default value is potentially used at every function invocation, because
+``z`` has no ``update`` or storage associated with it.
+
+.. _function_outputs:
+
+Outputs
+=======
+
+The ``outputs`` argument to function can be one of
+
+- ``None``, or
+- a Variable or ``Out`` instance, or
+- a list of Variables or ``Out`` instances.
+
+An ``Out`` instance is a structure that lets us attach options to individual output ``Variable`` instances,
+similarly to how ``In`` lets us attach options to individual input ``Variable`` instances.
+
+**Out(variable, borrow=False)** returns an ``Out`` instance:
+
+  * ``borrow``
+
+    If ``True``, a reference to function's internal storage
+    is OK.  A value returned for this output might be clobbered by running
+    the function again, but the function might be faster.
+
+    Default: ``False``
+
+
+
+
+If a single ``Variable`` or ``Out`` instance is given as argument, then the compiled function will return a single value.
+
+If a list of ``Variable`` or ``Out`` instances is given as argument, then the compiled function will return a list of their values.
+
+>>> import numpy
+>>> from aesara.compile.io import Out
+>>> x, y, s = at.matrices('xys')
+
+>>> # print a list of 2 ndarrays
+>>> fn1 = aesara.function([x], [x+x, Out((x+x).T, borrow=True)])
+>>> fn1(numpy.asarray([[1,0],[0,1]]))
+[array([[ 2.,  0.],
+       [ 0.,  2.]]), array([[ 2.,  0.],
+       [ 0.,  2.]])]
+
+>>> # print a list of 1 ndarray
+>>> fn2 = aesara.function([x], [x+x])
+>>> fn2(numpy.asarray([[1,0],[0,1]]))
+[array([[ 2.,  0.],
+       [ 0.,  2.]])]
+
+>>> # print an ndarray
+>>> fn3 = aesara.function([x], outputs=x+x)
+>>> fn3(numpy.asarray([[1,0],[0,1]]))
+array([[ 2.,  0.],
+       [ 0.,  2.]])
```

### Comparing `aesara-nightly-2.8.9.post118/doc/extending/using_params.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/using_params.rst`

 * *Files 1% similar despite different names*

```diff
@@ -65,22 +65,21 @@
 :meth:`c_headers <CLinkerType.c_headers>` if you need any special things.
 
 
 Registering the params with your Op
 -----------------------------------
 
 To declare that your Op uses params you have to set the class
-attribute :attr:`params_type` to an instance of your params Type.
+attribute to an instance of your params Type.
 
 .. note::
 
    If you want to have multiple parameters, Aesara provides the convenient class
    :class:`aesara.link.c.params_type.ParamsType` that allows to bundle many parameters into
    one object that will be available in both Python (as a Python object) and C code (as a struct).
-   See :ref:`ParamsType tutorial and API documentation <libdoc_graph_params_type>` for more infos.
 
 For example if we decide to use an int as the params the following
 would be appropriate:
 
 .. code-block:: python
 
    class MyOp(Op):
```

### Comparing `aesara-nightly-2.8.9.post118/doc/faq.rst` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/shapes.rst`

 * *Files 27% similar despite different names*

```diff
@@ -1,177 +1,194 @@
-:orphan:
+.. _reference_shapes:
 
-.. _faq:
+Shapes
+======
 
-==========================
-Frequently Asked Questions
-==========================
+How Shape Information is Handled by Aesara
+------------------------------------------
 
+Currently, information regarding shape is used in the following ways by Aesara:
 
-Output slight numerical difference
-----------------------------------
+- To remove computations in the graph when we only want to know the
+  shape, but not the actual value of a variable. This is done with the
+  :meth:`Op.infer_shape` method.
 
-Sometimes when you compare the output of Aesara using different Aesara flags,
-Aesara versions, CPU and GPU devices, or with other software like NumPy, you
-will see small numerical differences.
+- To generate faster compiled code (e.g. for a 2D convolution).
 
-This is normal. Floating point numbers are approximations of real
-numbers. This is why doing a+(b+c) vs (a+b)+c can give small
-differences of value.  This is normal. For more details, see: `What
-Every Computer Scientist Should Know About Floating-Point Arithmetic
-<https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html>`_.
 
+Example:
 
-Faster gcc optimization
------------------------
+>>> import aesara
+>>> x = aesara.tensor.matrix('x')
+>>> f = aesara.function([x], (x ** 2).shape)
+>>> aesara.dprint(f)
+MakeVector{dtype='int64'} [id A] ''   2
+ |Shape_i{0} [id B] ''   1
+ | |x [id C]
+ |Shape_i{1} [id D] ''   0
+   |x [id C]
 
-You can enable faster gcc optimization with the ``cxxflags`` option.
-This list of flags was suggested on the mailing list::
 
-    -O3 -ffast-math -ftree-loop-distribution -funroll-loops -ftracer
+The output of this compiled function does not contain any multiplication or
+power computations; Aesara has removed them to compute the shape of the output
+directly.
 
-Use it at your own risk. Some people warned that the ``-ftree-loop-distribution`` optimization resulted in wrong results in the past.
+Aesara propagates information about shapes within a graph using specialized
+:class:`Op`\s and static :class:`Type` information (see :ref:`aesara_type`).
 
-In the past we said that if the ``compiledir`` was not shared by multiple
-computers, you could add the ``-march=native`` flag. Now we recommend
-to remove this flag as Aesara does it automatically and safely,
-even if the ``compiledir`` is shared by multiple computers with different
-CPUs. In fact, Aesara asks g++ what are the equivalent flags it uses, and re-uses
-them directly.
 
-
-.. _faster-aesara-function-compilation:
-
-Faster Aesara Function Compilation
-----------------------------------
-
-Aesara function compilation can be time consuming. It can be sped up by setting
-the flag ``mode=FAST_COMPILE`` which instructs Aesara to skip most
-rewrites and disables the generation of any c/cuda code. This is useful
-for quickly testing a simple idea.
-
-If C code is necessary, the flag
-``optimizer=fast_compile`` can be used instead. It instructs Aesara to
-skip time consuming rewrites but still generate C code.
-
-Similarly using the flag ``optimizer_excluding=inplace`` will speed up
-compilation by preventing rewrites that replace operations with a
-version that reuses memory where it will not negatively impact the
-integrity of the operation. Such rewrites can be time
-consuming. However using this flag will result in greater memory usage
-because space must be allocated for the results which would be
-unnecessary otherwise. In short, using this flag will speed up
-compilation but it will also use more memory because
-``optimizer_excluding=inplace`` excludes inplace rewrites
-resulting in a trade off between speed of compilation and memory
-usage.
-
-Alternatively, if the graph is big, using the flag ``cycle_detection=fast``
-will speedup the computations by removing some of the inplace
-rewrites. This would allow aesara to skip a time consuming cycle
-detection algorithm. If the graph is big enough,we suggest that you use
-this flag instead of ``optimizer_excluding=inplace``. It will result in a
-computation time that is in between fast compile and fast run.
-
-Faster Aesara function
+Specifying Exact Shape
 ----------------------
 
-You can set the Aesara flag :attr:`allow_gc <config.allow_gc>` to ``False`` to get a speed-up by using
-more memory. By default, Aesara frees intermediate results when we don't need
-them anymore. Doing so prevents us from reusing this memory. So disabling the
-garbage collection will keep all intermediate results' memory space to allow to
-reuse them during the next call to the same Aesara function, if they are of the
-correct shape. The shape could change if the shapes of the inputs change.
-
-.. _unsafe_rewrites:
-
-Unsafe Rewrites
-===============
-
-
-Some Aesara rewrites make the assumption that the user inputs are
-valid. What this means is that if the user provides invalid values (like
-incompatible shapes or indexing values that are out of bounds) and
-the rewrites are applied, the user error will get lost. Most of the
-time, the assumption is that the user inputs are valid. So it is good
-to have the rewrite applied, but losing the error is bad.
-The newest rewrite in Aesara with such an assumption will add an
-assertion in the graph to keep the user error message. Computing
-these assertions could take some time. If you are sure everything is valid
-in your graph and want the fastest possible Aesara, you can enable a
-rewrite that will remove the assertions with:
-``optimizer_including=local_remove_all_assert``
-
-
-Faster Small Aesara function
-----------------------------
-
-.. note::
-
-   For Aesara 0.6 and up.
-
-For Aesara functions that don't do much work, like a regular logistic
-regression, the overhead of checking the input can be significant. You
-can disable it by setting ``f.trust_input`` to True.
-Make sure the types of arguments you provide match those defined when
-the function was compiled.
-
-For example, replace the following
-
-.. testcode:: faster
-
-    import aesara
-    from aesara import function
-
-    x = aesara.tensor.type.scalar('x')
-    f = function([x], x + 1.)
-    f(10.)
-
-with
-
-.. testcode:: faster
-
-    import numpy
-    import aesara
-    from aesara import function
-
-    x = aesara.tensor.type.scalar('x')
-    f = function([x], x + 1.)
-    f.trust_input = True
-    f(numpy.array([10.], dtype=aesara.config.floatX))
-
-Also, for small Aesara functions, you can remove more Python overhead by
-making an Aesara function that does not take any input. You can use shared
-variables to achieve this. Then you can call it like this: ``f.vm()`` or
-``f.vm(n_calls=N)`` to speed it up. In the last case, only the last
-function output (out of N calls) is returned.
-
-You can also use the ``C`` linker that will put all nodes in the same C
-compilation unit. This removes some overhead between node in the graph,
-but requires that all nodes in the graph have a C implementation:
+You can create variables with static shape information as follows:
 
 .. code-block:: python
 
-    x = aesara.tensor.type.scalar('x')
-    f = function([x], (x + 1.) * 2, mode=aesara.compile.mode.Mode(linker='c'))
-    f(10.)
+    aesara.tensor.tensor("float64", shape=(4, 3, 2))
 
-Related Projects
-----------------
 
-We try to list in this `wiki page <https://github.com/Aesara/Aesara/wiki/Related-projects>`_ other Aesara related projects.
+You can also pass shape infomation directly to some :class:`Op`\s, like ``RandomVariables``
 
+.. code-block:: python
 
-"What are Aesara's Limitations?"
---------------------------------
+    aesara.tensor.random.normal(size=(7, 3, 5, 5))
 
-Aesara offers a good amount of flexibility, but has some limitations too.
-You must answer for yourself the following question: How can my algorithm be cleverly written
-so as to make the most of what Aesara can do?
 
-Here is a list of some of the known limitations:
+- You can use the :class:`SpecifyShape`\ :class:`Op` to add shape information anywhere in the
+  graph. This allows to perform some optimizations. In the following example,
+  this makes it possible to precompute the Aesara function to a constant.
+
+
+>>> import aesara
+>>> x = aesara.tensor.matrix()
+>>> x_specify_shape = aesara.tensor.specify_shape(x, (2, 2))
+>>> f = aesara.function([x], (x_specify_shape ** 2).shape)
+>>> aesara.printing.debugprint(f) # doctest: +NORMALIZE_WHITESPACE
+DeepCopyOp [id A] ''   0
+ |TensorConstant{(2,) of 2} [id B]
+
+Problems with Shape inference
+-----------------------------
+
+Sometimes this can lead to errors.  Consider this example:
+
+>>> import numpy as np
+>>> import aesara
+>>> x = aesara.tensor.matrix('x')
+>>> y = aesara.tensor.matrix('y')
+>>> z = aesara.tensor.join(0, x, y)
+>>> xv = np.random.random((5, 4))
+>>> yv = np.random.random((3, 3))
+
+>>> f = aesara.function([x, y], z.shape)
+>>> aesara.printing.debugprint(f) # doctest: +NORMALIZE_WHITESPACE
+MakeVector{dtype='int64'} [id A] ''   4
+ |Elemwise{Add}[(0, 0)] [id B] ''   3
+ | |Shape_i{0} [id C] ''   2
+ | | |x [id D]
+ | |Shape_i{0} [id E] ''   1
+ |   |y [id F]
+ |Shape_i{1} [id G] ''   0
+   |x [id D]
+
+>>> f(xv, yv) # DOES NOT RAISE AN ERROR AS SHOULD BE.
+array([8, 4])
+
+>>> f = aesara.function([x,y], z)# Do not take the shape.
+>>> aesara.printing.debugprint(f) # doctest: +NORMALIZE_WHITESPACE
+Join [id A] ''   0
+ |TensorConstant{0} [id B]
+ |x [id C]
+ |y [id D]
+
+>>> f(xv, yv)  # doctest: +ELLIPSIS
+Traceback (most recent call last):
+  ...
+ValueError: ...
+
+As you can see, when asking only for the shape of some computation (``join`` in the
+example above), an inferred shape is computed directly, without executing
+the computation itself (there is no ``join`` in the first output or debugprint).
+
+This makes the computation of the shape faster, but it can also hide errors. In
+this example, the computation of the shape of the output of ``join`` is done only
+based on the first input Aesara variable, which leads to an error.
+
+This might happen with other `Op`\s such as :class:`Elemwise` and :class:`Dot`, for example.
+Indeed, to perform some optimizations/rewrites (for speed or stability, for instance),
+Aesara assumes that the computation is correct and consistent
+in the first place, as it does here.
+
+You can detect those problems by running the code without this optimization,
+using the Aesara flag ``optimizer_excluding=local_shape_to_shape_i``. You can
+also obtain the same effect by running in the modes ``FAST_COMPILE`` or
+:class:`DebugMode`.
+
+Broadcasting
+------------
+
+Broadcasting is a mechanism which allows tensors with
+different numbers of dimensions to be added or multiplied
+together by (virtually) replicating the smaller tensor along
+the dimensions that it is lacking.
+
+Broadcasting is the mechanism by which a scalar
+may be added to a matrix, a vector to a matrix or a scalar to
+a vector.
+
+.. figure:: bcast.png
+
+Broadcasting a row matrix. T and F respectively stand for
+True and False and indicate along which dimensions we allow
+broadcasting.
+
+If the second argument were a vector, its shape would be
+``(2,)`` and its broadcastable pattern ``(False,)``. They would
+be automatically expanded to the **left** to match the
+dimensions of the matrix (adding ``1`` to the shape and ``True``
+to the pattern), resulting in ``(1, 2)`` and ``(True, False)``.
+It would then behave just like the example above.
+
+Unlike numpy which does broadcasting dynamically, Aesara needs
+to know, for any operation which supports broadcasting, which
+dimensions will need to be broadcasted. When applicable, this
+information is given in the :ref:`type` of a *Variable*.
+
+The following code illustrates how rows and columns are broadcasted in order to perform an addition operation with a matrix:
+
+>>> r = at.row()
+>>> r.broadcastable
+(True, False)
+>>> mtr = at.matrix()
+>>> mtr.broadcastable
+(False, False)
+>>> f_row = aesara.function([r, mtr], [r + mtr])
+>>> R = np.arange(3).reshape(1, 3)
+>>> R
+array([[0, 1, 2]])
+>>> M = np.arange(9).reshape(3, 3)
+>>> M
+array([[0, 1, 2],
+       [3, 4, 5],
+       [6, 7, 8]])
+>>> f_row(R, M)
+[array([[  0.,   2.,   4.],
+       [  3.,   5.,   7.],
+       [  6.,   8.,  10.]])]
+>>> c = at.col()
+>>> c.broadcastable
+(False, True)
+>>> f_col = aesara.function([c, mtr], [c + mtr])
+>>> C = np.arange(3).reshape(3, 1)
+>>> C
+array([[0],
+       [1],
+       [2]])
+>>> M = np.arange(9).reshape(3, 3)
+>>> f_col(C, M)
+[array([[  0.,   1.,   2.],
+       [  4.,   5.,   6.],
+       [  8.,   9.,  10.]])]
 
-- *While*- or *for*-Loops within an expression graph are supported, but only via
-  the :func:`aesara.scan` op (which puts restrictions on how the loop body can
-  interact with the rest of the graph).
+In these examples, we can see that both the row vector and the column vector are broadcasted in order to be be added to the matrix.
 
-- Neither *goto* nor *recursion* is supported or planned within expression graphs.
+See the `Numpy documentation <https://numpy.org/doc/stable/user/basics.broadcasting.html>`_ for an in-depth explanation of the broadcasting mechanism.
```

### Comparing `aesara-nightly-2.8.9.post118/doc/generate_dtype_tensor_table.py` & `aesara_nightly-2.9.0.post2/doc/generate_dtype_tensor_table.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/glossary.rst` & `aesara_nightly-2.9.0.post2/doc/glossary.rst`

 * *Files 2% similar despite different names*

```diff
@@ -19,18 +19,14 @@
     Broadcasting
         Broadcasting is a mechanism which allows tensors with
         different numbers of dimensions to be used in element-by-element
         (i.e. element-wise) computations.  It works by
         (virtually) replicating the smaller tensor along
         the dimensions that it is lacking.
 
-        For more detail, see :ref:`tutbroadcasting`, and also
-        * `SciPy documentation about numpy's broadcasting <http://www.scipy.org/EricsBroadcastingDoc>`_
-        * `OnLamp article about numpy's broadcasting <http://www.onlamp.com/pub/a/python/2000/09/27/numerically.html>`_
-
     Constant
         A variable with an immutable value.
         For example, when you type
 
         >>> x = at.ivector()
         >>> y = x + 3
```

### Comparing `aesara-nightly-2.8.9.post118/doc/images/Elman_srnn.png` & `aesara_nightly-2.9.0.post2/doc/images/Elman_srnn.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/aesara_logo_2400.png` & `aesara_nightly-2.9.0.post2/doc/images/aesara_logo_2400.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/blocksparse.png` & `aesara_nightly-2.9.0.post2/doc/images/blocksparse.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/lstm.png` & `aesara_nightly-2.9.0.post2/doc/images/lstm.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/lstm_memorycell.png` & `aesara_nightly-2.9.0.post2/doc/images/lstm_memorycell.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/talk2010.gif` & `aesara_nightly-2.9.0.post2/doc/images/talk2010.gif`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/images/talk2010.png` & `aesara_nightly-2.9.0.post2/doc/images/talk2010.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/introduction.rst` & `aesara_nightly-2.9.0.post2/doc/introduction.rst`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 
 .. _introduction:
 
-==================
-Aesara at a Glance
-==================
+What is Aesara?
+===============
 
 Aesara is a Python library that allows one to define, optimize/rewrite, and
 evaluate mathematical expressions, especially ones involving multi-dimensional
 arrays (e.g. :class:`numpy.ndarray`\s).  Using Aesara, it is possible to attain
 speeds rivaling hand-crafted C implementations for problems involving large
 amounts of data.
 
@@ -22,43 +21,43 @@
 features such as automatic differentiation.
 
 Aesara's compiler applies many default optimizations of varying
 complexity. These optimizations include, but are not limited to:
 
 * constant folding
 * merging of similar sub-graphs, to avoid redundant calculations
-* arithmetic simplifications (e.g. ``x * y / x -> y``, ``-(-x) -> x``)
+* arithmetic simplifications (e.g. ``x * y / x -> y`` and ``-(-x) -> x``)
 * inserting efficient BLAS_ operations (e.g. ``GEMM``) in a variety of
   contexts
 * using memory aliasing to avoid unnecessary calculations
 * using in-place operations wherever it does not interfere with aliasing
 * loop fusion for element-wise sub-expressions
 * improvements to numerical stability (e.g.  :math:`\log(1+\exp(x))` and :math:`\log(\sum_i \exp(x[i]))`)
 
 For more information see :ref:`optimizations`.
 
 Theano
 ------
 
-The library that Aesara is based on, Theano, was written at the LISA lab to support rapid development of efficient machine learning algorithms but while Theano was commonly referred to as a "deep learning" (DL) library, Aesara is not a DL library.
+Theano, the library on which Aesara is based, was written at the LISA lab to support rapid development of efficient machine learning algorithms. While Theano was commonly referred to as a "deep learning" (DL) library, Aesara is not a DL library.
 
-Designations like "deep learning library" reflect the priorities/goals of a library; specifically, that the library serves the purposes of DL and its computational needs. Aesara is not explicitly intended to serve the purpose of constructing and evaluating DL models, but that doesn't mean it can't serve that purpose well.
+Designations like "deep learning library" reflect the priorities/goals of a library; specifically, that the library serves the purposes of DL and its computational needs. Aesara is not explicitly intended to serve the purpose of constructing and evaluating DL models, although it can serve that purpose well.
 
-The designation "tensor library" is more apt, but, unlike most other tensor libraries (e.g. TensorFlow, PyTorch, etc.), Aesara is more focused on what one might call the symbolic functionality.
+The designation "tensor library" is more apt, but, unlike most other tensor libraries (e.g. TensorFlow, PyTorch, etc.), Aesara is more focused on symbolic functionality.
 
 Most tensor libraries perform similar operations to some extent, but many do not expose the underlying operations for use at any level other than internal library development. Furthermore, when they do, many libraries cross a large language barrier that unnecessarily hampers rapid development (e.g. moving from Python to C++ and back).
 
 If you follow the history of this project, you can see that it grew out of work on PyMC, and PyMC is a library for domain-specific (i.e. probabilistic modeling) computations. Likewise, the other ``aesara-devs`` projects demonstrate the use of Aesara graphs as an intermediate representation (IR) for a domain-specific language/interface (e.g. `aeppl <https://github.com/aesara-devs/aeppl>`_ provides a graph representation for a PPL) and advanced automations based on IR (e.g. `aemcmc <https://github.com/aesara-devs/aemcmc>`_ as a means of constructing custom samplers from IR, ``aeppl`` as a means of automatically deriving log-probabilities for basic tensor operations represented in IR).
 
-This topic is a little more advanced and doesn't really have parallels in other tensor libraries, but it's one of the things that Aesara uniquely facilitates.
+This topic of symbolic manipulation of intermediate representations is a little more advanced and doesn't really have parallels in other tensor libraries, but it's one of the things that Aesara uniquely facilitates.
 
 The PyMC/probabilistic programming connection is similar to the DL connection Theano had, butunlike Theanowe don't want Aesara to be conflated with one of its domains of applicationlike probabilistic modeling. Those primary domains of application will always have some influence on the development of Aesara, but that's also why we need to avoid labels/designations like "deep learning library" and focus on the functionality, so that we don't unnecessarily compromise Aesara's general applicability, relative simplicity, and/or prevent useful input/collaboration from other domains.
 
 Sneak peek
-==========
+----------
 
 Here is an example of how to use Aesara. It doesn't show off many of
 its features, but it illustrates concretely what Aesara is.
 
 
 .. If you modify this code, also change :
 .. tests/test_tutorial.py:T_introduction.test_introduction_1
@@ -84,26 +83,26 @@
 
 
 Aesara is not a programming language in the normal sense because you
 write a program in Python that builds expressions for Aesara. Still it
 is like a programming language in the sense that you have to
 
 - declare variables ``a`` and ``b`` and give their types,
-- build expressions graphs using those variables,
+- build expression graphs using those variables,
 - compile the expression graphs into functions that can be used for computation.
 
 It is good to think of :func:`aesara.function` as the interface to a
 compiler which builds a callable object from a purely symbolic graph.
 One of Aesara's most important features is that :func:`aesara.function`
 can optimize a graph and even compile some or all of it into native
 machine instructions.
 
 
 What does it do that NumPy doesn't
-==================================
+----------------------------------
 
 Aesara is a essentially an optimizing compiler for manipulating
 and evaluating expressions, especially tensor-valued
 ones. Manipulation of tensors is typically done using the NumPy
 package, so what does Aesara do that Python and NumPy don't do?
 
 - *execution speed optimizations*: Aesara can use C, Numba, or JAX to compile
@@ -113,51 +112,23 @@
 - *symbolic differentiation*: Aesara can automatically build symbolic graphs
   for computing gradients.
 
 - *stability optimizations*: Aesara can recognize some numerically unstable
   expressions and compute them with more stable algorithms.
 
 The closest Python package to Aesara is sympy_.
-Aesara focuses more on tensor expressions than Sympy, and has more machinery
+Aesara focuses more on tensor expressions than Sympy, and it has more machinery
 for compilation.  Sympy has more sophisticated algebra rules and can
 handle a wider variety of mathematical operations (such as series, limits, and integrals).
 
 If numpy_ is to be compared to MATLAB_ and sympy_ to Mathematica_,
-Aesara is a sort of hybrid of the two which tries to combine the best of
+then Aesara is a sort of hybrid of the two that tries to combine the best of
 both worlds.
 
-
-Getting started
-===============
-
-:ref:`install`
-  Instructions to download and install Aesara on your system.
-
-:ref:`tutorial`
-  Getting started with Aesara's basic features. Go here if you are
-  new!
-
-:ref:`libdoc`
-  Details of what Aesara provides. It is recommended to go through
-  the :ref:`tutorial` first though.
-
-
-Contact us
-==========
-
-Questions and bug reports should be submitted in the form of an issue at
-aesara-dev_
-
-We welcome all kinds of contributions. If you have any questions regarding how
-to extend Aesara, please feel free to ask.
-
-
 .. _LISA:  https://mila.umontreal.ca/
 .. _Greek mathematician: http://en.wikipedia.org/wiki/Theano_(mathematician)
 .. _numpy: http://numpy.scipy.org/
 .. _BLAS: http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms
 
 .. _sympy: http://www.sympy.org/
 .. _MATLAB: http://www.mathworks.com/products/matlab/
 .. _Mathematica: http://www.wolfram.com/mathematica/
-
-.. _aesara-dev: https://github.com/aesara-devs/aesara/issues
```

### Comparing `aesara-nightly-2.8.9.post118/doc/library/compile/debugmode.rst` & `aesara_nightly-2.9.0.post2/doc/compile/debugmode.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/compile/mode.rst` & `aesara_nightly-2.9.0.post2/doc/compile/mode.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/compile/nanguardmode.rst` & `aesara_nightly-2.9.0.post2/doc/compile/nanguardmode.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/compile/opfromgraph.rst` & `aesara_nightly-2.9.0.post2/doc/compile/opfromgraph.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/config.rst` & `aesara_nightly-2.9.0.post2/doc/config.rst`

 * *Files 2% similar despite different names*

```diff
@@ -184,35 +184,35 @@
 
     If :attr:`config.allow_gc` is ``True``, but :attr:`config.scan__allow_gc` is
     ``False``, then Aesara will perform garbage collection during the inner
     operations of a :class:`Scan` after each iterations.
 
 .. attribute:: cycle_detection
 
-    String value, either ``regular`` or ``fast```
+    String value, either ``"regular"`` or ``"fast"```
 
-    Default: ``regular``
+    Default: ``"regular"``
 
-    If :attr:`cycle_detection` is set to ``regular``, most in-place operations are allowed,
-    but graph compilation is slower. If :attr:`cycle_detection` is set to ``faster``,
+    If :attr:`cycle_detection` is set to ``"regular"``, most in-place operations are allowed,
+    but graph compilation is slower. If :attr:`cycle_detection` is set to ``"fast"``,
     less in-place operations are allowed, but graph compilation is faster.
 
 .. attribute:: check_stack_trace
 
-    String value, either ``off``, ``log``, ``warn``, ``raise``
+    String value, either ``"off"``, ``"log"``, ``"warn"``, ``"raise"``
 
-    Default: ``off``
+    Default: ``"off"``
 
     This is a flag for checking stack traces during graph rewriting.
-    If :attr:`check_stack_trace` is set to ``off``, no check is performed on the
-    stack trace. If :attr:`check_stack_trace` is set to ``log`` or ``warn``, a
+    If :attr:`check_stack_trace` is set to ``"off"``, no check is performed on the
+    stack trace. If :attr:`check_stack_trace` is set to ``"log"`` or ``"warn"``, a
     dummy stack trace is inserted that indicates which rewrite inserted the
-    variable that had an empty stack trace, but, when ``warn`` is set, a warning
+    variable that had an empty stack trace, but, when ``"warn"`` is set, a warning
     is also printed.
-    If :attr:`check_stack_trace` is set to ``raise``, an exception is raised if a
+    If :attr:`check_stack_trace` is set to ``"raise"``, an exception is raised if a
     stack trace is missing.
 
 .. attribute:: openmp
 
     Bool value: either ``True`` or ``False``
 
     Default: ``False``
```

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/css/d3viz.css` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/css/d3viz.css`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3-context-menu.js` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3-context-menu.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3.v3.min.js` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3.v3.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/d3viz.js` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/d3viz.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/dagre-d3.min.js` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/dagre-d3.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/d3viz/js/graphlib-dot.min.js` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/d3viz/js/graphlib-dot.min.js`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp.html` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.html` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.pdf` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.pdf`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/mlp2.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/mlp2.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/ofg.html` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/ofg.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/examples/ofg2.html` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/examples/ofg2.html`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index.ipynb` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index.ipynb`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_10_0.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_10_0.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_11_0.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_11_0.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_24_0.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_24_0.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/d3viz/index_files/index_25_0.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz/index_files/index_25_0.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/graph/features.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/features.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/graph/fgraph.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/graph/fgraph.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/printing.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/printing.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/library/scan.rst` & `aesara_nightly-2.9.0.post2/doc/reference/loops/loops_api.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,9 @@
 
-.. _lib_scan:
-
-================================
-:mod:`scan` -- Looping in Aesara
-================================
-
+.. _reference_scan:
 
 Guide
 =====
 
 The scan functions provides the basic functionality needed to do loops
 in Aesara. Scan comes with many whistles and bells, which we will introduce
 by way of examples.
@@ -661,21 +656,7 @@
 :math:`W_*`, are merged into a single shared matrix :math:`W` and the graph
 performs a single larger matrix multiplication between :math:`W` and
 :math:`x_t`. The resulting matrix is then sliced to obtain the results of that
 the small individual matrix multiplications would have produced. This
 rewrite replaces several small and inefficient matrix multiplications by
 a single larger one and thus improves performance at the cost of a potentially
 higher memory usage.
-
-
-reference
-=========
-
-.. automodule:: aesara.scan
-
-.. autofunction:: aesara.map
-.. autofunction:: aesara.reduce
-.. autofunction:: aesara.foldl
-.. autofunction:: aesara.foldr
-.. autofunction:: aesara.scan
-   :noindex:
-.. autofunction:: aesara.scan.scan_checkpoints
```

### Comparing `aesara-nightly-2.8.9.post118/doc/library/sparse/index.rst` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/sparse_api.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,14 @@
 
 .. _libdoc_sparse:
 
 =========================================
 :mod:`sparse` -- Symbolic Sparse Matrices
 =========================================
 
-In the tutorial section, you can find a :ref:`sparse tutorial
-<tutsparse>`.
-
 The sparse submodule is not loaded when we import Aesara. You must
 import ``aesara.sparse`` to enable it.
 
 The sparse module provides the same functionality as the tensor
 module. The difference lies under the covers because sparse matrices
 do not store data in a contiguous array. The sparse module has
 been used in:
@@ -195,15 +192,15 @@
     - ``rint``
     - ``ceil``
     - ``floor``
     - ``trunc``
     - ``sgn``
     - ``log1p``
     - ``expm1``
-    - ``sqr``
+    - ``square``
     - ``sqrt``
 
 - Dot Product
     - :func:`dot <aesara.sparse.basic.dot>`.
 
         - One of the inputs must be sparse, the other sparse or dense.
         - The grad implemented is regular.
```

### Comparing `aesara-nightly-2.8.9.post118/doc/library/sparse/sandbox.rst` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/sandbox.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/mission.rst` & `aesara_nightly-2.9.0.post2/doc/mission.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/optimizations.rst` & `aesara_nightly-2.9.0.post2/doc/fundamentals/rewrites/optimizations.rst`

 * *Files 2% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 When compiling, we can make a tradeoff between compile-time and run-time.
 Faster compile times will result in fewer optimizations being applied, hence generally slower run-times.
 For making this tradeoff when compiling, we provide a set of 4 optimization
 modes, 'o1' to 'o4', where 'o1' leads to fastest compile-time and 'o4' leads to
 fastest run-time in general.
 For an even faster run-time, we could disable assertions (which could be time
 consuming) for valid user inputs, using the optimization mode 'unsafe', but this
-is, as the name suggests, unsafe.  See :ref:`unsafe_rewrites`.
+is, as the name suggests, unsafe.
 
 ..  note::
 
     This list is partial.
 
     The print_summary method allows several OpDBs and optimizers to list the
     executed optimizations.  This makes it possible to have an up-to-date list.
@@ -261,9 +261,7 @@
 
     local_remove_all_assert
         This is an unsafe optimization.
         For the fastest possible Aesara, this optimization can be enabled by
 	setting ``optimizer_including=local_remove_all_assert`` which will
 	remove all assertions in the graph for checking user inputs are valid.
         Use this optimization if you are sure everything is valid in your graph.
-
-	See :ref:`unsafe_rewrites`
```

### Comparing `aesara-nightly-2.8.9.post118/doc/pylintrc` & `aesara_nightly-2.9.0.post2/doc/pylintrc`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/ccodegen.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/ccodegen.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/debugging_with_stepmode.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/debugging_with_stepmode.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/elemwise_compiler.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/elemwise_compiler.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/how_to_make_ops.rst` & `aesara_nightly-2.9.0.post2/doc/extend/op/how_to_make_ops.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/interactive_debugger.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/interactive_debugger.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/logistic_regression_example.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/logistic_regression_example.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/performance.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/performance.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/randomnumbers.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/randomnumbers.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/rethinkccodegen.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/rethinkccodegen.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/sandbox.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/sandbox.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/software.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/software.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/sandbox/sparse.rst` & `aesara_nightly-2.9.0.post2/doc/sandbox/sparse.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/scripts/docgen.py` & `aesara_nightly-2.9.0.post2/doc/scripts/docgen.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/troubleshooting.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/troubleshooting.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/adding.rst` & `aesara_nightly-2.9.0.post2/doc/how_to_think_in_aesara.rst`

 * *Files 17% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 .. _adding:
 
-====================
-Baby Steps - Algebra
-====================
+How to think in Aesara
+======================
 
 Adding two Scalars
-==================
+------------------
 
 To get us started with Aesara and get a feel of what we're working with,
 let's make a simple function: add two numbers together. Here is how you do
 it:
 
 >>> import numpy
 >>> import aesara.tensor as at
@@ -139,15 +138,15 @@
     it needs to call :func:`function` to compile the expression behind
     the scenes. Subsequent calls to :func:`eval` on that same variable
     will be fast, because the variable caches the compiled function.
 
 
 
 Adding two Matrices
-===================
+-------------------
 
 You might already have guessed how to do this. Indeed, the only change
 from the previous example is that you need to instantiate *x* and
 *y* using the matrix Types:
 
 >>> x = at.dmatrix('x')
 >>> y = at.dmatrix('y')
@@ -167,50 +166,27 @@
 >>> import numpy
 >>> f(numpy.array([[1, 2], [3, 4]]), numpy.array([[10, 20], [30, 40]]))
 array([[ 11.,  22.],
        [ 33.,  44.]])
 
 It is possible to add scalars to matrices, vectors to matrices,
 scalars to vectors, etc. The behavior of these operations is defined
-by :ref:`broadcasting <libdoc_tensor_broadcastable>`.
+by :ref:`broadcasting rules<reference_shapes>`.
 
 The following types are available:
 
 * **byte**: ``bscalar, bvector, bmatrix, brow, bcol, btensor3, btensor4, btensor5, btensor6, btensor7``
 * **16-bit integers**: ``wscalar, wvector, wmatrix, wrow, wcol, wtensor3, wtensor4, wtensor5, wtensor6, wtensor7``
 * **32-bit integers**: ``iscalar, ivector, imatrix, irow, icol, itensor3, itensor4, itensor5, itensor6, itensor7``
 * **64-bit integers**: ``lscalar, lvector, lmatrix, lrow, lcol, ltensor3, ltensor4, ltensor5, ltensor6, ltensor7``
 * **float**: ``fscalar, fvector, fmatrix, frow, fcol, ftensor3, ftensor4, ftensor5, ftensor6, ftensor7``
 * **double**: ``dscalar, dvector, dmatrix, drow, dcol, dtensor3, dtensor4, dtensor5, dtensor6, dtensor7``
 * **complex**: ``cscalar, cvector, cmatrix, crow, ccol, ctensor3, ctensor4, ctensor5, ctensor6, ctensor7``
 
 The previous list is not exhaustive and a guide to all types compatible
-with NumPy arrays may be found here: :ref:`tensor creation<libdoc_tensor_creation>`.
+with NumPy arrays may be found here: :ref:`tensor creation<reference_tensor_create>`.
 
 .. note::
 
    You, the user---not the system architecture---have to choose whether your
    program will use 32- or 64-bit integers (``i`` prefix vs. the ``l`` prefix)
    and floats (``f`` prefix vs. the ``d`` prefix).
-
-
-
-Exercise
-========
-
-.. testcode::
-
-   import aesara
-   a = aesara.tensor.vector() # declare variable
-   out = a + a ** 10               # build symbolic expression
-   f = aesara.function([a], out)   # compile function
-   print(f([0, 1, 2]))
-
-.. testoutput::
-
-   [    0.     2.  1026.]
-
-
-Modify and execute this code to compute this expression: a ** 2 + b ** 2 + 2 * a * b.
-
-
-:download:`Solution<adding_solution_1.py>`
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/aliasing.rst` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/shared/aliasing.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/apply.png` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/apply.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/apply.svg` & `aesara_nightly-2.9.0.post2/doc/fundamentals/graph/apply.svg`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/conditions.rst` & `aesara_nightly-2.9.0.post2/doc/reference/conditionals.rst`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
-.. _tutconditions:
+.. _reference_conditionals:
 
-==========
-Conditions
-==========
+============
+Conditionals
+============
 
 IfElse vs Switch
 ================
 
 
 - Both ops build a condition over symbolic variables.
 - ``IfElse`` takes a *boolean* condition and two variables as inputs.
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/debug_faq.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/debug_faq.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/dlogistic.png` & `aesara_nightly-2.9.0.post2/doc/reference/gradient/dlogistic.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/gradients.rst` & `aesara_nightly-2.9.0.post2/doc/reference/gradient/gradient_tutorial.rst`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 
-.. _tutcomputinggrads:
+.. _reference_gradient_tutorial:
 
 
-=====================
 Derivatives in Aesara
 =====================
 
 Computing Gradients
 ===================
 
 Now let's use Aesara for a slightly more sophisticated task: create a
@@ -84,18 +83,15 @@
    The second argument of `at.grad` can be a list, in which case the
    output is also a list. The order in both lists is important: element
    ``i`` of the output list is the gradient of the first argument of
    `at.grad` with respect to the ``i``-th element of the list given as second argument.
    The first argument of `at.grad` has to be a scalar (a tensor
    of size 1). For more information on the semantics of the arguments of
    `at.grad` and details about the implementation, see
-   :ref:`this<libdoc_gradient>` section of the library.
-
-   Additional information on the inner workings of differentiation may also be
-   found in the more advanced tutorial :ref:`Extending Aesara<extending>`.
+   :ref:`this<reference_gradient_api>` section of the library.
 
 Computing the Jacobian
 ======================
 
 In Aesara's parlance, the term **Jacobian** designates the tensor comprising the
 first partial derivatives of the output of a function with respect to its inputs.
 (This is a generalization of to the so-called Jacobian matrix in Mathematics.)
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/loading_and_saving.rst` & `aesara_nightly-2.9.0.post2/doc/serializing/loading_and_saving.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/loop.rst` & `aesara_nightly-2.9.0.post2/doc/reference/loops/loops_tutorial.rst`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 .. _tutloop:
 
-====
-Loop
-====
+========
+Tutorial
+========
 
 
 Scan
 ====
 
 - A general form of *recurrence*, which can be used for looping.
 - *Reduction* and *map* (loop over the leading dimensions) are special cases of ``scan``.
@@ -17,15 +17,15 @@
 - Advantages of using ``scan`` over *for* loops:
 
   - Number of iterations to be part of the symbolic graph.
   - Computes gradients through sequential steps.
   - Slightly faster than using a *for* loop in Python with a compiled Aesara function.
   - Can lower the overall memory usage by detecting the actual amount of memory needed.
 
-The full documentation can be found in the library: :ref:`Scan <lib_scan>`.
+The full documentation can be found in the library: :ref:`Scan <reference_scan>`.
 
 `A good ipython notebook with explanation and more examples.
 <https://github.com/lamblin/ccw_tutorial/blob/master/Scan_W2016/scan_tutorial.ipynb>`_
 
 **Scan Example: Computing tanh(x(t).dot(W) + b) elementwise**
 
 .. testcode::
@@ -413,20 +413,7 @@
 
   test_coeff = numpy.asarray([1, 0, 2], dtype=numpy.float32)
   print(calculate_polynomial(test_coeff, 3))
 
 .. testoutput::
 
     19.0
-
-
-
-
-Exercise
-========
-
-Run both examples.
-
-Modify and execute the polynomial example to have the reduction done by ``scan``.
-
-
-:download:`Solution<loop_solution_1.py>`
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/loop_solution_1.py` & `aesara_nightly-2.9.0.post2/doc/reference/loops/loop_solution_1.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/modes.rst` & `aesara_nightly-2.9.0.post2/doc/compile/modes.rst`

 * *Files 5% similar despite different names*

```diff
@@ -17,17 +17,17 @@
 
 Aesara's code comes with default values for these attributes, but you can
 override them from your ``.aesararc`` file, and override those values in turn by
 the :envvar:`AESARA_FLAGS` environment variable.
 
 The order of precedence is:
 
-1. an assignment to ``aesara.config.<property>``
-2. an assignment in :envvar:`AESARA_FLAGS`
-3. an assignment in the ``.aesararc`` file (or the file indicated in :envvar:`AESARARC`)
+1. values of `aesara.config` properties,
+2. values specified in :envvar:`AESARA_FLAGS`, and
+3. values specified in the ``.aesararc`` file (or the file indicated in :envvar:`AESARARC`).
 
 You can display the current/effective configuration at any time by printing
 `aesara.config`.  For example, to see a list  of all active configuration
 variables, type this from the command-line:
 
 .. code-block:: bash
 
@@ -111,87 +111,85 @@
    prediction on D
    ...
 
 Modify and execute this example to run on CPU (the default) with ``floatX=float32`` and
 time the execution using the command line ``time python file.py``.  Save your code
 as it will be useful later on.
 
-.. Note::
+.. note::
 
    * Apply the Aesara flag ``floatX=float32`` (through ``aesara.config.floatX``) in your code.
    * Cast inputs before storing them into a shared variable.
    * Circumvent the automatic cast of int32 with float32 to float64:
 
      * Insert manual cast in your code or use [u]int{8,16}.
      * Insert manual cast around the mean operator (this involves division by length, which is an int64).
      * Note that a new casting mechanism is being developed.
 
 :download:`Solution<modes_solution_1.py>`
 
--------------------------------------------
-
 Default Modes
 =============
 
 Every time :func:`aesara.function <function.function>` is called,
 the symbolic relationships between the input and output Aesara *variables*
 are rewritten and compiled. The way this compilation occurs
-is controlled by the value of the ``mode`` parameter.
+is controlled by the value of the ``mode`` parameter and/or
+:attr:`aesara.config.mode` value.
 
 Aesara defines the following modes by name:
 
 - ``'FAST_COMPILE'``: Apply just a few graph optimizations and only use Python implementations.
 - ``'FAST_RUN'``: Apply all optimizations and use C implementations where possible.
 - ``'DebugMode'``: Verify the correctness of all optimizations, and compare C and Python
-    implementations. This mode can take much longer than the other modes, but can identify
-    several kinds of problems.
+   implementations. This mode can take much longer than the other modes, but can identify
+   several kinds of problems.
 - ``'NanGuardMode'``: Same optimization as FAST_RUN, but :ref:`check if a node generate nans. <nanguardmode>`
 
-The default mode is typically ``FAST_RUN``, but it can be controlled via
-the configuration variable :attr:`config.mode`,
-which can be overridden by passing the keyword argument to
-:func:`aesara.function <function.function>`.
-
-================= =============================================================== ===============================================================================
-short name        Full constructor                                                What does it do?
-================= =============================================================== ===============================================================================
-``FAST_COMPILE``  ``compile.mode.Mode(linker='py', optimizer='fast_compile')``    Python implementations only, quick and cheap graph transformations
-``FAST_RUN``      ``compile.mode.Mode(linker='cvm', optimizer='fast_run')``       C implementations where available, all available graph transformations.
-``DebugMode``     ``compile.debugmode.DebugMode()``                               Both implementations where available, all available graph transformations.
-================= =============================================================== ===============================================================================
-
-.. Note::
-
-    For debugging purpose, there also exists a :class:`MonitorMode` (which has no
-    short name). It can be used to step through the execution of a function:
-    see :ref:`the debugging FAQ<faq_monitormode>` for details.
+The default mode is typically ``'FAST_RUN'``, but it can be controlled via
+the configuration variable :attr:`aesara.config.mode`.
+
+=================  ===============================================================  ==========================================================================
+short name         Full constructor                                                 What does it do?
+=================  ===============================================================  ==========================================================================
+``FAST_COMPILE``   ``compile.mode.Mode(linker='py', optimizer='fast_compile')``     Python implementations only, quick and cheap graph transformations
+``FAST_RUN``       ``compile.mode.Mode(linker='cvm', optimizer='fast_run')``        C implementations where available, all available graph transformations.
+``DebugMode``      ``compile.debugmode.DebugMode()``                                Both implementations where available, all available graph transformations.
+=================  ===============================================================  ==========================================================================
+
+.. note::
+
+   For debugging purpose, there also exists a :class:`MonitorMode` (which has no
+   short name). It can be used to step through the execution of a function:
+   see :ref:`the debugging FAQ<faq_monitormode>` for details.
 
 
 Default Linkers
 ===============
 
 A :class:`Mode` object is composed of two things: an optimizer and a linker. Some modes,
 like `NanGuardMode` and `DebugMode`, add logic around the
 optimizer and linker. `DebugMode` uses its own linker.
 
 You can select which linker to use with the Aesara flag :attr:`config.linker`.
 Here is a table to compare the different linkers.
 
-=============  =========  =================  =========  ===
+
+=============  =========  =================  =========  =============================================================
 linker         gc [#gc]_  Raise error by op  Overhead   Definition
-=============  =========  =================  =========  ===
+=============  =========  =================  =========  =============================================================
 cvm            yes        yes                "++"       As c|py, but the runtime algo to execute the code is in c
 cvm_nogc       no         yes                "+"        As cvm, but without gc
 c|py [#cpy1]_  yes        yes                "+++"      Try C code. If none exists for an op, use Python
 c|py_nogc      no         yes                "++"       As c|py, but without gc
 c              no         yes                "+"        Use only C code (if none available for an op, raise an error)
 py             yes        yes                "+++"      Use only Python code
 NanGuardMode   yes        yes                "++++"     Check if nodes generate NaN
 DebugMode      no         yes                VERY HIGH  Make many checks on what Aesara computes
-=============  =========  =================  =========  ===
+=============  =========  =================  =========  =============================================================
 
 
 .. [#gc] Garbage collection of intermediate results during computation.
          Otherwise, their memory space used by the ops is kept between
          Aesara function calls, in order not to
          reallocate memory, and lower the overhead (make it faster...).
 .. [#cpy1] Default
@@ -209,32 +207,31 @@
 An optimizer is technically just a :class:`Rewriter`, or an object that
 indicates a particular set of rewrites (e.g. a string used to query `optdb` for
 a :class:`Rewriter`).
 
 The optimizers Aesara provides are summarized below to indicate the trade-offs
 one might make between compilation time and execution time.
 
-These optimizers can be enabled globally with the Aesara flag: ``optimizer=name``
-or per call to aesara functions with ``function(...mode=Mode(optimizer="name"))``.
+These optimizers can be enabled globally with the Aesara config flag ``optimizer=name``,
+or per call to Aesara functions with ``function(...mode=Mode(optimizer="name"))``.
 
-=================  ============  ==============  ==================================================
+=================  ============  ==============  =====================================================
 optimizer          Compile time  Execution time  Description
-=================  ============  ==============  ==================================================
+=================  ============  ==============  =====================================================
 None               "++++++"      "+"             Applies none of Aesara's rewrites
 o1 (fast_compile)  "+++++"       "++"            Applies only basic rewrites
 o2                 "++++"        "+++"           Applies few basic rewrites and some that compile fast
 o3                 "+++"         "++++"          Applies all rewrites except ones that compile slower
 o4 (fast_run)      "++"          "+++++"         Applies all rewrites
 unsafe             "+"           "++++++"        Applies all rewrites, and removes safety checks
 stabilize          "+++++"       "++"            Only applies stability rewrites
-=================  ============  ==============  ==================================================
+=================  ============  ==============  =====================================================
 
 For a detailed list of the specific rewrites applied for each of these
-optimizers, see :ref:`optimizations`. Also, see :ref:`unsafe_rewrites` and
-:ref:`faster-aesara-function-compilation` for other trade-off.
+optimizers, see :ref:`optimizations`.
 
 
 .. _using_debugmode:
 
 Using :class:`DebugMode`
 ========================
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/modes_solution_1.py` & `aesara_nightly-2.9.0.post2/doc/compile/modes_solution_1.py`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/nan_tutorial.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/nan_tutorial.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/pics/d3viz.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/d3viz.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_predict.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_predict.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_prediction.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_prediction.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/pics/logreg_pydotprint_train.png` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/logreg_pydotprint_train.png`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/printing_drawing.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/printing_drawing.rst`

 * *Files 8% similar despite different names*

```diff
@@ -63,15 +63,15 @@
 Debug Print
 ===========
 
 The pre-compilation graph:
 
 >>> aesara.printing.debugprint(prediction) # doctest: +NORMALIZE_WHITESPACE, +ELLIPSIS
 Elemwise{gt,no_inplace} [id A] ''
- |Elemwise{true_div,no_inplace} [id B] ''
+ |Elemwise{true_divide,no_inplace} [id B] ''
  | |InplaceDimShuffle{x} [id C] ''
  | | |TensorConstant{1} [id D]
  | |Elemwise{add,no_inplace} [id E] ''
  |   |InplaceDimShuffle{x} [id F] ''
  |   | |TensorConstant{1} [id D]
  |   |Elemwise{exp,no_inplace} [id G] ''
  |     |Elemwise{sub,no_inplace} [id H] ''
@@ -102,43 +102,43 @@
 
 
 Picture Printing of Graphs
 ==========================
 
 The pre-compilation graph:
 
->>> aesara.printing.pydotprint(prediction, outfile="pics/logreg_pydotprint_prediction.png", var_with_name_simple=True)  # doctest: +SKIP
-The output file is available at pics/logreg_pydotprint_prediction.png
+>>> aesara.printing.pydotprint(prediction, outfile="logreg_pydotprint_prediction.png", var_with_name_simple=True)  # doctest: +SKIP
+The output file is available at logreg_pydotprint_prediction.png
 
-.. image:: ./pics/logreg_pydotprint_prediction.png
+.. image:: ./logreg_pydotprint_prediction.png
    :width: 800 px
 
 The post-compilation graph:
 
->>> aesara.printing.pydotprint(predict, outfile="pics/logreg_pydotprint_predict.png", var_with_name_simple=True)  # doctest: +SKIP
-The output file is available at pics/logreg_pydotprint_predict.png
+>>> aesara.printing.pydotprint(predict, outfile="logreg_pydotprint_predict.png", var_with_name_simple=True)  # doctest: +SKIP
+The output file is available at logreg_pydotprint_predict.png
 
-.. image:: ./pics/logreg_pydotprint_predict.png
+.. image:: ./logreg_pydotprint_predict.png
    :width: 800 px
 
 The optimized training graph:
 
->>> aesara.printing.pydotprint(train, outfile="pics/logreg_pydotprint_train.png", var_with_name_simple=True)  # doctest: +SKIP
-The output file is available at pics/logreg_pydotprint_train.png
+>>> aesara.printing.pydotprint(train, outfile="logreg_pydotprint_train.png", var_with_name_simple=True)  # doctest: +SKIP
+The output file is available at logreg_pydotprint_train.png
 
-.. image:: ./pics/logreg_pydotprint_train.png
+.. image:: ./logreg_pydotprint_train.png
    :width: 1500 px
 
 
 Interactive Graph Visualization
 ===============================
 
 The new :mod:`d3viz` module complements :func:`aesara.printing.pydotprint` to
 visualize complex graph structures. Instead of creating a static image, it
 generates an HTML file, which allows to dynamically inspect graph structures in
 a web browser. Features include zooming, drag-and-drop, editing node labels, or
 coloring nodes by their compute time.
 
 => :mod:`d3viz` <=
 
-.. image:: ./pics/d3viz.png
+.. image:: ./d3viz.png
    :width: 350 px
```

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/profiling.rst` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/profiling.rst`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/profiling_example_out.prof` & `aesara_nightly-2.9.0.post2/doc/troubleshoot/profiling_example_out.prof`

 * *Files identical despite different names*

### Comparing `aesara-nightly-2.8.9.post118/doc/tutorial/sparse.rst` & `aesara_nightly-2.9.0.post2/doc/reference/tensor/sparse/index.rst`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,9 @@
-.. _tutsparse:
+.. _reference_sparse:
 
-======
 Sparse
 ======
 
 In general, *sparse* matrices provide the same functionality as regular
 matrices. The difference lies in the way the elements of *sparse* matrices are
 represented and stored in memory. Only the non-zero elements of the latter are stored.
 This has some potential advantages: first, this
@@ -48,15 +47,15 @@
 
 >>> import aesara
 >>> import numpy as np
 >>> import scipy.sparse as sp
 >>> from aesara import sparse
 
 Compressed Sparse Format
-========================
+------------------------
 
 .. Changes to this section should also result in changes to library/sparse/index.txt.
 
 Aesara supports two *compressed sparse formats*: ``csc`` and ``csr``, respectively based on columns
 and rows. They have both the same attributes: ``data``, ``indices``, ``indptr`` and ``shape``.
 
   * The ``data`` attribute is a one-dimensional ``ndarray`` which contains all the non-zero
@@ -66,15 +65,15 @@
     sparse matrix.
 
   * The ``shape`` attribute is exactly the same as the ``shape`` attribute of a dense (i.e. generic)
     matrix. It can be explicitly specified at the creation of a sparse matrix if it cannot be inferred
     from the first three attributes.
 
 Which format should I use?
---------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 At the end, the format does not affect the length of the ``data`` and ``indices`` attributes. They are both
 completely fixed by the number of elements you want to store. The only thing that changes with the format
 is ``indptr``. In ``csc`` format, the matrix is compressed along columns so a lower number of columns will
 result in less memory use. On the other hand, with the ``csr`` format, the matrix is compressed along
 the rows and with a matrix that have a lower number of rows, ``csr`` format is a better choice. So here is the rule:
 
@@ -89,15 +88,15 @@
 
     Use the format compatible with the ops in your computation graph.
 
 The documentation about the ops and their supported format may be found in
 the :ref:`Sparse Library Reference <libdoc_sparse>`.
 
 Handling Sparse in Aesara
-=========================
+-------------------------
 
 Most of the ops in Aesara depend on the ``format`` of the sparse matrix.
 That is why there are two kinds of constructors of sparse variables:
 ``csc_matrix`` and ``csr_matrix``. These can be called with the usual
 ``name`` and ``dtype`` parameters, but no ``broadcastable`` flags are
 allowed. This is forbidden since the sparse package, as the SciPy sparse module,
 does not provide any way to handle a number of dimensions different from two.
@@ -105,27 +104,27 @@
 ``sparse.all_dtypes``.
 
 >>> sparse.all_dtypes  # doctest: +SKIP
 set(['int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64',
      'float32', 'float64', 'complex64', 'complex128'])
 
 To and Fro
-----------
+~~~~~~~~~~
 
 To move back and forth from a dense matrix to a sparse matrix representation, Aesara
 provides the ``dense_from_sparse``, ``csr_from_dense`` and
 ``csc_from_dense`` functions. No additional detail must be provided. Here is
 an example that performs a full cycle from sparse to sparse:
 
 >>> x = sparse.csc_matrix(name='x', dtype='float32')
 >>> y = sparse.dense_from_sparse(x)
 >>> z = sparse.csc_from_dense(y)
 
 Properties and Construction
----------------------------
+~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 Although sparse variables do not allow direct access to their properties,
 this can be accomplished using the ``csm_properties`` function. This will return
 a tuple of one-dimensional ``tensor`` variables that represents the internal characteristics
 of the sparse matrix.
 
 In order to reconstruct a sparse matrix from some properties, the functions ``CSC``
@@ -149,15 +148,15 @@
 
 The last example shows that one format can be obtained from transposition of
 the other. Indeed, when calling the ``transpose`` function,
 the sparse characteristics of the resulting matrix cannot be the same as the one
 provided as input.
 
 Structured Operation
---------------------
+~~~~~~~~~~~~~~~~~~~~
 
 Several ops are set to make use of the very peculiar structure of the sparse
 matrices. These ops are said to be *structured* and simply do not perform any
 computations on the zero elements of the sparse matrix. They can be thought as being
 applied only to the data attribute of the latter. Note that these structured ops
 provide a structured gradient. More explication below.
 
@@ -173,17 +172,24 @@
 [[ 0.  0.  1.]
  [ 0.  0.  3.]
  [ 5.  0.  0.]]
 
 .. _tutsparse_gradient:
 
 Gradient
---------
+~~~~~~~~
 
 The gradients of the ops in the sparse module can also be structured. Some ops provide
 a *flag* to indicate if the gradient is to be structured or not. The documentation can
 be used to determine if the gradient of an op is regular or structured or if its
 implementation can be modified. Similarly to structured ops, when a structured gradient is calculated, the
 computation is done only for the non-zero elements of the sparse matrix.
 
 More documentation regarding the gradients of specific ops can be found in the
 :ref:`Sparse Library Reference <libdoc_sparse>`.
+
+
+.. toctree::
+    :maxdepth: 1
+
+    sparse_api
+    sandbox
```

### Comparing `aesara-nightly-2.8.9.post118/pyproject.toml` & `aesara_nightly-2.9.0.post2/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,29 +1,31 @@
 
 [build-system]
-  build-backend = "setuptools.build_meta"
-  requires = ["setuptools>=61.2", "setuptools_scm[toml]>=6.2"]
+  build-backend = "hatchling.build"
+  requires = ["hatchling >=1.11.1,<2.0.0", "hatch-vcs >=0.3.0,<0.4.0"]
 
 [project]
-  classifiers = ["Development Status :: 6 - Mature", "Intended Audience :: Education", "Intended Audience :: Science/Research", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Topic :: Software Development :: Code Generators", "Topic :: Software Development :: Compilers", "Topic :: Scientific/Engineering :: Mathematics", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: Unix", "Operating System :: MacOS", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.7", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3.9"]
+  classifiers = ["Development Status :: 6 - Mature", "Intended Audience :: Education", "Intended Audience :: Science/Research", "Intended Audience :: Developers", "License :: OSI Approved :: BSD License", "Programming Language :: Python", "Topic :: Software Development :: Code Generators", "Topic :: Software Development :: Compilers", "Topic :: Scientific/Engineering :: Mathematics", "Operating System :: Microsoft :: Windows", "Operating System :: POSIX", "Operating System :: POSIX :: Linux", "Operating System :: POSIX :: SunOS/Solaris", "Operating System :: Unix", "Operating System :: MacOS", "Operating System :: MacOS :: MacOS X", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.8", "Programming Language :: Python :: 3.9", "Programming Language :: Python :: 3.10", "Programming Language :: Python :: 3.11"]
   dependencies = ["numpy >=1.17.0", "scipy >=0.14", "filelock", "etuples", "logical-unification", "miniKanren", "cons", "typing_extensions", "setuptools >=48.0.0"]
   description = "A library for defining, optimizing, and efficiently evaluating mathematical expressions involving multi-dimensional arrays."
   dynamic = ["version"]
   keywords = ["aesara", "math", "numerical", "symbolic", "blas", "numpy", "autodiff", "differentiation"]
   name = "aesara-nightly"
-  requires-python = ">=3.7"
+  requires-python = ">=3.8"
 
   [[project.authors]]
     email = "aesara.devs@gmail.com"
     name = "aesara-devs"
 
   [project.license]
-    files = ["LICENSE.txt"]
     text = "BSD-3-Clause"
 
+  [project.license-files]
+    paths = ["LICENSE.txt"]
+
   [project.readme]
     content-type = "text/x-rst"
     file = "DESCRIPTION.txt"
 
   [project.scripts]
     aesara-cache = "aesara.bin.aesara_cache:main"
 
@@ -40,14 +42,37 @@
       show_missing = true
 
     [tool.coverage.run]
       branch = true
       omit = ["tests/*", "aesara/assert_op.py", "aesara/version.py", "aesara/bin/aesara_cache.py", "aesara/graph/opt.py", "aesara/graph/opt_utils.py", "aesara/graph/optdb.py", "aesara/graph/kanren.py", "aesara/graph/unify.py", "aesara/link/jax/jax_linker.py", "aesara/link/jax/jax_dispatch.py", "aesara/graph/toolbox.py", "aesara/scalar/basic_scipy.py", "bin/aesara_cache.py"]
       relative_files = true
 
+  [tool.hatch]
+
+    [tool.hatch.build]
+      exclude = ["/.github", "/.flake8", "/.gitignore", "/.hgignore", "/.pre-commit-config.yaml", "/.github/CODE_OF_CONDUCT.md", "/.github/CONTRIBUTING.md", "Makefile", "codecov.yml", "environment-arm.yml", "environment.yml", "readthedocs.yml"]
+
+      [tool.hatch.build.hooks]
+
+        [tool.hatch.build.hooks.vcs]
+          version-file = "aesara/_version.py"
+
+      [tool.hatch.build.targets]
+
+        [tool.hatch.build.targets.wheel]
+          packages = ["aesara", "bin"]
+
+    [tool.hatch.version]
+      source = "vcs"
+      tag-pattern = "^rel-(?P<version>[vV]?\\d+(?:\\.\\d+){0,2}[^\\+]*)(?:\\+.*)?$"
+
+      [tool.hatch.version.raw-options]
+        local_scheme = "no-local-version"
+        version_scheme = "post-release"
+
   [tool.isort]
     honor_noqa = true
     lines_after_imports = 2
     lines_between_sections = 1
     profile = "black"
     skip = ["aesara/version.py"]
     skip_gitignore = true
@@ -303,29 +328,7 @@
     disable = "C0330, C0326"
 
   [tool.pytest]
 
     [tool.pytest.ini_options]
       addopts = "--durations=50"
       testpaths = ["tests/"]
-
-  [tool.setuptools]
-    include-package-data = false
-    platforms = ["Windows", "Linux", "Solaris", "Mac OS-X", "Unix"]
-
-    [tool.setuptools.package-data]
-      "*" = ["*.txt", "*.rst", "*.cu", "*.cuh", "*.c", "*.sh", "*.pkl", "*.h", "*.cpp", "*.pyx", "ChangeLog", "c_code/*"]
-      aesara = ["py.typed"]
-      "aesara.d3viz" = ["html/*", "css/*", "js/*"]
-      "aesara.misc" = ["*.sh"]
-
-    [tool.setuptools.packages]
-
-      [tool.setuptools.packages.find]
-        exclude = ["tests", "tests.*"]
-        namespaces = false
-
-  [tool.setuptools_scm]
-    local_scheme = "no-local-version"
-    tag_regex = "^rel-(?P<version>[vV]?\\d+(?:\\.\\d+){0,2}[^\\+]*)(?:\\+.*)?$"
-    version_scheme = "post-release"
-    write_to = "aesara/_version.py"
```

